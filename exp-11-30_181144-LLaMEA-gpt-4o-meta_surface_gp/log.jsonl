{"id": "d20daf78-7bfa-4aca-a46e-88fdf20a119d", "fitness": 0.5385333333333334, "name": "DynamicPSO", "description": "A novel Particle Swarm Optimization (PSO) variant using dynamic inertia weight and local search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 0, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001]}}
{"id": "4fae1bac-7e9a-4be1-a267-f219c48e54a5", "fitness": 0.5379166666666666, "name": "DynamicPSO", "description": "Enhanced convergence by altering the frequency of local search adjustments to improve global best updates.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 8 == 0:  # Change: Alter the frequency of local search from 10 to 8\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 1, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736]}}
{"id": "1a11b750-ffcc-4fe2-bb56-139ad01ae4c5", "fitness": 0.4637333333333334, "name": "DynamicPSO", "description": "An enhanced PSO with adaptive cognitive and social parameters, improving convergence balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Adjusting cognitive and social coefficients\n                self.c1 = 2.5 - 0.5 * (self.func_evals / self.budget)\n                self.c2 = 1.5 + 0.5 * (self.func_evals / self.budget)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 2, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004]}}
{"id": "d2da6565-d7e7-4772-ae9c-dc9f1f60f71f", "fitness": 0.5243666666666668, "name": "DynamicPSO", "description": "Introduce a velocity clamping mechanism to limit particle speeds, enhancing convergence stability in PSO.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n        self.velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # New line\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)  # New line\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775]}}
{"id": "6c1c2634-ad7e-4c87-aea3-76f953605c96", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Enhanced DynamicPSO by introducing adaptive mutation to increase diversity and avoid local optima.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n            \n            # Apply mutation for diversity\n            if t % 5 == 0:\n                mutation = np.random.normal(0, 0.01, self.dim)\n                self.positions += mutation\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 4, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "f2535c1f-f76b-4cae-ba95-55ed2ebfee59", "fitness": 0.70887, "name": "DynamicPSO", "description": "An enhanced Particle Swarm Optimization (PSO) variant incorporating adaptive velocity scaling to improve convergence speed and solution precision.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.6839999999999999, 0.7314, 0.71595, 0.6839999999999999, 0.7314, 0.71595, 0.6839999999999999, 0.7314, 0.71595, 0.6839999999999999, 0.7314, 0.71595, 0.6603, 0.7314, 0.71595]}}
{"id": "dde1f3e8-3634-4896-9f51-2007ed576f6d", "fitness": 0.6549499999999999, "name": "DynamicPSO", "description": "Enhanced the DynamicPSO by increasing adaptive velocity scaling factor to improve convergence precision.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.95  # Adaptive velocity scaling increased slightly\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 6, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.62975, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725]}}
{"id": "eb58c138-7b1c-4eda-ae64-85fc3c2e1e76", "fitness": 0.7016833333333333, "name": "DynamicPSO", "description": "Introduce a dynamic number of particles based on the dimensionality to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(30, 5 + self.dim)  # Dynamic number of particles based on dimensionality\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 7, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [0.7106, 0.6549, 0.6953, 0.7106, 0.6549, 0.76905, 0.7106, 0.6549, 0.76905, 0.7106, 0.6549, 0.76905, 0.7106, 0.6549, 0.6953]}}
{"id": "0217a5f0-1171-4356-bf4f-1b171ed331be", "fitness": 0.6827715346185413, "name": "DynamicPSO", "description": "Enhanced Particle Swarm Optimization (PSO) with adaptive velocity scaling and periodic local search to improve solution precision.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.95  # Adaptive velocity scaling\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 8, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.09 on similar problems with similar landscape features.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [1.0, 0.7002032671489776, 0.6905197521291431, 0.6186499999999999, 0.68225, 0.62975, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725]}}
{"id": "1484665f-280d-46e3-9d4a-3b48868fbb47", "fitness": 0.9793552688146114, "name": "DynamicPSO", "description": "Introduced velocity clamping to prevent overly large velocity values, aiding in more controlled particle exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 9, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [0.9907941377704881, 0.9905458654629009, 0.9567258032104453]}}
{"id": "4683c188-e036-48b9-bb46-64dfe693d3a1", "fitness": 0.6973333333333334, "name": "DynamicPSO", "description": "Incorporated a dynamic adjustment of the cognitive parameter based on the iteration count to enhance exploration in early stages and exploitation in later stages.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c1 = 2.0 - 1.5 * (t / eval_budget)  # Dynamic cognitive parameter adjustment\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 10, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001]}}
{"id": "c6ab171d-74a1-4ff6-bb10-1201fee34ea5", "fitness": 0.66315, "name": "DynamicPSO", "description": "Enhanced global best update by incorporating simulated annealing for better exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best with simulated annealing\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                temperature = 1 / (t + 1)  # Simulated annealing schedule\n                if candidate_value < self.global_best_value or np.exp((self.global_best_value - candidate_value) / temperature) > np.random.rand():\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 11, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615]}}
{"id": "a5ba3783-4bff-4807-9116-cbb31a92f522", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced the local search by increasing the perturbation frequency to every 5 iterations to explore the solution space more effectively.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Changed from 10 to 5\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 12, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
