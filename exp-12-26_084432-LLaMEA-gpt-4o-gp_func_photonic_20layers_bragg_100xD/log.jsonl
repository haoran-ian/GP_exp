{"id": "23bb7d56-e933-4dcb-be19-9585bd9b16b4", "fitness": 0.09400765379236094, "name": "HybridPSODE", "description": "A hybrid swarm-based algorithm that combines Particle Swarm Optimization (PSO) with Differential Evolution (DE) for enhanced exploration and exploitation in the search space.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Differential Evolution scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11391999267275721, 0.11391999267275721, 0.11391999267275721, 0.07348216156850529, 0.07348216156850529, 0.07348216156850529, 0.09462080713582033, 0.09462080713582033, 0.09462080713582033]}}
{"id": "edc5e0dd-e388-414f-924d-fe15f37e9013", "fitness": 0.09400816039559723, "name": "HybridPSODE", "description": "A hybrid swarm-based algorithm that enhances particle position updating by modifying the inertia weight for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.8  # Modified inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Differential Evolution scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["23bb7d56-e933-4dcb-be19-9585bd9b16b4"], "operator": null, "metadata": {"aucs": [0.11392076483363323, 0.11392076483363323, 0.11392076483363323, 0.07348243706300661, 0.07348243706300661, 0.07348243706300661, 0.09462127929015185, 0.09462127929015185, 0.09462127929015185]}}
{"id": "e6e08f6a-2c7d-43df-917b-cd5db597b892", "fitness": 0.09400844465233187, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm integrating adaptive inertia weight and dynamically adjusted DE parameters for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["edc5e0dd-e388-414f-924d-fe15f37e9013"], "operator": null, "metadata": {"aucs": [0.11392119807884271, 0.11392119807884271, 0.11392119807884271, 0.07348259165416815, 0.07348259165416815, 0.07348259165416815, 0.09462154422398472, 0.09462154422398472, 0.09462154422398472]}}
{"id": "8e1750cd-473d-4bd4-9134-0733d2b9c6f0", "fitness": 0.09400775073187029, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm integrating adaptive inertia weight and dynamically adjusted DE parameters for enhanced convergence and exploration-exploitation balance, with slightly increased cognitive component for improved individual learning.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.6  # Slightly increased cognitive component\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392014042283338, 0.11392014042283338, 0.11392014042283338, 0.07348221428758528, 0.07348221428758528, 0.07348221428758528, 0.0946208974851922, 0.0946208974851922, 0.0946208974851922]}}
{"id": "b1b4efcf-605c-4278-b7e1-5a3b9a288434", "fitness": 0.09400588538510457, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with enhanced adaptive inertia weight range for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.5  # Minimum inertia weight (changed from 0.4 to 0.5)\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391729735478728, 0.11391729735478728, 0.11391729735478728, 0.0734811998498085, 0.0734811998498085, 0.0734811998498085, 0.09461915895071793, 0.09461915895071793, 0.09461915895071793]}}
{"id": "34b2021f-7ffc-4196-bcb8-1dca28c4b3c6", "fitness": 0.0940041982592719, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm integrating adaptive inertia weight and dynamically adjusted DE parameters with an enhanced mutation strategy for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) * (np.random.rand() + 0.5), lower_bound, upper_bound)  # Enhanced mutation\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391472595443064, 0.11391472595443064, 0.11391472595443064, 0.07348028231478188, 0.07348028231478188, 0.07348028231478188, 0.09461758650860319, 0.09461758650860319, 0.09461758650860319]}}
{"id": "1881ccdf-6046-4be2-af03-6940adb6d8b7", "fitness": 0.09400472092653796, "name": "EnhancedHybridPSODE", "description": "Refined Hybrid PSO-DE with modified inertia weight schedule for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight (modified equation)\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * np.exp(-5 * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391552254919612, 0.11391552254919612, 0.11391552254919612, 0.07348056657609048, 0.07348056657609048, 0.07348056657609048, 0.09461807365432728, 0.09461807365432728, 0.09461807365432728]}}
{"id": "15ce16d0-c9ba-49a1-a7d4-a92e9a93ce0f", "fitness": 0.09400380267108992, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with a refined adaptive inertia weight for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.85 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391412299370107, 0.11391412299370107, 0.11391412299370107, 0.0734800671960445, 0.0734800671960445, 0.0734800671960445, 0.09461721782352417, 0.09461721782352417, 0.09461721782352417]}}
{"id": "91a9e09d-513f-4d75-acc3-241260f75661", "fitness": 0.09400816379729597, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with adaptive inertia weight, dynamically adjusted DE parameters, and dynamic crossover probability for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392077001138268, 0.11392077001138268, 0.11392077001138268, 0.0734824389172184, 0.0734824389172184, 0.0734824389172184, 0.09462128246328683, 0.09462128246328683, 0.09462128246328683]}}
{"id": "df791b94-5949-4b30-95d0-4a78b9108312", "fitness": 0.09400629057099912, "name": "AdvancedAdaptivePSODE", "description": "A novel adaptive hybrid PSO-DE algorithm enhancing convergence by introducing a fitness-based dynamic learning rate and rebalancing exploration-exploitation via adaptive DE parameters and adaptive mutation strategy.", "code": "import numpy as np\n\nclass AdvancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f_initial = 0.5\n        self.cr_initial = 0.9\n        self.learning_rate = 0.1  # Additional adaptive learning rate\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            fitness_variance = np.var(personal_best_scores)\n            adaptive_rate = 1 / (1 + np.exp(-fitness_variance))\n            \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * adaptive_rate * r1 * (personal_best_positions - positions) +\n                          self.social_component * adaptive_rate * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = self.f_initial + adaptive_rate * 0.3 * (evaluations / self.budget)\n            self.cr = self.cr_initial - adaptive_rate * 0.1 * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm AdvancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392000737163688, 0.11392000737163688, 0.11392000737163688, 0.0734807624455368, 0.0734807624455368, 0.0734807624455368, 0.09461810189582365, 0.09461810189582365, 0.09461810189582365]}}
{"id": "50f62098-2ee1-426d-b8b6-8bec3f94a0b7", "fitness": 0.09400632226322585, "name": "RefinedEnhancedHybridPSODE", "description": "Integration of adaptive parameter control and cooperative search mechanisms to enhance exploration-exploitation balance and convergence speed in a hybrid PSO-DE framework.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f_min = 0.4\n        self.f_max = 0.9\n        self.cr = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = self.f_min + (self.f_max - self.f_min) * (evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm RefinedEnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391796327137971, 0.11391796327137971, 0.11391796327137971, 0.07348143740886515, 0.07348143740886515, 0.07348143740886515, 0.09461956610943267, 0.09461956610943267, 0.09461956610943267]}}
{"id": "7fb364c6-47b1-4320-bb93-40e1b83f5658", "fitness": 0.09400844465233187, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with adaptive inertia weight, dynamically adjusted DE parameters, and improved initial global best estimation for enhanced convergence and exploration-exploitation balance. ", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392119807884271, 0.11392119807884271, 0.11392119807884271, 0.07348259165416815, 0.07348259165416815, 0.07348259165416815, 0.09462154422398472, 0.09462154422398472, 0.09462154422398472]}}
{"id": "3e099a9d-b6f5-4f77-b9db-de36811614de", "fitness": 0.09400816379729597, "name": "EnhancedHybridPSODE", "description": "Improved exploration-exploitation balance through adaptive crossover probability adjustment in the DE mutation process.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive crossover rate\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392077001138268, 0.11392077001138268, 0.11392077001138268, 0.0734824389172184, 0.0734824389172184, 0.0734824389172184, 0.09462128246328683, 0.09462128246328683, 0.09462128246328683]}}
{"id": "acb75e69-8106-4803-a1cb-c6657ed90afc", "fitness": 0.09400475612975234, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with an adaptive crossover probability that decreases over iterations for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 * (1 - evaluations / self.budget)  # Update crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391557618698467, 0.11391557618698467, 0.11391557618698467, 0.07348058573121141, 0.07348058573121141, 0.07348058573121141, 0.09461810647106095, 0.09461810647106095, 0.09461810647106095]}}
{"id": "1e2ecc41-b7de-42ea-a3a5-e06f300e3840", "fitness": 0.09400784697700008, "name": "EnhancedHybridPSODE", "description": "Enhancing global exploration by dynamically adjusting DE's crossover probability (cr) based on evaluations.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392028711809787, 0.11392028711809787, 0.11392028711809787, 0.07348226662694524, 0.07348226662694524, 0.07348226662694524, 0.09462098718595713, 0.09462098718595713, 0.09462098718595713]}}
{"id": "b1f5715a-7a38-4866-b7a3-3b45b890dd3d", "fitness": 0.09400652403838956, "name": "EnhancedHybridPSODE", "description": "A refined hybrid swarm algorithm with a modified cognitive component for enhanced local exploration in high-dimensional spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.7  # Adjusted for better local exploration\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391827072906013, 0.11391827072906013, 0.11391827072906013, 0.07348154718847, 0.07348154718847, 0.07348154718847, 0.09461975419763857, 0.09461975419763857, 0.09461975419763857]}}
{"id": "243f1214-601a-4418-992b-5d0c1cfd83fd", "fitness": 0.09400775073187029, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm that integrates adaptive inertia weight and dynamically adjusted DE parameters with a slightly enhanced cognitive component for improved swarm intelligence and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.6  # Slightly increased cognitive component\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392014042283338, 0.11392014042283338, 0.11392014042283338, 0.07348221428758528, 0.07348221428758528, 0.07348221428758528, 0.0946208974851922, 0.0946208974851922, 0.0946208974851922]}}
{"id": "79b77ae8-4733-49e3-b3b1-f2e69b2e7304", "fitness": 0.09400816379729597, "name": "EnhancedHybridPSODE", "description": "Introduced an adaptive crossover probability in the DE phase based on evaluations to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392077001138268, 0.11392077001138268, 0.11392077001138268, 0.0734824389172184, 0.0734824389172184, 0.0734824389172184, 0.09462128246328683, 0.09462128246328683, 0.09462128246328683]}}
{"id": "bc3ceee2-e89d-42cd-8a5f-08cc41bffe1c", "fitness": 0.09400726448371104, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive cognitive component for improved personal best updates.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive_component = 1.5 + 0.5 * (evaluations / self.budget)  # Adaptive cognitive component\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.1139193992880887, 0.1139193992880887, 0.1139193992880887, 0.07348194986162593, 0.07348194986162593, 0.07348194986162593, 0.09462044430141847, 0.09462044430141847, 0.09462044430141847]}}
{"id": "602241d4-ea2c-448c-9670-a382fcbe7b23", "fitness": 0.09400844465233187, "name": "ImprovedHybridSwarm", "description": "An improved hybrid swarm algorithm using adaptive learning rates and dynamic population size for better exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass ImprovedHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_population_size = self.population_size\n        self.inertia_weight_max = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (self.inertia_weight_max - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Dynamic population size adjustment\n            self.population_size = int(self.initial_population_size * (1 + 0.5 * (evaluations / self.budget)))\n            self.population_size = min(self.population_size, len(scores))  # Ensure it doesn't exceed evaluated count\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm ImprovedHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392119807884271, 0.11392119807884271, 0.11392119807884271, 0.07348259165416815, 0.07348259165416815, 0.07348259165416815, 0.09462154422398472, 0.09462154422398472, 0.09462154422398472]}}
{"id": "ab6449b1-a88c-4894-b91e-0b638513ad02", "fitness": 0.0940043927591353, "name": "EnhancedHybridPSODE", "description": "A hybrid algorithm with refined DE scaling factor for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.2 * (evaluations / self.budget)  # Adjusted DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391502238701379, 0.11391502238701379, 0.11391502238701379, 0.0734803880990752, 0.0734803880990752, 0.0734803880990752, 0.09461776779131692, 0.09461776779131692, 0.09461776779131692]}}
{"id": "920fb7c4-0475-44ec-a0a3-7868b50fb40a", "fitness": 0.09400670645838909, "name": "EnhancedHybridPSODE", "description": "Improved hybrid swarm-type algorithm with adaptive DE mutation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)  # Dynamic DE scaling factor (improved)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391854878069985, 0.11391854878069985, 0.11391854878069985, 0.07348164638468402, 0.07348164638468402, 0.07348164638468402, 0.09461992420978338, 0.09461992420978338, 0.09461992420978338]}}
{"id": "8d181f5d-f069-4613-b922-c382082db3c9", "fitness": 0.09400906847625667, "name": "AdaptiveMultiSwarmPSODE", "description": "An adaptive hybrid algorithm combining multi-swarm PSO with dynamically tuned DE parameters and local search to enhance convergence and exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392219306817308, 0.11392219306817308, 0.11392219306817308, 0.07348294392361077, 0.07348294392361077, 0.07348294392361077, 0.09462206843698617, 0.09462206843698617, 0.09462206843698617]}}
{"id": "cc86ed59-b020-4dab-bfe3-b5b040a0ca25", "fitness": 0.09400887796369313, "name": "AdaptiveMultiSwarmPSODE", "description": "Introduced control of DE's crossover rates based on particle diversity and adaptive inertia weight adjustment for enhanced exploration-exploitation trade-off.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with diversity\n            diversity = np.mean(np.std(positions, axis=0))\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget) * diversity\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                diversity_factor = np.mean(np.std(positions, axis=0))\n                self.cr = 0.5 + 0.4 * diversity_factor\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392189285603138, 0.11392189285603138, 0.11392189285603138, 0.07348278320952528, 0.07348278320952528, 0.07348278320952528, 0.09462195782552274, 0.09462195782552274, 0.09462195782552274]}}
{"id": "342732ce-26cd-4b82-ba3f-4b6423994176", "fitness": 0.09400788876437043, "name": "AdaptiveMultiSwarmPSODE", "description": "Enhanced adaptive hybrid algorithm by introducing a non-linear inertia weight decay, improving convergence and exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight - changed to non-linear decay\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - (evaluations / self.budget)**2)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392000166158556, 0.11392000166158556, 0.11392000166158556, 0.0734821822101176, 0.0734821822101176, 0.0734821822101176, 0.09462148242140811, 0.09462148242140811, 0.09462148242140811]}}
{"id": "d5f952e0-5ced-48ba-b1e6-b2aec758d565", "fitness": 0.09400823553623205, "name": "AdaptiveMultiSwarmPSODE", "description": "Enhanced exploration and exploitation balance by introducing adaptive cognitive and social components along with self-adaptive DE parameters.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Adaptive cognitive and social components\n            adaptive_cognitive = self.cognitive_component * (1 - evaluations / self.budget)\n            adaptive_social = self.social_component * evaluations / self.budget\n            \n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             adaptive_cognitive * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             adaptive_social * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392008572347079, 0.11392008572347079, 0.11392008572347079, 0.0734827879415828, 0.0734827879415828, 0.0734827879415828, 0.09462183294364257, 0.09462183294364257, 0.09462183294364257]}}
