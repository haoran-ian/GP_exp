{"id": "c26ac09a-a405-4034-9513-22db7b046709", "fitness": 0.3811683526351499, "name": "AdaptiveHybridOptimizer", "description": "An adaptive hybrid metaheuristic combining particle swarm optimization and simulated annealing for efficient black-box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n        \n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38117 with standard deviation 0.38452.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13225940462978358, 0.9243294936025064, 0.0869161596731598]}}
{"id": "c4e01432-a8f4-4a5c-aa44-b27d89a5c107", "fitness": 0.4881071053551222, "name": "EnhancedAdaptiveHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer leveraging dynamic parameter adaptation and a diversity preservation mechanism to improve black-box optimization performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48811 with standard deviation 0.32570.", "error": "", "parent_ids": ["c26ac09a-a405-4034-9513-22db7b046709"], "operator": null, "metadata": {"aucs": [0.48159827011630385, 0.8902246204249304, 0.09249842552413212]}}
{"id": "7edf5284-8b28-4d7e-a983-83c1399e6c56", "fitness": 0.10631593228969034, "name": "RefinedAdaptiveHybridOptimizer", "description": "A refined adaptive hybrid optimizer with dynamic neighborhood adaptation and a quantum-inspired diversity mechanism for enhanced black-box optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.neighborhood_radius = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Quantum-inspired diversity mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                perturbation_radius = np.random.uniform(0, self.neighborhood_radius, self.dim)\n                quantum_particles = global_best + perturbation_radius * (np.random.rand(self.dim) - 0.5)\n                quantum_particles = np.clip(quantum_particles, lb, ub)\n                quantum_value = func(quantum_particles)\n                eval_count += 1\n                \n                if quantum_value < best_value:\n                    global_best = quantum_particles\n                    best_value = quantum_value\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm RefinedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10632 with standard deviation 0.02543.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.1356398446806295, 0.10967986661497953, 0.07362808557346201]}}
{"id": "caf7f9b0-d8c9-4f1e-9a6f-f3c609441c9f", "fitness": 0.4385128709528961, "name": "EnhancedAdaptiveHybridOptimizer", "description": "Introduced a linear decrease in cognitive and social coefficients over time to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n\n            # Linear decrease of coefficients\n            t = eval_count / self.budget\n            self.cognitive_coeff = 1.5 * (1 - t)\n            self.social_coeff = 2.0 * (1 - t)\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43851 with standard deviation 0.28653.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.4630629802901455, 0.7765161850486729, 0.07595944751986983]}}
{"id": "0b48a2b7-dd86-40f4-a2f2-0dd7194601be", "fitness": 0.4151516349199415, "name": "SynergyBasedOptimizer", "description": "A synergy-based optimizer that harmonizes evolutionary strategies and adaptive annealing with a focus on maintaining diversity and improving convergence.", "code": "import numpy as np\n\nclass SynergyBasedOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.9  # Slightly slower cooling rate for more gradual adaptation\n        self.diversity_threshold = 0.1\n        self.mutation_rate = 0.05  # Introduce mutation\n        self.elitism_rate = 0.1  # Preserve top solutions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Mutation operation\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    particles[i] = np.clip(particles[i] + mutation_vector, lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n\n            # Adaptive annealing\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n\n            self.temperature *= self.cooling_rate\n\n            # Diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n\n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n\n            # Elitism - retain best solutions\n            elite_count = int(self.elitism_rate * self.num_particles)\n            elite_indices = np.argsort(personal_best_values)[:elite_count]\n            elite_particles = personal_best[elite_indices]\n            elite_velocities = velocities[elite_indices]\n\n            # Replace worst performing particles with elite\n            worst_indices = np.argsort(personal_best_values)[-elite_count:]\n            particles[worst_indices] = elite_particles\n            velocities[worst_indices] = elite_velocities\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm SynergyBasedOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41515 with standard deviation 0.38526.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.17517787067409452, 0.11152270833826217, 0.9587543257474679]}}
{"id": "9f467b0c-e779-4c3b-96f8-624a98ad7db9", "fitness": 0.7143030039248415, "name": "EnhancedAdaptiveHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer with improved exploration via adaptive velocity scaling and increased diversity through probabilistic particle reset.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Improved diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71430 with standard deviation 0.22636.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.8048793974223831, 0.4031147481609765, 0.9349148661911648]}}
{"id": "70ef8831-c972-4cd5-b7c3-2622ab4758eb", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridOptimizerV2", "description": "Introducing a dynamic multi-faceted velocity update mechanism and adaptive population sizing to enhance exploration and exploitation balance in particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = self.initial_particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = num_particles\n        \n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                # Introduce velocity clamping for more stable convergence\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Improved diversity and population size adjustment\n            if np.std(personal_best_values) < self.diversity_threshold:\n                additional_particles = np.random.uniform(lb, ub, (num_particles // 5, self.dim))\n                additional_values = np.array([func(x) for x in additional_particles])\n                eval_count += len(additional_particles)\n                \n                for j, val in enumerate(additional_values):\n                    if val < best_value or np.random.rand() < 0.1:\n                        global_best = additional_particles[j]\n                        best_value = val\n                        break\n                # Increase population size adaptively to escape stagnation\n                num_particles = min(num_particles + num_particles // 10, self.budget - eval_count)\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["9f467b0c-e779-4c3b-96f8-624a98ad7db9"], "operator": null, "metadata": {}}
{"id": "ab80fdd8-96d0-44e0-98d4-fa9b419496bf", "fitness": 0.6147198617272477, "name": "ImprovedHybridOptimizer", "description": "A hybrid optimizer with enhanced local search through quadratic interpolation and improved convergence using adaptive population resizing.", "code": "import numpy as np\n\nclass ImprovedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_num_particles = 50\n        self.max_num_particles = 100\n        self.min_num_particles = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = self.init_num_particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = num_particles\n        \n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Improved diversity preservation and population adjustment mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n                        break\n\n                # Adaptive population resizing\n                num_particles = min(self.max_num_particles, max(self.min_num_particles, num_particles + 5))\n                particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n                velocities = np.zeros((num_particles, self.dim))\n                personal_best = particles.copy()\n                personal_best_values = np.array([func(x) for x in personal_best])\n                eval_count += num_particles - len(personal_best_values)\n        \n        return global_best", "configspace": "", "generation": 7, "feedback": "The algorithm ImprovedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61472 with standard deviation 0.19415.", "error": "", "parent_ids": ["9f467b0c-e779-4c3b-96f8-624a98ad7db9"], "operator": null, "metadata": {"aucs": [0.4038563138260478, 0.8724383831822466, 0.5678648881734487]}}
{"id": "49032317-2983-4a6c-9a8b-242ea1db2f21", "fitness": 0.9122986376703599, "name": "AdvancedParticleOptimizer", "description": "An advanced particle swarm optimizer enhanced with adaptive compression control and elite leader selection to boost convergence and robustness.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91230 with standard deviation 0.01105.", "error": "", "parent_ids": ["9f467b0c-e779-4c3b-96f8-624a98ad7db9"], "operator": null, "metadata": {"aucs": [0.89890730347514, 0.9259770236574656, 0.9120115858784739]}}
{"id": "8c7cba38-713f-4939-9560-380e30529a5a", "fitness": 0.10938737233847666, "name": "QuantumEnhancedParticleOptimizer", "description": "A hybrid optimizer combining Quantum-inspired Particle Swarm with dynamic inertia and enhanced diversity to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass QuantumEnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.warmup = 0.3 * budget\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic inertia weight adjustment\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * (1 - eval_count / self.budget))\n            \n            # Quantum-inspired exploration\n            if eval_count > self.warmup and np.std(personal_best_values) < self.diversity_threshold:\n                Q = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n                quantum_particles = global_best + Q * (particles - global_best)\n                quantum_particles = np.clip(quantum_particles, lb, ub)\n                quantum_values = np.array([func(x) for x in quantum_particles])\n                eval_count += len(quantum_particles)\n\n                for j in range(len(quantum_particles)):\n                    if quantum_values[j] < best_value:\n                        global_best = quantum_particles[j]\n                        best_value = quantum_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm QuantumEnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10939 with standard deviation 0.02824.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.14507556993557724, 0.10705920576646699, 0.07602734131338573]}}
{"id": "007e5016-4889-4874-9135-b89f0bda43a5", "fitness": 0.6903642188737921, "name": "EnhancedParticleSwarmOptimizer", "description": "An enhanced particle swarm optimizer incorporating dynamic neighborhood topology and evolutionary learning for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neighborhood_size = 5  # New parameter for dynamic neighborhood\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Dynamic Neighborhood Selection\n                neighbors = self.get_neighbors(i, self.neighborhood_size)\n                local_best = min(neighbors, key=lambda x: personal_best_values[x])\n\n                r1, r2, r3 = np.random.rand(3)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (personal_best[local_best] - particles[i]))\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n            \n            # Evolutionary Learning Step\n            self.evolutionary_learning(particles, personal_best, lb, ub)\n        \n        return global_best\n    \n    def get_neighbors(self, index, size):\n        # Select neighbors in a cyclic manner\n        return [(index + offset) % self.num_particles for offset in range(-size//2, size//2 + 1) if offset != 0]\n\n    def evolutionary_learning(self, particles, personal_best, lb, ub):\n        # Introduce genetic algorithm inspired crossover\n        for i in range(0, self.num_particles, 2):\n            if i + 1 < self.num_particles:\n                crossover_point = np.random.randint(1, self.dim - 1)\n                parent1, parent2 = personal_best[i], personal_best[i + 1]\n                offspring1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n                offspring2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n                \n                # Mutation\n                if np.random.rand() < self.learning_rate:\n                    mutation_point = np.random.randint(0, self.dim)\n                    offspring1[mutation_point] += np.random.randn()\n                    offspring2[mutation_point] += np.random.randn()\n                \n                particles[i], particles[i + 1] = np.clip(offspring1, lb, ub), np.clip(offspring2, lb, ub)", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69036 with standard deviation 0.20884.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.39648934255916524, 0.8627874994088034, 0.8118158146534077]}}
