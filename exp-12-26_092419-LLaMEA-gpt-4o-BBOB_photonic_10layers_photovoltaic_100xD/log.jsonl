{"id": "e3d7d4bc-43f7-4918-876e-97afd484191d", "fitness": 0.09225550913918816, "name": "HybridDESA", "description": "A novel hybrid metaheuristic combining Differential Evolution and Simulated Annealing for efficient exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass HybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)  # Adjust population size based on budget\n        self.mutation_factor = 0.8  # Differential Evolution mutation factor\n        self.crossover_rate = 0.7  # Differential Evolution crossover rate\n        self.temperature = 1.0  # Initial temperature for Simulated Annealing\n        self.cooling_rate = 0.99  # Cooling rate for Simulated Annealing\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            # Mutation\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + self.mutation_factor * (population[b] - population[c])\n            # Crossover\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < self.crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            # Selection\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if (new_fitness < candidate_fitness or\n            np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature)):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        # Initialize population\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Apply Differential Evolution\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            # Apply Simulated Annealing to best candidate\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1  # Increment for SA evaluation\n            self.temperature *= self.cooling_rate  # Cool down\n\n        return population[np.argmin(fitness)]\n\n# Example usage:\n# optimizer = HybridDESA(budget=1000, dim=10)\n# best_solution = optimizer(func)", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09226 with standard deviation 0.04828.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0352230290272042, 0.03605885412297383, 0.06398638809962642, 0.14371132768332862, 0.16610614381970956, 0.15913020372145004, 0.08594193586186327, 0.07940004781166177, 0.0607416521048757]}}
{"id": "8723b910-7732-4d9e-9cfb-0d5591a682bb", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Introduce adaptive mutation and crossover rates based on population diversity and add a local search phase to enhance convergence in HybridDESA.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c])\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]\n\n# Example usage:\n# optimizer = AdaptiveHybridDESA(budget=1000, dim=10)\n# best_solution = optimizer(func)", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["e3d7d4bc-43f7-4918-876e-97afd484191d"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "77712874-7df3-43a8-b6ab-11a4d11dce8a", "fitness": -Infinity, "name": "AdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA by introducing adaptive population size based on convergence rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = min(50, budget // 10)\n        self.population_size = self.base_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c])\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        prev_best_fitness = np.inf\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            if best_fitness < prev_best_fitness:\n                self.population_size = self.base_population_size * 1.2\n                prev_best_fitness = best_fitness\n            else:\n                self.population_size = self.base_population_size\n\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]\n\n# Example usage:\n# optimizer = AdaptiveHybridDESA(budget=1000, dim=10)\n# best_solution = optimizer(func)", "configspace": "", "generation": 2, "feedback": "An exception occurred: TypeError(\"'float' object cannot be interpreted as an integer\").", "error": "TypeError(\"'float' object cannot be interpreted as an integer\")", "parent_ids": ["8723b910-7732-4d9e-9cfb-0d5591a682bb"], "operator": null, "metadata": {}}
{"id": "b5913d96-3b6b-4a89-85e9-845f729371bc", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA by integrating a self-adjusting strategy for mutation and crossover rates based on historical performance and introducing a dynamic population resizing mechanism for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.success_memory = []\n\n    def adjust_parameters(self):\n        if len(self.success_memory) >= 5:\n            success_rate = np.mean(self.success_memory[-5:])\n            if success_rate > 0.2:\n                self.mutation_factor = min(self.mutation_factor * 1.1, 1.5)\n                self.crossover_rate = min(self.crossover_rate * 1.1, 1.0)\n            else:\n                self.mutation_factor = max(self.mutation_factor * 0.9, 0.4)\n                self.crossover_rate = max(self.crossover_rate * 0.9, 0.1)\n            self.success_memory = []\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        success_count = 0\n        \n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c])\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n                success_count += 1\n        self.success_memory.append(success_count / self.population_size)\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def resize_population(self):\n        if self.success_memory[-1] > 0.2:\n            self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n        else:\n            self.population_size = max(self.population_size - 1, self.initial_population_size // 2)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            if len(self.success_memory) >= 5:\n                self.adjust_parameters()\n                self.resize_population()\n\n                # Reinitialize population for new size\n                if self.population_size != population.shape[0]:\n                    population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                    fitness = np.array([func(ind) for ind in population])\n                    evaluations += self.population_size\n\n        return population[np.argmin(fitness)]\n\n# Example usage:\n# optimizer = EnhancedAdaptiveHybridDESA(budget=1000, dim=10)\n# best_solution = optimizer(func)", "configspace": "", "generation": 3, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["8723b910-7732-4d9e-9cfb-0d5591a682bb"], "operator": null, "metadata": {}}
{"id": "2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e", "fitness": 0.14865439542788014, "name": "AdaptiveHybridDESA", "description": "Integrate a novel adaptive inertia-based velocity update in DE to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14865 with standard deviation 0.12865.", "error": "", "parent_ids": ["8723b910-7732-4d9e-9cfb-0d5591a682bb"], "operator": null, "metadata": {"aucs": [0.4960553344147286, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "b9cba02e-4675-4f18-9b6b-4f63fefd5f55", "fitness": 0.10902710476318815, "name": "AdaptiveHybridDESA", "description": "Improve exploitation using adaptive local search while preserving exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.005  # changed step size for finer search\n        for _ in range(20):  # increased iterations for more thorough search\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 20 <= self.budget:  # adjusted remaining budget check for local search\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 20\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10903 with standard deviation 0.03688.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.07350670853034214, 0.06405752862113812, 0.07114210060713222, 0.14264560134360682, 0.16610614381970956, 0.14841803348150162, 0.12992906785341518, 0.1101954519773154, 0.07524330663453227]}}
{"id": "f7b23463-d956-4b11-ace5-cc56ae0ba3ef", "fitness": 0.09951509712801448, "name": "AdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA by incorporating a restart mechanism and adaptive temperature control for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Adjust cooling rate for better convergence \n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        no_improvement_counter = 0  # Initialize counter\n        best_overall_fitness = float('inf')\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n                no_improvement_counter = 0  # Reset counter if improvement\n            else:\n                no_improvement_counter += 1\n\n            self.temperature *= self.cooling_rate + 0.005  # Adaptive cooling adjustment\n\n            if no_improvement_counter > 5:  # Restart mechanism if stagnation\n                population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                fitness = np.array([func(ind) for ind in population])\n                no_improvement_counter = 0\n                evaluations += self.population_size\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09952 with standard deviation 0.04108.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05897671304283081, 0.04790511426966115, 0.04758278471925581, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.10926942642444104, 0.10896108751936784, 0.07871360261002103]}}
{"id": "76568725-6bba-4506-9089-f3d0bda1fd8b", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Improve AdaptiveHybridDESA by adjusting the adaptive mutation factor's calculation to incorporate a balance parameter for better exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        balance_param = 0.5  # New balance parameter\n        adaptive_mutation_factor = self.mutation_factor * (1 + balance_param * diversity)  # Adjusted calculation\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "c3c1a2cd-0234-4477-9516-f160be93bb6b", "fitness": 0.09999726912449845, "name": "EnhancedAdaptiveDE", "description": "Enhance exploration-exploitation in DE by introducing adaptive mutation and crossover based on fitness diversity with periodic restart strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.restart_interval = 0.2 * budget\n\n    def adaptive_parameters(self, diversity):\n        mutation_factor = self.base_mutation_factor * (1 + diversity)\n        crossover_rate = self.base_crossover_rate * (1 - diversity)\n        return mutation_factor, crossover_rate\n\n    def differential_evolution(self, population, fitness, func, bounds):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        mutation_factor, crossover_rate = self.adaptive_parameters(diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def restart_population(self, bounds):\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.restart_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func, bounds)\n            evaluations += self.population_size\n\n            if evaluations % self.restart_interval < self.population_size:\n                population = self.restart_population(bounds)\n                fitness = np.array([func(ind) for ind in population])\n                evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10000 with standard deviation 0.04082.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.04192188920525164, 0.04320590016212844, 0.07766373229924906, 0.14020469573086392, 0.16610614381970956, 0.14177964607281734, 0.09999275524451312, 0.10195991686334394, 0.08714074272260908]}}
{"id": "bcb5096b-9fb0-4c8e-9e51-1b33cd4b143a", "fitness": 0.10284158686029848, "name": "DynamicAdaptiveDESA", "description": "Introduce dynamic multi-strategy learning in DE with stochastic feedback for adaptive balance of exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicAdaptiveDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.adaptive_strategy = [0.3, 0.3, 0.4]  # Probabilities for DE, SA, Local Search\n\n    def differential_evolution(self, population, fitness, func, inertia_weight):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n\n            strategy_choice = np.random.choice(['DE', 'SA', 'LS'], p=self.adaptive_strategy)\n            if strategy_choice == 'DE':\n                population, fitness = self.differential_evolution(population, fitness, func, inertia_weight)\n                evaluations += self.population_size\n            elif strategy_choice == 'SA':\n                new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n                if new_fitness < best_fitness:\n                    population[best_idx] = new_candidate\n                    fitness[best_idx] = new_fitness\n                evaluations += 1\n            elif strategy_choice == 'LS' and evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            self.update_adaptive_strategy(fitness, best_fitness)\n            self.temperature *= self.cooling_rate\n\n        return population[np.argmin(fitness)]\n\n    def update_adaptive_strategy(self, fitness, best_fitness):\n        improvement = (min(fitness) - best_fitness) / max(abs(min(fitness)), 1e-7)\n        if improvement > 0:\n            self.adaptive_strategy = np.clip(np.array(self.adaptive_strategy) + [improvement, improvement, improvement], 0.1, 0.9)\n        else:\n            self.adaptive_strategy = np.clip(np.array(self.adaptive_strategy) - [improvement, improvement, improvement], 0.1, 0.9)\n        self.adaptive_strategy /= np.sum(self.adaptive_strategy)", "configspace": "", "generation": 9, "feedback": "The algorithm DynamicAdaptiveDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10284 with standard deviation 0.04023.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08567104445311913, 0.049971157611087946, 0.048364579625711945, 0.1433140655017977, 0.16863378683444197, 0.140018901019756, 0.10999921614505725, 0.10941533154024696, 0.0701861990114675]}}
{"id": "33e79bd7-ef28-450d-89c4-84ff51db484b", "fitness": 0.10130850981516143, "name": "ImprovedAdaptiveHybridDESA", "description": "Introduce adaptive mutation and crossover rates based on fitness diversity in a hybrid DE-SA framework to improve exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass ImprovedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor_base = 0.8\n        self.crossover_rate_base = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        fitness_range = max(fitness) - min(fitness) + 1e-7\n        fitness_diversity = np.std(fitness) / fitness_range\n        adaptive_mutation_factor = self.mutation_factor_base * (1 + fitness_diversity)\n        adaptive_crossover_rate = self.crossover_rate_base * (1 - fitness_diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / fitness_range\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(5):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 5 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 5\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 10, "feedback": "The algorithm ImprovedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10131 with standard deviation 0.04190.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.051667773088323155, 0.05756901375135126, 0.05910081555500313, 0.155057697086731, 0.16610614381970956, 0.14578348515609718, 0.1021396182560319, 0.09645444214405563, 0.07789759947914998]}}
{"id": "842e4049-b07e-4ad3-b43f-a3a2211bcd32", "fitness": -Infinity, "name": "ChaosAdaptiveHybridDESA", "description": "Enhance DE-SA hybrid by introducing chaos-based mutation and adaptive cooling for improved exploration and convergence.", "code": "import numpy as np\n\nclass ChaosAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.chaos_param = 0.5\n\n    def chaotic_mutation(self, population):\n        chaotic_sequence = np.random.rand(self.population_size, self.dim)\n        chaotic_sequence = (4 * chaotic_sequence * (1 - chaotic_sequence)) * self.chaos_param\n        return population + chaotic_sequence * (np.max(population, axis=0) - np.min(population, axis=0))\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            mutant_vector = self.chaotic_mutation(mutant_vector)\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        acceptance_prob = np.exp((candidate_fitness - new_fitness) / (self.temperature + 1e-10))\n        if new_fitness < candidate_fitness or np.random.rand() < acceptance_prob:\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate * (1 - evaluations / self.budget)\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 11, "feedback": "An exception occurred: IndexError('boolean index did not match indexed array along dimension 0; dimension is 50 but corresponding boolean dimension is 10').", "error": "IndexError('boolean index did not match indexed array along dimension 0; dimension is 50 but corresponding boolean dimension is 10')", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {}}
{"id": "12a4c1a1-5dcb-4ccf-879c-357b3baf6fcb", "fitness": 0.10603385243065992, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance adaptive inertia-based velocity update and incorporate learning-based mutation strategy to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.learning_rate = 0.1  # New parameter for learning-based mutation\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            past_mutation = self.learning_rate * (population[a] - population[i])\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c])) + past_mutation\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10603 with standard deviation 0.03833.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.11247044743974666, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "7f92715c-e748-4fc9-89e1-9025cbdc392e", "fitness": 0.10552258679369177, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance exploration and exploitation balance by dynamically adjusting population size and incorporating a feedback-driven self-adaptive mutation strategy in DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor + diversity * 0.1\n        adaptive_crossover_rate = self.crossover_rate - diversity * 0.1\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            # Dynamically adjust population size based on remaining budget\n            remaining_budget = self.budget - evaluations\n            self.population_size = max(5, min(self.initial_population_size, remaining_budget // 10))\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10552 with standard deviation 0.03582.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.0761640635637606, 0.05976826434461702, 0.06590264921690225, 0.1436937250600483, 0.16610614381970956, 0.140018901019756, 0.11471741802870383, 0.10258943076771954, 0.08074268532200879]}}
{"id": "bb2c2093-e723-49ed-9868-2128db2d22ad", "fitness": 0.0982528429871365, "name": "AdaptiveOppositionHybridDESA", "description": "Incorporate adaptive opposition-based learning in DE to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass AdaptiveOppositionHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func, bounds):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def opposition_based_learning(self, population, fitness, func, bounds):\n        opposition_population = bounds.lb + bounds.ub - population\n        opposition_fitness = np.array([func(ind) for ind in opposition_population])\n        combined_population = np.vstack((population, opposition_population))\n        combined_fitness = np.concatenate((fitness, opposition_fitness))\n        best_indices = np.argsort(combined_fitness)[:self.population_size]\n        return combined_population[best_indices], combined_fitness[best_indices]\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func, bounds)\n            evaluations += self.population_size\n\n            population, fitness = self.opposition_based_learning(population, fitness, func, bounds)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveOppositionHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09825 with standard deviation 0.04213.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.04449089924281813, 0.03967791225120021, 0.07307275887534503, 0.14167552337767753, 0.16610614381970956, 0.140018901019756, 0.10682747534030546, 0.10069453714791321, 0.07171143580950345]}}
{"id": "adb6d894-aaf9-4557-b1a6-109bfd64c694", "fitness": 0.10814839478300525, "name": "AdvancedAdaptiveHybridDESA", "description": "Introduce adaptive population sizing and multi-tiered crossover strategies in DE to further enhance exploration-exploitation balance and convergence efficiency.", "code": "import numpy as np\n\nclass AdvancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def adaptive_population_size(self, evaluations):\n        return max(4, self.initial_population_size * (1 - evaluations / self.budget))\n\n    def differential_evolution(self, population, fitness, func, evaluations):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(len(population)):\n            indices = list(range(len(population)))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            \n            crossover_points_one = np.random.rand(self.dim) < adaptive_crossover_rate\n            crossover_points_two = np.random.rand(self.dim) < 0.3\n            trial_vector[np.logical_or(crossover_points_one, crossover_points_two)] = mutant_vector[np.logical_or(crossover_points_one, crossover_points_two)]\n            \n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        \n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = int(self.adaptive_population_size(0))\n        population = np.random.rand(population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            population_size = int(self.adaptive_population_size(evaluations))\n            population, fitness = self.differential_evolution(population, fitness, func, evaluations)\n            evaluations += len(population)\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 15, "feedback": "The algorithm AdvancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10815 with standard deviation 0.04065.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.058040845273315544, 0.0461467568443229, 0.077101062707159, 0.15926246047534043, 0.16610614381970956, 0.14718202319481144, 0.11192623389005385, 0.10548675447011802, 0.1020832723722166]}}
{"id": "2b81d84b-c157-45a7-b833-a19cd3eea9ce", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Integrate a novel adaptive inertia-based velocity update in DE to enhance exploration and convergence balance with slightly increased adaptive mutation factor for improved exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1.1 + diversity)  # Slight increase from 1 to 1.1\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "f02bba21-c506-4dea-9d3c-8741dd9f2d79", "fitness": 0.1026052501538624, "name": "AdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA by incorporating a dynamic step-size adjustment during local search and adaptive perturbation magnitude for simulated annealing.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation_scale = 0.1 / (1 + np.log1p(self.temperature))\n        perturbation = np.random.normal(0, perturbation_scale, self.dim) * (bounds.ub - bounds.lb)\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n            step_size *= 0.9  # Dynamically reduce step size\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10261 with standard deviation 0.04051.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06838214694886158, 0.04961555957907948, 0.049681861182396814, 0.13810210072708717, 0.16610614381970956, 0.14999332702215107, 0.11084886164376329, 0.10718614240079649, 0.08353110806091624]}}
{"id": "15454c5f-72c0-4db5-a2d4-d3c02f6470b6", "fitness": 0.10334310017930101, "name": "EnhancedLevyHybridDESA", "description": "Enhance diversification and exploitation by introducing Lvy flights into DE's mutation strategy for improved global search capability.", "code": "import numpy as np\n\nclass EnhancedLevyHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def levy_flight(self, lam=1.5):\n        u = np.random.normal(0, 1, self.dim) * 0.01\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.power(np.abs(v), 1/lam)\n        return step\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c]) + self.levy_flight()\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedLevyHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10334 with standard deviation 0.04065.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.07030626423286734, 0.0530603034672692, 0.05079612094251518, 0.14939722976560765, 0.16610614381970956, 0.140018901019756, 0.12195946707654881, 0.10230719467313953, 0.07613627661629585]}}
{"id": "2eb864c7-3b6c-4d95-83ba-74f8d166b892", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Enhance adaptive mutation and crossover rates with dynamic parameter tuning for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "ea5963e6-1dd7-494f-abc6-32cb45bc9f96", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Enhance balance between exploration and exploitation by incorporating adaptive crossover rate in local search.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        adaptive_step_size = step_size * (1 + 0.5 * (1 - candidate_fitness / np.max(candidate_fitness)))  # Change 1\n        for _ in range(10):\n            perturbation = np.random.uniform(-adaptive_step_size, adaptive_step_size, self.dim)  # Change 2\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 20, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "f3674d06-a5c9-4ec0-a663-0e82d85054e2", "fitness": 0.10640233675467019, "name": "EnhancedAdaptiveHybridDESA", "description": "Introduce a diversity-based adaptive local search in the DE framework to enhance convergence under exploration-exploitation dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def adaptive_local_search(self, candidate, candidate_fitness, func, bounds, diversity):\n        step_size = (bounds.ub - bounds.lb) * 0.01 * (1 + diversity)\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                diversity = np.mean(np.std(population, axis=0))\n                best_candidate, best_fitness = self.adaptive_local_search(best_candidate, best_fitness, func, bounds, diversity)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10640 with standard deviation 0.03201.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08678880671543854, 0.07913441345648786, 0.08162310377304449, 0.13820307183290537, 0.16610614381970956, 0.14702799612191186, 0.09110569932331647, 0.08362832965887956, 0.08400346609033793]}}
{"id": "213e2504-8ffb-4bc3-90c6-ef24715a326f", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Enhance adaptive balance between exploration and exploitation by dynamically adjusting mutation and crossover rates based on fitness variance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        fitness_variance = np.var(fitness) + 1e-7  # Added calculation of fitness variance\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity * fitness_variance)  # Modified\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity * fitness_variance)  # Modified\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "5a573a34-f7a6-4753-b578-5536af295ff4", "fitness": 0.09879743386843501, "name": "EnhancedAdaptiveHybridDESA", "description": "Introduce a chaotic perturbation factor in DE and SA to enhance global exploration and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.chaotic_sequence = self.init_chaotic_sequence()\n\n    def init_chaotic_sequence(self):\n        sequence = np.zeros(self.budget)\n        sequence[0] = np.random.rand()\n        for i in range(1, self.budget):\n            sequence[i] = 4.0 * sequence[i - 1] * (1.0 - sequence[i - 1])\n        return sequence\n\n    def differential_evolution(self, population, fitness, func, eval_index):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity + self.chaotic_sequence[eval_index])\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds, eval_index):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * (0.1 + self.chaotic_sequence[eval_index])\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func, evaluations)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds, evaluations)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09880 with standard deviation 0.05015.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.037259040951561184, 0.0634576726442092, 0.17849376181819143, 0.1574584936912371, 0.14266968628524024, 0.13078354752938814, 0.06068534270677328, 0.07074011590588525, 0.04762924328342921]}}
{"id": "4401fe20-a11c-4307-9628-0331fcbbcbd6", "fitness": 0.10032068004099987, "name": "EnhancedAdaptiveDESA", "description": "Introduce adaptive selection pressure in DE with enhanced local search for a balanced exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        selection_pressure = 1.5\n\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / (selection_pressure * self.temperature)):\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def enhanced_local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        best_candidate, best_fitness = candidate, candidate_fitness\n        for _ in range(20):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < best_fitness:\n                best_candidate, best_fitness = new_candidate, new_fitness\n        return best_candidate, best_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.enhanced_local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10032 with standard deviation 0.04981.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.04275081079481069, 0.037614699538046525, 0.0407974886113871, 0.16406320912445949, 0.16610614381970956, 0.1525738948498354, 0.10746532416866073, 0.1085905179456329, 0.08292403151645633]}}
{"id": "e7dc433a-d13d-494e-856a-dca0fa710661", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Introduce elitist selection to ensure that the best solution is preserved across generations to enhance convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        # Ensure the best solution is preserved\n        best_idx = np.argmin(fitness)\n        new_population[0] = population[best_idx]\n        fitness[0] = fitness[best_idx]\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "c03816fb-0e5c-4eae-b267-0fe16b28d9b3", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Enhance DE for better convergence by refining adaptive parameters and integrating an elitism strategy.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.85  # Increased slightly for better exploration\n        self.crossover_rate = 0.75  # Increased slightly to promote diversity\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Adjusted for more gradual cooling\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        # Elitism: retain the best solution found so far\n        best_idx = np.argmin(fitness)\n        new_population[np.argmax(fitness)] = population[best_idx]\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 26, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "928a5321-9ed6-4052-9138-5baeb232a0d8", "fitness": 0.1092040188398152, "name": "AdaptiveHybridDESA", "description": "Enhance DE by integrating a dynamic population size strategy to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.initial_population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            self.population_size = max(10, int(self.initial_population_size * (1 - evaluations / self.budget)))\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10920 with standard deviation 0.03668.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08504256093955853, 0.06331006749418866, 0.06583249866444818, 0.1389163212422625, 0.1693636171560895, 0.1533054871239321, 0.11745202864314863, 0.11220285100729788, 0.07741073728741088]}}
{"id": "d36c23d7-ceea-49e9-b679-ba38c46ecb5b", "fitness": 0.0907503620880163, "name": "AdaptiveHybridDESA", "description": "Introduce a dynamic step size in local_search to enhance local refinement capabilities.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01 * (1.0 - self.temperature)  # Introduced dynamic step size\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 28, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09075 with standard deviation 0.05368.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.045569857382562584, 0.02821696339913482, 0.03285562498354144, 0.14265037725257435, 0.18118856937483985, 0.15620275782832294, 0.09450191259428964, 0.08195125631584743, 0.05361593966103373]}}
{"id": "71e4148b-35d0-466d-b83c-5e6ad22abacf", "fitness": 0.10325195978714859, "name": "RefinedAdaptiveHybridDESA", "description": "Enhance DE with adaptive inertia and stochastic ranking for improved convergence and diversity handling.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def stochastic_ranking(self, population, fitness, func, bounds):\n        for _ in range(5):  # number of stochastic ranking iterations\n            indices = np.random.permutation(self.population_size)\n            for i in range(0, self.population_size-1, 2):\n                idx1, idx2 = indices[i], indices[i+1]\n                if fitness[idx1] > fitness[idx2]:\n                    if np.random.rand() < 0.45:  # probability of accepting worse\n                        population[idx1], population[idx2] = population[idx2], population[idx1]\n                        fitness[idx1], fitness[idx2] = fitness[idx2], fitness[idx1]\n        return population, fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            population, fitness = self.stochastic_ranking(population, fitness, func, bounds)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 29, "feedback": "The algorithm RefinedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10325 with standard deviation 0.03938.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05098717566983202, 0.0592272161297146, 0.0630560246366546, 0.13810210072710627, 0.16610614381970956, 0.1503242862185611, 0.10657262284412794, 0.107671727469423, 0.08722034056920824]}}
{"id": "d3282de0-6f8f-4c67-a44d-fcb35ecc75f4", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Enhance adaptive crossover rate by incorporating historical success rate for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        successful_trials = 0  # Track successful trials to adjust crossover rate\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity + 0.5 * successful_trials / self.population_size)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n                successful_trials += 1  # Increment successful trials\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "c4f1681e-b200-42b7-9b2e-5f6126221dcb", "fitness": 0.10334310017930101, "name": "AdaptiveHybridDESA", "description": "Enhance exploration with Lvy flights and dynamic parameters in DE to improve convergence.  ", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c])) + self.levy_flight(self.dim)\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 31, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10334 with standard deviation 0.04065.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.07030626423286734, 0.0530603034672692, 0.05079612094251518, 0.14939722976560765, 0.16610614381970956, 0.140018901019756, 0.12195946707654881, 0.10230719467313953, 0.07613627661629585]}}
{"id": "c7c78e9d-10bd-476f-b99f-c3f2ce684c4d", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Incorporate a dynamic temperature adjustment in simulated annealing to enhance convergence speed.  ", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        acceptance_probability = np.exp((candidate_fitness - new_fitness) / (self.temperature * (bounds.ub-bounds.lb).mean())) # Changed line\n        if new_fitness < candidate_fitness or np.random.rand() < acceptance_probability: # Changed line\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "5432a011-9c45-48da-bd74-58ef1d49dbb9", "fitness": 0.10373055368888603, "name": "AdaptiveHybridDESA", "description": "Integrate a novel adaptive inertia-based velocity update in DE with multi-parent crossover and adaptive annealing for enhanced exploration and convergence balance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for faster cooling\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c, d = np.random.choice(indices, 4, replace=False)  # Use 4 parents\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (\n                            population[a] + adaptive_mutation_factor * (population[b] - population[c]) + 0.5 * (population[d] - population[i]))  # Multi-parent crossover\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05  # Reduced step size\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10373 with standard deviation 0.03706.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.0748231274383313, 0.056588276590831765, 0.06033843780566839, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "9f245e9b-2bdf-47d2-804f-0aaf2dc5b8ca", "fitness": 0.1145684957251981, "name": "AdaptiveHybridDESA", "description": "Introduce a dynamic population resizing mechanism and enhanced local search to improve diversity and convergence in AdaptiveHybridDESA.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def enhanced_local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(20):  # Increased iterations for finer local search\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.initial_population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 10) == 0 and self.population_size < self.initial_population_size * 2:\n                self.population_size += 5  # Dynamically increase population size\n\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.enhanced_local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 20\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11457 with standard deviation 0.03075.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.09124778482858209, 0.08176360677414296, 0.0824017339220009, 0.1523118860595004, 0.16610614381970956, 0.14115419963735465, 0.12516518840691782, 0.1061724717151058, 0.08479344636346864]}}
{"id": "537db906-8602-40ce-8c5b-010418487517", "fitness": 0.10192057332058256, "name": "EnhancedDynamicDE", "description": "Introduce dynamic population management and self-adaptive parameter control in DE for enhanced balance in exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            # Dynamic population management\n            if evaluations < self.budget // 2:\n                self.population_size = min(self.population_size + 1, budget // 5)\n                new_individuals = np.random.rand(self.population_size - len(population), self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                new_fitness = np.array([func(ind) for ind in new_individuals])\n                population = np.vstack((population, new_individuals))\n                fitness = np.concatenate((fitness, new_fitness))\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedDynamicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10192 with standard deviation 0.04159.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.060674499464675735, 0.05030944816226035, 0.046915250548645315, 0.13810210072708717, 0.16610614381970956, 0.14068443812574194, 0.12287263065285581, 0.11493335371554825, 0.07668729466871893]}}
{"id": "3c6ffac7-ac0b-4c31-bba7-d579006c0bf2", "fitness": 0.10949597681141, "name": "AdaptiveHybridDESA", "description": "Enhance solution exploration and diversity via adaptive mutation scaling and dynamic crossover rates with a focus on convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Adjusted to maintain a longer exploration phase\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor + 0.5 * diversity  # Enhanced adaptive mutation scaling\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity + 0.5) # Adjusted for dynamic crossover control\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 0.5, self.dim) * (bounds.ub - bounds.lb) * 0.1  # Adjusted perturbation scale\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.02  # Adjusted step size for finer local search\n        for _ in range(12):  # Increased iterations for more thorough local optimization\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 12 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 12\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10950 with standard deviation 0.03523.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.0960014415314826, 0.060517376727081906, 0.07028251270154906, 0.13810210072708717, 0.16610614381970956, 0.15860331075299394, 0.10985498783101821, 0.09892590933411893, 0.08707000787764863]}}
{"id": "932961f5-0e26-4dc2-8ec6-58a7140c9ba9", "fitness": 0.10105217359720381, "name": "EnhancedAdaptiveHybridDESA", "description": "Integrate a diversification-driven mechanism in DE to dynamically balance exploration and exploitation phases for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.diversification_factor = 0.5\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity * self.diversification_factor)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity * self.diversification_factor)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "364580c4-6838-4ecc-801f-2aa9316d8d62", "fitness": 0.08915014534760424, "name": "AdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA by introducing dynamic population size adjustment and adaptive perturbation in local search.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        adaptive_step_size = step_size * (1 - self.temperature)  # Adjust step size based on temperature\n        for _ in range(10):\n            perturbation = np.random.uniform(-adaptive_step_size, adaptive_step_size, self.dim)  # Use adaptive step size\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def dynamic_population(self, evaluations):\n        self.population_size = max(10, self.initial_population_size - evaluations // 100)  # Reduce population size over time\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.initial_population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            self.dynamic_population(evaluations)  # Adjust population size\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08915 with standard deviation 0.05581.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.03339939505866718, 0.028233207260492943, 0.028764887057697863, 0.14418853725220793, 0.18692452932478143, 0.15156052247318452, 0.08996461853226989, 0.08233809982505025, 0.05697751134408613]}}
{"id": "8f3565e1-ffd5-44fb-bf54-426b1811af43", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Introduced a dynamic cooling rate to enhance exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate * 0.995  # Adjusted cooling rate to be dynamic\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "bb4cefa5-31f6-41ac-a53b-ce78c562b53c", "fitness": -Infinity, "name": "AdaptiveChaoticHybridDESA", "description": "Introduce adaptive learning rates and chaotic perturbations in DE and SA to enhance convergence in multimodal landscapes.", "code": "import numpy as np\n\nclass AdaptiveChaoticHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def chaotic_sequence(self, length):\n        x = np.random.rand()\n        seq = np.zeros(length)\n        for i in range(length):\n            x = 4 * x * (1 - x)  # Logistic map\n            seq[i] = x\n        return seq\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0)\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n\n        learning_rate = self.chaotic_sequence(self.population_size)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - learning_rate[i]) * population[i] + learning_rate[i] * (population[a] + adaptive_mutation_factor[i] * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate[i]\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        perturbation *= self.chaotic_sequence(self.dim)\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 40, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {}}
{"id": "cb10aa4d-aca3-46dd-8d50-5475fb65ca64", "fitness": 0.1046995225221554, "name": "EnhancedLevyDESA", "description": "Enhance DE with adaptive mutation based on diversity and integrate Levy flight-based exploration for improved global search and convergence.", "code": "import numpy as np\n\nclass EnhancedLevyDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                levy_step = self.levy_flight(self.dim)\n                new_candidate = np.clip(population[i] + levy_step, bounds.lb, bounds.ub)\n                new_fitness = func(new_candidate)\n                if new_fitness < fitness[i]:\n                    population[i] = new_candidate\n                    fitness[i] = new_fitness\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedLevyDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10470 with standard deviation 0.04325.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.10295998939059825, 0.04797477709589926, 0.03924016491169757, 0.1475067927690482, 0.16610614381970956, 0.15845129379673606, 0.1011090410750537, 0.1028914907417664, 0.07605600909888965]}}
{"id": "c7fff0b7-e151-4e16-a88e-a82d0ff1dece", "fitness": 0.10339409241047243, "name": "AdaptiveHybridDESA", "description": "Introduce adaptive perturbation scaling in local search to enhance convergence precision.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        adaptive_step_size = step_size * (candidate_fitness / np.min(func.bounds.ub - func.bounds.lb))  # Added line\n        for _ in range(10):\n            perturbation = np.random.uniform(-adaptive_step_size, adaptive_step_size, self.dim)  # Modified line\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10339 with standard deviation 0.03694.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.0959683768699584, 0.07055808227633775, 0.07848034477368282, 0.13810210072708717, 0.16610614381970956, 0.15524505647657183, 0.08594193586186327, 0.07940004781166177, 0.060744743077379315]}}
{"id": "ced4bc84-6e21-419d-a10e-a82be7a6b44c", "fitness": 0.0998327368003252, "name": "AdaptiveHybridDESA", "description": "Enhance DE with stochastic ranking to better handle constraint balancing, improving exploration-exploitation dynamics.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def stochastic_ranking(self, population, fitness):\n        indices = np.arange(self.population_size)\n        np.random.shuffle(indices)\n        for i in range(self.population_size - 1):\n            for j in range(self.population_size - 1 - i):\n                if fitness[indices[j]] > fitness[indices[j + 1]]:\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], fitness[indices]\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09983 with standard deviation 0.04013.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05991897639068844, 0.04975181018714814, 0.05466008371803943, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.11592501301147384, 0.09906795781432365, 0.07494364451470059]}}
{"id": "4cc9b803-0c7a-43c8-8870-bff70b37bf83", "fitness": 0.10105217359720381, "name": "RefinedAdaptiveHybridDESA", "description": "Integrate a diversity-enhanced adaptive inertia and temperature control mechanism to improve exploration and convergence.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        acceptance_prob = np.exp((candidate_fitness - new_fitness) / (self.temperature + 1e-10))\n        if new_fitness < candidate_fitness or np.random.rand() < acceptance_prob:\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 44, "feedback": "The algorithm RefinedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "83bda864-c2c5-43c3-9dc9-23655865aa4c", "fitness": 0.10368200687697304, "name": "AdaptiveHybridDESA", "description": "Enhance exploration and convergence by integrating stochastic inertia adaptation and dynamic crossover in DE.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - 0.5 * diversity)\n        \n        # Stochastic inertia weight adaptation\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n        inertia_weight *= np.random.uniform(0.9, 1.1, size=self.population_size)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 45, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10368 with standard deviation 0.03899.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.07179299007865847, 0.059485433630950824, 0.051176702333781576, 0.13810210072708717, 0.17256082758946734, 0.14046758114556046, 0.11384783562214185, 0.1057884061049088, 0.0799161846602009]}}
{"id": "90278b12-c9b3-48bc-8b6c-c8d6daf7f8ea", "fitness": 0.10105217359720381, "name": "EnhancedAdaptiveDESA", "description": "Enhance the exploration-exploitation balance by incorporating an adaptive inertia weight mechanism and self-adaptive parameter controls in DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.weight_bounds = (0.4, 0.9)\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - 0.5 * diversity)\n        \n        fitness_range = max(fitness) - min(fitness)\n        inertia_weight = np.clip(0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (fitness_range + 1e-7), *self.weight_bounds)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "085eb94c-cbee-4e78-ad9c-01bf560470f3", "fitness": 0.09235974556085451, "name": "EnhancedAdaptiveHybridDESA", "description": "Integrate a novel adaptive scaling factor and local search intensity modulation to enhance diversity and exploitation in DE.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.98\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.base_mutation_factor * (1 + 0.5 * diversity)\n        adaptive_crossover_rate = self.base_crossover_rate * (1 - 0.5 * diversity)\n        \n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c])\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.005\n        for _ in range(5):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 5 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 5\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09236 with standard deviation 0.04695.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.04030605567832091, 0.03640609871450984, 0.031148661037338377, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.10652208266143759, 0.09573507073859477, 0.07689259565093631]}}
{"id": "9db5653c-a2eb-4cc2-83f6-f9daf93d27f2", "fitness": 0.10536946768891679, "name": "AdaptiveHybridDESA", "description": "Introduce a random mutation strategy to enhance diversity and exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c])) + np.random.normal(0, 0.1, self.dim)  # Random mutation\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10537 with standard deviation 0.03712.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.0843594911718023, 0.052286050387122085, 0.056541891707602154, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.11313452258532997, 0.11697679477385226, 0.08079931300798959]}}
{"id": "e33c9d45-163c-48f1-ada9-86c7b739446e", "fitness": 0.08750040769724692, "name": "AdaptiveHybridDESA", "description": "Enhance exploration by introducing a dominance-based local search to diversify solutions and improve convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def dominance_local_search(self, population, fitness, func, bounds):\n        for i in range(self.population_size):\n            step_size = (bounds.ub - bounds.lb) * 0.05\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(population[i] + perturbation, bounds.lb, bounds.ub)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < fitness[i]:\n                population[i], fitness[i] = candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                self.dominance_local_search(population, fitness, func, bounds)\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 49, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08750 with standard deviation 0.04706.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.04788303074728473, 0.041992505010880476, 0.02600086151786718, 0.13963921896992904, 0.16610614381970956, 0.14036925488568186, 0.08594193586186327, 0.07940004781166177, 0.060170670650344316]}}
{"id": "92b486a2-bba0-4e6e-a573-1ea06bb21a99", "fitness": 0.09903980668161294, "name": "AdaptiveHybridDESA", "description": "Implement a multi-stage adaptive strategy with dynamic population resizing and adaptive weight adjustments for exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.98\n        self.stagnation_threshold = 5\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def dynamic_population_resize(self, evaluations):\n        if evaluations > self.budget * 0.5 and self.population_size > 10:\n            self.population_size = max(10, self.population_size - 1)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        stagnation_counter = 0\n        best_fitness = np.min(fitness)\n\n        while evaluations < self.budget:\n            prev_best_fitness = best_fitness\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            current_best_fitness = np.min(fitness)\n            if current_best_fitness < best_fitness:\n                best_fitness = current_best_fitness\n                stagnation_counter = 0\n            else:\n                stagnation_counter += 1\n\n            if stagnation_counter >= self.stagnation_threshold:\n                best_idx = np.argmin(fitness)\n                best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n                new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n                if new_fitness < best_fitness:\n                    population[best_idx] = new_candidate\n                    fitness[best_idx] = new_fitness\n                evaluations += 1\n                stagnation_counter = 0\n\n            self.dynamic_population_resize(evaluations)\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = population[np.argmin(fitness)], np.min(fitness)\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[np.argmin(fitness)]:\n                    population[np.argmin(fitness)] = best_candidate\n                    fitness[np.argmin(fitness)] = best_fitness\n                evaluations += 10\n\n            self.temperature *= self.cooling_rate\n\n        return population[np.argmin(fitness)]\n", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09904 with standard deviation 0.04233.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.0527611280686765, 0.04701464830665103, 0.04758284054781514, 0.13810210072708717, 0.16610614381970956, 0.1402736096147117, 0.12358264020441312, 0.09324453067401828, 0.08269061817143397]}}
{"id": "952ff327-abe6-4ac6-b10b-ccc3bacd4199", "fitness": 0.08400978155721045, "name": "AdaptiveRegroupingDESA", "description": "Introduce a diversity-based regrouping mechanism in DE to maintain exploration while integrating a temperature-adaptive mutation in Simulated Annealing for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveRegroupingDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Changed for faster cooling\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        # Regroup mechanism based on diversity\n        if diversity < 0.1:\n            new_population = np.random.rand(self.population_size, self.dim) * (func.bounds.ub - func.bounds.lb) + func.bounds.lb\n            fitness = np.array([func(ind) for ind in new_population])\n\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05  # Smaller step due to faster cooling\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        acceptance_prob = np.exp((candidate_fitness - new_fitness) / max(self.temperature, 1e-10))  # Ensure temperature doesn't hit zero\n        if new_fitness < candidate_fitness or np.random.rand() < acceptance_prob:\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 51, "feedback": "The algorithm AdaptiveRegroupingDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08401 with standard deviation 0.04958.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.03909003964315649, 0.02998428592356439, 0.027449749023849446, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.08594193586186327, 0.07940004781166177, 0.049994830184246]}}
{"id": "ffb9fb79-e5d9-4516-98f4-0b233080106c", "fitness": 0.09883878285992083, "name": "EnhancedAdaptiveHybridDESA", "description": "Leverage adaptive learning rates and dynamic population resizing in a hybrid DE and SA framework to improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.max_population_size = min(100, budget // 5)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_resize_rate = 0.1\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population_size = self.initial_population_size\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n            \n            # Dynamic population resizing\n            if evaluations < self.budget * 0.5:\n                self.population_size = min(self.max_population_size, int(self.population_size * (1 + self.dynamic_pop_resize_rate)))\n                new_individuals = np.random.rand(self.population_size - len(population), self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                population = np.vstack((population, new_individuals))\n                new_fitness_values = np.array([func(ind) for ind in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness_values))\n                evaluations += len(new_individuals)\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09884 with standard deviation 0.04283.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05071504186137188, 0.047069631218744856, 0.04998424504117083, 0.14592812480534212, 0.16610614381970956, 0.14302334162393027, 0.10268168891892504, 0.10474087179114933, 0.07929995665894363]}}
{"id": "f07cbffc-77d4-4eef-8e02-2809fd1aea94", "fitness": 0.10014288331806559, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA by introducing a fitness-based adaptive population size and a dynamic exploration-exploitation balance mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.population_growth_rate = 1.05\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(len(population)):\n            indices = list(range(len(population)))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = self.initial_population_size\n        population = np.random.rand(population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += len(population)\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            if evaluations < self.budget:\n                # Adjust population size based on current fitness\n                population_size = min(int(population_size * self.population_growth_rate), self.budget - evaluations)\n                if population_size > len(population):\n                    extra_population = np.random.rand(population_size - len(population), self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                    extra_fitness = np.array([func(ind) for ind in extra_population])\n                    population = np.vstack((population, extra_population))\n                    fitness = np.concatenate((fitness, extra_fitness))\n                    evaluations += len(extra_population)\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10014 with standard deviation 0.04334.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.07284160316886124, 0.04437063065943059, 0.042273103725301575, 0.13810210072708717, 0.16610614381970956, 0.15672819794590043, 0.10437644348564501, 0.10245030085149553, 0.07403742547915926]}}
{"id": "5bbf662b-70d7-4336-93b4-f519cf8a5ade", "fitness": -Infinity, "name": "AdaptiveHybridDESA_V2", "description": "Introduce adaptive population management and self-adaptive parameter tuning in DE to enhance exploration and convergence trade-off.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.population_management_interval = 5\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def manage_population(self, population, fitness):\n        if len(population) < self.initial_population_size * 2:\n            new_individuals = np.random.rand(self.initial_population_size, self.dim) * (func.bounds.ub - func.bounds.lb) + func.bounds.lb\n            new_fitness = np.array([func(ind) for ind in new_individuals])\n            population = np.concatenate((population, new_individuals))\n            fitness = np.concatenate((fitness, new_fitness))\n        else:\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices][:self.initial_population_size]\n            fitness = fitness[sorted_indices][:self.initial_population_size]\n        self.population_size = len(population)\n        return population, fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % self.population_management_interval == 0:\n                population, fitness = self.manage_population(population, fitness)\n\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 54, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {}}
{"id": "3dc74323-1d34-4829-b32f-36448de02bbc", "fitness": 0.10603385243065992, "name": "AdaptiveHybridDESA", "description": "Enhance DE's adaptive parameters with a nonlinear cooling schedule for improved exploration-convergence trade-off.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= (1 - self.cooling_rate**2)  # Changed cooling schedule to nonlinear\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 55, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10603 with standard deviation 0.03833.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.11247044743974666, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "efa8d924-3027-4046-a871-6d64497b76b4", "fitness": 0.10868955244077054, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance exploration and exploitation balance by integrating an adaptive learning rate in DE and optimized local search strategies.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.learning_rate = 0.1\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + self.learning_rate * diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - self.learning_rate * diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(15):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 15 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 15\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10869 with standard deviation 0.03527.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08942343015201026, 0.05700965867973595, 0.07347629432539304, 0.143910508069111, 0.16610614381970956, 0.15032209757247972, 0.10848748194223845, 0.10598080388330355, 0.08348955352295329]}}
{"id": "0836edd4-bb96-4676-940e-9553ce5574c0", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Slightly adjust the mutation factor for better exploration in the adaptive hybrid DE algorithm.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.85  # Adjusted mutation factor for better exploration\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "cd2d0f97-79ad-4994-93b9-eb8b96082205", "fitness": 0.10373055368888603, "name": "AdaptiveHybridDESA", "description": "Enhance the cooling schedule and mutation strategy to improve exploration and precision in AdaptiveHybridDESA.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Adjusted cooling rate for better convergence\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)  # Modified adaptive mutation\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05  # Smaller perturbation for precision\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 58, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10373 with standard deviation 0.03706.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.0748231274383313, 0.056588276590831765, 0.06033843780566839, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "6b60911a-8a0c-46ca-9255-483fdb47da69", "fitness": 0.09806772127267882, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance DE with adaptive learning rate and elitist selection to improve exploration and convergence effectiveness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.learning_rate = 0.1\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n            else:\n                # Introduce elitist selection\n                if np.random.rand() < self.learning_rate:\n                    new_population[i] = population[np.argmin(fitness)]\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09807 with standard deviation 0.04134.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05590259575279344, 0.04245921083156101, 0.05513038578434615, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.11450586721574396, 0.09134787222802099, 0.0790364140750911]}}
{"id": "9c1f5c47-67bc-4086-9f9e-175fcd2e7add", "fitness": 0.10105217359720381, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance exploration-exploitation balance by incorporating a dynamic diversity-driven self-adjustment in DE and integrating a random-spatial local restart strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - 0.5 * diversity)\n        \n        inertia_weight = 0.9 - 0.5 * (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def random_spatial_restart(self, bounds):\n        return np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            if evaluations + self.population_size <= self.budget and np.std(fitness) < 1e-5:\n                for i in range(self.population_size):\n                    population[i] = self.random_spatial_restart(bounds)\n                    fitness[i] = func(population[i])\n                evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "022ee285-19d9-40b9-ac7f-145da24aa22b", "fitness": 0.10789682800909488, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance the balance between exploration and exploitation by incorporating adaptive differential group strategies and dynamic local intensification.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def adaptive_parameters(self, diversity):\n        return (self.base_mutation_factor * (1 + diversity), \n                self.base_crossover_rate * (1 - diversity) + 0.1 * diversity)\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor, adaptive_crossover_rate = self.adaptive_parameters(diversity)\n        \n        fitness_range = max(fitness) - min(fitness) + 1e-7\n        inertia_weight = 0.5 + 0.4 * np.exp(-0.5 * fitness / fitness_range)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        acceptance = np.exp((candidate_fitness - new_fitness) / self.temperature)\n        if new_fitness < candidate_fitness or np.random.rand() < acceptance:\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(15):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 15 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 15\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10790 with standard deviation 0.03439.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08942343015201026, 0.05700965867973595, 0.07347629432539304, 0.143910508069111, 0.16610614381970956, 0.14318757768739876, 0.10848748194223845, 0.10598080388330355, 0.08348955352295329]}}
{"id": "517091e4-2070-431f-9a23-b2da3c2786cb", "fitness": 0.10473655920016182, "name": "AdaptiveHybridDESA", "description": "Introduce diversity control by adjusting the step size in local search based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        diversity = np.mean(np.std(candidate, axis=0))  # Line modified for diversity control\n        step_size = (bounds.ub - bounds.lb) * 0.01 * (1 + diversity)\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10474 with standard deviation 0.03347.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08809755074275938, 0.07728422162737392, 0.08048636162370681, 0.14272232391410455, 0.16610614381970956, 0.14331719500914009, 0.09071109304892455, 0.08035021752797888, 0.07355392548775863]}}
{"id": "369e0029-c1b4-4de1-ab30-8e91a8c5ea3a", "fitness": 0.10545565516264899, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance the adaptive hybrid DE with a stochastic global search leap and dynamic temperature scaling for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def stochastic_global_search(self, candidate, func, bounds):\n        leap_intensity = np.random.uniform(0.05, 0.2)\n        perturbation = np.random.uniform(-leap_intensity, leap_intensity, self.dim) * (bounds.ub - bounds.lb)\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        return new_candidate, new_fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n\n            # Apply stochastic global search leap\n            new_candidate, new_fitness = self.stochastic_global_search(best_candidate, func, bounds)\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n            evaluations += 1\n\n            # Simulated Annealing with dynamic temperature scaling\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            # Local search\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10546 with standard deviation 0.03971.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06859494267602828, 0.051907348889128735, 0.06242789592947584, 0.13810210072708717, 0.16610614381970956, 0.1588624904262247, 0.1171602929652168, 0.09880706078475388, 0.08713262024621593]}}
{"id": "4c70c722-752d-4c6a-8d25-35c52d1d1391", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Refined inertia-based velocity update and enhanced crossover strategy in DE for improved diversity control and convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity * 0.5)  # Enhanced crossover strategy\n        \n        inertia_weight = 0.9 - (0.9 - 0.3) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)  # Refined inertia weight\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 64, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "120aa948-2aeb-494a-af95-191e9abf9817", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Refine adaptive parameters and incorporate early convergence detection to enhance optimization efficiency.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.9  # Adjusted mutation factor\n        self.crossover_rate = 0.6  # Adjusted crossover rate\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Adjusted cooling rate\n        self.convergence_threshold = 1e-6  # New convergence threshold\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            if np.std(fitness) < self.convergence_threshold:  # Early convergence detection\n                break\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "f189f6b8-6179-4dae-beed-89b11faaea7d", "fitness": 0.1065475110750507, "name": "AdaptiveHybridDESA", "description": "Introduce adaptive scaling in local search and incorporate a restart mechanism for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.restart_threshold = 0.2  # Restart threshold added for diversity\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * np.random.uniform(0.005, 0.02)  # Adaptive step size\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            if np.std(fitness) < self.restart_threshold:  # Restart mechanism for diversity\n                population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                fitness = np.array([func(ind) for ind in population])\n                evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 66, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10655 with standard deviation 0.03680.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.07324729991410583, 0.06003612490366761, 0.06867052332156431, 0.14162736941846343, 0.16610614381970956, 0.14210414935484617, 0.12561355049778344, 0.10773035744823556, 0.07379208099708034]}}
{"id": "39b2ce34-1202-4c89-b899-5772fe286e1d", "fitness": 0.09283573725005374, "name": "EnhancedDEWithDynamicScaling", "description": "Integrate a novel dynamic scaling factor and adaptive local search intensification in DE to enhance exploitation and convergence speed.", "code": "import numpy as np\n\nclass EnhancedDEWithDynamicScaling:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            diversity_factor = np.mean(np.std(population, axis=0))\n            dynamic_scaling_factor = self.base_mutation_factor * (1 + diversity_factor)\n            adaptive_crossover_rate = self.base_crossover_rate * (1 - diversity_factor)\n\n            mutant_vector = population[a] + dynamic_scaling_factor * (population[b] - population[c])\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def adaptive_local_search(self, candidate, candidate_fitness, func, bounds):\n        for _ in range(5):  # Increase local search intensity\n            step_size = (bounds.ub - bounds.lb) * 0.01\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n\n            if evaluations + 5 <= self.budget:\n                best_candidate, best_fitness = self.adaptive_local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n\n            evaluations += 5\n            self.temperature *= self.cooling_rate\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedDEWithDynamicScaling got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09284 with standard deviation 0.04610.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.03670599441459421, 0.04026368303420913, 0.03990480676630237, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.11246601569599834, 0.08798501319983132, 0.07396897657299562]}}
{"id": "6ae03ebd-451e-4329-976a-25d8c92f92b2", "fitness": 0.0949958015767462, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance convergence by integrating a feedback-based mechanism for adaptive parameter tuning in DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n            # Feedback mechanism to adjust parameters\n            if diversity < 0.5:\n                adaptive_mutation_factor *= 1.05\n            else:\n                adaptive_mutation_factor *= 0.95\n        \n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(5):  # Reduced iterations for efficiency\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 5 <= self.budget:  # Adjusted to match changes above\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 5\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09500 with standard deviation 0.04357.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.051667773088323155, 0.04171759682174547, 0.04008634722502946, 0.13810210072708717, 0.16610614381970956, 0.1407905926295835, 0.1021396182560319, 0.09645444214405563, 0.07789759947914998]}}
{"id": "4e40258b-4dd6-4f41-9543-53a88db8952a", "fitness": 0.10105217359720381, "name": "AdaptiveLearningHybridDESA", "description": "Introduce adaptive learning automata to refine mutation and crossover rates dynamically in DE for enhanced convergence and solution diversity.", "code": "import numpy as np\n\nclass AdaptiveLearningHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.learning_rate = 0.1  # Learning rate for adaptive automata\n        self.rewards = np.zeros((self.population_size, 2))  # Reward counters for each individual\n\n    def update_parameters(self):\n        self.mutation_factor = max(0.1, self.mutation_factor * (1 + np.mean(self.rewards[:, 0] - self.rewards[:, 1])))\n        self.crossover_rate = min(0.9, self.crossover_rate * (1 + np.mean(self.rewards[:, 1] - self.rewards[:, 0])))\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n                self.rewards[i] = self.rewards[i] * (1 - self.learning_rate) + np.array([1, 0]) * self.learning_rate\n            else:\n                self.rewards[i] = self.rewards[i] * (1 - self.learning_rate) + np.array([0, 1]) * self.learning_rate\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.update_parameters()\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptiveLearningHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "db086a21-1745-47f2-afa7-4cd6a222cb01", "fitness": 0.09160820786317442, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance the exploration capability of AdaptiveHybridDESA by dynamically adjusting mutation and crossover based on population diversity and introducing a diversity-driven penalty for stagnation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.stagnation_count = 0\n        self.diversity_penalty_factor = 0.5\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            \n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n                self.stagnation_count = 0  # Reset stagnation counter\n            else:\n                self.stagnation_count += 1\n\n        # Apply diversity-driven penalty if stagnation is detected\n        if self.stagnation_count > self.population_size // 2:\n            diversity_penalty = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.diversity_penalty_factor\n            new_population += diversity_penalty * (population.max(axis=0) - population.min(axis=0))\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n            \n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09161 with standard deviation 0.04941.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.03281920605230193, 0.05923454440102005, 0.024090577870580332, 0.143563913803057, 0.16610614381970956, 0.15678552474073304, 0.08594193586186327, 0.07940004781166177, 0.07653197640764287]}}
{"id": "8c5fe335-d2c1-41ab-bfa4-6342429d0ee7", "fitness": 0.09175899702329963, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance DE with adaptive inertia and hybrid exploration using SA and LS to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.995  # Slightly slower cooling\n        self.local_search_probability = 0.3  # Probability to apply local search\n\n    def differential_evolution(self, population, fitness, func, bounds):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.005  # Smaller steps for finer local adjustments\n        for _ in range(20):  # Increased number of local search iterations\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func, bounds)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n\n            # Apply simulated annealing with a chance of local search\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 20 <= self.budget and np.random.rand() < self.local_search_probability:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 20\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09176 with standard deviation 0.04496.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05151550939338423, 0.03783625082746733, 0.0387679233895043, 0.13810210072708717, 0.16610614381970956, 0.14193212209146122, 0.09668661351322783, 0.08826923201742443, 0.0666150774304306]}}
{"id": "93d1b3aa-b962-496f-a562-468c60e7144a", "fitness": 0.10476092705805372, "name": "EnhancedHybridOptimizer", "description": "Employ a dynamic strategy combining adaptive mutation and crossover rates with targeted local search and stochastic tunneling to escape local optima.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - 0.5 * diversity)\n        \n        inertia_weight = 0.9 - 0.5 * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.005\n        for _ in range(15):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 15 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 15\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10476 with standard deviation 0.04259.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06936185119893745, 0.0487192766567458, 0.04409546182845803, 0.13810210072708717, 0.1742096262787044, 0.15236842444755694, 0.11003547705267203, 0.1059822356657919, 0.09997388966652976]}}
{"id": "b449a871-c7c1-4356-935d-3c397017a32e", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Refine AdaptiveHybridDESA by adjusting the inertia weight calculation for more robust convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * ((fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-8))\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "ab4db716-881b-4edd-b179-f26211290cef", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance exploration and exploitation by combining adaptive inertia-based DE with dynamic perturbation and gradient local search.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.98\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - 0.5 * diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def gradient_local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        grad_approximation = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbation = np.zeros(self.dim)\n            perturbation[i] = step_size\n            forward_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            backward_candidate = np.clip(candidate - perturbation, bounds.lb, bounds.ub)\n            forward_fitness = func(forward_candidate)\n            backward_fitness = func(backward_candidate)\n            grad_approximation[i] = (forward_fitness - backward_fitness) / (2 * step_size)\n        \n        gradient_step = np.clip(candidate - grad_approximation * step_size, bounds.lb, bounds.ub)\n        gradient_fitness = func(gradient_step)\n        \n        if gradient_fitness < candidate_fitness:\n            return gradient_step, gradient_fitness\n        \n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.gradient_local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 74, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {}}
{"id": "b03ae868-8e2a-4f34-bc8d-e8c151011045", "fitness": 0.11109316509937762, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA with self-adaptive mutation and crossover rates, and incorporate dynamic local search intensity based on convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds, intensity):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(int(10 * intensity)):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            # Dynamic local search intensity based on convergence speed\n            convergence_speed = (fitness[best_idx] - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n            local_search_intensity = 1.0 - convergence_speed\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds, local_search_intensity)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += int(10 * local_search_intensity)\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11109 with standard deviation 0.04170.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.158004261458206, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "5f014265-0196-4752-9221-05be37d87a46", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Refine adaptive parameter tuning and incorporate elitism in DE to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)  # Change 1\n        adaptive_crossover_rate = self.crossover_rate * (1 - 0.5 * diversity)  # Change 2\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n\n        elite_index = np.argmin(fitness)  # Change 3\n        new_population[0] = population[elite_index]  # Change 4\n        fitness[0] = fitness[elite_index]  # Change 5\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 76, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "51519f47-ae9d-47a5-bf65-ff83ef085cd4", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA by introducing a dynamic crossover rate adjustment based on historical convergence trends for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.history_window = 5\n        self.history = []\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        \n        history_change = np.mean(self.history[-self.history_window:]) if len(self.history) >= self.history_window else 0\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity) * (1 + history_change)\n\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            prev_best_fitness = min(fitness)\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            current_best_fitness = min(fitness)\n            self.history.append(current_best_fitness - prev_best_fitness)\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "bed31de5-b4c7-400c-a09d-75f216c88415", "fitness": 0.10083005571985294, "name": "EnhancedAdaptiveHybridDESA", "description": "Enhance AdaptiveHybridDESA with dynamic strategy adaptation for mutation and crossover rates based on population convergence and include a swarm-based exploration phase.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def dynamic_adaptation(self, population, fitness):\n        diversity = np.mean(np.std(population, axis=0))\n        fitness_range = max(fitness) - min(fitness) + 1e-7\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity / fitness_range)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity / fitness_range)\n        return adaptive_mutation_factor, adaptive_crossover_rate\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n        adaptive_mutation_factor, adaptive_crossover_rate = self.dynamic_adaptation(population, fitness)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def swarm_exploration(self, population, func, bounds):\n        global_best = population[np.argmin([func(ind) for ind in population])]\n        for i in range(self.population_size):\n            cognitive_component = np.random.rand(self.dim) * (global_best - population[i])\n            social_component = np.random.rand(self.dim) * (population[np.random.randint(self.population_size)] - population[i])\n            velocity = cognitive_component + social_component\n            population[i] = np.clip(population[i] + velocity, bounds.lb, bounds.ub)\n        return population\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population = self.swarm_exploration(population, func, bounds)\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10083 with standard deviation 0.04305.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08516625101684172, 0.06324025178503279, 0.026649207909206996, 0.14631712401046892, 0.16610614381970956, 0.1522230130424257, 0.0990035888139793, 0.08347096861288283, 0.08529395246812865]}}
{"id": "6f2ea3e9-5e01-4d33-a861-ea39c2553be0", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Introduce a dynamic crossover rate adjustment based on population diversity to improve the exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity / 2)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 79, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "2072c3a0-d7b2-43e0-8929-62864dff6ad1", "fitness": 0.10321872942244169, "name": "AdaptiveHybridDESA", "description": "Introduce dynamic crossover and mutation adaptation in DE to enhance convergence and robustness.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            # Adjust mutation factor to improve exploration capabilities\n            adaptive_mutation_factor = 0.5 + np.random.rand() * (diversity + 0.5)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            # Introduce dynamic crossover rate adjustment\n            adaptive_crossover_rate = np.random.uniform(0.5, 1.0) if np.random.rand() < 0.5 else self.crossover_rate\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10322 with standard deviation 0.04076.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05722493542772922, 0.052791162497783595, 0.05453250919775521, 0.14318502496658903, 0.16610614381970956, 0.1489244686097364, 0.11139214278903908, 0.10610061208300314, 0.08871156541062997]}}
{"id": "d5b1a632-3ab5-49b1-964e-226b9e8b3321", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Refine the inertia weight calculation for improved convergence in DE.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        # Modified inertia_weight calculation for improved convergence\n        inertia_weight = 0.9 - (0.9 - 0.4) * np.sqrt((fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7))\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "870d9f72-0ca4-404e-a9d4-968533fbef28", "fitness": 0.09532302608981648, "name": "MultiPhaseAdaptiveDESA", "description": "Introduce multi-phase adaptive mechanisms in DE with simulated annealing and local search to dynamically balance exploration-exploitation.", "code": "import numpy as np\n\nclass MultiPhaseAdaptiveDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98\n        self.exploration_exploitation_balance = 0.5  # Initial balance between exploration and exploitation\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds, temperature):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def adjust_exploration_exploitation(self, evaluations):\n        if evaluations < self.budget * 0.3:\n            self.exploration_exploitation_balance = 0.7  # Focus more on exploration early on\n        elif evaluations < self.budget * 0.7:\n            self.exploration_exploitation_balance = 0.5  # Balance exploration and exploitation\n        else:\n            self.exploration_exploitation_balance = 0.3  # Focus more on exploitation later on\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            self.adjust_exploration_exploitation(evaluations)\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds, temperature)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget and np.random.rand() < self.exploration_exploitation_balance:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 82, "feedback": "The algorithm MultiPhaseAdaptiveDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09532 with standard deviation 0.04570.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.061100362172491485, 0.04222396214139901, 0.03877932446188748, 0.14992867043145097, 0.16610614381970956, 0.1403943880504196, 0.11367341848521229, 0.08373263161910394, 0.06196833362667398]}}
{"id": "60b25be2-3dcd-4ee8-bf71-18a480a9310a", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Integrate a novel adaptive inertia-based velocity update in DE by adjusting the mutation factor's impact on the mutant vector.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * ((1+self.mutation_factor) * population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 83, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "41ba4fac-5ccd-4cc2-9156-c27f3edaeef0", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Enhance DE with adaptive mutation and crossover rates based on population diversity and fitness variance.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Change 1: Slightly increased cooling rate for SA\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        fitness_variance = np.std(fitness) / (np.mean(fitness) + 1e-7)  # Change 2\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity + 0.5 * fitness_variance)  # Change 3\n        adaptive_crossover_rate = self.crossover_rate * (1 - 0.5 * diversity - 0.5 * fitness_variance)  # Change 4\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 84, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "d30c4be6-3528-4090-9e45-57ee703201ab", "fitness": 0.10045809545044297, "name": "AdaptiveHybridDESA", "description": "Introduce a diversity-enhancing mutation strategy in AdaptiveHybridDESA to boost exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            if np.random.rand() < 0.15:  # Introduce random mutation\n                mutant_vector = np.random.rand(self.dim) * (func.bounds.ub - func.bounds.lb) + func.bounds.lb\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10046 with standard deviation 0.04003.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.05612589858513428, 0.053972255339297504, 0.05586800228781652, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.1152099880958104, 0.1059172037470465, 0.07280236543232876]}}
{"id": "199a18f9-6a75-4693-8776-c87d727b4e69", "fitness": 0.09830121008409515, "name": "AdaptiveHybridDESA", "description": "Introduce a diversity-driven adaptive operator selection to balance exploration and exploitation in AdaptiveHybridDESA.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def diversity_metric(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def differential_evolution(self, population, fitness, func, diversity):\n        new_population = np.copy(population)\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def adaptive_operator_selection(self, population, fitness, func, bounds):\n        diversity = self.diversity_metric(population)\n        if diversity > 0.2:\n            return self.differential_evolution(population, fitness, func, diversity)\n        else:\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n            return population, fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.adaptive_operator_selection(population, fitness, func, bounds)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n            self.temperature *= self.cooling_rate\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09830 with standard deviation 0.04237.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.054722324137702505, 0.046506894592573844, 0.04666988525795546, 0.13810210072708717, 0.16610614381970956, 0.1402736096147117, 0.12087126646669577, 0.09420240570655103, 0.07725626043386924]}}
{"id": "ec4e80d6-a1bd-49fe-9cc3-c30e52ad76e2", "fitness": -Infinity, "name": "EnhancedHybridDESAPSO", "description": "Enhance DE with dynamic adaptive parameters and hybridize with Particle Swarm Optimization (PSO) for improved global and local search balance.", "code": "import numpy as np\n\nclass EnhancedHybridDESAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.inertia_weight = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c])\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def particle_swarm_optimization(self, population, fitness, personal_best, personal_best_fitness, global_best):\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  self.c1 * r1 * (personal_best[i] - population[i]) +\n                                  self.c2 * r2 * (global_best - population[i]))\n            population[i] = np.clip(population[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n            curr_fitness = func(population[i])\n            if curr_fitness < personal_best_fitness[i]:\n                personal_best[i] = population[i]\n                personal_best_fitness[i] = curr_fitness\n        return population, personal_best, personal_best_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        personal_best = np.copy(population)\n        personal_best_fitness = np.copy(fitness)\n        global_best = population[np.argmin(fitness)]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            global_best = population[np.argmin(fitness)]\n            population, personal_best, personal_best_fitness = self.particle_swarm_optimization(population, fitness, personal_best, personal_best_fitness, global_best)\n            evaluations += self.population_size\n\n            if evaluations + 10 <= self.budget:\n                best_idx = np.argmin(fitness)\n                best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n                step_size = (bounds.ub - bounds.lb) * 0.01\n                for _ in range(10):\n                    perturbation = np.random.uniform(-step_size, step_size, self.dim)\n                    new_candidate = np.clip(best_candidate + perturbation, bounds.lb, bounds.ub)\n                    new_fitness = func(new_candidate)\n                    if new_fitness < best_fitness:\n                        best_candidate, best_fitness = new_candidate, new_fitness\n                population[best_idx], fitness[best_idx] = best_candidate, best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 87, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {}}
{"id": "5e8256d3-738c-4ca2-bd84-3ca785914a27", "fitness": 0.10361962069546611, "name": "AdaptiveHybridDESA2", "description": "Enhance DE with adaptive mutation and crossover rates using historical success rates and integrate a greedy local search.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.successful_mutations = []\n        self.successful_crossovers = []\n        self.temperature = 1.0\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity) * (1 + np.mean(self.successful_mutations))\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity) * (1 + np.mean(self.successful_crossovers))\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n                self.successful_mutations.append(1)\n                self.successful_crossovers.append(1)\n            else:\n                self.successful_mutations.append(0)\n                self.successful_crossovers.append(0)\n        return new_population, fitness\n\n    def greedy_local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(5):  # Reduced iterations for speed\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n                break  # Greedy acceptance\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.greedy_local_search(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= 0.99\n\n            if evaluations + 5 <= self.budget:\n                best_candidate, best_fitness = self.greedy_local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 5\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptiveHybridDESA2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10362 with standard deviation 0.04502.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.1289710353371143, 0.034634788801179206, 0.03115520240235714, 0.13810210072708717, 0.16610614381970956, 0.1402736096147117, 0.11423150775267343, 0.10746237403345882, 0.07163982377090372]}}
{"id": "cbd78cf9-44b4-4f9e-94a7-74b55f9b1950", "fitness": 0.10105217359720381, "name": "EnhancedAdaptiveDESA", "description": "Enhance adaptive DE with diversity-guided exploration and adaptive temperature control for robust performance across diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        acceptance_probability = np.exp((candidate_fitness - new_fitness) / max(self.temperature, 1e-10))\n        if new_fitness < candidate_fitness or np.random.rand() < acceptance_probability:\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "962ca9de-b3db-4d42-8528-b2b305fe4fad", "fitness": 0.10765001910083746, "name": "AdaptiveHybridDESA", "description": "Enhance balance between exploration and exploitation by dynamically adjusting crossover rate and integrating local search more frequently.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1.2 - diversity)  # Adjusted line\n\n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(15):  # Adjusted line\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 5 <= self.budget:  # Adjusted line\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 5  # Adjusted line\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 90, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10765 with standard deviation 0.03469.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.09143117400520795, 0.05979012284512242, 0.06646680613249223, 0.143910508069111, 0.16610614381970956, 0.14318757768739876, 0.10848748194223845, 0.10598080388330355, 0.08348955352295329]}}
{"id": "cdfb9ca7-caa6-4d33-8283-a05d94d54ed7", "fitness": -Infinity, "name": "AdaptiveHybridDESA", "description": "Enhance mutation factor adaptivity by incorporating a time-dependent element to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity) * (1 - evaluations/self.budget)  # Change here\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 91, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {}}
{"id": "2e4e1642-7a11-4f59-9759-8937f1e378b3", "fitness": 0.08927367098602128, "name": "EnhancedHybridDE", "description": "Enhance DE with adaptive parameter control and stochastic tunneling for improved exploration and convergence. ", "code": "import numpy as np\n\nclass EnhancedHybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Faster cooling rate for more rapid adaptation\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.base_mutation_factor * (1 + 0.5 * diversity)\n        adaptive_crossover_rate = self.base_crossover_rate * (1 - 0.5 * diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def stochastic_tunneling(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.05\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / (self.temperature * 0.1)):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.stochastic_tunneling(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08927 with standard deviation 0.04697.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08646504450245385, 0.02998428592356439, 0.027449749023849446, 0.13810210072708717, 0.16610614381970956, 0.140018901019756, 0.08594193586186327, 0.07940004781166177, 0.049994830184246]}}
{"id": "72bc94ec-a159-4e69-988d-bfda37b0b1dd", "fitness": 0.10334310017930101, "name": "AdaptiveHybridDESA", "description": "Enhance diversity control and dynamic parameter adjustment in DE with integration of Levy flight for better exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Updated cooling rate\n\n    def levy_flight(self, lambda_param=1.5):\n        sigma_u = np.power((np.math.gamma(1 + lambda_param) * np.sin(np.pi * lambda_param / 2)) /\n                           (np.math.gamma((1 + lambda_param) / 2) * lambda_param * np.power(2, (lambda_param - 1) / 2)), 1 / lambda_param)\n        u = np.random.normal(0, sigma_u, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.power(np.abs(v), 1 / lambda_param)\n        return step\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c]) + self.levy_flight()  # Added levy flight\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.initial_temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.initial_temperature *= self.cooling_rate  # Updated temperature variable\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10334 with standard deviation 0.04065.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.07030626423286734, 0.0530603034672692, 0.05079612094251518, 0.14939722976560765, 0.16610614381970956, 0.140018901019756, 0.12195946707654881, 0.10230719467313953, 0.07613627661629585]}}
{"id": "12051560-574b-491b-996f-6e07503564b3", "fitness": 0.10730005028509565, "name": "AdaptiveHybridDESA", "description": "Incorporate adaptive step size in local search to enhance exploitation precision.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * (0.01 + 0.05 * np.random.rand())  # Adaptive step size\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 94, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10730 with standard deviation 0.03262.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.08924993649933277, 0.08655522773134838, 0.07292971179573349, 0.14561644586951905, 0.16610614381970956, 0.1432214228876657, 0.09291352128246533, 0.09401771546872861, 0.07509032721135789]}}
{"id": "56656d92-f4de-4a75-b048-9221e2b298e4", "fitness": 0.10105217359720381, "name": "EnhancedAdaptiveHybridDESA", "description": "Integrate adaptive temperature cooling and diversity-driven mutation in DE for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.initial_temperature = 1.0\n        self.final_temperature = 0.1\n        self.cooling_rate = (self.final_temperature / self.initial_temperature) ** (2 / budget)\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = population[a] + adaptive_mutation_factor * (population[b] - population[c])\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        acceptance_probability = np.exp((candidate_fitness - new_fitness) / self.temperature)\n        if new_fitness < candidate_fitness or np.random.rand() < acceptance_probability:\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        self.temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "63e83605-186b-472e-a1bb-efc3b5af8906", "fitness": 0.10105217359720381, "name": "RefinedAdaptiveHybridDESA", "description": "Introduce multi-level adaptive control for mutation and crossover rates in DE using population diversity and fitness variance for enhanced convergence.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        fitness_variance = np.var(fitness)\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity * (1 - fitness_variance))\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity * fitness_variance)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 96, "feedback": "The algorithm RefinedAdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "c541c40a-7ecd-4ecc-b6f3-2597ee42fcd0", "fitness": 0.10105217359720381, "name": "AdaptiveHybridDESA", "description": "Integrate adaptive population sizing and dynamic crossover control in DE to improve exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func, evaluations):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n            evaluations += 1\n            if evaluations >= self.budget:\n                break\n        return new_population, fitness, evaluations\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness, evaluations = self.differential_evolution(population, fitness, func, evaluations)\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 97, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10105 with standard deviation 0.04005.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.06763533793864174, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
{"id": "aa30f570-d091-4516-81e0-07dc80c29265", "fitness": -Infinity, "name": "AdaptiveHybridDESA", "description": "Enhance DE with deterministic chaos-based perturbations and dynamic crossover for refined exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.dynamic_crossover_rate(diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - min(fitness)) / (max(fitness) - min(fitness) + 1e-7)\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            mutant_vector = self.chaotic_perturbation(mutant_vector, fitness[i], func)\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def chaotic_perturbation(self, vector, current_fitness, func):\n        chaos = np.sin(np.pi * vector)\n        new_vector = np.clip(vector + chaos * 0.1, func.bounds.lb, func.bounds.ub)\n        if func(new_vector) < current_fitness:\n            return new_vector\n        return vector\n\n    def dynamic_crossover_rate(self, diversity):\n        return 0.5 + 0.5 * np.tanh(10 * (diversity - 0.5))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 98, "feedback": "An exception occurred: AttributeError(\"'AdaptiveHybridDESA' object has no attribute 'simulated_annealing'\").", "error": "AttributeError(\"'AdaptiveHybridDESA' object has no attribute 'simulated_annealing'\")", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {}}
{"id": "ac03ecc7-acd9-4349-ac4c-c994cf74c6ff", "fitness": 0.11597149777168535, "name": "AdaptiveHybridDESA", "description": "Refine inertia weight calculation by incorporating mean fitness to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def differential_evolution(self, population, fitness, func):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)\n        adaptive_crossover_rate = self.crossover_rate * (1 - diversity)\n        \n        inertia_weight = 0.9 - (0.9 - 0.4) * (fitness - np.mean(fitness)) / (max(fitness) - min(fitness) + 1e-7)  # Refined line for inertia weight\n\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = (1 - inertia_weight[i]) * population[i] + inertia_weight[i] * (population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n            trial_vector = np.copy(population[i])\n            crossover_points = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial_vector[crossover_points] = mutant_vector[crossover_points]\n            trial_fitness = func(trial_vector)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial_vector\n                fitness[i] = trial_fitness\n        return new_population, fitness\n\n    def simulated_annealing(self, candidate, candidate_fitness, func, bounds):\n        perturbation = np.random.normal(0, 1, self.dim) * (bounds.ub - bounds.lb) * 0.1\n        new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        new_fitness = func(new_candidate)\n        if new_fitness < candidate_fitness or np.random.rand() < np.exp((candidate_fitness - new_fitness) / self.temperature):\n            return new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def local_search(self, candidate, candidate_fitness, func, bounds):\n        step_size = (bounds.ub - bounds.lb) * 0.01\n        for _ in range(10):\n            perturbation = np.random.uniform(-step_size, step_size, self.dim)\n            new_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            new_fitness = func(new_candidate)\n            if new_fitness < candidate_fitness:\n                candidate, candidate_fitness = new_candidate, new_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            population, fitness = self.differential_evolution(population, fitness, func)\n            evaluations += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_candidate, best_fitness = population[best_idx], fitness[best_idx]\n            new_candidate, new_fitness = self.simulated_annealing(best_candidate, best_fitness, func, bounds)\n\n            if new_fitness < best_fitness:\n                population[best_idx] = new_candidate\n                fitness[best_idx] = new_fitness\n\n            evaluations += 1\n            self.temperature *= self.cooling_rate\n\n            if evaluations + 10 <= self.budget:\n                best_candidate, best_fitness = self.local_search(best_candidate, best_fitness, func, bounds)\n                if best_fitness < fitness[best_idx]:\n                    population[best_idx] = best_candidate\n                    fitness[best_idx] = best_fitness\n                evaluations += 10\n\n        return population[np.argmin(fitness)]", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveHybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11597 with standard deviation 0.04886.", "error": "", "parent_ids": ["2c81cc09-3bcd-4967-83c6-76a9bcf8fc5e"], "operator": null, "metadata": {"aucs": [0.20190925550897554, 0.05061257145268505, 0.04939651161836467, 0.13977629691105742, 0.16610614381970956, 0.140018901019756, 0.11501143798326607, 0.10518584671244557, 0.07572651491890825]}}
