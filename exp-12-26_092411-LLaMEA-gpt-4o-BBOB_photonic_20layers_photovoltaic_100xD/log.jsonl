{"id": "9e6aea6d-0969-4691-ab2a-6dde155a62f0", "fitness": 0.06877974174244016, "name": "HybridDELocalSearchOptimizer", "description": "A hybrid algorithm combining Differential Evolution and Local Search for efficient exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass HybridDELocalSearchOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.num_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                # Local Search (Exploitation phase)\n                if self.num_evaluations < self.budget:\n                    local_candidates = np.random.normal(trial, 0.1 * (ub - lb), size=(5, self.dim))\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 5\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n            \n            # Sort and save best solution found\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDELocalSearchOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06878 with standard deviation 0.05267.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.013846324688329803, 0.014597243273523408, 0.012807085250587713, 0.05672877520527775, 0.05081733341626382, 0.051380426268693435, 0.13381869806343127, 0.14061751136493428, 0.14440427815091994]}}
{"id": "0c54fd3e-6e4b-40a9-a599-a762cad6ff69", "fitness": 0.06945193340068964, "name": "EnhancedHybridDELocalSearchOptimizer", "description": "Enhanced HybridDELocalSearchOptimizer with adaptive parameter control and elitism to improve convergence and diversity management.", "code": "import numpy as np\n\nclass EnhancedHybridDELocalSearchOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        \n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on current evaluations\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            # Sort population by fitness for elitism\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                # Mutation\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                # Local Search (Exploitation phase)\n                if self.num_evaluations < self.budget:\n                    local_candidates = np.random.normal(trial, 0.1 * (ub - lb), size=(5, self.dim))\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 5\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Sort and save best solution found\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridDELocalSearchOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06945 with standard deviation 0.05570.", "error": "", "parent_ids": ["9e6aea6d-0969-4691-ab2a-6dde155a62f0"], "operator": null, "metadata": {"aucs": [0.012107088346343886, 0.014597243273523408, 0.01337288791259017, 0.04762836452015995, 0.05017647914062884, 0.0521341689014192, 0.13355067386423902, 0.15278932605391438, 0.14871116859338795]}}
{"id": "8442958e-76f8-45e4-8efe-e5a6463bbcc0", "fitness": 0.06978153913781038, "name": "EnhancedHybridDELocalSearchOptimizer", "description": "Enhanced HybridDELocalSearchOptimizer with improved local search strategy using adaptive Gaussian mutation for exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDELocalSearchOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        \n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on current evaluations\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb)  # Standard deviation for mutation\n                    local_candidates = trial + np.random.randn(5, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)  # Ensure within bounds\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 5\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridDELocalSearchOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06978 with standard deviation 0.05487.", "error": "", "parent_ids": ["0c54fd3e-6e4b-40a9-a599-a762cad6ff69"], "operator": null, "metadata": {"aucs": [0.012967396299489065, 0.014597243273523408, 0.0124767669974154, 0.0513535562641928, 0.05343093942987476, 0.05156960790102805, 0.134462454059732, 0.14819344349812458, 0.14898244451691334]}}
{"id": "2ff67c3f-f3cb-423a-a89c-bf0eba7eed79", "fitness": -Infinity, "name": "EnhancedHybridDELocalSearchOptimizer", "description": "EnhancedHybridDELocalSearchOptimizer with adaptive population size and diversity promotion using crowding distance for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDELocalSearchOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10 * dim\n        self.population_size = self.base_population_size\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on current evaluations\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        # Adjust population size based on progress\n        progress_ratio = self.num_evaluations / self.budget\n        self.population_size = max(4 * self.dim, int(self.base_population_size * (1 - progress_ratio)))\n\n    def crowding_distance(self, population, fitness):\n        # Compute crowding distance to promote diversity\n        distances = np.zeros(len(population))\n        order = np.argsort(fitness)\n        for i in range(self.dim):\n            sorted_pop = population[order, i]\n            sorted_fit = fitness[order]\n            distances[order[0]] = distances[order[-1]] = np.inf\n            for j in range(1, len(population) - 1):\n                if sorted_fit[-1] > sorted_fit[0]:\n                    distances[order[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (sorted_fit[-1] - sorted_fit[0])\n        return distances\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            crowding_distances = self.crowding_distance(population, fitness)\n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                selected_idxs = np.random.choice(idxs, 3, replace=False, p=crowding_distances / crowding_distances.sum())\n                a, b, c = population[selected_idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb)\n                    local_candidates = trial + np.random.randn(5, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 5\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 3, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_ids": ["8442958e-76f8-45e4-8efe-e5a6463bbcc0"], "operator": null, "metadata": {}}
{"id": "ad11887d-37f3-4eaa-bcc9-3d8ce30e2032", "fitness": 0.08278717284211032, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce Diversity-Preserving Strategies and Adaptive Neighborhoods to enhance the exploration and exploitation balance in DE.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08279 with standard deviation 0.05205.", "error": "", "parent_ids": ["8442958e-76f8-45e4-8efe-e5a6463bbcc0"], "operator": null, "metadata": {"aucs": [0.11639086065111592, 0.014597243273523408, 0.0124767669974154, 0.053257307982217394, 0.0635689876541694, 0.051380426268693435, 0.14548136165974157, 0.14132346558482445, 0.1466081355072919]}}
{"id": "1f02353b-8c82-4d4c-a239-5864c0d47520", "fitness": 0.07089140075247866, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Adjust mutation strategy by incorporating dynamic scaling of differential weight based on population diversity.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                diversity = self.calculate_diversity(population)\n                F_dynamic = self.F * (1 + diversity)  # Dynamic scaling of differential weight\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07089 with standard deviation 0.05377.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.0124767669974154, 0.05358132447029673, 0.055773764994028086, 0.06251440890766435, 0.14293884901329645, 0.1413716624394027, 0.14293587811571473]}}
{"id": "fb29023e-b42f-459e-a478-ca3eb39a3c27", "fitness": 0.07090645642458063, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce Dynamic Population Resizing and Adaptive Mutation Strategies in DE to enhance convergence and diversity balance.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.dynamic_population = True\n        self.gradual_shrink_factor = 0.95\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def resize_population(self, current_size):\n        # Dynamically resize the population if enabled\n        if self.dynamic_population and current_size > 5:\n            return int(current_size * self.gradual_shrink_factor)\n        return current_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        current_population_size = self.population_size\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * current_population_size))\n\n            for i in range(elite_size, current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            current_population_size = self.resize_population(current_population_size)\n            population = population[:current_population_size]\n            fitness = fitness[:current_population_size]\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n        \n        return best_solution, best_fitness", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07091 with standard deviation 0.05366.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.0124767669974154, 0.048440679545824095, 0.0635689876541694, 0.05165067114536104, 0.14379319483103714, 0.14061751136493428, 0.14476265127599053]}}
{"id": "99898b23-0a46-4fdf-9cf2-1da6365c05a4", "fitness": 0.07191534094839962, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce dynamic population resizing to enhance convergence speed in the EnhancedDiversityAdaptiveDEOptimizer.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n            # Dynamic population resizing\n            if self.num_evaluations / self.budget > 0.5:\n                self.population_size = max(5 * self.dim, int(0.5 * self.population_size))\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07192 with standard deviation 0.05409.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.012555732875983217, 0.053257307982217394, 0.0635689876541694, 0.05159543226487484, 0.14548136165974157, 0.14132346558482445, 0.1466081355072919]}}
{"id": "275b75a0-742c-489e-b13a-0a96226bbf8a", "fitness": 0.07028896385492185, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Enhance local exploration by increasing the number of local candidates for diverse solutions in proximity.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(5, self.dim) * sigma  # Increased local candidates\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 5\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07029 with standard deviation 0.05560.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.012036281651779057, 0.014597243273523408, 0.0124767669974154, 0.05144071537467321, 0.054557424552696854, 0.051380426268693435, 0.13855236088310952, 0.14416971205242368, 0.15338974363998215]}}
{"id": "c724650a-3ad3-4969-b342-f40276c07d03", "fitness": 0.07172135768742237, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce adaptive mutation scaling and integrate neighborhood-based learning to refine diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity and evaluations\n        diversity_factor = (1.0 - self.num_evaluations / self.budget)\n        self.F = 0.5 + 0.5 * np.random.rand() * diversity_factor\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07172 with standard deviation 0.05401.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018233432410776795, 0.014597243273523408, 0.01283189040326893, 0.05074888632752561, 0.06441311669231808, 0.051975530754795884, 0.14534847380223126, 0.14440776740664663, 0.14293587811571473]}}
{"id": "dd25200b-d5e7-4ac8-91b2-851750a4a698", "fitness": 0.06997753409231439, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Integrate an adaptive scaling factor based on convergence speed to refine DE's differential weight dynamically.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity and convergence speed\n        convergence_speed = np.clip(np.exp(-self.num_evaluations / self.budget), 0.1, 1.0)\n        self.F = (0.5 + 0.5 * np.random.rand()) * convergence_speed\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06998 with standard deviation 0.05382.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.01774804524857343, 0.014597243273523408, 0.01288271069777569, 0.045980440911112974, 0.04856886962463658, 0.06202475000045826, 0.13763455627563448, 0.1417186260447667, 0.1486425647543479]}}
{"id": "3af2f5c2-2b8f-4ad7-8730-14fc33e46e7c", "fitness": 0.07013151068793654, "name": "EnhancedAdaptiveDEOptimizer", "description": "Integrate Adaptive Mutation Scaling and Dynamic Elite Strategy in DE to further enhance exploration while maintaining convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F_base = 0.5\n        self.CR = 0.9\n        self.num_evaluations = 0\n        self.elite_rate = 0.1\n\n    def adapt_parameters(self, diversity):\n        # Adaptive differential weight based on diversity\n        self.F = self.F_base + 0.3 * np.random.rand() * diversity\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07013 with standard deviation 0.05478.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.0124767669974154, 0.05256270186409118, 0.053417923781046706, 0.0544416857027612, 0.14750834201923146, 0.14141034587667867, 0.14293587811571473]}}
{"id": "aaf0eee2-6547-4950-8e41-d0ed2cb7b26c", "fitness": 0.07044067614122937, "name": "DynamicSubpopRotationDEOptimizer", "description": "Implement Dynamic Subpopulation Rotation and Adaptive Selection for Improved Diversity and Convergence in DE.", "code": "import numpy as np\n\nclass DynamicSubpopRotationDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.num_evaluations = 0\n        self.elite_rate = 0.1\n        self.subpop_size = 5 * dim  # Size of subpopulations for rotation\n\n    def adapt_parameters(self):\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def rotate_subpopulations(self, population, fitness):\n        indices = np.arange(self.population_size)\n        np.random.shuffle(indices)\n        subpop_indices = [indices[i:i + self.subpop_size] for i in range(0, len(indices), self.subpop_size)]\n        \n        new_population = np.zeros_like(population)\n        new_fitness = np.zeros_like(fitness)\n        for subpop in subpop_indices:\n            sorted_subpop = subpop[np.argsort(fitness[subpop])]\n            new_population[subpop], new_fitness[subpop] = population[sorted_subpop], fitness[sorted_subpop]\n        return new_population, new_fitness\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            population, fitness = self.rotate_subpopulations(population, fitness)\n            \n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 12, "feedback": "The algorithm DynamicSubpopRotationDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07044 with standard deviation 0.05539.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011927711262422869, 0.014597243273523408, 0.0124767669974154, 0.050000868067074045, 0.05793144120150873, 0.051380426268693435, 0.14637697944236006, 0.1448811756105396, 0.14439347314752682]}}
{"id": "758abd4e-2704-42d5-b211-1b685fe92186", "fitness": 0.0697060428472034, "name": "MultiSwarmAdaptiveDEOptimizer", "description": "Introduce a Multi-Swarm Strategy with Adaptive Communication and Dynamic Parameter Tuning to improve diversity and convergence in DE.", "code": "import numpy as np\n\nclass MultiSwarmAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.sub_swarm_count = 3  # Number of sub-swarms\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.communication_rate = 0.2  # Rate of inter-swarm communication\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using diversity metrics\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize multiple swarms\n        swarms = [np.random.rand(self.population_size // self.sub_swarm_count, self.dim) * (ub - lb) + lb\n                  for _ in range(self.sub_swarm_count)]\n        fitnesses = [np.array([func(ind) for ind in swarm]) for swarm in swarms]\n        self.num_evaluations += sum(len(fit) for fit in fitnesses)\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            for swarm_idx, (population, fitness) in enumerate(zip(swarms, fitnesses)):\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices]\n                fitness = fitness[sorted_indices]\n                elite_size = max(1, int(self.elite_rate * len(population)))\n                \n                for i in range(elite_size, len(population)):\n                    idxs = [idx for idx in range(len(population)) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                    \n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, population[i])\n                    \n                    trial_fitness = func(trial)\n                    self.num_evaluations += 1\n                    if trial_fitness < fitness[i]:\n                        population[i], fitness[i] = trial, trial_fitness\n                    \n                    if self.num_evaluations < self.budget:\n                        diversity = self.calculate_diversity(population)\n                        sigma = 0.1 * (ub - lb) * (1 + diversity)\n                        local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                        local_candidates = np.clip(local_candidates, lb, ub)\n                        local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                        self.num_evaluations += 3\n                        best_local_idx = np.argmin(local_fitnesses)\n                        if local_fitnesses[best_local_idx] < trial_fitness:\n                            population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n                \n                # Update swarm with new solutions\n                swarms[swarm_idx] = population\n                fitnesses[swarm_idx] = fitness\n            \n            # Inter-swarm communication\n            if np.random.rand() < self.communication_rate and self.num_evaluations < self.budget:\n                best_solutions = [swarm[np.argmin(fit)] for swarm, fit in zip(swarms, fitnesses)]\n                best_fitnesses = [np.min(fit) for fit in fitnesses]\n                global_best_idx = np.argmin(best_fitnesses)\n                \n                for swarm_idx in range(self.sub_swarm_count):\n                    if swarm_idx != global_best_idx:\n                        rand_idx = np.random.randint(0, len(swarms[swarm_idx]))\n                        swarms[swarm_idx][rand_idx] = best_solutions[global_best_idx]\n                        fitnesses[swarm_idx][rand_idx] = best_fitnesses[global_best_idx]\n\n        best_fitness = np.min([np.min(fit) for fit in fitnesses])\n        best_solution = swarms[np.argmin([np.min(fit) for fit in fitnesses])][np.argmin([np.min(fit) for fit in fitnesses])]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 13, "feedback": "The algorithm MultiSwarmAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06971 with standard deviation 0.05450.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.013438530657345016, 0.054711082203347305, 0.04531653141611125, 0.05798394030053533, 0.13848619921979455, 0.14714625413338933, 0.14384189585981833]}}
{"id": "a78a682d-356b-49e5-bdf2-7c53fb27f7e5", "fitness": 0.07085070661929223, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Integrate Self-Adjusting Population Size and Adaptive Mutation Scaling to enhance dynamic balance in DE.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.min_population_size = 4 * dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.num_evaluations = 0\n        self.elite_rate = 0.1\n\n    def adapt_parameters(self, diversity):\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        # Adjust population size based on diversity\n        diversity_factor = max(0.1, min(1.0, diversity))\n        self.population_size = int(self.initial_population_size * diversity_factor)\n        self.population_size = max(self.min_population_size, self.population_size)\n        \n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.initial_population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.initial_population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices][:self.population_size]\n            fitness = fitness[sorted_indices][:self.population_size]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07085 with standard deviation 0.05381.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.0124767669974154, 0.05398749319378604, 0.0560653886364173, 0.051804643445481746, 0.14692103281338686, 0.14061751136493428, 0.14293587811571473]}}
{"id": "20b73eb9-7a39-433e-a831-14da363a22fd", "fitness": 0.07070107922687635, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Enhance the exploration by increasing the elite rate and introducing stochastic variability in local search.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.2  # Adjusted rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.15 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07070 with standard deviation 0.05415.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.014229588769231971, 0.014597243273523408, 0.0124767669974154, 0.05795589953927027, 0.054929955766302996, 0.051700226744566424, 0.14467068037933795, 0.14281347345652395, 0.14293587811571473]}}
{"id": "018d9e7b-4c4a-4780-9dbc-4540a324a3b5", "fitness": -Infinity, "name": "EnhancedAdaptiveDEOptimizer", "description": "Introduce Adaptive Population Resizing and Dynamic Parameters Tuning to enhance diversity and convergence in DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1\n\n    def adapt_parameters(self, diversity):\n        # Adaptive parameter adjustment based on diversity and evaluation progress\n        progress = self.num_evaluations / self.budget\n        self.F = 0.5 + 0.5 * np.random.rand() * (1 - progress)\n        self.CR = 0.8 + 0.2 * np.random.rand() * (1 - diversity)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def resize_population(self, current_size):\n        # Adaptive resizing based on progress\n        progress = self.num_evaluations / self.budget\n        return int(current_size * (1 - progress))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            self.population_size = max(elite_size, self.resize_population(self.initial_population_size))\n            population = population[:self.population_size]\n            fitness = fitness[:self.population_size]\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n        return best_solution, best_fitness", "configspace": "", "generation": 16, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {}}
{"id": "c5c7271c-0ebf-46cb-a904-08d4632ef689", "fitness": -Infinity, "name": "EnhancedMemoryPopulationDEOptimizer", "description": "Enhance Diversity and Performance in DE with Historical Memory of Parameters and Dynamic Population Sizing.", "code": "import numpy as np\n\nclass EnhancedMemoryPopulationDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.parameter_memory = []\n\n    def adapt_parameters(self):\n        # Adaptation using historical memory\n        if self.parameter_memory:\n            self.F, self.CR = np.mean(self.parameter_memory, axis=0)\n        else:\n            self.F = 0.5 + 0.5 * np.random.rand()\n            self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def adjust_population_size(self, diversity):\n        # Dynamic adjustment of population size based on diversity\n        base_size = 10 * self.dim\n        self.population_size = int(base_size * (1 + diversity))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            diversity = self.calculate_diversity(population)\n            self.adjust_population_size(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n                if len(self.parameter_memory) > 100:\n                    self.parameter_memory.pop(0)\n                self.parameter_memory.append((self.F, self.CR))\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 17, "feedback": "An exception occurred: IndexError('index 1582 is out of bounds for axis 0 with size 200').", "error": "IndexError('index 1582 is out of bounds for axis 0 with size 200')", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {}}
{"id": "0177dcfc-6531-4905-aa47-fe976d8f57dd", "fitness": 0.08192397668081064, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Integrate adaptive mutation scaling based on convergence speed to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity) * (1 - (self.num_evaluations / self.budget))  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08192 with standard deviation 0.05109.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.11697435370016251, 0.014597243273523408, 0.0124767669974154, 0.05339023430495582, 0.05842110155700131, 0.05556519048922304, 0.13712924714509445, 0.14495396178487552, 0.1438076908750443]}}
{"id": "50040ef5-9671-4ff9-b603-e43ed3572673", "fitness": 0.07085070661929223, "name": "AdaptiveDEWithDynamicPopulation", "description": "Integrate Adaptive Differential Evolution with Dynamic Population Resizing and Adaptive Elite Learning for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDEWithDynamicPopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.F = 0.8\n        self.CR = 0.9\n        self.num_evaluations = 0\n        self.elite_rate = 0.1\n        self.resizing_factor = 0.8\n\n    def adapt_parameters(self, diversity):\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        if diversity < 0.1:\n            self.population_size = int(self.population_size * self.resizing_factor)\n            self.population_size = max(4, self.population_size)\n        else:\n            self.population_size = min(int(self.population_size / self.resizing_factor), self.initial_population_size)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * len(population)))\n            \n            for i in range(elite_size, len(population)):\n                idxs = [idx for idx in range(len(population)) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            if len(population) < self.initial_population_size:\n                additional_population = np.random.rand(self.initial_population_size - len(population), self.dim) * (ub - lb) + lb\n                additional_fitness = np.array([func(ind) for ind in additional_population])\n                self.num_evaluations += len(additional_population)\n                population = np.vstack((population, additional_population))\n                fitness = np.hstack((fitness, additional_fitness))\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:self.initial_population_size]]\n                fitness = fitness[sorted_indices[:self.initial_population_size]]\n            \n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveDEWithDynamicPopulation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07085 with standard deviation 0.05381.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.0124767669974154, 0.05398749319378604, 0.0560653886364173, 0.051804643445481746, 0.14692103281338686, 0.14061751136493428, 0.14293587811571473]}}
{"id": "7857faff-7eb9-4101-8b04-bf9bc1a55775", "fitness": 0.07089140075247866, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Fine-tune mutation strategy by adjusting the differential weight with diversity-dependent scaling for improved exploration.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                diversity = self.calculate_diversity(population)\n                adjusted_F = self.F * (1 + diversity)\n                mutant = np.clip(a + adjusted_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07089 with standard deviation 0.05377.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.0124767669974154, 0.05358132447029673, 0.055773764994028086, 0.06251440890766435, 0.14293884901329645, 0.1413716624394027, 0.14293587811571473]}}
{"id": "22ee46c7-46f2-4842-8c58-5a64363665b7", "fitness": 0.07048004749776676, "name": "AdaptiveLocalSearchDEOptimizer", "description": "Integrate Adaptive Local Search and Enhanced Parameter Tuning into Diversity-Preserving Differential Evolution for improved convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveLocalSearchDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self, diversity):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand() * (1 - diversity)\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.std(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n\n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n\n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    # Adaptive local search based on diversity\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveLocalSearchDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07048 with standard deviation 0.05529.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.014338398411371966, 0.014597243273523408, 0.01371715648890548, 0.048992521300541325, 0.05473713240134792, 0.051380426268693435, 0.14253974407676961, 0.15108192714303303, 0.14293587811571473]}}
{"id": "dd2eacba-5afe-4707-9158-b5b2a0b4a905", "fitness": 0.07144269243402866, "name": "DynamicParamAdaptiveMutationDEOptimizer", "description": "Introduce Dynamic Parameter Control and Adaptive Mutation Strategies to further balance exploration and exploitation in DE.", "code": "import numpy as np\n\nclass DynamicParamAdaptiveMutationDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.diversity_threshold = 0.05  # Threshold for diversity adaptation\n\n    def adapt_parameters(self, diversity):\n        # Adaptive parameter adjustment based on diversity\n        if diversity < self.diversity_threshold:\n            self.F = min(1.0, self.F + 0.05)\n            self.CR = max(0.5, self.CR - 0.05)\n        else:\n            self.F = max(0.5, self.F - 0.05)\n            self.CR = min(1.0, self.CR + 0.05)\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 22, "feedback": "The algorithm DynamicParamAdaptiveMutationDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07144 with standard deviation 0.05714.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.014389919507743043, 0.014606204779716636, 0.012500274271879386, 0.04800547546467249, 0.05436515265694153, 0.051380426268693435, 0.15164281918094014, 0.14578655590113765, 0.15030740387453367]}}
{"id": "6bb98492-13d6-4be9-a331-5ebefc2bf16d", "fitness": 0.07085070661929223, "name": "EnhancedDynamicDEOptimizer", "description": "Introduce dynamic population sizing and adaptive mutation strategies based on convergence speed and diversity to improve DE performance.", "code": "import numpy as np\n\nclass EnhancedDynamicDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.num_evaluations = 0\n        self.elite_rate = 0.1\n        self.dynamic_population_size = self.initial_population_size\n        self.convergence_speed_factor = 0.1  # Factor to adjust population size based on convergence speed\n\n    def adapt_parameters(self, diversity):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        # Adjust population size dynamically based on diversity and convergence speed\n        if diversity < 0.1:\n            self.dynamic_population_size = max(4, int(self.dynamic_population_size * (1 - self.convergence_speed_factor)))\n        else:\n            self.dynamic_population_size = min(self.initial_population_size, int(self.dynamic_population_size * (1 + self.convergence_speed_factor)))\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.initial_population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.initial_population_size\n\n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.dynamic_population_size))\n            \n            for i in range(elite_size, self.dynamic_population_size):\n                idxs = [idx for idx in range(self.dynamic_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedDynamicDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07085 with standard deviation 0.05381.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.0124767669974154, 0.05398749319378604, 0.0560653886364173, 0.051804643445481746, 0.14692103281338686, 0.14061751136493428, 0.14293587811571473]}}
{"id": "480f06b1-2495-471f-b34c-589a497ffac7", "fitness": 0.07034537436835121, "name": "RefinedDEOptimizer", "description": "Introduce Dynamic Scaling of Mutation Factor and Hybrid Local Search to Enhance Convergence Speed and Solution Precision in Differential Evolution.", "code": "import numpy as np\n\nclass RefinedDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.scaling_factor = 0.1  # Initial scaling factor for mutation adjustment\n\n    def adapt_parameters(self):\n        # Dynamic scaling of mutation factor based on performance\n        self.F = 0.5 + 0.2 * np.random.rand()  # Adjust within a smaller range\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                # Hybrid local search with Gaussian perturbation\n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = self.scaling_factor * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07035 with standard deviation 0.05338.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.017252280918090612, 0.014597243273523408, 0.013518586186533565, 0.05792884782840568, 0.05081284596882907, 0.05174217324964636, 0.13842892144175567, 0.14339119695537417, 0.14543627349300237]}}
{"id": "d456aba2-8238-4935-a6f4-4a3f21f4f703", "fitness": 0.0701729452239873, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Enhance mutation strategy by incorporating dimensional learning from elite solutions.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - population[0]), lb, ub)  # Change line to use elite\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07017 with standard deviation 0.05501.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.0124767669974154, 0.05039147280900513, 0.054504121158883256, 0.054582216836670416, 0.14637793689667955, 0.14268091500757063, 0.14411312547517185]}}
{"id": "4f368de2-5bb7-4b26-ae14-3d9722595348", "fitness": 0.06934511300504191, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce a dynamic elite preservation rate to adaptively enhance convergence.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        self.elite_rate = 0.05 + 0.15 * np.random.rand()  # Dynamic elite rate adjustment\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06935 with standard deviation 0.05450.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.012435163116576664, 0.014597243273523408, 0.013540889885360063, 0.04729477112541003, 0.05203493100194734, 0.054643519141923114, 0.13984550240790072, 0.1467781189770211, 0.14293587811571473]}}
{"id": "40a4213c-b6b2-42d5-b8e7-e87a63ae833e", "fitness": 0.07244761698201249, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Enhance parameter adaptation by dynamically adjusting the population size based on convergence.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            if self.num_evaluations < self.budget:  # Line 1 changed\n                self.population_size = max(4, int(self.population_size * 0.95))  # Dynamically adjust population size\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07245 with standard deviation 0.05439.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.0124767669974154, 0.0539444404680921, 0.0635689876541694, 0.05319096857557859, 0.14626513108449002, 0.14274628894098373, 0.14698832411088947]}}
{"id": "4c8ddc85-131e-4cc9-8474-e18aa57b713a", "fitness": 0.07121418611351585, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce Self-Adaptive Mutation Scaling and Hybridized Local Search to enhance diversity and convergence in DE.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F_base = 0.5  # Base differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Self-adaptive mutation scaling\n        self.F = self.F_base + 0.3 * np.random.randn()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def hybrid_local_search(self, candidate, fitness, func, lb, ub):\n        # Hybrid local search with simulated annealing\n        if np.random.rand() > 0.5:\n            temperature = 1.0\n            for _ in range(5):  # Attempt 5 local moves\n                candidate_new = candidate + np.random.randn(self.dim) * temperature\n                candidate_new = np.clip(candidate_new, lb, ub)\n                fitness_new = func(candidate_new)\n                self.num_evaluations += 1\n                if fitness_new < fitness or np.random.rand() < np.exp((fitness - fitness_new) / temperature):\n                    candidate, fitness = candidate_new, fitness_new\n                temperature *= 0.9\n        return candidate, fitness\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                # Hybrid local search\n                if self.num_evaluations < self.budget:\n                    candidate, candidate_fitness = self.hybrid_local_search(trial, trial_fitness, func, lb, ub)\n                    if candidate_fitness < fitness[i]:\n                        population[i], fitness[i] = candidate, candidate_fitness\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07121 with standard deviation 0.05378.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.012556090492588767, 0.01510096583774767, 0.01448054374898955, 0.05105057074483277, 0.06487452777296909, 0.053827820232474455, 0.14242705259232913, 0.14082599240908156, 0.14578411119062962]}}
{"id": "d0da3c62-bfe8-4d58-8837-1a90005e39cb", "fitness": 0.0696473190959248, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce an adaptive elite_rate based on population diversity to dynamically adjust exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            diversity = self.calculate_diversity(population)  # Change to make elite_rate adaptive\n            self.elite_rate = 0.1 + 0.1 * (1 - diversity)  # Changed line\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06965 with standard deviation 0.05461.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.014025573442077888, 0.014597243273523408, 0.0124767669974154, 0.052933990175311196, 0.050369130243663296, 0.051380426268693435, 0.14043870965985905, 0.14701662557316564, 0.14358740622961386]}}
{"id": "7637203b-63ca-4a98-b7fd-5eb5075dd083", "fitness": 0.0696473190959248, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce a dynamic adjustment for the elite rate based on population diversity to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            diversity = self.calculate_diversity(population)\n            self.elite_rate = 0.05 + 0.15 * (1 - diversity)  # Dynamic elite rate\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06965 with standard deviation 0.05461.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.014025573442077888, 0.014597243273523408, 0.0124767669974154, 0.052933990175311196, 0.050369130243663296, 0.051380426268693435, 0.14043870965985905, 0.14701662557316564, 0.14358740622961386]}}
{"id": "a18d4b0e-dff4-4251-867f-701b607cc5a2", "fitness": -Infinity, "name": "DynamicPopulationDEOptimizer", "description": "Introduce a dynamic population strategy and enhanced mutation to improve exploration-exploitation balance in DE.", "code": "import numpy as np\n\nclass DynamicPopulationDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.max_population_size = 20 * dim\n        self.population_size = self.initial_population_size\n        self.F = 0.8\n        self.CR = 0.9\n        self.num_evaluations = 0\n        self.elite_rate = 0.1\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on progress\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def adjust_population_size(self, progress):\n        if progress > 0.1:\n            self.population_size = min(self.max_population_size, self.population_size + self.dim)\n        elif progress < 0.01:\n            self.population_size = max(self.initial_population_size, self.population_size - self.dim)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        best_fitness = np.min(fitness)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in np.random.choice(self.population_size, 5, replace=False) if idx != i]\n                a, b, c, d, e = population[idxs]\n                mutant = np.clip(a + self.F * (b - c + d - e), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    new_population[i], new_fitness[i] = trial, trial_fitness\n\n            progress = np.abs(best_fitness - np.min(new_fitness)) / (1 + np.abs(best_fitness))\n            self.adjust_population_size(progress)\n            best_idx = np.argmin(new_fitness)\n            best_fitness = new_fitness[best_idx]\n            population, fitness = new_population, new_fitness\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n        return best_solution, best_fitness", "configspace": "", "generation": 31, "feedback": "An exception occurred: ValueError('not enough values to unpack (expected 5, got 4)').", "error": "ValueError('not enough values to unpack (expected 5, got 4)')", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {}}
{"id": "19f31a84-404f-4772-b533-cb5642f6b151", "fitness": 0.08166075500118515, "name": "EnhancedAdaptiveMutationDEOptimizer", "description": "Combine adaptive mutation scaling and fitness-based population perturbation to enhance global exploration and local exploitation in DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMutationDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F_min, self.F_max = 0.5, 1.0  # Range for adaptive differential weight\n        self.CR = 0.9  # Crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_F(self, fitness, base_F):\n        # Adaptive mutation scaling based on fitness ranking\n        rank = np.argsort(fitness)\n        norm_rank = rank / (len(rank) - 1)\n        return self.F_min + (self.F_max - self.F_min) * norm_rank\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            adaptive_F = self.adapt_F(fitness, self.F_max)\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = adaptive_F[i]  # Use adaptive F for the current individual\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveMutationDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08166 with standard deviation 0.05202.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.12452238323284193, 0.014597243273523408, 0.012954651704482623, 0.051526989562315606, 0.052245108156402154, 0.05431654003013353, 0.14123048957031814, 0.14061751136493428, 0.14293587811571473]}}
{"id": "e7f28a9e-f45d-4143-a7c6-4f4e58118ff5", "fitness": 0.07188267740676081, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce Dynamic Elite Replacement and Adaptive Mutation to further balance exploration and exploitation in DE.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n                # Dynamic Elite Replacement Strategy\n                if i < elite_size:\n                    elite_candidate = trial + np.random.randn(self.dim) * 0.01 * (ub - lb)\n                    elite_candidate = np.clip(elite_candidate, lb, ub)\n                    elite_fitness = func(elite_candidate)\n                    self.num_evaluations += 1\n                    if elite_fitness < fitness[i]:\n                        population[i], fitness[i] = elite_candidate, elite_fitness\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07188 with standard deviation 0.05410.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.0124767669974154, 0.053257307982217394, 0.0635689876541694, 0.051380426268693435, 0.14548136165974157, 0.14132346558482445, 0.1466081355072919]}}
{"id": "78ec3504-cb6e-4d4e-8e92-1f137af670c8", "fitness": 0.0696898929828164, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce Self-Adaptive Mutation and Crossover Rates with Dynamic Diversity Control to enhance convergence and robustness in DE.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.diversity_threshold = 0.1  # Dynamic diversity threshold\n\n    def adapt_parameters(self, diversity):\n        # Self-adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand() * (1 + diversity)\n        self.CR = 0.8 + 0.2 * np.random.rand() * (1 - diversity)\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n    \n    def dynamic_diversity_control(self, diversity):\n        # Adjust elite rate based on diversity\n        if diversity < self.diversity_threshold:\n            self.elite_rate = min(0.2, self.elite_rate + 0.01)\n        else:\n            self.elite_rate = max(0.05, self.elite_rate - 0.01)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.dynamic_diversity_control(diversity)\n            self.adapt_parameters(diversity)\n            \n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06969 with standard deviation 0.05446.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.016336227840724526, 0.0124767669974154, 0.04871593585932987, 0.05288635094596006, 0.05572253810854877, 0.1355173163926363, 0.14098990477840523, 0.15273128736136132]}}
{"id": "3b32d6d9-8a22-40a1-9b52-6a7e714926df", "fitness": 0.07050014440797475, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce a dynamic scaling factor to F based on the generation's best fitness improvement to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        best_fitness_prev = np.inf\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            best_fitness_current = fitness[0]\n            if best_fitness_current < best_fitness_prev:\n                self.F *= 1.1  # Slight increase to F if improvement\n            best_fitness_prev = best_fitness_current\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07050 with standard deviation 0.05414.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.017661663578041775, 0.014597243273523408, 0.0124767669974154, 0.054076161057966865, 0.04866937981930597, 0.05570354622332918, 0.14723612888733795, 0.14082150085692424, 0.14325890897792803]}}
{"id": "dd4d1f5b-a874-43b1-abbc-bec16d604d89", "fitness": 0.06968398556550244, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Enhance mutation strategy by adapting step size based on fitness variance to improve convergence in DE.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                fitness_var = np.var(fitness)  # Calculate fitness variance\n                mutant = np.clip(a + self.F * (b - c) * (1 + fitness_var), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06968 with standard deviation 0.05357.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.0124767669974154, 0.05848156548688288, 0.04712120636930428, 0.05890243418089225, 0.1353017686915512, 0.14550629841327178, 0.14293587811571473]}}
{"id": "4bc87c85-f4ee-4305-a337-c1f6f643dd61", "fitness": 0.07027095526739238, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce a more dynamic adjustment of the crossover probability to improve exploration in search space.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.1 + 0.8 * np.random.rand()  # Modified crossover probability range\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07027 with standard deviation 0.05462.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.01204913524378426, 0.014597243273523408, 0.012766107789860426, 0.05228260655990513, 0.04750233594396047, 0.062330925580024066, 0.14170931123721142, 0.14492982430764512, 0.1442711074706171]}}
{"id": "eaa4fab1-2ac4-4b10-a9c6-ffda19d114a7", "fitness": 0.07098428151198317, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Implement elitist mutation strategy for enhanced exploration while maintaining convergence.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n            # Elitist mutation introduction\n            elite_mutant = np.clip(population[0] + self.F * (population[np.random.randint(elite_size)] - population[np.random.randint(elite_size)]), lb, ub)\n            if func(elite_mutant) < best_fitness:\n                population[best_idx], fitness[best_idx] = elite_mutant, func(elite_mutant)\n\n        return best_solution, best_fitness", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07098 with standard deviation 0.05394.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018250401732970323, 0.014597243273523408, 0.0124767669974154, 0.04775103549209969, 0.0635689876541694, 0.051380426268693435, 0.14379319483103714, 0.1427853346650526, 0.1442551426928872]}}
{"id": "9a5e892e-d758-4abc-b702-9de85cf2c02b", "fitness": 0.07153738087589295, "name": "AdaptivePopulationDEOptimizer", "description": "Utilizes an adaptive population size and diversity-driven mutation scaling to balance exploration and exploitation more effectively in DE.", "code": "import numpy as np\n\nclass AdaptivePopulationDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.shrink_threshold = 0.2  # Threshold for population shrinkage\n\n    def adapt_parameters(self, diversity):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand() * (1 + diversity)\n        self.CR = 0.8 + 0.2 * np.random.rand() * (1 - diversity)\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * population_size))\n            \n            for i in range(elite_size, population_size):\n                idxs = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Shrink population size if diversity is below threshold\n            if diversity < self.shrink_threshold and population_size > 2 * self.dim:\n                population_size = int(population_size * 0.9)\n                population = population[:population_size]\n                fitness = fitness[:population_size]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptivePopulationDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07154 with standard deviation 0.05636.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.012067563224401612, 0.014597243273523408, 0.0124767669974154, 0.05217023237865426, 0.055436951898573006, 0.05443420139261934, 0.15342540637029867, 0.1462921842318362, 0.14293587811571473]}}
{"id": "85d0742e-6627-4a00-8cec-3f6e7a6f0af1", "fitness": 0.06798041728028315, "name": "MultiFidelityAdaptiveDEOptimizer", "description": "Incorporate multi-fidelity evaluations and adaptive mutation strategies to further balance exploration and exploitation in DE.", "code": "import numpy as np\n\nclass MultiFidelityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def multi_fidelity_evaluation(self, candidates, func):\n        # Evaluate candidates with a subset of dimensions to save budget\n        reduced_dim = max(1, int(self.dim * 0.5))\n        reduced_candidates = candidates[:, :reduced_dim]\n        reduced_bounds = (func.bounds.lb[:reduced_dim], func.bounds.ub[:reduced_dim])\n        scaled_candidates = reduced_candidates * (reduced_bounds[1] - reduced_bounds[0]) + reduced_bounds[0]\n        return np.array([func(cand) for cand in scaled_candidates])\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = self.multi_fidelity_evaluation(local_candidates, func)\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 40, "feedback": "The algorithm MultiFidelityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06798 with standard deviation 0.05353.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.018318229393703644, 0.014104466453692344, 0.012680417583461279, 0.04886604713553033, 0.04357354874867381, 0.050906056779599584, 0.13609417472099583, 0.14018789079090355, 0.14709292391598794]}}
{"id": "d3184a4e-3414-417a-88e3-93e39d36e6f3", "fitness": 0.07048518100236635, "name": "EnhancedNichingAdaptiveDEOptimizer", "description": "Integrate Dynamic Niching Strategy with Adaptive Parameters to foster diverse exploration and maintain robust convergence in DE.", "code": "import numpy as np\n\nclass EnhancedNichingAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n        self.niche_radius = 0.1  # Initial niche radius\n\n    def adapt_parameters(self, diversity):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        self.niche_radius = 0.1 + 0.1 * diversity\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    local_candidates = trial + np.random.randn(3, self.dim) * self.niche_radius\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedNichingAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07049 with standard deviation 0.05433.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.013548557891653878, 0.014597243273523408, 0.012882737032515634, 0.048455295354149275, 0.05652646498442404, 0.05796937222001064, 0.13767917910533634, 0.1497719010439692, 0.14293587811571473]}}
{"id": "8d6d1b41-da3c-4824-b734-650e171bbe13", "fitness": 0.07128219564650112, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Integrate a dynamic mutation scaling factor to improve the exploration-exploitation balance in the Differential Evolution process.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n\n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                # Modify mutation scaling factor based on max-min difference\n                F_dynamic = self.F * np.clip((fitness.max() - fitness.min()) / (1 + fitness.max()), 0.5, 1.0)\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)  # Adjusted F to F_dynamic\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05534.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.014385468489589326, 0.014597243273523408, 0.014272240233234257, 0.05044421422179557, 0.05166811300737606, 0.05781274150130522, 0.14032562753757405, 0.15137131950529858, 0.1466627930488137]}}
{"id": "1ea80c5b-efce-416a-9a7a-87130f60b6dc", "fitness": 0.06975953364468618, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce additional mutation strategies and dynamic elite rate adjustment to enhance exploration capability.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + np.random.randn(self.dim), lb, ub)  # Added additional mutation term\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n            self.elite_rate = np.clip(self.elite_rate * (1 + 0.1 * np.random.randn()), 0.05, 0.2)  # Dynamic elite rate adjustment\n\n        return best_solution, best_fitness", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06976 with standard deviation 0.05657.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011849929531861592, 0.014597243273523408, 0.0124767669974154, 0.04935450884826442, 0.048564986327439774, 0.05179719636979929, 0.13590621359541655, 0.16035307974274038, 0.14293587811571473]}}
{"id": "1371f611-0756-4067-94b6-0f227cd50a9b", "fitness": 0.06943955191956308, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Enhance exploration by integrating adaptive mutation scaling and fitness-based elitism in DE.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        diversity = self.calculate_diversity(self.population)\n        self.F = 0.5 + 0.4 * np.random.rand() * (1 + diversity)\n        self.CR = 0.8 + 0.1 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in self.population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            self.population = self.population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(self.population)\n                    sigma = 0.1 * (ub - lb)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        self.population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = self.population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06944 with standard deviation 0.05367.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.01290506064360819, 0.014597243273523408, 0.0124767669974154, 0.052319419446050563, 0.05335205673909149, 0.05417839164984861, 0.13774113399348376, 0.14444697865088607, 0.14293891588216023]}}
{"id": "74a9a06c-099d-4481-9ba6-a8ad8f5ed8d0", "fitness": 0.07247866482369172, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Enhance exploration by increasing the randomization factor in diversity calculation and adjusting crossover probability.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.7 + 0.3 * np.random.rand()  # Adjust crossover probability range\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity with increased randomization\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1)) * (1 + np.random.rand() * 0.1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07248 with standard deviation 0.05601.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.01764132597025958, 0.014597243273523408, 0.012739126029623349, 0.05222066162353256, 0.057528897088393705, 0.052655927895141064, 0.1462803529012392, 0.15254006755947191, 0.1461043810720407]}}
{"id": "58a8e585-66b7-4602-80d8-e531419f00d7", "fitness": 0.07023181325985849, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Integrate Elite Preservation and Adaptive Neighborhood Strategies in DE to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.15  # Increased rate for stronger elite preservation\n\n    def adapt_parameters(self, diversity):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.3 * diversity  # Adjusted to increase with diversity\n        self.CR = 0.7 + 0.3 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_parameters(diversity)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedDiversityAdaptiveDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07023 with standard deviation 0.05669.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.0124767669974154, 0.04702708134520606, 0.05270855642264716, 0.051380426268693435, 0.15169355090949932, 0.14710360334355088, 0.14326638221722465]}}
{"id": "def4c6d5-93e6-438e-904c-17c8b2b02b81", "fitness": -Infinity, "name": "EnhancedDiversityAdaptiveDEOptimizer", "description": "Introduce a dynamic adaptation of the population size based on diversity to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.num_evaluations = 0\n        self.elite_rate = 0.1  # Rate of elite preservation\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment based on diversity\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n\n    def calculate_diversity(self, population):\n        # Calculate population diversity\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        \n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    self.population_size = min(20 * self.dim, max(5, int(10 * self.dim * (1 + diversity))))  # Dynamic population size adjustment\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)  # Adjusted std deviation for mutation\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            best_idx = np.argmin(fitness)\n            best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 47, "feedback": "An exception occurred: IndexError('index 285 is out of bounds for axis 0 with size 200').", "error": "IndexError('index 285 is out of bounds for axis 0 with size 200')", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {}}
{"id": "34ed4085-804d-4c5a-9179-b1a758802168", "fitness": 0.0847661619090282, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Enhance exploration and exploitation by integrating adaptive learning rate and chaotic sequence to the DE mutation strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08477 with standard deviation 0.05353.", "error": "", "parent_ids": ["ad11887d-37f3-4eaa-bcc9-3d8ce30e2032"], "operator": null, "metadata": {"aucs": [0.11277453659302084, 0.014597243273523408, 0.01286529935629066, 0.056698923011600066, 0.06111103010323948, 0.05694122819906966, 0.1631288849024649, 0.14064604501919042, 0.1441322667228544]}}
{"id": "723dd8e0-3e5e-4716-b8be-52ec1def7f3f", "fitness": 0.07080331793292921, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Fine-tune differential mutation scaling factor and improve local search intensity for better convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.9  # Increased from 0.8 to 0.9\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.15 * (ub - lb) * (1 + diversity)  # Changed from 0.1 to 0.15\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07080 with standard deviation 0.05407.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.01298663663781452, 0.014597243273523408, 0.0124767669974154, 0.054579270589346196, 0.059243486063821904, 0.05459364512211995, 0.1332802034426419, 0.14921184709794177, 0.1462607621717379]}}
{"id": "4aa5ac0a-d539-41bb-940b-d140d311c8f5", "fitness": 0.07039415795929688, "name": "EnhancedAdaptiveEliteChaoticDEOptimizer", "description": "Integrate adaptive chaotic mutation and learning from elite solutions to enhance convergence in DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveEliteChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.2\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            elite = population[:elite_size]\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                elite_choice = elite[np.random.randint(elite_size)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (elite_choice - a), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveEliteChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07039 with standard deviation 0.05524.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.013974001212741949, 0.014597243273523408, 0.014480106307321328, 0.05275801295962834, 0.04995497755256195, 0.051380426268693435, 0.14126288584604552, 0.14481043619135892, 0.150329332021797]}}
{"id": "cb344572-a300-4187-905d-5e64e65c6943", "fitness": -Infinity, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Integrate a self-adaptive parameter control mechanism with stochastic adaptive jumps to balance global exploration and local exploitation in DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self, fitness, best_fitness):\n        # Self-adaptive parameter adjustment based on fitness improvement\n        improvement_factor = (best_fitness - np.min(fitness)) / abs(best_fitness)\n        self.F = self.initial_F * (0.5 + improvement_factor * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + improvement_factor * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        best_fitness = np.min(fitness)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters(fitness, best_fitness)\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                # Stochastic adaptive jumps\n                if self.num_evaluations < self.budget:\n                    jump_prob = improvement_factor * self.initial_CR\n                    if np.random.rand() < jump_prob:\n                        jump_vector = np.random.randn(self.dim)\n                        trial += jump_vector * (ub - lb) * 0.05\n                        trial = np.clip(trial, lb, ub)\n                        trial_fitness = func(trial)\n                        self.num_evaluations += 1\n                        if trial_fitness < fitness[i]:\n                            population[i], fitness[i] = trial, trial_fitness\n\n            best_fitness = np.min(fitness)\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 51, "feedback": "An exception occurred: NameError(\"name 'improvement_factor' is not defined\").", "error": "NameError(\"name 'improvement_factor' is not defined\")", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {}}
{"id": "1c88d843-25b5-4fbc-832a-058a400ab160", "fitness": 0.082284134627157, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Integrate quadratic crossover to enhance exploration in DE mutation strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Introducing quadratic crossover; slight modification within allowed limit\n                trial = np.clip(trial + 0.1 * (mutant - trial)**2, lb, ub)\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08228 with standard deviation 0.05078.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.11194484182152054, 0.014597243273523408, 0.014354645370405317, 0.05232167241653152, 0.05395254362187751, 0.064230676286399, 0.14129106637493438, 0.14074449052765725, 0.1471200319515641]}}
{"id": "8c270846-ef1c-45a5-856b-432bf6e492b0", "fitness": 0.07169499148834567, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Enhance exploration by incorporating tournament selection and dynamic elite size adjustment.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                tournament_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[tournament_indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07169 with standard deviation 0.05668.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.012485996357570195, 0.014597243273523408, 0.012776301197759188, 0.05731018637436769, 0.04882583266447371, 0.05492138119292578, 0.15757935753417263, 0.14061751136493428, 0.14614111343538416]}}
{"id": "6ee97a72-8060-4457-8d37-cbc7925fd2d9", "fitness": 0.07355436342264694, "name": "EnhancedAdaptiveChaoticDEOptimizerV2", "description": "Utilize an enhanced adaptive chaotic DE optimizer with multi-layered selection and mutation strategies to balance global exploration and local exploitation.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07355 with standard deviation 0.05695.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.011868350215589518, 0.014597243273523408, 0.01286529935629066, 0.056698923011600066, 0.06111103010323948, 0.05694122819906966, 0.1631288849024649, 0.14064604501919042, 0.1441322667228544]}}
{"id": "1a55e03e-47a5-4919-bdf4-460236882f55", "fitness": 0.0747693242867942, "name": "EnhancedDynamicChaoticDEOptimizer", "description": "Enhance exploration and exploitation by integrating adaptive learning rate, chaotic sequence, and dynamic population size to the DE mutation strategy.", "code": "import numpy as np\n\nclass EnhancedDynamicChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def dynamic_population_size(self, current_pop_size):\n        # Reduce population size dynamically to exploit better regions\n        return max(5, current_pop_size - int(current_pop_size * 0.05))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += population_size\n        chaos_sequence = np.random.rand(population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * population_size))\n\n            for i in range(elite_size, population_size):\n                idxs = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n            # Dynamically adjust population size based on evaluations\n            population_size = self.dynamic_population_size(population_size)\n            population = population[:population_size]\n            fitness = fitness[:population_size]\n            chaos_sequence = chaos_sequence[:population_size]\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedDynamicChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07477 with standard deviation 0.05731.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.011968707657930788, 0.014597243273523408, 0.01286529935629066, 0.05797650842365143, 0.06111103010323948, 0.06224631050445051, 0.1631288849024649, 0.14398126192860683, 0.14504867243098973]}}
{"id": "f63efc4a-6693-4ae5-a73b-b0eb1dce9f8c", "fitness": 0.07134548736264158, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Enhance exploration by introducing adaptive population size scaling and incorporate Levy flight for improved diversification.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        return r * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**(beta - 1)))**(1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        return u / np.abs(v)**(1 / beta)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_candidates += self.levy_flight(3 * self.dim).reshape(3, self.dim)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n            \n            if self.num_evaluations % (self.population_size // 2) == 0:  # Adaptive scaling of population size\n                self.population_size = max(int(self.population_size * 0.9), 5)\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07135 with standard deviation 0.05618.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.014550235982926929, 0.014597243273523408, 0.012873056002503214, 0.04820711230624242, 0.053699874815810955, 0.05583994859409991, 0.1449564371209514, 0.15444960005200126, 0.14293587811571473]}}
{"id": "8e53020f-f5de-4673-8c8c-e57ed246800f", "fitness": 0.0706303613739372, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Improve convergence by adjusting initial CR to 0.95 for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.95  # Changed from 0.9 to 0.95\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07063 with standard deviation 0.05505.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.013862682994584485, 0.014597243273523408, 0.01286529935629066, 0.05753579418089927, 0.05042925122970421, 0.051380426268693435, 0.14070069346354774, 0.1493399898034572, 0.1449618717947344]}}
{"id": "15e9eccc-22c1-4d79-8e26-01f0064f6f24", "fitness": 0.06960530198644342, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Enhance global diversification by introducing a dynamic boundary scaling method during mutation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutation_scale = 1.5  # New dynamic boundary scaling factor\n                mutant = np.clip(a + self.F * (b - c) * mutation_scale, lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06961 with standard deviation 0.05509.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.0124767669974154, 0.05208397271290799, 0.0514927302587721, 0.051380426268693435, 0.13958884148683903, 0.14553716147994122, 0.14745786683893214]}}
{"id": "f4f0d1d7-8d7b-4347-8c06-7c10f671495e", "fitness": 0.07064404426055587, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Introduce a neighborhood-based perturbation mechanism and adaptive chaotic sequence scaling to refine exploration and exploitation balance in the DE strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def neighborhood_perturbation(self, individual, neighbor, lb, ub):\n        # Introduce small perturbations based on neighborhood information\n        perturbation = np.random.randn(self.dim) * 0.01 * (ub - lb)\n        return np.clip(individual + perturbation * (neighbor - individual), lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                neighbor_idx = np.random.choice(idxs)\n                trial = self.neighborhood_perturbation(trial, population[neighbor_idx], lb, ub)\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence with adaptive scaling\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            best_chaos_idx = np.argmin(fitness)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[best_chaos_idx])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[best_chaos_idx])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07064 with standard deviation 0.05606.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.011832708560966076, 0.014597243273523408, 0.012915520105133083, 0.047219485539879535, 0.05408555336621068, 0.055661325330652045, 0.15092974045687313, 0.14175041795496168, 0.14680440375680315]}}
{"id": "dbf59122-f6d1-42e1-8ddd-8c243f57b3a4", "fitness": 0.06812597493612103, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Refine the strategy by incorporating a scaled chaotic factor in the diversity calculation to enhance convergence precision.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        chaos_factor = np.mean(self.logistic_map(np.random.rand(self.population_size)))\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1)) * chaos_factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06813 with standard deviation 0.05297.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.012339119463734227, 0.014597243273523408, 0.013105581670148636, 0.047630925684567615, 0.05309151146301516, 0.05342043751654646, 0.13439363305585705, 0.14161944418198202, 0.14293587811571473]}}
{"id": "6e97a153-90e3-43d8-bf3d-1dfe279afc99", "fitness": 0.07355436342264694, "name": "EnhancedAdaptiveChaoticDEOptimizer", "description": "Enhance exploration and exploitation by integrating adaptive learning rate and chaotic sequence to the DE mutation strategy with improved elite sampling.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaoticDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        # Adaptive parameter adjustment using chaotic sequence\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        # Logistic map for generating chaotic sequence\n        return r * x * (1 - x)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    sigma = 0.1 * (ub - lb) * (1 + diversity)\n                    local_candidates = trial + np.random.randn(3, self.dim) * sigma\n                    local_candidates = np.clip(local_candidates, lb, ub)\n                    local_fitnesses = np.array([func(cand) for cand in local_candidates])\n                    self.num_evaluations += 3\n                    best_local_idx = np.argmin(local_fitnesses)\n                    if local_fitnesses[best_local_idx] < trial_fitness:\n                        population[i], fitness[i] = local_candidates[best_local_idx], local_fitnesses[best_local_idx]\n\n            # Update chaotic sequence\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveChaoticDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07355 with standard deviation 0.05695.", "error": "", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {"aucs": [0.011868350215589518, 0.014597243273523408, 0.01286529935629066, 0.056698923011600066, 0.06111103010323948, 0.05694122819906966, 0.1631288849024649, 0.14064604501919042, 0.1441322667228544]}}
{"id": "3eb140ea-cbc7-43e9-ae80-95e32b46406f", "fitness": -Infinity, "name": "EnhancedLevyDynamicDEOptimizer", "description": "Introduce Lvy flight-based perturbation and dynamic population sizing to enhance diversity and convergence in the adaptive chaotic DE strategy.", "code": "import numpy as np\n\nclass EnhancedLevyDynamicDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.elite_rate = 0.1\n        self.num_evaluations = 0\n\n    def adapt_parameters(self):\n        self.F = self.initial_F * (0.5 + 0.5 * np.random.rand())\n        self.CR = self.initial_CR * (0.8 + 0.2 * np.random.rand())\n\n    def logistic_map(self, x, r=4.0):\n        return r * x * (1 - x)\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return L * step\n\n    def calculate_diversity(self, population):\n        return np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        self.num_evaluations += self.population_size\n        chaos_sequence = np.random.rand(self.population_size)\n\n        while self.num_evaluations < self.budget:\n            self.adapt_parameters()\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite_size = max(1, int(self.elite_rate * self.population_size))\n            \n            for i in range(elite_size, self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                self.num_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                \n                if self.num_evaluations < self.budget:\n                    diversity = self.calculate_diversity(population)\n                    levy_step = self.levy_flight(0.01 * (ub - lb) * (1 + diversity))\n                    local_trial = trial + levy_step\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    self.num_evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i], fitness[i] = local_trial, local_fitness\n\n            self.population_size = max(4, int(self.population_size * 0.995))\n            population = population[:self.population_size]\n            fitness = fitness[:self.population_size]\n\n            chaos_sequence = self.logistic_map(chaos_sequence)\n            self.F = self.initial_F * (0.5 + 0.5 * chaos_sequence[np.argmin(fitness)])\n            self.CR = self.initial_CR * (0.8 + 0.2 * chaos_sequence[np.argmin(fitness)])\n\n        best_idx = np.argmin(fitness)\n        best_solution, best_fitness = population[best_idx], fitness[best_idx]\n\n        return best_solution, best_fitness", "configspace": "", "generation": 62, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["34ed4085-804d-4c5a-9179-b1a758802168"], "operator": null, "metadata": {}}
