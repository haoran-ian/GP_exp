{"id": "aa521839-c803-44f6-b305-b0c967d53561", "fitness": 0.09399713912916925, "name": "HybridPSOSA", "description": "A novel hybrid metaheuristic combining Particle Swarm Optimization (PSO) and Simulated Annealing (SA) to effectively explore and exploit the search space for robust black box optimization under strict evaluation budgets.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive weight\n        self.c2 = 1.5  # social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.99  # cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            # Evaluate current fitness\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Update personal best\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            # Update velocities and positions using PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                # Clipping to remain within bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Apply Simulated Annealing perturbation\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11389454307741842, 0.11391633432495185, 0.1139010643485644, 0.07347307682257453, 0.07348081525603267, 0.07347541217890297, 0.0946052404550376, 0.0946185287307818, 0.09460923696825907]}}
{"id": "a542be04-3c35-4dad-bcf2-52394ba86508", "fitness": 0.09400149576683416, "name": "HybridPSOSA", "description": "A refined hybrid metaheuristic integrating dynamic particle inertia and adaptive simulated annealing to enhance convergence in black box optimization under strict evaluation budgets.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9  # initial inertia weight\n        self.w_min = 0.4  # final inertia weight\n        self.c1 = 1.5  # cognitive weight\n        self.c2 = 1.5  # social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.97  # modified cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            # Evaluate current fitness\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Update personal best\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            # Dynamic inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n\n            # Update velocities and positions using PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                # Clipping to remain within bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Apply Simulated Annealing perturbation\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["aa521839-c803-44f6-b305-b0c967d53561"], "operator": null, "metadata": {"aucs": [0.11390548524458188, 0.11390860744428133, 0.11391775715926078, 0.0734769878855207, 0.0734780579486145, 0.07348137385753528, 0.09461193859442696, 0.09461380346636972, 0.09461945030091623]}}
{"id": "35e80deb-ced8-4cf0-b716-94e83c0d4809", "fitness": 0.09399983308160581, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA by fine-tuning particle updating strategy and cooling schedule for improved convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9  # initial inertia weight\n        self.w_min = 0.4  # final inertia weight\n        self.c1 = 1.5  # cognitive weight\n        self.c2 = 1.8  # slightly increased social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.95  # slightly increased cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            # Evaluate current fitness\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Update personal best\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            # Dynamic inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n\n            # Update velocities and positions using PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                # Clipping to remain within bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Apply Simulated Annealing perturbation\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a542be04-3c35-4dad-bcf2-52394ba86508"], "operator": null, "metadata": {"aucs": [0.1139165834498791, 0.11390562858379838, 0.11390203726668369, 0.07348095055433956, 0.07347699474489244, 0.07347576050105997, 0.0946187279413645, 0.09461198157034989, 0.09460983312208482]}}
{"id": "c68bc87c-3351-4104-93cc-573b07972216", "fitness": 0.09399882570103447, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive learning rates and swarm diversity preservation for improved convergence under constrained evaluation budgets.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9  # initial inertia weight\n        self.w_min = 0.4  # final inertia weight\n        self.c1_initial = 1.5  # initial cognitive weight\n        self.c2_initial = 1.5  # initial social weight\n        self.c1_final = 0.5    # final cognitive weight\n        self.c2_final = 2.0    # final social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.97  # modified cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            c1 = self.c1_initial + ((self.c1_final - self.c1_initial) * (self.current_evals / self.budget))\n            c2 = self.c2_initial + ((self.c2_final - self.c2_initial) * (self.current_evals / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a542be04-3c35-4dad-bcf2-52394ba86508"], "operator": null, "metadata": {"aucs": [0.11391360240326454, 0.11391493768134897, 0.11389110110014822, 0.07347988767163838, 0.07348031700120705, 0.07347185875918305, 0.09461690584750515, 0.09461767476988803, 0.09460314607512688]}}
{"id": "7f65eff1-4c07-489d-b91b-31352f7f1654", "fitness": 0.09400231670874698, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid metaheuristic combining adaptive neighborhood-based perturbation and dynamic convergence acceleration for improved black box optimization performance under limited evaluation budgets.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a542be04-3c35-4dad-bcf2-52394ba86508"], "operator": null, "metadata": {"aucs": [0.11390703503713984, 0.11391782324313982, 0.11391074286777592, 0.07347754130077422, 0.07348134663378947, 0.07347887259943586, 0.09461288673881652, 0.09461943932301853, 0.0946151626348326]}}
{"id": "26b5456f-ae2c-45ce-8d74-b7e3b78356aa", "fitness": 0.0939984986959961, "name": "EnhancedHybridPSOSA", "description": "A refined hybrid metaheuristic introducing adaptive inertia weight updating and neighborhood search strategy to enhance convergence and exploration in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget)**0.5)  # Adaptive inertia weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * np.random.rand() * (func.bounds.ub - func.bounds.lb)  # Improved neighborhood search\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11391592148130869, 0.11391068017818318, 0.11389154652198286, 0.07348071444730242, 0.07347879750917818, 0.07347201661618763, 0.09461832324147001, 0.09461507092792332, 0.09460341734042854]}}
{"id": "10642da7-15ae-4abe-8023-c163682f70ed", "fitness": 0.09400137886227374, "name": "EnhancedHybridPSOSA", "description": "Fine-tune inertia weight adaptation for better balance between exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * ((self.current_evals + 1) / self.budget))  # Adjusted\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11391107891766694, 0.11391471663239328, 0.11390551999066578, 0.07347898544301767, 0.07348023781060686, 0.07347700556661807, 0.09461536085360467, 0.09461753926950434, 0.09461196527638605]}}
{"id": "7f05ad1a-aa8d-496a-b277-9b7a29a63c32", "fitness": 0.09399925310737546, "name": "RefinedHybridPSOSA", "description": "A refined hybrid metaheuristic integrating adaptive neighborhood mutation and temperature-based convergence control for enhanced black box optimization efficiency within constrained evaluation budgets.", "code": "import numpy as np\n\nclass RefinedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                adaptive_radius = np.random.rand() * self.neighbor_radius # Adaptive neighborhood\n                perturbation = np.random.uniform(-adaptive_radius, adaptive_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.98  # Modified shrink rate\n\n        return self.best_global_position", "configspace": "", "generation": 7, "feedback": "The algorithm RefinedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11391048367780199, 0.11390132618155002, 0.11390978714285638, 0.073478773845716, 0.07347545988865656, 0.07347852607949967, 0.09461499768273773, 0.09460935095179102, 0.09461457251576977]}}
{"id": "50763132-1545-414e-955d-a9528e17a26b", "fitness": 0.09400232204793393, "name": "EnhancedHybridPSOSA", "description": "Introduced a dynamic adaptation of personal best update to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Changed line: Introduce dynamic adaptation of personal best update\n                if fitness_value < personal_best_values[i] or np.random.rand() < np.exp(-(self.current_evals / self.budget)):\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11390602049845722, 0.11391786776482449, 0.11391173764592533, 0.07347717904386886, 0.07348136251836501, 0.07347922747033031, 0.09461226608146867, 0.09461946654655506, 0.09461577086161044]}}
{"id": "c3b5a1c1-b624-4cc4-816a-212f90dc5f53", "fitness": 0.09400326869802461, "name": "GeneticHybridPSOSA", "description": "Introduce adaptive crossover and mutation strategies inspired by genetic algorithms to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass GeneticHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n        self.crossover_rate = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i] or np.random.rand() < np.exp(-(self.current_evals / self.budget)):\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.crossover_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    particles[i, cross_point:], particles[i+1, cross_point:] = particles[i+1, cross_point:], particles[i, cross_point:]\n                    \n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        particles[i][j] += np.random.uniform(-self.neighbor_radius, self.neighbor_radius)\n                        particles[i+1][j] += np.random.uniform(-self.neighbor_radius, self.neighbor_radius)\n\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                particles[i+1] = np.clip(particles[i+1], func.bounds.lb, func.bounds.ub)\n            \n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99\n        \n        return self.best_global_position", "configspace": "", "generation": 9, "feedback": "The algorithm GeneticHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["50763132-1545-414e-955d-a9528e17a26b"], "operator": null, "metadata": {"aucs": [0.1139157178645962, 0.11391518940320478, 0.11390904800871804, 0.07348064227636808, 0.07348040682312806, 0.07347826386823875, 0.09461819922843495, 0.09461782870262048, 0.09461412210691222]}}
{"id": "cd7a1185-d2c6-4142-86f5-68ad396ddd8d", "fitness": 0.09400092785351156, "name": "GeneticHybridPSOSA", "description": "Introduce a dynamic swarm neighborhood adjustment and elitist selection strategy to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass GeneticHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            elite_indices = np.argsort(personal_best_values)[:10]\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.crossover_rate:\n                    parent1, parent2 = np.random.choice(elite_indices, 2, replace=False)\n                    cross_point = np.random.randint(1, self.dim)\n                    particles[parent1, cross_point:], particles[parent2, cross_point:] = particles[parent2, cross_point:], particles[parent1, cross_point:]\n                    \n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        particles[i][j] += np.random.uniform(-w, w)\n                        particles[i+1][j] += np.random.uniform(-w, w)\n\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                particles[i+1] = np.clip(particles[i+1], func.bounds.lb, func.bounds.ub)\n            \n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 10, "feedback": "The algorithm GeneticHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["c3b5a1c1-b624-4cc4-816a-212f90dc5f53"], "operator": null, "metadata": {"aucs": [0.1138982012009665, 0.11391810731259311, 0.11391294427910414, 0.07347439061017746, 0.073481447928058, 0.07347965478609897, 0.09460748621685022, 0.09461961296420052, 0.09461650538355515]}}
{"id": "b21aab3e-1683-4a76-8a02-c1ba62fd445d", "fitness": 0.09400349177819146, "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration and exploitation by incorporating adaptive differential evolution strategies with self-adaptive control of crossover and mutation rates.  ", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["c3b5a1c1-b624-4cc4-816a-212f90dc5f53"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391826775337466, 0.1139111773851913, 0.07347914662019295, 0.0734815051894172, 0.07347902614798674, 0.09461563655251182, 0.09461971108845968, 0.09461542679919144]}}
{"id": "2d1ea307-247b-48cc-86cb-59bced543056", "fitness": 0.0939573917098222, "name": "AdaptiveDifferentialEvolution", "description": "Improve convergence by introducing chaotic local search using tent map for exploration and diversity enhancement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n                \n                # Chaotic local search using tent map\n                chaotic_factor = 0.7\n                chaotic_factor = 2 * chaotic_factor if chaotic_factor < 0.5 else 2 * (1 - chaotic_factor)\n                mutant_vector = chaotic_factor * func.bounds.lb + (1 - chaotic_factor) * func.bounds.ub\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09396 with standard deviation 0.01649.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11388294193892678, 0.11387229845824298, 0.11377500949598018, 0.07346894454097186, 0.0734650979540401, 0.0734303825751893, 0.09459815374012903, 0.09459159583225862, 0.09453210085266095]}}
{"id": "27d201a4-374d-4892-af7a-b51f83df7113", "fitness": 0.09399813569328608, "name": "AdaptiveDifferentialEvolution", "description": "Integrate a dynamic mutation factor adjustment and enhance exploration by introducing a greedy selection mechanism.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            if self.best_global_value < fitness_values.mean():  # Greedy selection mechanism\n                self.mutation_f *= 1.1\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 13, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391167732180452, 0.11391781869547923, 0.1138869889269869, 0.07347919973226058, 0.07348134497542091, 0.07347039371863351, 0.09461572757606618, 0.09461943650507665, 0.09460063378784622]}}
{"id": "6982793b-d006-4474-9741-f7155844c2da", "fitness": 0.09400186303079035, "name": "AdaptiveDifferentialEvolution", "description": "Enhance the algorithm by incorporating dynamic scaling of the mutation factor based on improvement in fitness values to maintain diversity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Dynamic adjustment of mutation factor based on fitness improvement\n            improvement = np.max(fitness_values) - np.min(fitness_values)\n            self.mutation_f = 0.8 * (1 - improvement / (np.max(fitness_values) + 1e-6))\n        \n        return self.best_global_position", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391164047332059, 0.11391781869547923, 0.11390068265721098, 0.0734803040986598, 0.07348158764263701, 0.07347556486820495, 0.09461563655251182, 0.09461964096149744, 0.09461389132759135]}}
{"id": "af543eb9-3647-418f-9faa-5bdc7523ddc9", "fitness": 0.09400108233767701, "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic population size adjustment and adaptive mutation scaling to enhance convergence.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            self.population_size = max(20, int(self.population_size * (1 - self.current_evals / self.budget)))\n            self.mutation_f *= 1 + self.adaptive_factor * np.sin(np.pi * self.current_evals / self.budget)\n        \n        return self.best_global_position", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391167894445564, 0.11391781869547923, 0.11390045933924975, 0.07347920031186095, 0.07348134497542091, 0.07347520141243469, 0.09461572856898404, 0.09461943650507665, 0.09460887228613124]}}
{"id": "0e8fbcbb-6855-43f5-bc77-4e4193c2d1c6", "fitness": 0.0939971459542645, "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by incorporating a dynamic learning rate factor for adaptive mutation control and introduce a probabilistic selection of trial vectors based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i] and np.random.rand() < 0.5 + 0.5 * (fitness_values[i] - trial_fitness) / (fitness_values[i] + 1e-9):\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f = 0.5 + 0.5 * (self.best_global_value / (np.mean(fitness_values) + 1e-9))  # Dynamic learning rate\n        \n        return self.best_global_position", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391077991834264, 0.11389838943953534, 0.11389186381607486, 0.07347974003449931, 0.07347697043207724, 0.07347782781148204, 0.09461517837407973, 0.09461193229306197, 0.09461163146922735]}}
{"id": "3092ff6f-4357-448f-9ae3-f07987215072", "fitness": 0.09400327717253457, "name": "DynamicAdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and adaptive selection pressure to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamic population resizing to enhance exploration-exploitation\n            if self.current_evals < self.budget / 2:\n                self.population_size = min(self.population_size + 1, 2 * self.initial_population_size)\n            else:\n                self.population_size = max(self.population_size - 1, self.initial_population_size // 2)\n            new_population = np.random.uniform(\n                low=func.bounds.lb,\n                high=func.bounds.ub,\n                size=(self.population_size, self.dim)\n            )\n            population = np.vstack((population[:self.population_size], new_population))\n            fitness_values = np.concatenate((fitness_values[:self.population_size], np.full(self.population_size, float('inf'))))\n\n        return self.best_global_position", "configspace": "", "generation": 17, "feedback": "The algorithm DynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11391064493504754, 0.07347914662019295, 0.07348134497542091, 0.07347883637596953, 0.09461563655251182, 0.09461943650507665, 0.09461510142571505]}}
{"id": "ba5f134b-67cf-4e09-8376-0278783e286a", "fitness": 0.09400259257452487, "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size adjustment based on convergence to enhance adaptability and improve optimization performance.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Dynamic adjustment of population size\n            self.population_size = max(20, int(50 * (1 - (self.current_evals / self.budget))))\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390751525499776, 0.07347914662019295, 0.07348134497542091, 0.07347771908201417, 0.09461563655251182, 0.09461943650507665, 0.09461318701763288]}}
{"id": "3f40d5be-a9eb-4c81-85cf-1d02feabca01", "fitness": 0.09400349177819146, "name": "DynamicAdaptiveDifferentialEvolution", "description": "Enhance exploration and exploitation by introducing dynamic population size adaptation and differential evolution strategies with adaptive crossover and mutation rates.", "code": "import numpy as np\n\nclass DynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        dynamic_population_size = self.initial_population_size\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(dynamic_population_size, self.dim)\n        )\n        fitness_values = np.full(dynamic_population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(dynamic_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(dynamic_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(dynamic_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamic population size adjustment\n            if (self.current_evals / self.budget) > 0.5 and dynamic_population_size > 10:\n                dynamic_population_size = int(dynamic_population_size * 0.9)\n                population = population[:dynamic_population_size]\n                fitness_values = fitness_values[:dynamic_population_size]\n        \n        return self.best_global_position", "configspace": "", "generation": 19, "feedback": "The algorithm DynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391826775337466, 0.1139111773851913, 0.07347914662019295, 0.0734815051894172, 0.07347902614798674, 0.09461563655251182, 0.09461971108845968, 0.09461542679919144]}}
{"id": "08f2ee16-06f1-4aad-ab15-14bf6f5b0b26", "fitness": 0.09400349177819146, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrate adaptive differential evolution with a dynamic population size and diversity preservation to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.current_population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.initial_population_size, self.dim)\n        )\n        fitness_values = np.full(self.initial_population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.current_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.current_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Adjust population size based on diversity\n            diversity = np.std(population, axis=0).mean()\n            if diversity < self.diversity_threshold:\n                self.current_population_size = max(10, self.current_population_size // 2)\n            else:\n                self.current_population_size = min(self.initial_population_size, self.current_population_size + 1)\n\n        return self.best_global_position", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391826775337466, 0.1139111773851913, 0.07347914662019295, 0.0734815051894172, 0.07347902614798674, 0.09461563655251182, 0.09461971108845968, 0.09461542679919144]}}
{"id": "9d53ed28-b73d-4b74-a246-338669e31d61", "fitness": 0.09400259257452487, "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive population size to enhance convergence dynamics and improve solution quality.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Adaptive population size adjustment\n            self.population_size = max(10, int(50 * (1 - self.current_evals / self.budget)))\n        \n        return self.best_global_position", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390751525499776, 0.07347914662019295, 0.07348134497542091, 0.07347771908201417, 0.09461563655251182, 0.09461943650507665, 0.09461318701763288]}}
{"id": "9a3fa871-f586-4102-b02c-743131fb607f", "fitness": 0.09400342035688133, "name": "AdaptiveDifferentialEvolution", "description": "Integrate dynamic population resizing to improve the balance between exploration and exploitation over time.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            current_population_size = max(5, int(self.population_size * (1 - self.current_evals / self.budget)))  # Dynamic resizing\n            for i in range(current_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391406921795144, 0.11391781869547923, 0.11390875925580168, 0.07348005316766171, 0.07348134497542091, 0.07347816320907896, 0.09461719019922987, 0.09461943650507665, 0.09461394798623157]}}
{"id": "1a739c43-7b5e-439e-a608-38a8c8b297ac", "fitness": 0.09398692769068676, "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduce a novel swarm-inspired mechanism that dynamically adjusts mutation strategies based on convergence trends to enhance optimization performance.", "code": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.inertia_weight = 0.5\n        self.velocity = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = (\n                    self.inertia_weight * self.velocity[i]\n                    + (1 - self.inertia_weight) * (a + self.mutation_f * (b - c))\n                )\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    self.velocity[i] = mutant_vector - population[i]\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Dynamic adjustment of parameters\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f *= 1 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.inertia_weight = 0.4 + 0.6 * (1 - self.current_evals / self.budget)\n        \n        return self.best_global_position", "configspace": "", "generation": 23, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11388391290736932, 0.1138988011764841, 0.11388255239995837, 0.07346928561455324, 0.07347455857305696, 0.07346879031956444, 0.09459874192472528, 0.094607806533749, 0.09459789976672006]}}
{"id": "b427629a-2afb-49d7-865c-24309c4989fe", "fitness": 0.09399647120254967, "name": "AdaptiveDifferentialEvolution", "description": "Introduce tournament selection for improved diversity and exploration in adaptive differential evolution.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                tournament_indices = np.random.choice(idxs, 5, replace=False)\n                tournament_winner = min(tournament_indices, key=lambda idx: fitness_values[idx])\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11390626094115464, 0.11390268407875004, 0.11389993433863743, 0.0734772673037355, 0.07347594380831379, 0.07347500851283728, 0.09461241566416534, 0.09461018069151006, 0.0946085454838429]}}
{"id": "35c2ec21-8d90-4202-a0dd-bf6f11ea938e", "fitness": 0.09400259257452487, "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size adjustment based on convergence to enhance solution diversity and adaptability.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment of crossover rate, mutation factor, and population size\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.population_size = max(10, int(50 * (1 - (self.current_evals / self.budget))))  # Adjust population size\n\n        return self.best_global_position", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390751525499776, 0.07347914662019295, 0.07348134497542091, 0.07347771908201417, 0.09461563655251182, 0.09461943650507665, 0.09461318701763288]}}
{"id": "a76716b6-36f7-4fd4-b7fd-179be2c73df7", "fitness": 0.09399344592562955, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and elitism to enhance convergence speed and solution quality by adjusting exploration-exploitation balance based on budget exhaustion.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.elitism_rate = 0.2\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            elite_size = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness_values)[:elite_size]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i and idx not in elite_indices]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamically resize population based on budget utilization\n            if self.current_evals < self.budget * 0.5:\n                self.population_size = int(self.initial_population_size * 1.2)\n            else:\n                self.population_size = int(self.initial_population_size * 0.8) \n\n            # Maintain the elite solutions\n            new_population = np.copy(population[elite_indices])\n            new_population = np.vstack([new_population, np.random.uniform(\n                low=func.bounds.lb,\n                high=func.bounds.ub,\n                size=(self.population_size - elite_size, self.dim)\n            )])\n            population = new_population\n            fitness_values = np.full(self.population_size, float('inf'))\n            for idx in range(elite_size):\n                fitness_values[idx] = func(population[idx])\n        \n        return self.best_global_position", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11390492544266051, 0.11388941582509071, 0.11390070906541949, 0.0734767894517474, 0.07347120820139519, 0.07347528384912816, 0.09461159762973115, 0.09460206576608488, 0.09460901809940847]}}
{"id": "a7e817d1-6401-4345-a74b-0fce2a3af9d2", "fitness": 0.09400274073045863, "name": "DynamicPopulationAdaptiveDE", "description": "Introduce dynamic population size and adaptive local search to enhance convergence and diversity in adaptive differential evolution.", "code": "import numpy as np\n\nclass DynamicPopulationAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 50\n        self.current_pop_size = self.initial_pop_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.initial_pop_size, self.dim)\n        )\n        fitness_values = np.full(self.initial_pop_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.current_pop_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.current_pop_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamic population resizing\n            self.current_pop_size = max(5, self.initial_pop_size - int((self.current_evals / self.budget) * self.initial_pop_size))\n            population = population[:self.current_pop_size]\n            fitness_values = fitness_values[:self.current_pop_size]\n\n            # Local search around the current best position\n            local_search_radius = (func.bounds.ub - func.bounds.lb) * 0.01\n            local_search = self.best_global_position + np.random.uniform(-local_search_radius, local_search_radius, self.dim)\n            local_search = np.clip(local_search, func.bounds.lb, func.bounds.ub)\n            local_fitness = func(local_search)\n            self.current_evals += 1\n\n            if local_fitness < self.best_global_value:\n                self.best_global_value = local_fitness\n                self.best_global_position = local_search\n        \n        return self.best_global_position", "configspace": "", "generation": 27, "feedback": "The algorithm DynamicPopulationAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391349447372767, 0.11391781869547923, 0.11390622634397396, 0.07347984808919206, 0.07348134497542091, 0.07347725953707207, 0.09461683873986804, 0.09461943650507665, 0.09461239921431708]}}
{"id": "7ba94d92-5fad-419a-9cd1-38fd789df81f", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce dynamic population sizing and adaptive mutation strategies to enhance convergence and exploration in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "386bfb57-e427-4323-9d1c-02803ddb9122", "fitness": 0.09400298470624124, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce a random restart mechanism to enhance diversification and escape local optima in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.restart_threshold = 20  # New restart threshold parameter\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n            \n            # Random restart mechanism\n            if self.current_evals % self.restart_threshold == 0:\n                population = np.random.uniform(\n                    low=func.bounds.lb,\n                    high=func.bounds.ub,\n                    size=(self.population_size, self.dim)\n                )\n                fitness_values = np.full(self.population_size, float('inf'))\n\n        return self.best_global_position", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391477465801392, 0.11391781869547923, 0.11390606156021554, 0.07348030486136248, 0.07348134497542091, 0.0734772009129917, 0.09461762155990783, 0.09461943650507665, 0.09461229862770293]}}
{"id": "41e2ea10-da2e-44f9-8653-fb2f4c3f1868", "fitness": 0.09400273400705013, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive scaling of mutation factor based on fitness variance to improve convergence in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + np.var(fitness_values) * self.adaptive_factor\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391390686754743, 0.11391781869547923, 0.11390477287841383, 0.0734799952733679, 0.07348134497542091, 0.07347818754656632, 0.09461709092979753, 0.09461943650507665, 0.09461205239178139]}}
{"id": "752ab317-7bec-47f6-b541-597fe0d65bce", "fitness": 0.09399708307119192, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Modify the trial vector selection criterion to include a small probability for random exploration, enhancing diversity and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or np.random.rand() < 0.05:  # Added exploration\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11389191361948969, 0.11390229947436525, 0.11391746060477947, 0.07347214577956884, 0.07347580696970235, 0.07348126721500625, 0.09460363996428611, 0.09460994591237626, 0.09461926810115306]}}
{"id": "83375837-0b84-4c1e-9c6c-6d55c25be1b1", "fitness": 0.09400283789767978, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce fitness sharing and temporal diversity preservation to balance exploration and exploitation in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.sharing_sigma = 0.1\n\n    def fitness_sharing(self, fitness_values, population):\n        shared_fitness = np.copy(fitness_values)\n        for i in range(self.population_size):\n            sharing_sum = 0\n            for j in range(self.population_size):\n                distance = np.linalg.norm(population[i] - population[j])\n                if distance < self.sharing_sigma:\n                    sharing_sum += 1 - (distance / self.sharing_sigma)\n            if sharing_sum > 0:\n                shared_fitness[i] /= sharing_sum\n        return shared_fitness\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            shared_fitness = self.fitness_sharing(fitness_values, population)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < shared_fitness[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(shared_fitness)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391650885072802, 0.11391781869547923, 0.11390365670249047, 0.07348092359604208, 0.07348134497542091, 0.07347634228797895, 0.09461868197185297, 0.09461943650507665, 0.09461082749404881]}}
{"id": "d8a5e15f-c2b8-4d5e-9b39-af683db73d9f", "fitness": 0.09400115555352656, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation scaling that increases exploitation as evaluations progress in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Adjust mutation factor dynamically to enhance exploitation\n            self.mutation_f *= (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391439135827375, 0.11391849593811465, 0.11389740497505152, 0.07348016810632108, 0.07348158660011117, 0.07347411112970204, 0.0946173871831314, 0.0946198506148741, 0.0946070040761593]}}
{"id": "b4c656c3-5594-42b7-bbc5-197e09062256", "fitness": 0.09400115555352656, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation factor decay to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Adjust mutation factor decay to favor exploitation towards the end\n            self.mutation_f *= (1 - (self.current_evals / self.budget))\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391439135827375, 0.11391849593811465, 0.11389740497505152, 0.07348016810632108, 0.07348158660011117, 0.07347411112970204, 0.0946173871831314, 0.0946198506148741, 0.0946070040761593]}}
{"id": "6a6f7721-2de5-40cb-8ac8-503ae0298d9c", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce an adaptive learning rate to fine-tune exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "738ee77a-5bbb-4b4b-aee3-69508bb19122", "fitness": 0.09400220605920807, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhance exploration by dynamically adjusting mutation factor's range to improve search capability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.5 + 0.3 * np.random.rand()  # Adjusted line to add randomness\n           \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.1139165643729938, 0.11391781869547923, 0.11390071197337781, 0.07348094341033384, 0.07348134497542091, 0.07347529172516487, 0.09461871592721749, 0.09461943650507665, 0.09460902694780804]}}
{"id": "c3f66284-9856-4c1a-b35d-368c2b3495af", "fitness": 0.0940017574374914, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Introduce adaptive learning rates and topological neighborhood restructuring to enhance convergence in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.learning_rate = 0.1  # Initial learning rate for adaptive adjustments\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                # Select neighborhood dynamically\n                idxs = np.random.choice(range(self.population_size), size=3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(range(self.population_size), size=3, replace=False)\n                a, b, c = population[idxs]\n                \n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = max(0.1, 0.9 - self.adaptive_factor * (self.current_evals / self.budget))\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Learning rate adaptation\n            self.learning_rate *= (1 - self.current_evals / self.budget)\n\n            # Dynamic population resizing with learning rate influence\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.learning_rate)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 37, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.1139079537037857, 0.11391756123468211, 0.11390752920843095, 0.07347786973793224, 0.07348125306297493, 0.07347772513671191, 0.0946134491718631, 0.09461927901868317, 0.09461319666235846]}}
{"id": "1d39ffac-f938-4897-8954-e936d2fb62f3", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhance exploration by integrating a random reinitialization strategy and adjusting mutation dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n            # Random reinitialization for exploration\n            if self.current_evals % (self.budget // 10) == 0:  # Line 1 change\n                random_idx = np.random.choice(self.population_size)  # Line 2 change\n                population[random_idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Line 3 change\n\n        return self.best_global_position", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "52b6bc9a-5e54-47f6-bf51-d6030d0c4c99", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrate a selection diversity mechanism and restart strategy to mitigate premature convergence in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.diversity_threshold = 1e-5\n        self.restart_allowed = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n            # Check for diversity and restart if necessary\n            if np.std(population) < self.diversity_threshold and self.restart_allowed:\n                population = np.random.uniform(\n                    low=func.bounds.lb,\n                    high=func.bounds.ub,\n                    size=(self.population_size, self.dim)\n                )\n                fitness_values = np.full(self.population_size, float('inf'))\n                self.restart_allowed = False  # Allow only one restart\n\n        return self.best_global_position", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "8fa993ec-cc70-4100-80f7-ca936d019680", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrate a diversity maintenance strategy and mutation rate self-adaptation in Enhanced Adaptive Differential Evolution to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Diversity maintenance strategy\n            if np.std(fitness_values) < self.diversity_threshold:\n                self.mutation_f = min(1.0, self.mutation_f + 0.1)\n\n            # Dynamic population resizing\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.current_evals / self.budget)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "3ae59c20-5388-47b2-88e3-bde1f3d5e112", "fitness": 0.09399648236229843, "name": "EnhancedAdaptiveDifferentialEvolutionWithOBL", "description": "Integrate opposition-based learning and a dynamic inertia weight in Enhanced Adaptive Differential Evolution to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionWithOBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def opposition_based_learning(self, population, bounds):\n        min_b, max_b = bounds.lb, bounds.ub\n        return min_b + max_b - population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.uniform(\n            low=bounds.lb,\n            high=bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            opposite_population = self.opposition_based_learning(population, bounds)\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                fitness_value_opp = func(opposite_population[i])\n                self.current_evals += 1\n\n                if fitness_value_opp < fitness_values[i]:\n                    population[i] = opposite_population[i]\n                    fitness_values[i] = fitness_value_opp\n                    if fitness_value_opp < self.best_global_value:\n                        self.best_global_value = fitness_value_opp\n                        self.best_global_position = opposite_population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, bounds.lb, bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionWithOBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391968519705487, 0.11391743307319502, 0.11387180933572794, 0.07348205805305463, 0.07348120727985574, 0.07346497419817466, 0.0946206254455153, 0.09461920059242268, 0.09459134808568503]}}
{"id": "7dbd42ce-72c3-4695-97f8-991c5d47646c", "fitness": 0.09400203621332472, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce chaotic maps for parameter adaptation and an elitism mechanism to improve convergence and robustness in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\nimport math\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.elitism_rate = 0.1\n        self.logistic_map_r = 4.0\n        self.logistic_map_x = 0.5\n\n    def chaotic_map(self):\n        self.logistic_map_x = self.logistic_map_r * self.logistic_map_x * (1 - self.logistic_map_x)\n        return self.logistic_map_x\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment using chaotic maps\n            self.crossover_rate = 0.7 + 0.2 * self.chaotic_map()\n            self.mutation_f = 0.5 + 0.3 * self.chaotic_map()\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n            # Elitism mechanism\n            num_elites = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness_values)[:num_elites]\n            elites = population[elite_indices]\n\n            # Replace some non-elite individuals with elites\n            non_elite_indices = np.setdiff1d(range(self.population_size), elite_indices)\n            np.random.shuffle(non_elite_indices)\n            replace_indices = non_elite_indices[:num_elites]\n            population[replace_indices] = elites\n\n        return self.best_global_position", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391574877852217, 0.11391781869547923, 0.11390075092089125, 0.07348065240815471, 0.07348134497542091, 0.07347530564524218, 0.09461821720287455, 0.09461943650507665, 0.09460905078826076]}}
{"id": "b97eb8da-b2c4-434c-a73d-78200b61a008", "fitness": 0.0935420964539772, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce fitness diversity-based mutation and a memory-based adaptive control strategy to improve convergence in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.memory_mutation = self.mutation_f  # New line\n        self.memory_crossover = self.crossover_rate  # New line\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            # Calculate diversity (new block)\n            fitness_std = np.std(fitness_values)\n            diversity_factor = 1.0 / (1.0 + fitness_std)\n            \n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                # Use diversity-based mutation\n                mutant_vector = a + self.memory_mutation * diversity_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Memory-based adaptive control\n            self.memory_crossover = (self.memory_crossover + self.crossover_rate) / 2\n            self.memory_mutation = (self.memory_mutation + self.mutation_f) / 2\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget) + self.memory_crossover / 5\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget)) + self.memory_mutation / 5\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09354 with standard deviation 0.01652.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11346592539446954, 0.11346193981918484, 0.11344572022745736, 0.07301466049105043, 0.07301318961565073, 0.07301040113760204, 0.09416101553729894, 0.09415708382538823, 0.09414893203769259]}}
{"id": "de3155a6-2652-4a52-bb4f-626a2897bcf8", "fitness": 0.09400102946214273, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Introduce self-adaptive mechanisms for both crossover rate and mutation factor, along with fitness-based dynamic population resizing to further enhance convergence and exploration in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Self-adaptive adjustment of crossover rate and mutation factor\n            successful_trials = (fitness_values < self.best_global_value).sum()\n            success_ratio = successful_trials / self.population_size\n            self.crossover_rate = np.clip(0.9 - success_ratio * self.adaptive_factor, 0.1, 0.9)\n            self.mutation_f = np.clip(0.8 + success_ratio * self.adaptive_factor, 0.4, 1.2)\n            \n            # Fitness-based dynamic population resizing\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.current_evals / self.budget)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 44, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391185853817909, 0.11391796136714916, 0.11389989513708543, 0.07347926438740593, 0.07348139587747027, 0.07347500026976783, 0.09461583838476428, 0.09461952374379978, 0.09460852745366277]}}
{"id": "1b96dcf3-f0bc-4cc7-8bc3-56ed2d5c4dad", "fitness": 0.09399139673497237, "name": "RefinedEnhancedAdaptiveDifferentialEvolution", "description": "Incorporate a self-adaptive learning mechanism for mutation and crossover rates along with a memory-based elitism strategy to optimize performance in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass RefinedEnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.elite_memory = []\n        self.memory_size = 5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n                    self.elite_memory.append((fitness_value, population[i]))\n                    self.elite_memory.sort(key=lambda x: x[0])\n                    if len(self.elite_memory) > self.memory_size:\n                        self.elite_memory.pop()\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                if np.random.rand() < 0.1 and self.elite_memory:\n                    a, _ = self.elite_memory[np.random.randint(len(self.elite_memory))]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            self.crossover_rate = np.tanh(0.9 - self.adaptive_factor * (self.current_evals / self.budget))\n            self.mutation_f = np.tanh(0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget)))\n            \n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 45, "feedback": "The algorithm RefinedEnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01650.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11389947375800535, 0.11388651759247825, 0.11388038689612567, 0.07347384399036416, 0.07347907675358545, 0.07347167153555068, 0.09460498165512587, 0.09461725107949148, 0.09460936735402437]}}
{"id": "cc120213-2294-4460-8916-452533c79702", "fitness": 0.09400212700455371, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Adjust the adaptive factor to improve balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.08  # Modified adaptive factor for improved performance\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391390938505053, 0.11391823438129323, 0.11390258969413103, 0.07347999614365874, 0.07348149328290576, 0.07347596177255, 0.0946170924679195, 0.09461969068245757, 0.094610175231017]}}
{"id": "8f345c86-9b1f-4af8-ab56-578f3400cc74", "fitness": 0.09400174631386352, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Incorporate adaptive learning rates and self-adaptive differential weights to enhance convergence efficiency in an advanced differential evolution algorithm.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.learning_rate = 0.1  # New adaptive learning rate\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate, mutation factor, and learning rate\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.learning_rate *= (1 - self.adaptive_factor * (self.current_evals / self.budget))  # New update rule\n            \n            # Self-adaptive differential weights\n            if np.random.rand() < self.learning_rate:\n                self.mutation_f *= np.random.uniform(0.9, 1.1)\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391341955696932, 0.11391781869547923, 0.11390175461779506, 0.07347982136617037, 0.07348134497542091, 0.07347566370037284, 0.09461679293677272, 0.09461943650507665, 0.0946096644707145]}}
{"id": "f2b6b33c-800a-436e-bd1e-75de73200594", "fitness": 0.09400100007835546, "name": "SelfAdaptiveCrowdedDifferentialEvolution", "description": "Implement a self-adaptive crowding distance and mutation strategy in Differential Evolution to balance exploration and exploitation and improve solution diversity.", "code": "import numpy as np\n\nclass SelfAdaptiveCrowdedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Self-adaptive crowding distance calculation\n            distances = np.zeros(self.population_size)\n            for i in range(self.population_size):\n                distances[i] = np.sum((population[i] - self.best_global_position) ** 2)\n            distances = np.sqrt(distances)\n\n            # Adaptive adjustment of crossover rate and mutation factor based on crowding distance\n            max_distance = np.max(distances)\n            min_distance = np.min(distances)\n            if max_distance > 0:\n                crowding_factor = (distances - min_distance) / (max_distance - min_distance)\n            else:\n                crowding_factor = np.zeros_like(distances)\n            \n            self.crossover_rate = 0.9 - self.adaptive_factor * crowding_factor.mean()\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - crowding_factor.mean())\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 48, "feedback": "The algorithm SelfAdaptiveCrowdedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390023349650358, 0.07347914662019295, 0.07348134497542091, 0.07347512101594444, 0.09461563655251182, 0.09461943650507665, 0.09460873437667217]}}
{"id": "fe28d493-db58-479b-b1ca-27d6a31e96d7", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Integrate a dynamic mutation factor adjustment based on fitness improvement history and incorporate elitism to retain the best solutions in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "f613bb00-b2fa-42a6-90b9-28da4a7f947b", "fitness": 0.09400329026602998, "name": "RefinedEnhancedAdaptiveDifferentialEvolution", "description": "Incorporate a strategy that dynamically adjusts learning rates and implements adaptive parameter control based on diversity and convergence metrics in an Enhanced Adaptive Differential Evolution framework to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedEnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor based on diversity\n            diversity = np.mean(np.std(population, axis=0))\n            self.crossover_rate = max(0.5, 0.9 - self.adaptive_factor * diversity)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing with minimum size and based on convergence\n            convergence_metric = np.std(fitness_values)\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.current_evals / self.budget) * (convergence_metric / self.diversity_threshold)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 50, "feedback": "The algorithm RefinedEnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391327150633057, 0.11391781869547923, 0.11390896214115076, 0.07347976854016314, 0.07348134497542091, 0.07347823558864974, 0.09461670240401743, 0.09461943650507665, 0.09461407203798133]}}
{"id": "3944d372-b3cc-46af-afdd-bb429bf0c851", "fitness": 0.0939924941000826, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Refine mutation strategy by introducing random scaling of difference vectors and a probability-based elitism mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                scaling_factor = np.random.rand()  # Randomized scaling factor\n                mutant_vector = a + scaling_factor * self.mutation_f * (b - c)  # Random scaling\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11387829531199745, 0.11391376349749815, 0.11389863867674321, 0.07346728323427731, 0.07347989815435063, 0.07347454762352479, 0.09459530887567213, 0.09461695687593397, 0.09460775465074578]}}
{"id": "a469c46f-c4e1-4e5a-9a6e-ccfcf19bcd9b", "fitness": 0.09399979682696981, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a stochastic crossover rate in Enhanced Adaptive Differential Evolution to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:  # Stochastic crossover rate\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            self.crossover_rate = np.random.rand() * (0.9 - self.adaptive_factor * (self.current_evals / self.budget))\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391275675025003, 0.11391781869547923, 0.11389350412233679, 0.07347958487721917, 0.07348134497542091, 0.07347271921773302, 0.0946163876388012, 0.09461943650507665, 0.09460461866041125]}}
{"id": "a05717d9-1ba0-46d4-9886-083902714b80", "fitness": 0.09399563154612763, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a conditional mutation strategy to adaptively vary the mutation factor to guide convergence more effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                self.mutation_f = 0.5 if self.best_global_value - fitness_values[i] > 1e-3 else 0.9  # Changed line\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391378747392311, 0.11391264464457673, 0.11387862167530316, 0.07347995394807671, 0.07347949877611204, 0.07346738861651014, 0.09461701926758814, 0.0946162725331583, 0.09459549697990033]}}
{"id": "b3474ec5-6df4-4a83-a8f2-0eaa9b6193d9", "fitness": 0.09400410610817853, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce adaptive mutation scaling based on population diversity in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget) * diversity\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391585263856985, 0.11391781869547923, 0.11391011112240768, 0.07348068947408959, 0.07348134497542091, 0.07347864587444719, 0.094618280720981, 0.09461943650507665, 0.09461477496713466]}}
