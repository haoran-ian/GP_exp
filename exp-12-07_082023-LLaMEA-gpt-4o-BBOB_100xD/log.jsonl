{"id": "ab0bdce9-d758-474d-a38e-45c6aad9b6b3", "fitness": 0.043137293797355064, "name": "HybridPSO_DE", "description": "Hybrid Particle Swarm Optimization and Differential Evolution with Adaptive Boundary Handling", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.population_size = 40  # Typically small for PSO-DE hybrid\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Differential Evolution scaling factor\n        self.CR = 0.9  # Crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Particle Swarm Optimization update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = 0.5 * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Differential Evolution mutation and crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Evaluation and selection\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04314 with standard deviation 0.05572.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14222754369898027, 0.17994419548360174, 0.15715162940510996, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.029283460479724632, 0.021864249767163613, 0.02757611131234483, 0.03228889748333985, 0.0004444444444444695, 0.005572783234666812, 0.15969016017479976, 0.12842203917352735, 0.20410785038505186, 0.05913892312624924, 0.05880739557502901, 0.03611428986462928, 0.10186032274527668, 0.07652052593328662, 0.08167496101129978, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07368712918464837, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.16419357991188455, 0.1695136800526046, 0.2514181913773611, 0.027922035887147256, 0.047634687076992144, 0.023816141601127216, 0.10675778750098375, 0.08964272135979834, 0.08963192602180847, 0.14618602428782201, 0.1501463826510846, 0.1384393256876486, 0.07837976055271412, 0.08755030928633922, 0.09676936181879392, 0.13738070398719682, 0.12532640403473394, 0.12023123245900791, 0.0004444444444444695, 0.0012502545779514707, 0.1278729735944375, 0.11435872489894183, 0.12520038867019234, 0.1516360828952783, 0.09327840754407413, 0.04981833033022709, 0.09461613833305316, 0.17492874780402, 0.16513436309811869, 0.16857790409329587, 0.04305320237721566, 0.05546271192132679, 0.045512090940743044, 0.08517612260593377, 0.05553638889786372, 0.07679205848438564, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06858086849629763, 0.0764381442236245, 0.08736871118530443, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0007895919225103798, 0.00564135174789937, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011602853369993893, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09291760474513522, 0.08646571419721683, 0.11170222990467238, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0808108806305956, 0.07845547245331663, 0.0732311425441512, 0.11455069581017752, 0.10598082891215077, 0.11445560540648891, 0.06692460921410892, 0.06921048041518107, 0.055542935209136224, 0.09167302315076786, 0.09200927244395307, 0.10646959309476278, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04144367753806244, 0.053646733956840165, 0.04693740486455655, 0.039631817128013114, 0.04748481935794169, 0.05552810485328519, 0.1823868577511767, 0.15484376138777411, 0.17641455374692938, 0.0004444444444444695, 0.0004444444444444695, 0.0015508294098885989, 0.01123752369906994, 0.009591497157090956, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010535201990460319, 0.00317458400659576, 0.0199019370454957, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06062095301777415, 0.07382202629095935, 0.061934109808938986, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06810601264260085, 0.0564540088361043, 0.05541719334768436, 0.1076627516956542, 0.10194788800572441, 0.0931885614743595, 0.04373923764262855, 0.04495224651203655, 0.037698406095433845, 0.08428594066358341, 0.06492024913186023, 0.07732862030667031, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.022940943414964665, 0.01610094470419343, 0.015736759354019414, 0.015117284617176208, 0.014920991634918335, 0.016696856041403696, 0.15183850985954805, 0.1450193640470051, 0.14121929567420966, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "8c13f9ca-1959-4a21-b0d1-5ec0390f2b23", "fitness": 0.045807870941540846, "name": "HybridPSO_DE", "description": "Introduce adaptive inertia weight to HybridPSO_DE for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.population_size = 40  # Typically small for PSO-DE hybrid\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Differential Evolution scaling factor\n        self.CR = 0.9  # Crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            for i in range(self.population_size):\n                # Particle Swarm Optimization update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Differential Evolution mutation and crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Evaluation and selection\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04581 with standard deviation 0.08159.", "error": "", "parent_ids": ["ab0bdce9-d758-474d-a38e-45c6aad9b6b3"], "operator": null, "metadata": {"aucs": [0.14936280589589268, 0.17101039558689413, 0.11728340075846, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.040706016175310666, 0.015591834028476637, 0.020503388418403268, 0.03228889748333985, 0.0004444444444444695, 0.007724186660720833, 0.9073157210325429, 0.20500988011012522, 0.32371180787625253, 0.05039297631040063, 0.052798823940896855, 0.045808504017250784, 0.112788705232307, 0.05121287960792531, 0.08092420249014709, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.022166096836423455, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15724976288427572, 0.18636269791594806, 0.22577678372725152, 0.027922035887147256, 0.047634687076992144, 0.03309185748917054, 0.11750696064338872, 0.08856534105986769, 0.09531312161094507, 0.13211662311679018, 0.13293488231735084, 0.14571145478050773, 0.0766667153039845, 0.06015004198766882, 0.0849085535933789, 0.11645660030761529, 0.11638006072714968, 0.1411788094772407, 0.0004444444444444695, 0.0012502545779514707, 0.1311577837335095, 0.10368791063936622, 0.11004903632929386, 0.12755420923949434, 0.09448734467388631, 0.09744652752414651, 0.1415835501999838, 0.16054929022395215, 0.14638813948330287, 0.15094713953427752, 0.03245040939413346, 0.035065249258494524, 0.0364922907038292, 0.07736222492241374, 0.07182502216030606, 0.06480333872179067, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08589735432597445, 0.09516207291356626, 0.08061547544154424, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016793864241543055, 0.000814438570096998, 0.006511901194093506, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0006688013846675167, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10099994495245701, 0.09728564447604382, 0.09068652895312979, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06597974786323657, 0.07485604822029523, 0.06605002609115496, 0.10963895825408998, 0.10598082891215077, 0.11445560540648891, 0.05844483403226697, 0.061987603628515964, 0.06284804911465292, 0.09098802801424954, 0.08397038223776365, 0.10388487039441074, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.034277150761346964, 0.053467199689813394, 0.044680816636411436, 0.03511041456465658, 0.08185339980332562, 0.02019923389952072, 0.15284432670940828, 0.19125663079411792, 0.17641455374692938, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017131210755477966, 0.0004444444444444695, 0.006377998921268335, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02825834140967587, 0.0072604814074129775, 0.009944601990552138, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.057394203798009635, 0.045236620287975815, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.058708863479074, 0.057140569855198664, 0.05163000208925905, 0.09994102540033678, 0.0924379531460846, 0.0931885614743595, 0.030950487690125428, 0.037766581179540015, 0.040380135722965504, 0.06528068916914609, 0.05844850159656201, 0.06731983907948291, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017115041939524955, 0.013600033366320652, 0.013288632222107633, 0.012345545982962225, 0.025133880787825746, 0.01114880578452615, 0.14183703160461436, 0.14311258091521528, 0.15821770241862432, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "43b3962b-0bf2-4457-a962-cdf22c2c379d", "fitness": 0.04635594451508149, "name": "ImprovedHybridPSO_DE", "description": "Incorporate dynamic population resizing and adaptive parameter tuning in HybridPSO_DE for enhanced convergence speed and accuracy.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            adaptive_F = self.F * (1 - (evaluations / self.budget))  # Adaptive scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + adaptive_F * (x2 - x3), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 2, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04636 with standard deviation 0.08207.", "error": "", "parent_ids": ["8c13f9ca-1959-4a21-b0d1-5ec0390f2b23"], "operator": null, "metadata": {"aucs": [0.16535240255488393, 0.13397951151090592, 0.1231111449078457, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04099846982977717, 0.015591834028476637, 0.040403041445810195, 0.019950122290248395, 0.019837034427419797, 0.01450551020393609, 0.2703963329872753, 0.9342354538797665, 0.22110392182519467, 0.05957535117867807, 0.04604617003033007, 0.060271577173157564, 0.08730915361697689, 0.06463231762289778, 0.07690192848431776, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1592715972541443, 0.1695136800526046, 0.16722675464083092, 0.027922035887147256, 0.031511579561466, 0.034594123748227124, 0.14213366673087868, 0.11256549228857837, 0.09405719355957387, 0.1603256253984039, 0.14580670589222755, 0.14892223594226894, 0.09440624300558353, 0.09241153432655613, 0.09748535335283293, 0.12633461415580793, 0.12751766214522609, 0.11644333423312436, 0.0004444444444444695, 0.12399362613130249, 0.0004444444444444695, 0.09584549369619189, 0.08849999997924896, 0.134474241853772, 0.07522037507948087, 0.09310425646101494, 0.06680595755979146, 0.15882820388048402, 0.2104259695052687, 0.15846422956110706, 0.03613084300730118, 0.04104485013544179, 0.030784154722642953, 0.0781462162513692, 0.06594066205776228, 0.06080241624821814, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07466097974834018, 0.09218349733442244, 0.07533163405193333, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0027888587229276673, 0.012920341114185163, 0.011333732004280894, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10925282883954068, 0.11298842913840723, 0.11167702478438313, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09577979564011152, 0.08152994247813228, 0.08279660438106151, 0.11951719546434836, 0.11524210208011054, 0.12376297847031648, 0.05559363615379154, 0.05722524021957842, 0.06622806172597906, 0.09776024604439548, 0.10837485674668201, 0.08821174655088926, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04650627820278408, 0.04158854422698033, 0.031824756198453374, 0.08863801726776044, 0.05707321370550422, 0.026402086484870857, 0.1610644653703116, 0.15748998632609823, 0.14480329160789074, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011615087505603805, 0.014990222248499219, 0.015539362602923212, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016927964406152296, 0.004706816462794694, 0.01075714911222081, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.04884773005540188, 0.06520566265321459, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.052515080079956755, 0.0564540088361043, 0.05058934993357578, 0.09615421161583604, 0.10436616342358063, 0.0931885614743595, 0.030950487690125428, 0.04447892876755977, 0.037698406095433845, 0.07848397231946036, 0.08328774821503526, 0.06731983907948291, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016534761032888312, 0.019107395270630767, 0.016856160941656873, 0.01530054707021633, 0.014813117481458526, 0.018142693289977974, 0.14047970598227522, 0.138673125055215, 0.14309050374117327, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "f4fb8b72-eb17-45ea-8e0e-e9d435561c43", "fitness": 0.04635594451508149, "name": "AdvancedHybridPSO_DE", "description": "Introduce a self-adaptive learning mechanism and diversity preservation strategy in ImprovedHybridPSO_DE to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  \n        self.CR = 0.9  \n        self.c1, self.c2 = 2.0, 2.0  \n        self.w_max, self.w_min = 0.9, 0.4  \n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            adaptive_F = self.F * (1 - (evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + adaptive_F * (x2 - x3), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive learning mechanism\n            if evaluations % (self.budget // 10) == 0: \n                successful_trials = values < self.best_global_value\n                if np.sum(successful_trials) > 0:\n                    F_success = np.mean(self.F[successful_trials])\n                    CR_success = np.mean(self.CR[successful_trials])\n                    self.F = 0.8 * self.F + 0.2 * F_success\n                    self.CR = 0.8 * self.CR + 0.2 * CR_success\n\n            # Diversity preservation strategy\n            if evaluations % (self.budget // 5) == 0:\n                diversity = np.std(positions, axis=0)\n                if np.all(diversity < 0.1):\n                    new_positions = np.random.uniform(self.lb, self.ub, (self.population_size // 2, self.dim))\n                    positions[-(self.population_size // 2):] = new_positions\n                    values[-(self.population_size // 2):] = np.apply_along_axis(func, 1, new_positions)\n                    evaluations += self.population_size // 2\n\n        return self.best_global_value", "configspace": "", "generation": 3, "feedback": "The algorithm AdvancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04636 with standard deviation 0.08207.", "error": "", "parent_ids": ["43b3962b-0bf2-4457-a962-cdf22c2c379d"], "operator": null, "metadata": {"aucs": [0.16535240255488393, 0.13397951151090592, 0.1231111449078457, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04099846982977717, 0.015591834028476637, 0.040403041445810195, 0.019950122290248395, 0.019837034427419797, 0.01450551020393609, 0.2703963329872753, 0.9342354538797665, 0.22110392182519467, 0.05957535117867807, 0.04604617003033007, 0.060271577173157564, 0.08730915361697689, 0.06463231762289778, 0.07690192848431776, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1592715972541443, 0.1695136800526046, 0.16722675464083092, 0.027922035887147256, 0.031511579561466, 0.034594123748227124, 0.14213366673087868, 0.11256549228857837, 0.09405719355957387, 0.1603256253984039, 0.14580670589222755, 0.14892223594226894, 0.09440624300558353, 0.09241153432655613, 0.09748535335283293, 0.12633461415580793, 0.12751766214522609, 0.11644333423312436, 0.0004444444444444695, 0.12399362613130249, 0.0004444444444444695, 0.09584549369619189, 0.08849999997924896, 0.134474241853772, 0.07522037507948087, 0.09310425646101494, 0.06680595755979146, 0.15882820388048402, 0.2104259695052687, 0.15846422956110706, 0.03613084300730118, 0.04104485013544179, 0.030784154722642953, 0.0781462162513692, 0.06594066205776228, 0.06080241624821814, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07466097974834018, 0.09218349733442244, 0.07533163405193333, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0027888587229276673, 0.012920341114185163, 0.011333732004280894, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10925282883954068, 0.11298842913840723, 0.11167702478438313, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09577979564011152, 0.08152994247813228, 0.08279660438106151, 0.11951719546434836, 0.11524210208011054, 0.12376297847031648, 0.05559363615379154, 0.05722524021957842, 0.06622806172597906, 0.09776024604439548, 0.10837485674668201, 0.08821174655088926, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04650627820278408, 0.04158854422698033, 0.031824756198453374, 0.08863801726776044, 0.05707321370550422, 0.026402086484870857, 0.1610644653703116, 0.15748998632609823, 0.14480329160789074, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011615087505603805, 0.014990222248499219, 0.015539362602923212, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016927964406152296, 0.004706816462794694, 0.01075714911222081, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.04884773005540188, 0.06520566265321459, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.052515080079956755, 0.0564540088361043, 0.05058934993357578, 0.09615421161583604, 0.10436616342358063, 0.0931885614743595, 0.030950487690125428, 0.04447892876755977, 0.037698406095433845, 0.07848397231946036, 0.08328774821503526, 0.06731983907948291, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016534761032888312, 0.019107395270630767, 0.016856160941656873, 0.01530054707021633, 0.014813117481458526, 0.018142693289977974, 0.14047970598227522, 0.138673125055215, 0.14309050374117327, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "246214f2-baa6-4a01-97ff-eb278ae1b539", "fitness": 0.05131094027680359, "name": "ImprovedHybridPSO_DE", "description": "Introduce gradient-informed mutation and local search enhancement to improve convergence precision and speed in ImprovedHybridPSO_DE.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            adaptive_F = self.F * (1 - (evaluations / self.budget))  # Adaptive scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + adaptive_F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.05 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 4, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05131 with standard deviation 0.12033.", "error": "", "parent_ids": ["43b3962b-0bf2-4457-a962-cdf22c2c379d"], "operator": null, "metadata": {"aucs": [0.13923346593996166, 0.15110881232521756, 0.13993941938801124, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008298614648340918, 0.015591834028476637, 0.044472394798502735, 0.0030985728658448064, 0.0004444444444444695, 0.013926566877351054, 0.9614482162375853, 0.978064071985922, 0.9735802434790507, 0.04124910568114559, 0.040276022160069314, 0.013996832332308307, 0.06448195027833958, 0.0670955486843755, 0.08501151555002329, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07061728183388716, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13195384075108718, 0.1695136800526046, 0.13071221314479853, 0.030736945628625945, 0.02201955112239251, 0.02000014404841144, 0.10789437567418692, 0.13323214795994587, 0.1233212453278344, 0.1283359396043554, 0.1352450341430672, 0.1400042280179885, 0.106507488989252, 0.07661711218610534, 0.08148385770243538, 0.10927094541639137, 0.10623934645994271, 0.14730017553121044, 0.0004444444444444695, 0.0004444444444444695, 0.0054475198152930115, 0.09227905241494838, 0.10410581877507075, 0.15394297656925837, 0.10958411355314912, 0.0939883869168272, 0.09945807944317198, 0.1548106448757448, 0.17979314452987827, 0.16430278805783294, 0.0209233530168913, 0.04292619160920674, 0.03986848672702925, 0.0618748462704245, 0.09727213502892484, 0.07793364444950279, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.085203577943473, 0.09966920270268598, 0.09230796034628108, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.003376628566823303, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010367708112193563, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09678641767583196, 0.08646571419721683, 0.08968472791704618, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06983981249183191, 0.06749029535886442, 0.0717092315572253, 0.11020671410240879, 0.10598082891215077, 0.12696060427640266, 0.05859300280562618, 0.056525458465238376, 0.053242012519856274, 0.08905429292206846, 0.09248167244471528, 0.09206127687834298, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04983902924540984, 0.03490499210279974, 0.049183175802262946, 0.02664689785894192, 0.035648192979478854, 0.018860136391976368, 0.17225367607282394, 0.15234680442672643, 0.1464125049165811, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001306497606935464, 0.01529247476053508, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.00725464001619569, 0.002478931007044549, 0.014748786807869285, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.06416785839348227, 0.06276384937250223, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07021512082463555, 0.06031113733168425, 0.05033742697053867, 0.09757394248764983, 0.09798296308044174, 0.09695427230203835, 0.042480597180031165, 0.04627544724301025, 0.040108947374495774, 0.06726754250873157, 0.05844850159656201, 0.0738482662961718, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016160333562560858, 0.018919621018610444, 0.015873652312072273, 0.014010254654250431, 0.019330132231514696, 0.012967967123265312, 0.16127101146403588, 0.15745775731106226, 0.14787712973473244, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "c378e2f3-416a-477c-8832-28e9990a5797", "fitness": 0.04753405863839574, "name": "EnhancedHybridPSO_DE", "description": "Enhance convergence accuracy and speed by incorporating a covariance matrix adaptation mechanism and refined local search in ImprovedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.cov_matrix = np.eye(dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            adaptive_F = self.F * (1 - (evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Covariance matrix adaptation mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + adaptive_F * (x2 - x3) + np.random.multivariate_normal(np.zeros(self.dim), self.cov_matrix), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                        # Update covariance matrix\n                        self.cov_matrix = 0.5 * self.cov_matrix + 0.5 * np.outer(trial_vector - self.best_global_position, trial_vector - self.best_global_position)\n\n                # Refined local search\n                if evaluations < self.budget:\n                    local_search_step = (self.best_global_position - positions[i]) * np.random.uniform(0.02, 0.1)\n                    local_search_vector = positions[i] + local_search_step\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04753 with standard deviation 0.08209.", "error": "", "parent_ids": ["246214f2-baa6-4a01-97ff-eb278ae1b539"], "operator": null, "metadata": {"aucs": [0.14433189800470547, 0.14138565700730565, 0.12927951393514725, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03679852551313367, 0.015591834028476637, 0.023113300711892326, 0.03775615335786686, 0.03129973000749209, 0.04020858748773526, 0.5768153184840044, 0.7605099803259603, 0.3110322134456286, 0.04124910568114559, 0.054534447793687324, 0.06352126214129039, 0.0997722369093148, 0.09612982657346059, 0.12466833089047158, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15498415813163224, 0.1695136800526046, 0.19011793532107713, 0.027922035887147256, 0.02201955112239251, 0.021589540894494497, 0.11687664140365528, 0.1018732385380342, 0.1112649816687501, 0.14381063537444705, 0.15103547987718458, 0.14737824539344346, 0.09140170195847486, 0.1055652156945801, 0.07651923166487018, 0.13404868069006848, 0.12884209267966795, 0.12211568731666067, 0.13153181718797757, 0.0004444444444444695, 0.0004444444444444695, 0.16408120904389878, 0.11988196388337158, 0.12545208802439822, 0.10873838478899112, 0.12111107073889815, 0.055366507781794416, 0.15057669049643863, 0.14656470556661194, 0.14655182419832813, 0.03230052230096547, 0.046377080725391706, 0.020667830298757184, 0.06008791692818338, 0.056113891811803485, 0.06878833565386477, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10708455807718054, 0.09395779142939253, 0.09038503548761379, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005378100107195194, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.018803432293158617, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09117765367521313, 0.08646571419721683, 0.09674999649801175, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08175325567467229, 0.08672913834689788, 0.08387476479979317, 0.12120447054857819, 0.12339118367034163, 0.10655088400058521, 0.06475667422509546, 0.04800122761776182, 0.059562262664409005, 0.10846626624229894, 0.09861037670321782, 0.09587566419186277, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04868049871587654, 0.03217582620902204, 0.04002822357921876, 0.0583733338932082, 0.018267488839886714, 0.02190634414827297, 0.15880491005420838, 0.15905899060915019, 0.17118963649413665, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03016799312140539, 0.005906346081726577, 0.013650033872381728, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.055066655890004146, 0.06724254108941385, 0.05190399781673838, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06360583281763943, 0.05958143128873172, 0.05547037899442653, 0.08474427977112964, 0.10425074272492785, 0.0931885614743595, 0.030950487690125428, 0.036946924250411683, 0.04529167855078797, 0.0741835590380443, 0.05844850159656201, 0.06821709464786974, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016477972763977, 0.02077491033595047, 0.014836411160843, 0.018942433865543618, 0.016088785612249912, 0.02718651368441738, 0.13371012922237446, 0.14482181488749024, 0.15136845525288933, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "648d0680-17f0-44e8-ad87-5dda1ee65162", "fitness": 0.052230260815793926, "name": "ImprovedHybridPSO_DE", "description": "Refine updated strategy by dynamically adapting DE scaling factor for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adapt DE scaling factor dynamically\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.05 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 6, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05223 with standard deviation 0.12091.", "error": "", "parent_ids": ["246214f2-baa6-4a01-97ff-eb278ae1b539"], "operator": null, "metadata": {"aucs": [0.13790198458659608, 0.13397951151090592, 0.14099602661252775, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02442561498611373, 0.015591834028476637, 0.044472394798502735, 0.0030985728658448064, 0.0004444444444444695, 0.013926566877351054, 0.961460592021068, 0.978049256214902, 0.9735786526753847, 0.04124910568114559, 0.040276022160069314, 0.013996832332308307, 0.06560097287090905, 0.08509519259104648, 0.06903674832601847, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07061728183388716, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13195384075108718, 0.1695136800526046, 0.13713402694320498, 0.027922035887147256, 0.02201955112239251, 0.02000014404841144, 0.12365618026822789, 0.10728138767841333, 0.18890502530418818, 0.14425380750298988, 0.13211344339979236, 0.15249098227495672, 0.09858264168042874, 0.09092545375582717, 0.11379183787279701, 0.11408146403767028, 0.12678375011888077, 0.12632274090091622, 0.0004444444444444695, 0.0004444444444444695, 0.0054475198152930115, 0.15991785936925007, 0.0863624689103395, 0.09878570833668765, 0.08771754386338038, 0.09468417340805713, 0.10656392966026595, 0.16786613303006503, 0.1698083648949711, 0.15269382754866623, 0.027880555086063574, 0.046496198344996076, 0.023479830718162953, 0.05674961037179349, 0.07959247678474357, 0.06859843075826311, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08969109335419656, 0.09028875460421659, 0.20071687802238758, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0029529347886330104, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010367708112193563, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10646539971039282, 0.08646571419721683, 0.11093903652589532, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07861134190157326, 0.07332337951439893, 0.07284289710441527, 0.11405116864295728, 0.10598082891215077, 0.1247539105965556, 0.07292104158723045, 0.059639111832189284, 0.05677156650463078, 0.08905429292206846, 0.12798852457170573, 0.08945976723789151, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.042795841236268894, 0.04063600154308855, 0.04353841170971706, 0.02664689785894192, 0.016312879431406024, 0.02614924925987805, 0.1577308457669303, 0.1468650459669666, 0.14990237379541982, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0011080389116806533, 0.01004519040063434, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007279244324128187, 0.011400791672373733, 0.012049758313498748, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06418878920764615, 0.058168269047153665, 0.06045519063877147, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05514817787211013, 0.060584579856717835, 0.049240983940894156, 0.09243699417311435, 0.09677844118144951, 0.0931885614743595, 0.03898447320715159, 0.05323389095675546, 0.037698406095433845, 0.06951227206129751, 0.06951049088836225, 0.07263003530121404, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.025807022532246093, 0.015776752411448047, 0.012982302455560202, 0.013900915964788152, 0.015234720534929802, 0.014379314450864378, 0.15015058502004242, 0.13888544631562294, 0.14627290120461278, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "1fef27da-fb84-4610-84f7-8557bcbc5f25", "fitness": 0.04767182919073755, "name": "EnhancedHybridPSO_DE", "description": "Enhance the ImprovedHybridPSO_DE algorithm by integrating self-adaptive parameters and introducing opposition-based learning for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adapt DE scaling factor dynamically\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Opposition-based learning\n                opposition_vector = self.lb + self.ub - positions[i]\n                opposition_value = func(opposition_vector)\n                evaluations += 1\n                if opposition_value < values[i]:\n                    positions[i] = opposition_vector\n                    values[i] = opposition_value\n                    if opposition_value < self.best_global_value:\n                        self.best_global_value = opposition_value\n                        self.best_global_position = opposition_vector\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.05 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04767 with standard deviation 0.10326.", "error": "", "parent_ids": ["648d0680-17f0-44e8-ad87-5dda1ee65162"], "operator": null, "metadata": {"aucs": [0.0948639512903594, 0.13397951151090592, 0.1014819828762914, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01905312425091321, 0.015591834028476637, 0.04431326961086679, 0.0068358223033220256, 0.0004444444444444695, 0.0020416352974247376, 0.9465980674231347, 0.9709874253066463, 0.3720334019170747, 0.04124910568114559, 0.040276022160069314, 0.022052943459682006, 0.07570157684693024, 0.11770407856086018, 0.0562178256502478, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07050677342854927, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.17819015473961852, 0.1695136800526046, 0.14304770375443754, 0.027922035887147256, 0.02201955112239251, 0.007599403956028872, 0.10675778750098375, 0.127370149172511, 0.10512495550258771, 0.14756606822343143, 0.13013188003707954, 0.1341147116503143, 0.07706938005479991, 0.07022727456141065, 0.07013745050930142, 0.13775241428226448, 0.1107838005016164, 0.1315381255963648, 0.0004444444444444695, 0.0004444444444444695, 0.022494142104756976, 0.08598520858810232, 0.11023526405793782, 0.09534875916028274, 0.056185327362393456, 0.1034489045724073, 0.08250895073464237, 0.1524285007293832, 0.16865985955468077, 0.14288296439915693, 0.03234486900215294, 0.03166988172237828, 0.03419408859128492, 0.0642618803932633, 0.07959893828447984, 0.06348859195503953, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10419581417519852, 0.07288002583107944, 0.09157491331903722, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004720447202380962, 0.019217493828089016, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.019968691328286603, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08800693424404338, 0.09325613262649934, 0.0929747043035235, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07643616755582394, 0.0800865711516815, 0.07157011160492843, 0.1204032781998261, 0.10598082891215077, 0.1227022304544757, 0.0707867222291706, 0.05409555297054813, 0.05194239793098576, 0.08913456600766445, 0.08449937147123432, 0.09852474367422681, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0529113510442506, 0.05218297028535923, 0.04508787821397975, 0.02957553373413091, 0.01916557881519354, 0.08058840487390018, 0.14941643595414422, 0.15016546959555488, 0.14542608513686006, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.004045167979965236, 0.002777850786659375, 0.009444113376057217, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013398126417379475, 0.0004444444444444695, 0.017921991572735108, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.04715304656921826, 0.06406238134005093, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.058128876272218855, 0.0564540088361043, 0.06912554896343415, 0.09984278501967392, 0.1044081540893923, 0.0931885614743595, 0.042311689864499846, 0.04714711723041287, 0.04641797271733539, 0.059900343228484365, 0.06451805257504184, 0.07406526883566888, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.019238510925358332, 0.013719993019861376, 0.013984791970726884, 0.014903490973209643, 0.01521940172770686, 0.01504302114929168, 0.14812779326789594, 0.16218078873930442, 0.13852512229405778, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "dba4fb82-ad57-46e8-9438-eb6cbb18c390", "fitness": 0.05191189580261245, "name": "ImprovedHybridPSO_DE", "description": "Enhance algorithm's exploitative ability by dynamically adjusting cognitive coefficient in PSO.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adapt DE scaling factor dynamically\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            self.c1 = 2.0 - 1.5 * (evaluations / self.budget)  # Dynamically adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.05 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 8, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05191 with standard deviation 0.12054.", "error": "", "parent_ids": ["648d0680-17f0-44e8-ad87-5dda1ee65162"], "operator": null, "metadata": {"aucs": [0.1385976047206956, 0.1420570272382643, 0.14161181557889202, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008298614648340918, 0.015591834028476637, 0.04418916650313465, 0.0004444444444444695, 0.0004444444444444695, 0.007461087779531583, 0.9614649726895175, 0.9780483544763228, 0.9735786731291435, 0.0598360327314581, 0.04871674567839146, 0.013996832332308307, 0.08722600837842154, 0.08375812992299059, 0.08523022888057374, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0317098642883793, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13195384075108718, 0.1695136800526046, 0.14844416073847722, 0.027922035887147256, 0.02201955112239251, 0.02285723690483088, 0.11041465051671262, 0.10728138767841333, 0.14579430030142682, 0.13889732394895293, 0.15745944202445683, 0.1399156019363681, 0.09598967728097185, 0.08077466161692548, 0.08494621287314108, 0.1377486843186264, 0.1408697978242761, 0.12293526940474364, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08613337702029866, 0.09450493615880373, 0.10873652167654824, 0.0985243499558558, 0.0790527956052568, 0.09960915970866968, 0.15773102535441386, 0.1704865002826893, 0.1595044999996975, 0.02836740456026199, 0.052974240019889596, 0.03530406504217598, 0.052234667909560994, 0.08626949324511002, 0.0689040613556835, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001040324110191726, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08967739525468843, 0.100207943826364, 0.15912234632630262, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01948965731051877, 0.0004444444444444695, 0.0005419750499722209, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005569556535631515, 0.0004444444444444695, 0.009457002382426527, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08656452311556129, 0.08646571419721683, 0.09781851096540128, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07728632367527222, 0.08737634757242974, 0.09630976160583082, 0.10687178511928186, 0.12014130149643454, 0.11775047917373249, 0.053444804533866797, 0.055673951911577535, 0.05835042981975125, 0.08905429292206846, 0.11168315157524411, 0.08886156839393433, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.040871083427274746, 0.03946401141297373, 0.04035228459783946, 0.02664689785894192, 0.017535848526128883, 0.03499160491484732, 0.16923129066937725, 0.15872409001361876, 0.15497453346903034, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017825881779183983, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008250534127025588, 0.0004444444444444695, 0.016462083044786913, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.0737156436619183, 0.05504891244036603, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05446644137984025, 0.06687249946569296, 0.05893638651189692, 0.09971716522907459, 0.0941772664141789, 0.0931885614743595, 0.030950487690125428, 0.05306381887406919, 0.037698406095433845, 0.07787227488437065, 0.06735615334919809, 0.08133596596024895, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.021430007248244953, 0.01844360753901597, 0.014665413566604668, 0.01515877416096556, 0.014413159424277344, 0.018948778531864163, 0.14891960577638486, 0.14276709370523066, 0.14885616442501404, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "e9c02436-08e4-47a8-a72a-46905e4c69dc", "fitness": 0.048228167872119074, "name": "ImprovedHybridPSO_DE", "description": "Introduce a nonlinear adaptation to the DE scaling factor using a cosine function for enhanced balance between exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 + 0.3 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear adapt DE scaling factor using cosine\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.05 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 9, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04823 with standard deviation 0.10333.", "error": "", "parent_ids": ["648d0680-17f0-44e8-ad87-5dda1ee65162"], "operator": null, "metadata": {"aucs": [0.15852636247094876, 0.13397951151090592, 0.11643563562387571, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02467801548164672, 0.015591834028476637, 0.044472394798502735, 0.0030985728658448064, 0.0004444444444444695, 0.013926566877351054, 0.9618507658443811, 0.2260338550373684, 0.9735085137716294, 0.04124910568114559, 0.040276022160069314, 0.013996832332308307, 0.07120830147927149, 0.04892071945426568, 0.08980165580759103, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07061728183388716, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1336352329749123, 0.1695136800526046, 0.1513322578420081, 0.027922035887147256, 0.02201955112239251, 0.0204609999169435, 0.1307069590152905, 0.1319855756763758, 0.15387452293268522, 0.12684945687394955, 0.13733673881007247, 0.13620066354692362, 0.09571307820426533, 0.08070572548340615, 0.0933010289870645, 0.11676959165171241, 0.10479942285267685, 0.11945156280605518, 0.0004444444444444695, 0.0004444444444444695, 0.0054475198152930115, 0.12287251518210052, 0.10792526392797985, 0.15360250996797054, 0.10276401650430278, 0.10644168658055764, 0.08222451107194961, 0.20300717034852167, 0.1670134616984018, 0.19261084352712887, 0.027880555086063574, 0.03056461394376797, 0.04779850168636024, 0.0532044639657282, 0.03141199041250087, 0.07589656085206442, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07512704162369022, 0.0779795236742803, 0.0853800559071537, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010079453410380856, 0.012111246162616052, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010367708112193563, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07532012085817608, 0.08646571419721683, 0.09561307392740759, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08415574529903502, 0.0807204318261443, 0.07853506231763685, 0.12411601888453316, 0.10598082891215077, 0.11405971230341871, 0.06516812658156856, 0.06436513596606108, 0.06064038059469179, 0.08905429292206846, 0.08934814098578747, 0.08215488379290081, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0620804084878237, 0.04406033741286919, 0.045875302804144646, 0.07208384725355954, 0.08344211019335046, 0.0361296731736519, 0.1666024101981115, 0.1456062011088195, 0.15132121966499212, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001896364737558165, 0.009395629963143137, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015028106502806393, 0.0004444444444444695, 0.008367725548462546, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.05384154403777275, 0.057076646416950094, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.052070096932750554, 0.06537580771368445, 0.052531276884045686, 0.09835832626834629, 0.09452078820418264, 0.09583327651522544, 0.030950487690125428, 0.04627544724301025, 0.037698406095433845, 0.06507995212581708, 0.0678835852423334, 0.06731983907948291, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013184532503813129, 0.013019259578041509, 0.0152156476888069, 0.011276316879160975, 0.023239372037314743, 0.012614052589369984, 0.14312518762890325, 0.13973233390668716, 0.14602826122598145, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "1700b8ae-da2c-41ef-bcd8-611eac273c7c", "fitness": 0.048228167872119074, "name": "ImprovedHybridPSO_DE", "description": "Enhance convergence by refining the adaptive DE scaling factor using a cosine function for smoother transitions.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 + 0.3 * np.cos(np.pi * evaluations / self.budget)  # Adapt DE scaling factor dynamically\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.05 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 10, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04823 with standard deviation 0.10333.", "error": "", "parent_ids": ["648d0680-17f0-44e8-ad87-5dda1ee65162"], "operator": null, "metadata": {"aucs": [0.15852636247094876, 0.13397951151090592, 0.11643563562387571, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02467801548164672, 0.015591834028476637, 0.044472394798502735, 0.0030985728658448064, 0.0004444444444444695, 0.013926566877351054, 0.9618507658443811, 0.2260338550373684, 0.9735085137716294, 0.04124910568114559, 0.040276022160069314, 0.013996832332308307, 0.07120830147927149, 0.04892071945426568, 0.08980165580759103, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07061728183388716, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1336352329749123, 0.1695136800526046, 0.1513322578420081, 0.027922035887147256, 0.02201955112239251, 0.0204609999169435, 0.1307069590152905, 0.1319855756763758, 0.15387452293268522, 0.12684945687394955, 0.13733673881007247, 0.13620066354692362, 0.09571307820426533, 0.08070572548340615, 0.0933010289870645, 0.11676959165171241, 0.10479942285267685, 0.11945156280605518, 0.0004444444444444695, 0.0004444444444444695, 0.0054475198152930115, 0.12287251518210052, 0.10792526392797985, 0.15360250996797054, 0.10276401650430278, 0.10644168658055764, 0.08222451107194961, 0.20300717034852167, 0.1670134616984018, 0.19261084352712887, 0.027880555086063574, 0.03056461394376797, 0.04779850168636024, 0.0532044639657282, 0.03141199041250087, 0.07589656085206442, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07512704162369022, 0.0779795236742803, 0.0853800559071537, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010079453410380856, 0.012111246162616052, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010367708112193563, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07532012085817608, 0.08646571419721683, 0.09561307392740759, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08415574529903502, 0.0807204318261443, 0.07853506231763685, 0.12411601888453316, 0.10598082891215077, 0.11405971230341871, 0.06516812658156856, 0.06436513596606108, 0.06064038059469179, 0.08905429292206846, 0.08934814098578747, 0.08215488379290081, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0620804084878237, 0.04406033741286919, 0.045875302804144646, 0.07208384725355954, 0.08344211019335046, 0.0361296731736519, 0.1666024101981115, 0.1456062011088195, 0.15132121966499212, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001896364737558165, 0.009395629963143137, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015028106502806393, 0.0004444444444444695, 0.008367725548462546, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.05384154403777275, 0.057076646416950094, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.052070096932750554, 0.06537580771368445, 0.052531276884045686, 0.09835832626834629, 0.09452078820418264, 0.09583327651522544, 0.030950487690125428, 0.04627544724301025, 0.037698406095433845, 0.06507995212581708, 0.0678835852423334, 0.06731983907948291, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013184532503813129, 0.013019259578041509, 0.0152156476888069, 0.011276316879160975, 0.023239372037314743, 0.012614052589369984, 0.14312518762890325, 0.13973233390668716, 0.14602826122598145, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "1f77f34d-95d3-4b83-9b6c-f7b91fe384c1", "fitness": 0.04739938215851888, "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive learning rates and enhanced diversity mechanisms to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 + 0.3 * np.cos(np.pi * evaluations / self.budget)  # Adapt DE scaling factor dynamically with cosine\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            \n            # Introduce adaptive learning rate\n            learning_rate = 1.0 / (1 + 0.1 * evaluations/self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += learning_rate * self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Enhanced diversity mechanism\n                if evaluations < self.budget:\n                    diversity_vector = np.random.uniform(self.lb, self.ub, self.dim)\n                    diversity_step = 0.1 * (self.ub - self.lb) * (1 - evaluations / self.budget)\n                    diversity_vector = np.clip(positions[i] + diversity_step * (diversity_vector - positions[i]), self.lb, self.ub)\n                    diversity_value = func(diversity_vector)\n                    evaluations += 1\n                    if diversity_value < values[i]:\n                        positions[i] = diversity_vector\n                        values[i] = diversity_value\n                        if diversity_value < self.best_global_value:\n                            self.best_global_value = diversity_value\n                            self.best_global_position = diversity_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04740 with standard deviation 0.08078.", "error": "", "parent_ids": ["648d0680-17f0-44e8-ad87-5dda1ee65162"], "operator": null, "metadata": {"aucs": [0.11637252116506192, 0.13397951151090592, 0.13134932011618283, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.030514600980534934, 0.027530939765829543, 0.026213799104776614, 0.03194834759403686, 0.013441324179911285, 0.008806748840738843, 0.26397053104222346, 0.13548599952595997, 0.9335494354604822, 0.04124910568114559, 0.04678813773596391, 0.030752609087185023, 0.08437553775744044, 0.07615878815788324, 0.07758140458716112, 0.02212041918674912, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011376242661916391, 0.0295249204808693, 0.06763145867305709, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.16673932644870482, 0.1695136800526046, 0.14296983047099054, 0.028351398960243746, 0.03594735710433772, 0.0301408492869899, 0.10675778750098375, 0.10139844444655322, 0.13486761808752135, 0.13365009814256035, 0.14175268865540236, 0.1341147116503143, 0.07431599891892826, 0.06396002031955117, 0.08236144724428418, 0.13435935381242936, 0.14086635493019828, 0.11935027459627845, 0.13322342180532454, 0.11943818174156351, 0.0004444444444444695, 0.09638818349416611, 0.11228102023032216, 0.13157591752770847, 0.1059054891797766, 0.07226002672031362, 0.09896779608223849, 0.14612707465722252, 0.15838515282167698, 0.15228583379464145, 0.05674039286831434, 0.03056461394376797, 0.04161013753055143, 0.06112693620900078, 0.07911130171736136, 0.07297571097513234, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07216867705205121, 0.08881187109700761, 0.05843470979514698, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.006678164614636106, 0.010946256209855898, 0.033848830944974484, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.11446743689447869, 0.10478380519585251, 0.12458722479466688, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08806699812352703, 0.07324444269624109, 0.08090910866695733, 0.1159173628153265, 0.13652167917231595, 0.12124550418587765, 0.06470029861349147, 0.07558492761420832, 0.06370014967821203, 0.09780539911912722, 0.10451347755135687, 0.09932048811520167, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05647215018148377, 0.0477716635067611, 0.034974996927621516, 0.02664689785894192, 0.06979284556110177, 0.04267868473045622, 0.1699975988486293, 0.15411614549153574, 0.1695483846920075, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01964839805066687, 0.016491204623777622, 0.01809276435750451, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.00793343813038827, 0.007640728875504377, 0.019263859818116513, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06382788755862145, 0.06943589533518546, 0.07767615990671539, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05637294094272993, 0.0564540088361043, 0.05773589583553829, 0.10558987329472602, 0.11083270180517224, 0.10113017812633229, 0.0432600985995889, 0.04607407702457067, 0.050307625670718004, 0.08995842302411305, 0.09089729680905623, 0.10064168924255135, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016891280363500183, 0.018849049726560763, 0.018175957043887858, 0.013795454997005185, 0.012302771583867722, 0.013571660224385051, 0.13544203981691394, 0.14262393371679538, 0.15398693692645082, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "ae75db85-ae46-45f0-b13f-4d4b2a8b806a", "fitness": 0.05280140978566171, "name": "ImprovedHybridPSO_DE", "description": "ImprovedHybridPSO_DE: Refine updated strategy by dynamically adapting DE scaling factor for improved exploration-exploitation balance and enhanced local search using a more precise adjustment.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adapt DE scaling factor dynamically\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.1 * (self.best_global_position - positions[i])  # Increased precision in adjustment\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 12, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05280 with standard deviation 0.12070.", "error": "", "parent_ids": ["648d0680-17f0-44e8-ad87-5dda1ee65162"], "operator": null, "metadata": {"aucs": [0.16586350892429658, 0.13532584804804382, 0.13944616412145405, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01714444858405917, 0.03465207082792021, 0.023186780592542422, 0.0004444444444444695, 0.0004444444444444695, 0.015762964553599046, 0.9599603602609109, 0.9780521322990756, 0.973578093091757, 0.04124910568114559, 0.040276022160069314, 0.013996832332308307, 0.06067951738285993, 0.06009640079998324, 0.09196485418011602, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04475150776067571, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1534572994551422, 0.1695136800526046, 0.1496563445326441, 0.027922035887147256, 0.02201955112239251, 0.06708856969691523, 0.13556420671052238, 0.08939152421740215, 0.11227778634557772, 0.14252170228168293, 0.13595594356310414, 0.1341147116503143, 0.0891491581112821, 0.0908707066048301, 0.08485706133732629, 0.11958418380506364, 0.11799762110809042, 0.1506027230635033, 0.0004444444444444695, 0.0004444444444444695, 0.012996322836385299, 0.10267153580517052, 0.11565168193910969, 0.12431330330048007, 0.10203122653661745, 0.08851756393420651, 0.14681811368734698, 0.1778845915593299, 0.16537957931411718, 0.1784606177193533, 0.040291619823038416, 0.04501473123841182, 0.03787321959004453, 0.07357586292702101, 0.08477604569422859, 0.06931963470645208, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0732911524961678, 0.11509607519582865, 0.15825248208196974, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008373062605102954, 0.025394869253040353, 0.005105411168922269, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0957946219696375, 0.10779899530743009, 0.10014170781316578, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06901955314388297, 0.07651714729711578, 0.06474806022022028, 0.12686188917661756, 0.11730549659257727, 0.12104169350268545, 0.06080097925120631, 0.07080438302485992, 0.057628822444343974, 0.08905429292206846, 0.09062673215665484, 0.10213065512118813, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05566144789413696, 0.028770601554667263, 0.04287143090952017, 0.02664689785894192, 0.02780755457485351, 0.0373613852801451, 0.1437670917169136, 0.15034076854911882, 0.1697656791200962, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0022539221852861946, 0.017821021354856525, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.022765586027072127, 0.014099387307988875, 0.009893176179297747, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.07005198592117767, 0.05899233226421019, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.058570236960575284, 0.05949106865456677, 0.0676419218606219, 0.09769075387178783, 0.10118180272655986, 0.0965965485243887, 0.030950487690125428, 0.04407728825951507, 0.037698406095433845, 0.07203184834119669, 0.06470636105216343, 0.07758299244696398, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015351167259021747, 0.018789855784426157, 0.016695811468275368, 0.015384031352575267, 0.01546051381784852, 0.01585476119207674, 0.13892150379981894, 0.14769034125344582, 0.14898582377546965, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "1eaee451-b533-43a8-bc8f-999fe89434f0", "fitness": 0.053222935565715286, "name": "ImprovedHybridPSO_DE", "description": "Refine strategy by implementing a linearly decreasing DE scaling factor for a smoother transition between exploration and exploitation phases.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)  # Linearly decreasing DE scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.1 * (self.best_global_position - positions[i])  # Increased precision in adjustment\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 13, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05322 with standard deviation 0.12100.", "error": "", "parent_ids": ["ae75db85-ae46-45f0-b13f-4d4b2a8b806a"], "operator": null, "metadata": {"aucs": [0.15494787666332654, 0.13498848477496028, 0.1351716065050913, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01714444858405917, 0.027654348078796187, 0.023186780592542422, 0.0004444444444444695, 0.0004444444444444695, 0.015762964553599046, 0.9599502537408694, 0.9780618123439281, 0.9735803703933086, 0.04124910568114559, 0.040276022160069314, 0.013996832332308307, 0.06067951738285993, 0.04670907911358535, 0.07037587721640903, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04475150776067571, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13195384075108718, 0.1695136800526046, 0.157643797285281, 0.027922035887147256, 0.02201955112239251, 0.02059308002185023, 0.13556420671052238, 0.09174422322323084, 0.1149800763557024, 0.13708052713757357, 0.14245637115172338, 0.136557518172998, 0.09613494698697111, 0.07527217191270275, 0.10038803974253596, 0.12341891770453828, 0.15304504727444346, 0.13927746253666495, 0.0004444444444444695, 0.0004444444444444695, 0.012996322836385299, 0.13288316799015043, 0.10752380420517482, 0.10860601385334734, 0.113904006827937, 0.06869989250711073, 0.13552330946304336, 0.17474522269848347, 0.16132795590639848, 0.15702956328782225, 0.02834251516509012, 0.04501473123841182, 0.03955469288467284, 0.08532585828323824, 0.08477604569422859, 0.08598079190256125, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.059877756045110586, 0.1488903346109669, 0.17498832217894988, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015493454200636192, 0.029663399980450533, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10762078458924862, 0.13064874955144468, 0.11516054856845093, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05995597221061366, 0.08414524972309645, 0.07192432470382881, 0.13575753129238044, 0.12014346104087048, 0.12175102674969374, 0.06907977625120298, 0.06265687399724229, 0.05910003795142338, 0.08905429292206846, 0.09120813812768802, 0.10998618152557393, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.052914665872397904, 0.06903477629425248, 0.05208811081083531, 0.02708054151362238, 0.02706969216709576, 0.036518102123636154, 0.16203999753070508, 0.15315893660818192, 0.16358160331884453, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0023141802754188534, 0.017775808167166063, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010797079013008193, 0.0004444444444444695, 0.008453333272589236, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.06205500398503072, 0.06423941186252646, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06234763857425407, 0.05753113589030401, 0.0542126295150277, 0.1117558345008609, 0.1056234767265668, 0.0931885614743595, 0.04200751368528588, 0.0508412223147825, 0.037698406095433845, 0.0736315887806458, 0.08030988850929033, 0.0826891377254837, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01592440012129248, 0.016923737068047173, 0.01653452887078899, 0.014732269465222436, 0.025132255213298982, 0.017580364135638016, 0.14782376355453097, 0.13626297767575524, 0.135014563405504, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "7bc5b25d-560e-4a12-a4a3-52aa9bcae5a9", "fitness": 0.0494960216260422, "name": "EnhancedHybridPSO_DE", "description": "Introduce self-adaptive learning rates for PSO velocity update and dynamic archive-based DE mutation to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.archive = []\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                \n                self.velocity[i] *= np.random.uniform(0.5, 1.5, self.dim)  # Self-adaptive learning rate\n                \n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                if np.random.rand() < 0.5 and self.archive:\n                    archive_ind = np.random.choice(len(self.archive))\n                    x3 = self.archive[archive_ind]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                    self.archive.append(x3)\n                    if len(self.archive) > self.population_size:\n                        self.archive.pop(0)\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.1 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04950 with standard deviation 0.10348.", "error": "", "parent_ids": ["1eaee451-b533-43a8-bc8f-999fe89434f0"], "operator": null, "metadata": {"aucs": [0.1315346881606051, 0.1370812327129347, 0.13688660071011138, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03344778678837712, 0.017523646798991543, 0.027146803884919968, 0.0004444444444444695, 0.014923115328352443, 0.020337834389584364, 0.9671543163575484, 0.9672108510448771, 0.16412007005226792, 0.0607754041471823, 0.040276022160069314, 0.013996832332308307, 0.0752618405074027, 0.06897838954435187, 0.07113225650422428, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03512614040167805, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.16872078308850014, 0.17368609353707765, 0.1628730527024821, 0.027922035887147256, 0.02201955112239251, 0.02860616111612435, 0.11704760139570047, 0.09172513117280945, 0.10642251081193521, 0.16126161531082173, 0.14368946002696137, 0.14850396664782006, 0.09077957885449561, 0.07571328327782123, 0.09686022887925283, 0.12553992986532247, 0.11983636013244225, 0.11571574919690586, 0.0004444444444444695, 0.0004444444444444695, 0.12629763949831052, 0.10063362195634162, 0.1481673839770633, 0.09433929481981718, 0.11999220949942868, 0.11281029625649797, 0.10351792319387865, 0.1917271884235433, 0.17338518756752264, 0.14688048213709537, 0.021245542692803543, 0.0323032528482563, 0.0447518072939157, 0.0657944612628869, 0.07838934798877584, 0.05918686317946287, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07608882705678055, 0.11914313590234271, 0.12671636975398792, 0.003002332046522671, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0018491847112283022, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10786702720910502, 0.10979972289550055, 0.11073626560789285, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08780878567841843, 0.08636000362909135, 0.06710972919826275, 0.12728277765110085, 0.12180458208043032, 0.11343030441728552, 0.06983760907004821, 0.06520900323280132, 0.07023074616734626, 0.09138213463734068, 0.09737006379413127, 0.1008769610183533, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.029715651952736177, 0.037157149356386254, 0.042005443623049366, 0.061288948366857054, 0.046517615603510865, 0.04688610457828468, 0.14813009261889754, 0.1718155150992018, 0.1578621298527677, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008014938973281649, 0.0034064110941639525, 0.00898449854934591, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.06372394493757583, 0.06427164311984956, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05481355700791957, 0.0585680209042625, 0.054690029334799606, 0.10982818638765657, 0.09872300970296821, 0.0931885614743595, 0.041782896615505605, 0.04906733486433834, 0.0390045454707989, 0.07632787490800441, 0.0777822228369619, 0.08818278789241518, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01992172192104691, 0.016638596279018314, 0.0166414552005838, 0.009534136979238772, 0.013895781497470172, 0.015118918773738166, 0.14894788743390175, 0.13893166017714242, 0.1507319514273887, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "855ef0b1-9fbb-4fdc-993f-cf006957b6f4", "fitness": 0.053824085218281935, "name": "ImprovedHybridPSO_DE", "description": "Enhance the local search by increasing the precision of the adjustment for exploiting optimal solutions more effectively.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)  # Linearly decreasing DE scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.15 * (self.best_global_position - positions[i])  # Increased precision in adjustment\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 15, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05382 with standard deviation 0.12102.", "error": "", "parent_ids": ["1eaee451-b533-43a8-bc8f-999fe89434f0"], "operator": null, "metadata": {"aucs": [0.11710814604950803, 0.13397951151090592, 0.1181659080573948, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.027654238850959967, 0.015591834028476637, 0.03324410111774301, 0.0004444444444444695, 0.0004444444444444695, 0.0020416352974247376, 0.9590416642122174, 0.9780304293971911, 0.9735806892387627, 0.061366153966699755, 0.05249648275567009, 0.013996832332308307, 0.10490229103768511, 0.07683759172967464, 0.07530805734916246, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.030755603764281103, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.16168810308997295, 0.18042194567666658, 0.16890992347720402, 0.027922035887147256, 0.02201955112239251, 0.029331030757290155, 0.1409303705569247, 0.0896046758119432, 0.1385338641282844, 0.13640915982982282, 0.1399209067781949, 0.1341147116503143, 0.08531493900539944, 0.07271854978492853, 0.12292979893625866, 0.12199477689354599, 0.12141105841458488, 0.15061134328068138, 0.026001025967088975, 0.0004444444444444695, 0.015676155434444006, 0.10647489871428362, 0.11108834448048543, 0.16655647967187992, 0.16168710401097908, 0.0704001261969206, 0.1294826926677367, 0.1721466836790393, 0.1691637220137734, 0.16754771975674188, 0.03489172697496079, 0.03056461394376797, 0.02610006213997318, 0.08764551084404515, 0.07854276464374077, 0.07255222565620834, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07957638103616893, 0.13734168147761006, 0.06728032377583237, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.012792219067799815, 0.01621993703346536, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0033416988028748262, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.11132930668498298, 0.10481782122399497, 0.11122612734288007, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07383261575261835, 0.07038660066564806, 0.077486777184122, 0.1288656083254498, 0.12972315261920775, 0.1290094534845223, 0.05318569989870148, 0.0598935206673622, 0.07176689874636899, 0.08905429292206846, 0.10316858320891098, 0.09128598704398216, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.059519946737725204, 0.06585541372777881, 0.04988885658999642, 0.04105789233423618, 0.03165740059367028, 0.04111977321929372, 0.16211007649638542, 0.14548626452743763, 0.15991091344035668, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.004977950442745627, 0.028693186120303582, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007217436653348286, 0.0004444444444444695, 0.008615006213853915, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.07249727912811732, 0.06653901619824987, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05475275343104857, 0.059624578064599976, 0.05181485611477987, 0.10045068444018235, 0.10334773323629032, 0.0931885614743595, 0.042719513292188926, 0.06370917410307586, 0.037698406095433845, 0.08076371165159901, 0.07867217924160064, 0.09026528843286385, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.014755472963059457, 0.01708320008040265, 0.03224061388438326, 0.016764009973704086, 0.015560143553094097, 0.02547522537430491, 0.13671213117709746, 0.14576599226833298, 0.1575117420193063, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "9389b141-f147-449c-b1ae-02027ec176c1", "fitness": 0.05416005533696073, "name": "ImprovedHybridPSO_DE", "description": "Refine local search by increasing the precision of the adjustment for exploiting optimal solutions more effectively.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)  # Linearly decreasing DE scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i], self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])  # Increased precision in adjustment\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 16, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05416 with standard deviation 0.12088.", "error": "", "parent_ids": ["855ef0b1-9fbb-4fdc-993f-cf006957b6f4"], "operator": null, "metadata": {"aucs": [0.1395986157739414, 0.13397951151090592, 0.13502317473058623, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.019981289468479324, 0.029818773348652683, 0.037207999464376695, 0.0004444444444444695, 0.02937042374948695, 0.012990999472791587, 0.9586319334322073, 0.9780465788589163, 0.9735832504797768, 0.06250517259207256, 0.05428885478071688, 0.013996832332308307, 0.07000968469569513, 0.05369783348444779, 0.07211828263176301, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.024432211165807516, 0.0004444444444444695, 0.00686787957943491, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1755114466381461, 0.18874398143079996, 0.14945473054482328, 0.027922035887147256, 0.02201955112239251, 0.018175156284800376, 0.12049179876766891, 0.09641294724476934, 0.09199236959071855, 0.14985772837173827, 0.16247244323255605, 0.16099860311724745, 0.07997437789225115, 0.08076483198561357, 0.13562956137040083, 0.17045789288794988, 0.14313038359193764, 0.15161949888556758, 0.04696205745480986, 0.0004444444444444695, 0.01976313914213501, 0.11437472390916104, 0.10526757718917767, 0.10241239431004201, 0.12291965698464424, 0.09045931834067122, 0.10115838082086304, 0.17236393399777405, 0.16987514195729936, 0.19275701537851275, 0.030563096689479763, 0.03174218081922042, 0.04776372283914254, 0.08063904292429547, 0.08902328208313137, 0.09412421412069472, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06719348099430356, 0.09723038236132386, 0.06681026435579485, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007566382099079227, 0.005951712269382514, 0.0007535779929737085, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09526801799525719, 0.10574874041390081, 0.10844892896306535, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07625188000696126, 0.09439340559850673, 0.07226942459560415, 0.12457123170410422, 0.12093954032314502, 0.11667517234536517, 0.05372575680463265, 0.07008531678844765, 0.06649391093742507, 0.08905429292206846, 0.10155455750440268, 0.10489428596957928, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04988412195802161, 0.050029806272376964, 0.04738305096448214, 0.056966306517070686, 0.058026384197387704, 0.03639865250885832, 0.16071363604310585, 0.1578276905112661, 0.14193085898851932, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.033752940427143496, 0.005150476325585074, 0.020012412975126126, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005374428324788627, 0.0004444444444444695, 0.005865731595801393, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.07621785402553283, 0.06712529593498384, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05908078648023651, 0.05879206677915705, 0.05306856674507843, 0.11159739240982214, 0.10668856772520086, 0.0931885614743595, 0.04628204554364013, 0.04734604248589691, 0.037698406095433845, 0.08752768226989993, 0.07811536451288525, 0.09024600697219876, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02256133884195055, 0.016963817287074745, 0.02495891689016405, 0.020345692525494452, 0.032658065679861625, 0.025061314517067612, 0.13955506361896552, 0.14193825626142498, 0.1487583368102856, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "4861cf15-7a04-40d6-ac47-390bcf199874", "fitness": 0.05480594828325445, "name": "ImprovedHybridPSO_DE", "description": "Introduce Gaussian noise to enhance diversity during the mutation phase, potentially avoiding local optima traps.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)  # Linearly decreasing DE scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)  # Added Gaussian noise\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])  # Increased precision in adjustment\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 17, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05481 with standard deviation 0.11711.", "error": "", "parent_ids": ["9389b141-f147-449c-b1ae-02027ec176c1"], "operator": null, "metadata": {"aucs": [0.14523894134018467, 0.1766426184148041, 0.14650688451399396, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017780561451293697, 0.029461612287237537, 0.016670918385182087, 0.019205976126179802, 0.023009500305029906, 0.002364337876195499, 0.921901502701426, 0.9517148145134114, 0.9142674870116994, 0.05280491149564581, 0.040276022160069314, 0.013996832332308307, 0.10495518408754057, 0.07484621801535807, 0.08042527678398581, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02435301803168821, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15840388916322257, 0.18436104113312934, 0.20416236384286202, 0.027922035887147256, 0.02201955112239251, 0.023825344508730417, 0.12826050945914635, 0.08991211750513639, 0.09396460600820344, 0.1480244279229882, 0.151020367476004, 0.1341147116503143, 0.0994698388712425, 0.10540706368693276, 0.07139148728472156, 0.13435765406550648, 0.12965294313498388, 0.1393348794164302, 0.13020515582856496, 0.0004444444444444695, 0.12820082112697662, 0.14522904506842593, 0.13141635514746375, 0.1109566568055308, 0.10104330199630673, 0.0957016776272025, 0.15565131428851298, 0.16678797281947733, 0.172156406095459, 0.147946603032572, 0.0638775460991573, 0.05076413572769667, 0.03525377539685093, 0.0798840642198061, 0.08976070491765398, 0.09070057193660896, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08911558206773917, 0.07438548131861045, 0.07167634929684286, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.009136109869334219, 0.0004444444444444695, 0.020469586428180087, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.11348024349603025, 0.10640851423625375, 0.11779358587741451, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08583137797447349, 0.08635578557977652, 0.07638661684457793, 0.1228184149249727, 0.11770250807877403, 0.12630913398198917, 0.062354561311307566, 0.05397997622390138, 0.055328252068152395, 0.09700052033921136, 0.09972819831545854, 0.09775674024513836, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03371939667678714, 0.0604711757195312, 0.05202418014757615, 0.0483108522864788, 0.03565325991752977, 0.047348570513552124, 0.1568819790919137, 0.15312437065384776, 0.16874453850015647, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.024615777350420753, 0.0004444444444444695, 0.020149295110744148, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011104278170738557, 0.004365196778699287, 0.006124638520590642, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.07744786191672515, 0.0559551473653177, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0509811736407666, 0.05770649592151755, 0.06518202728940237, 0.1096250381284739, 0.10105226844660664, 0.0931885614743595, 0.03428793403196584, 0.047447773029154816, 0.037698406095433845, 0.09267074804277431, 0.08012099060793765, 0.07347562433186205, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.018563622720075945, 0.021610733051014908, 0.017269903405309428, 0.019939897667792472, 0.02086205108473349, 0.021590778796144128, 0.1397241287900609, 0.14534972348406439, 0.15801865841162965, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "59dec475-9fce-471b-8ffc-95640b8341bd", "fitness": 0.05449929745556318, "name": "ImprovedHybridPSO_DE", "description": "Enhance adaptability by incorporating a non-linear inertia weight adjustment and dynamical Gaussian noise variance reduction.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_min + (self.w_max - self.w_min) * (1 - (evaluations / self.budget)**2)  # Non-linear inertia weight\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise = np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)  # Dynamical Gaussian noise reduction\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i] + gaussian_noise, self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 18, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05450 with standard deviation 0.11691.", "error": "", "parent_ids": ["4861cf15-7a04-40d6-ac47-390bcf199874"], "operator": null, "metadata": {"aucs": [0.1308038225556586, 0.17656123022119674, 0.2150806248228493, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.032973309792996175, 0.031961285722267974, 0.014158748350702188, 0.03297610092749692, 0.003306579751725769, 0.020233009446541494, 0.9215123868561886, 0.9364490036255451, 0.9143255884480195, 0.060959808821761, 0.059794639325908894, 0.013996832332308307, 0.083833940920785, 0.046647145698155645, 0.07817959702970767, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.00960354180277101, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15839296206452913, 0.1737565138465501, 0.16953911082728612, 0.030370564720288207, 0.02201955112239251, 0.019885494873548515, 0.12872154987011009, 0.10555782027629301, 0.09042264811586354, 0.149375381486623, 0.151020367476004, 0.1550936489856497, 0.11802538427171583, 0.10069033698527496, 0.0884989809681671, 0.1320771888196297, 0.12965294313498388, 0.12874485484013043, 0.13020515582856496, 0.0004444444444444695, 0.013137964819748937, 0.11733745225592074, 0.16199447300494796, 0.10719724735379021, 0.11973014284028727, 0.1531022223521813, 0.1530513879101565, 0.15390038929777083, 0.15794978531165205, 0.16471825472751422, 0.03900141192783446, 0.04443179503944861, 0.03129073736054533, 0.0677016986264446, 0.07663166576846525, 0.08582103800516572, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14332531982680752, 0.10782131860718258, 0.05562653141361262, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0009959538501577159, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09527465296120075, 0.11208529106189613, 0.10645331034941818, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08123764918306409, 0.07704465283211037, 0.07476154615493624, 0.12667792443155723, 0.11910045137011138, 0.1367499353066588, 0.0674700744084783, 0.06834899215222001, 0.07669687021790317, 0.08905429292206846, 0.10872307854223007, 0.09514629524668528, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06128500141573001, 0.06775787595432448, 0.054617416420082665, 0.028043097415587526, 0.028127291117944986, 0.024911091218455472, 0.16556020711851105, 0.1520404025983314, 0.15211826566019593, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.024995138758514557, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01680064015208338, 0.0017593931258209627, 0.010381316872586477, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.06753224951184167, 0.06804077088620397, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06643759084189516, 0.05944049888235736, 0.05352450204043069, 0.10598405278751155, 0.1015811876865258, 0.0931885614743595, 0.030950487690125428, 0.048007241118410704, 0.037698406095433845, 0.08369718754722433, 0.07587362330348257, 0.08028353065707117, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.018749511748325953, 0.017580691506307256, 0.01719243039751639, 0.019418778291089178, 0.022036565604506286, 0.03444394660397221, 0.1479633624498915, 0.14657996994189826, 0.13726093878530532, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "d1652045-2a86-4431-88fb-28e987621ff9", "fitness": 0.05340385251252733, "name": "ImprovedHybridPSO_DE", "description": "Enhance exploitation with a feedback mechanism for adaptive learning rates in PSO velocity update.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n            adaptive_c1 = self.c1 * (1 + (0.5 * (self.best_global_value - np.min(values)) / (np.max(values) - np.min(values) + 1e-8)))\n            adaptive_c2 = self.c2 * (1 + (0.5 * (np.max(values) - self.best_global_value) / (np.max(values) - np.min(values) + 1e-8)))  # Feedback-based adaptation\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  adaptive_c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  adaptive_c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 19, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05340 with standard deviation 0.11926.", "error": "", "parent_ids": ["4861cf15-7a04-40d6-ac47-390bcf199874"], "operator": null, "metadata": {"aucs": [0.11065290561906649, 0.13397951151090592, 0.1516679991738562, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03795479371190802, 0.015591834028476637, 0.028629382931981806, 0.0004444444444444695, 0.0004444444444444695, 0.012233977883107872, 0.9547529358483893, 0.9720135928934807, 0.9265303254244435, 0.08645343602057098, 0.040276022160069314, 0.013996832332308307, 0.0796885592897264, 0.13375956794574884, 0.0601478544300309, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15951331401826563, 0.1695136800526046, 0.14584981728459656, 0.027922035887147256, 0.02201955112239251, 0.03910824579486405, 0.12646063958192044, 0.09577771423348569, 0.1512488547858042, 0.16877020607893822, 0.15338962382439603, 0.16988402592439633, 0.07998538243029585, 0.09651643509258367, 0.1148077714493555, 0.1491161784132793, 0.12253642157320466, 0.1447271792324084, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.11305900465680652, 0.12642565238394188, 0.10914344115788643, 0.11942499311351018, 0.12119290315688624, 0.08125289519113621, 0.1476187413205533, 0.15727332288640095, 0.14919469354968895, 0.040063517365511836, 0.03389951135778069, 0.033904371749062245, 0.06093967133881861, 0.0762276671581017, 0.07789104858928719, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1261415815979806, 0.17509120827550462, 0.09990783280254223, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0013144294890051755, 0.0004444444444444695, 0.012682373334258368, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10778826134924568, 0.08646571419721683, 0.1278450455579463, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08072518725033317, 0.07221208984158856, 0.07795002765613979, 0.1326391001013011, 0.10598082891215077, 0.1193402760895913, 0.06617395838137152, 0.06411918345229606, 0.06651681043278423, 0.08905429292206846, 0.10214431319813289, 0.09066989327706632, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.077018031473567, 0.05274080156051786, 0.05363918931901468, 0.04920734227704415, 0.01996080013439694, 0.02542158512085213, 0.1545563242491904, 0.16729612436831598, 0.1622938280566265, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01668248594187627, 0.011632885036525376, 0.014353405043455725, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.062368876867084366, 0.06555394756810806, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06774586382308312, 0.05783652566695385, 0.06252173465214983, 0.09409715828006693, 0.10906942422809174, 0.09765310290617202, 0.034836765337878495, 0.041331947200993424, 0.037698406095433845, 0.07410947670881995, 0.05844850159656201, 0.0784313380289362, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016967705291885626, 0.02092174847029893, 0.020376612555874085, 0.019913590913581025, 0.02005493062547392, 0.018019254335489898, 0.14298894428325792, 0.14707548707996165, 0.13744975999280584, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "1ab492ca-9e51-4ea8-a9be-fe4b8f060fd3", "fitness": 0.054932834583914306, "name": "EnhancedHybridPSO_DE", "description": "Enhance exploration by introducing dynamic Gaussian noise scaling and incorporate adaptive mutation and crossover operators to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Adaptive inertia weight\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)  # Linearly decreasing DE scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))  # Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                # Gradient-informed mutation\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)  # Dynamic Gaussian noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i] + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                # Local search enhancement\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])  # Increased precision in adjustment\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05493 with standard deviation 0.11713.", "error": "", "parent_ids": ["4861cf15-7a04-40d6-ac47-390bcf199874"], "operator": null, "metadata": {"aucs": [0.1453726108497474, 0.17656123022119674, 0.14647188606690265, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.025388037888917747, 0.029359892683679112, 0.017498039784203834, 0.023769552364980573, 0.023788902412645307, 0.002364337876195499, 0.9219017065133632, 0.9517153813521181, 0.9142690881843383, 0.05280491149564581, 0.040276022160069314, 0.013996832332308307, 0.10798782785269301, 0.07491369451750407, 0.07579802201277686, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02435301803168821, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15839296206452913, 0.1845278741066858, 0.20471049926432394, 0.027922035887147256, 0.02201955112239251, 0.027463862830878538, 0.10675778750098375, 0.08582821534197582, 0.14411159366626547, 0.14351995412585516, 0.151020367476004, 0.1341147116503143, 0.10127515358000216, 0.09424839636608595, 0.123445328699752, 0.11443400959220018, 0.12965294313498388, 0.13105444116557086, 0.13020515582856496, 0.0004444444444444695, 0.12820082112697662, 0.14675601865873278, 0.12981479550771235, 0.11100174098029558, 0.10099119677183777, 0.09900830673660177, 0.1530513879101565, 0.15134445395931617, 0.155870279306614, 0.16431648070969884, 0.03900141192783446, 0.05094237837982574, 0.02770192317513731, 0.08050848079990602, 0.09049582528040478, 0.09071419029601979, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08936054345365418, 0.07933178232577043, 0.0713235350907202, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0057456735742920095, 0.010095230466131144, 0.007730453615786281, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.11345126709889464, 0.10633192695188776, 0.11701508748496803, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07465650973597482, 0.07274524135024618, 0.07442101983370109, 0.1286788845037532, 0.1243532324835045, 0.12643744286811376, 0.08116071037646155, 0.06358033984488187, 0.06279492393668484, 0.09304072769575744, 0.09972819831545854, 0.10679999853325517, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03375913652660045, 0.06040797693278266, 0.05211383412041326, 0.048629554693371824, 0.035769347599286294, 0.04751215426419386, 0.14900732619722712, 0.1712922966156325, 0.17433360317915725, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02454738535390466, 0.0004444444444444695, 0.023040766637592802, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011066531196830653, 0.003221004009138051, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.047874453204313716, 0.07714904361673203, 0.05652133851019081, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.059832730579136406, 0.05912280051555474, 0.06008110430879687, 0.11327217817799784, 0.107312856626541, 0.0931885614743595, 0.030950487690125428, 0.05016327253771713, 0.037698406095433845, 0.07975356975366477, 0.07990524618197781, 0.07760748724329503, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01857833602715986, 0.02160763018611722, 0.01709535476493107, 0.019717785090132445, 0.021025299525301078, 0.0223706197013267, 0.14663818973326725, 0.13635344807177752, 0.13895067188882582, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "f72c40f2-7e9e-4eac-b63c-36aa08bed6f8", "fitness": 0.04863385725393723, "name": "EnhancedHybridPSO_DE_Improved", "description": "Integrate adaptive neighborhood search and chaotic maps to enhance diversity and convergence speed in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.chaotic_map = np.random.rand(self.population_size, dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            self.F = 0.5 - 0.3 * (evaluations / self.budget)\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                chaotic_term = self.chaotic_map[i] * 0.1\n                self.chaotic_map[i] = 4 * chaotic_term * (1 - chaotic_term)\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + chaotic_term + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_value", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04863 with standard deviation 0.08120.", "error": "", "parent_ids": ["1ab492ca-9e51-4ea8-a9be-fe4b8f060fd3"], "operator": null, "metadata": {"aucs": [0.14821942146496925, 0.12884749242766547, 0.14164949245196834, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04508012760276747, 0.0444731662060599, 0.028510418786750757, 0.010755694496702883, 0.01482841489650577, 0.00814900088454451, 0.9293218815834673, 0.22035388841579517, 0.17061452781431674, 0.04211502859865368, 0.03631230717943801, 0.04097329414159345, 0.06290505227181165, 0.09195605021665698, 0.08378906618299653, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007768958016155847, 0.0004444444444444695, 0.008690752275311131, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.174539681155636, 0.17153371337546253, 0.14832405801984105, 0.03331182465297955, 0.024442331071811485, 0.04158213949417222, 0.12976557080330686, 0.09842572941321903, 0.10302032934499206, 0.14469343099748266, 0.15037818325810093, 0.15438506061016144, 0.10163759371137504, 0.08607240767279312, 0.09649869835192781, 0.13957130359720415, 0.13581167836216101, 0.13219107085056436, 0.1353407284254564, 0.034619025156514716, 0.12930740864409418, 0.11299672889785495, 0.11686353037398767, 0.11078738846510539, 0.11653808634243368, 0.07799386507985562, 0.10836750741431922, 0.15945079951823216, 0.17085201265274996, 0.15632543214712835, 0.04398505443850198, 0.05604526563995127, 0.04155772001015268, 0.08522198992698193, 0.08109637741173659, 0.1069775462293564, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09238118139914064, 0.07516612220262564, 0.11670922500573766, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005794581645920394, 0.0007221532619886561, 0.024116214913773026, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12092995142865692, 0.11394319251128227, 0.09317235103134125, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07255163168280965, 0.06639293221469922, 0.0810626165860433, 0.13222089460061837, 0.13617742481109452, 0.1196254691169959, 0.07109465214230615, 0.06845736234272792, 0.05369982826530839, 0.09672533023301266, 0.10384246547529397, 0.10477875785473623, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04814720348045198, 0.06504389111740216, 0.044812450572497275, 0.04969032070868218, 0.046053506858882765, 0.048497135934912894, 0.15930343801230495, 0.1575117998682708, 0.15206738405080023, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.024582912764618325, 0.027460217496786288, 0.02822974832833658, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010651747209856288, 0.006318526539057068, 0.01177535814179198, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07959883466221496, 0.07776844798869798, 0.06296344697318923, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07106741149210327, 0.054779098386660396, 0.05566394571317268, 0.10336462993849538, 0.0988727485690063, 0.09997359523613059, 0.057883587219107246, 0.05033230640739361, 0.05162580561793362, 0.08035777582798331, 0.08010039940518654, 0.07659563858815088, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015907245005689075, 0.019941849072611095, 0.020051914335607046, 0.020517451419774124, 0.013953284095521434, 0.0352026905181293, 0.14046181851870054, 0.1424288534073257, 0.14552065676471082, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "a06f50e1-9621-46c5-ad99-e3e18649b8ab", "fitness": 0.05745894915957622, "name": "RefinedEnhancedHybridPSO_DE", "description": "Integrate an adaptive learning rate for PSO updates, employ a diversity-based restart mechanism, and introduce chaotic maps for parameter tuning to enhance convergence robustness.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n    \n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            self.F = chaotic_value * (0.5 - 0.3 * (evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i] + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                \n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n                \n                if evaluations >= self.budget:\n                    break\n            \n            # Diversity-based restart mechanism\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n\n        return self.best_global_value", "configspace": "", "generation": 22, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05746 with standard deviation 0.06354.", "error": "", "parent_ids": ["1ab492ca-9e51-4ea8-a9be-fe4b8f060fd3"], "operator": null, "metadata": {"aucs": [0.1745998958969236, 0.20735595717945476, 0.23258444415986657, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.049552202104641174, 0.04329343702748678, 0.05741009859020996, 0.04324858376496887, 0.036354923874986844, 0.034581431977555366, 0.11024332680369653, 0.1254871152450725, 0.11701445947910516, 0.11211174322886674, 0.08422812985944395, 0.11180969013789188, 0.11656146979183146, 0.17963183446250308, 0.12100469528332003, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017750638506313976, 0.029886922708848185, 0.027298611959889363, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04433273542285898, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.018236910326144273, 0.0004444444444444695, 0.2074399821644628, 0.22947343963864053, 0.20203847243797224, 0.05550509134510362, 0.061827440386064914, 0.03602304347062135, 0.12215823999956121, 0.12346016868891252, 0.10895627661648499, 0.1887673133846265, 0.1661691032843413, 0.17957263389878797, 0.11501691464757646, 0.12602742643924103, 0.10257541456670582, 0.15669358788492127, 0.1706352899713095, 0.13592513384055072, 0.14087968045903831, 0.15986450412781372, 0.1497768218068335, 0.10614631909456651, 0.15655667510693094, 0.1371703214630119, 0.10224030672996764, 0.06681734737187106, 0.06732944578755728, 0.18365732033358517, 0.18494849463623364, 0.1501831051783732, 0.05087094593791919, 0.06294300460552482, 0.047135602767560236, 0.12127516660988291, 0.117410236752573, 0.1407454799525758, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04044672602788668, 0.05708426982352188, 0.06848488812380737, 0.03123075184760049, 0.01910745843720829, 0.0004444444444444695, 0.03938916717170449, 0.040148481626171906, 0.040530466189547365, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15895780402894844, 0.15379728875572252, 0.1466661821993167, 0.0006510790283276169, 0.003236069098766614, 0.0004444444444444695, 0.07128153884407118, 0.0670137980418688, 0.07627187759348697, 0.15357384982748412, 0.13725106126886744, 0.166695800247059, 0.09392553560058148, 0.08410597839243239, 0.10006718038439733, 0.12082126666358595, 0.1407865403893841, 0.13915746106640892, 0.11721450158544944, 0.04272349743154735, 0.13974848741360502, 0.06986143127236455, 0.10705528335097403, 0.10049680978151787, 0.030037238135536493, 0.0949472434380716, 0.10179769319231724, 0.14744427935891435, 0.1538410713127244, 0.15678484949390703, 0.0004444444444444695, 0.0005799475142048705, 0.014646534490258767, 0.05537154307257519, 0.055036815755727275, 0.07030332231774683, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09723049195054145, 0.10188636499836745, 0.10162808771967535, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06171407599254919, 0.05919739628296117, 0.059285290062618734, 0.12062515854141975, 0.113605811626459, 0.12038217956671526, 0.066776997937814, 0.05723044926581089, 0.06236386894957813, 0.11823385869532488, 0.11574692065592485, 0.12186724858820597, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.043297883881940336, 0.04205188117350067, 0.027830945127601647, 0.04873813380468828, 0.03103099735722248, 0.02464879370909634, 0.1464091956160971, 0.146687844705374, 0.14485061903934593, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "69544421-d660-4ed2-b1b5-06f4c8f17a53", "fitness": 0.05918682023710937, "name": "RefinedEnhancedHybridPSO_DE", "description": "Refine the balance between exploration and exploitation by introducing a mutation factor based on fitness variance for enhanced convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n    \n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            self.F = chaotic_value * (0.5 - 0.3 * (evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)  # New line\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance)  # Modified line\n\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i] + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                \n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n                \n                if evaluations >= self.budget:\n                    break\n            \n            # Diversity-based restart mechanism\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n\n        return self.best_global_value", "configspace": "", "generation": 23, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05919 with standard deviation 0.08523.", "error": "", "parent_ids": ["a06f50e1-9621-46c5-ad99-e3e18649b8ab"], "operator": null, "metadata": {"aucs": [0.16031529619090013, 0.1943028344562615, 0.20452781632695605, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.053096848981752265, 0.06628543941426401, 0.04116351788569628, 0.027429905287970957, 0.036354923874986844, 0.024670829800592986, 0.10963380285316915, 0.11948362287021341, 0.9208507100163401, 0.11211174322886674, 0.08422812985944395, 0.11180969013789188, 0.07930981273967541, 0.1254132531956974, 0.10626024795721944, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017750638506313976, 0.029886922708848185, 0.027298611959889363, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04433273542285898, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.004426349729517387, 0.0004444444444444695, 0.2133058210196822, 0.21769471506519156, 0.17923345082307018, 0.04725738872818874, 0.09247275974808822, 0.03602304347062135, 0.11854489035966131, 0.12460684646919462, 0.10477571332097424, 0.15953667367896662, 0.1406234058710074, 0.19715823230993257, 0.12651820430499416, 0.09545956190033389, 0.11386043841454552, 0.15669358788492127, 0.16750979516029696, 0.15113792809507043, 0.1387458667799607, 0.15986450412781372, 0.16237991901642512, 0.15888527468455338, 0.14879978936931815, 0.17971529203882053, 0.12262273727023354, 0.06984892033251766, 0.07162265468597351, 0.1621604441435689, 0.18428646934721493, 0.15140299144556302, 0.04327660908488462, 0.04231850438318219, 0.047746853827940416, 0.1043755627078149, 0.10739899464874203, 0.1144921449400742, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07918777275936373, 0.05310723901147418, 0.056814798242893705, 0.03123075184760049, 0.01910745843720829, 0.0004444444444444695, 0.03077602056092943, 0.03370630471950631, 0.044138242078871515, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14456516925426222, 0.1591103988464948, 0.1438993839542274, 0.0004444444444444695, 0.004016051517530039, 0.0004444444444444695, 0.08179488763495946, 0.09205410144624349, 0.06530533990094045, 0.1248582649642449, 0.1436135276137822, 0.14976349092581487, 0.08415010103508958, 0.09405743778124509, 0.09241435782513441, 0.12303714042034963, 0.1413356398730956, 0.12466239482586228, 0.12017405695521932, 0.04272349743154735, 0.13974848741360502, 0.061230329641266734, 0.08639691782791181, 0.07041281683856548, 0.09958429257891399, 0.08755754660745696, 0.08335454177017587, 0.15576524903552968, 0.15156267881204666, 0.16267382126083307, 0.0004444444444444695, 0.0010840136073303475, 0.005854690712699395, 0.047166679956502144, 0.04570986302457458, 0.0632987596541833, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01427037977081802, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08126102754977138, 0.09388963116490723, 0.08732999834361943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06444667087866396, 0.05870314492757012, 0.05432080482966639, 0.10877071362939261, 0.10445470927097467, 0.11317395846569422, 0.05474365243105783, 0.05654450462539862, 0.05322764246984457, 0.11763006031448153, 0.11175534132450082, 0.11733339234769535, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.021258776276214753, 0.01965524724691592, 0.018959983595649765, 0.028427936887670535, 0.025989582320007476, 0.0228276365298673, 0.1486974926197403, 0.16965712604768934, 0.1422751214332113, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "b25dbab0-2fbc-4b37-92d8-bff7c69c3d0f", "fitness": 0.059214075521189055, "name": "RefinedEnhancedHybridPSO_DE", "description": "Introduce an adaptive chaotic map for updating DE's scaling factor and leverage a strategic diversity reset for enhanced exploration.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n    \n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            self.F = chaotic_value * (0.6 - 0.3 * (evaluations / self.budget))  # Modified line\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)  # Modified line\n\n                gradient = np.gradient(values)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + 0.1 * gradient[i] + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                \n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n                \n                if evaluations >= self.budget:\n                    break\n            \n            # Diversity-based restart mechanism\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf  # Reset for exploration enhancement\n\n        return self.best_global_value", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05921 with standard deviation 0.08516.", "error": "", "parent_ids": ["69544421-d660-4ed2-b1b5-06f4c8f17a53"], "operator": null, "metadata": {"aucs": [0.16031529619090013, 0.1943028344562615, 0.20452781632695605, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.053096848981752265, 0.06628543941426401, 0.04116351788569628, 0.027429905287970957, 0.036354923874986844, 0.024670829800592986, 0.10963380285316915, 0.11948362287021341, 0.9208507100163401, 0.11211174322886674, 0.08422812985944395, 0.11180969013789188, 0.07930981273967541, 0.1254132531956974, 0.10626024795721944, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017750638506313976, 0.029886922708848185, 0.027298611959889363, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04433273542285898, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.004426349729517387, 0.0004444444444444695, 0.2133058210196822, 0.21769471506519156, 0.17923345082307018, 0.04725738872818874, 0.09247275974808822, 0.03602304347062135, 0.11854489035966131, 0.12460684646919462, 0.10477571332097424, 0.15953667367896662, 0.1406234058710072, 0.19715823230993257, 0.12651820430499416, 0.09545956190033389, 0.11386043841454552, 0.15669358788492127, 0.16750979516029696, 0.15113792809507043, 0.1387458667799607, 0.15986450412781372, 0.16237991901642512, 0.15888527468455338, 0.14879978936931815, 0.17971529203882053, 0.12262273727023354, 0.06984892033251766, 0.07162265468597351, 0.1621604441435689, 0.18428646934721493, 0.15140299144556302, 0.04327660908488462, 0.04231850438318219, 0.047746853827940416, 0.1043755627078149, 0.10739899464874203, 0.1144921449400742, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07918777275936373, 0.05310723901147418, 0.056814798242893705, 0.03123075184760049, 0.01910745843720829, 0.0004444444444444695, 0.03077602056092943, 0.03370630471950631, 0.044138242078871515, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14456516925426222, 0.1591103988464948, 0.1438993839542274, 0.0004444444444444695, 0.004016051517530039, 0.0004444444444444695, 0.08179488763495946, 0.09205410144624349, 0.06530533990094045, 0.1248582649642449, 0.1436135276137822, 0.14976349092581487, 0.08415010103508958, 0.09405743778124509, 0.09241435782513441, 0.12303714042034963, 0.1413356398730956, 0.124662384026756, 0.12017405695521932, 0.04272349743154735, 0.13974848741360502, 0.061230329641266734, 0.08639691782791181, 0.07041281683856548, 0.09958429257891399, 0.0875575466263846, 0.08335454177022639, 0.1557515332888233, 0.15432123490113225, 0.16267277720091589, 0.0004444444444444695, 0.0010840136073303475, 0.005854690712699395, 0.047166679956502144, 0.04570986302457458, 0.0632987596541833, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01427037977081802, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08126102754977138, 0.09388963116490723, 0.08732999834361943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06444667087866396, 0.05870314492757012, 0.05432080482966639, 0.10877071362937207, 0.10445470927097467, 0.11317395846501266, 0.05474365243105783, 0.05654450462539862, 0.05322764246984457, 0.11763006031448153, 0.11175534132450082, 0.11733339234769535, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.021258776149879033, 0.01965524724691592, 0.018960050090904734, 0.03183510137634704, 0.03537902344777244, 0.025143605153419735, 0.13828444434863274, 0.16965712605903027, 0.14071888494364426, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "f7f694bb-aaab-4dd4-bef6-916772588a8b", "fitness": 0.061672426916197814, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce adaptive dynamic inertia weight for PSO, integrate Lvy flight for enhanced exploration, and employ a non-linear DE scaling factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Diversity-based restart mechanism\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 25, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06167 with standard deviation 0.08793.", "error": "", "parent_ids": ["b25dbab0-2fbc-4b37-92d8-bff7c69c3d0f"], "operator": null, "metadata": {"aucs": [0.1865465648428567, 0.2219922795863375, 0.17393150404967772, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04995569116490073, 0.05151869361643857, 0.03930863094215398, 0.034450054088608684, 0.024588595091878274, 0.0518550404493312, 0.19819251799287874, 0.938674699613686, 0.11475379671470742, 0.0857846047372316, 0.0907275870490698, 0.08957339094548433, 0.17816256167234634, 0.12966208585618222, 0.1224551080657802, 0.0004444444444444695, 0.023646142098559753, 0.0004444444444444695, 0.09083830298183038, 0.09463403215422617, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.004264364498359763, 0.21984799073161365, 0.1987318771388754, 0.2128620271681686, 0.05464993720274791, 0.04818534319291601, 0.025806706442884075, 0.11171506062164904, 0.11802251202159886, 0.08219885178684572, 0.176427029038576, 0.16284091175726, 0.19930828473665174, 0.10188359521043056, 0.10477259072002676, 0.12960008401072665, 0.1581873553949562, 0.18370063252551816, 0.15953700476917398, 0.15131306453059912, 0.1478583466061617, 0.15206994254617545, 0.1481253417648436, 0.22697059881556414, 0.11151730202210808, 0.11061882786762556, 0.11228954388242651, 0.1685098323073072, 0.17182093852600944, 0.14668851060092225, 0.20011879581475012, 0.07561031158904719, 0.05078567662204114, 0.051821233380347054, 0.10736389582784311, 0.12180511888644563, 0.14538054261802202, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005669633656694928, 0.0025142421664022807, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06900095715235366, 0.033342667211590515, 0.05843474781413249, 0.03319423687562084, 0.02672507642850397, 0.018089754912674838, 0.037287006125682365, 0.042523890062058256, 0.034684053372024626, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02044876959064923, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14545576636017454, 0.13349330829129358, 0.13747800647361808, 0.0004444444444444695, 0.0004444444444444695, 0.0020780064513965524, 0.0643300771557046, 0.08360516816137731, 0.067666063181966, 0.139634596227576, 0.13944499025063228, 0.14670286095960094, 0.10299238089889418, 0.07925173547682163, 0.07910295099326925, 0.13170818683685237, 0.12373987223011185, 0.1257686261280473, 0.13208667013148445, 0.12815726259449223, 0.131955465554914, 0.07031509527266988, 0.07055881205794134, 0.08190096661461066, 0.03676739542855445, 0.07642092341374562, 0.057672641863783736, 0.16162910968540234, 0.16216373261948303, 0.1596715906162378, 0.010369805721857528, 0.0004444444444444695, 0.007011195853913632, 0.04905845042188328, 0.039241675537799114, 0.05947358075396525, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0018346970711548005, 0.0004444444444444695, 0.014525756734789508, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0015056786259568522, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08505903596630504, 0.10074042301189812, 0.07852856251645124, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05412983751689293, 0.0564540088361043, 0.0526898946945451, 0.11393425776943267, 0.1097221370138114, 0.10876969419565685, 0.06264268465645528, 0.057129025235140185, 0.05493931725149559, 0.11770309136773383, 0.11825015382208581, 0.11529839064977332, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03771215395397953, 0.05031397384672365, 0.022673647563584587, 0.01516478713291547, 0.024437080342320172, 0.01855419189903118, 0.15281914602841817, 0.14475287226955957, 0.14945361922444067, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "e838af38-9f35-41b4-8cdb-5983d36b8e6c", "fitness": 0.05682913839877156, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce a dynamic adjustment to the cognitive and social coefficients of PSO based on the evaluation ratio to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Diversity-based restart mechanism\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n            # Change 1 line here: Adapt c1 and c2 based on evaluations\n            self.c1 = 1.5 + 0.5 * (1 - evaluations / self.budget)\n            self.c2 = 1.5 + 0.5 * evaluations / self.budget\n\n        return self.best_global_value", "configspace": "", "generation": 26, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05683 with standard deviation 0.06484.", "error": "", "parent_ids": ["f7f694bb-aaab-4dd4-bef6-916772588a8b"], "operator": null, "metadata": {"aucs": [0.18720428028530256, 0.21827983935060424, 0.1708394516993471, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04541582442747538, 0.043817708949882794, 0.052858780237515446, 0.04170840559769873, 0.022752268222763328, 0.04046393724110875, 0.19777510450453717, 0.2947155794981696, 0.1075620546717293, 0.05191378414702108, 0.08732975276194577, 0.08930003809127429, 0.11948168254166502, 0.1250726214709056, 0.13377164823596321, 0.0004444444444444695, 0.017878741812405785, 0.0004444444444444695, 0.05178670157024401, 0.06535300276122225, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03690483818101231, 0.008120922805548991, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.22980850819339715, 0.20100334843599887, 0.18483127659980159, 0.050252895336833414, 0.0519880671381624, 0.03666579436424788, 0.11206183392786306, 0.10889298962171257, 0.12123939905458969, 0.15819212877298194, 0.1664686491344166, 0.19621999319603278, 0.11746839635118567, 0.11368845071494105, 0.10137907809182489, 0.16309503209616538, 0.18370063252551816, 0.16590868224371746, 0.14987506087865832, 0.14961665890885156, 0.1660838430894025, 0.15122991919499873, 0.22931220275538622, 0.12376217118658939, 0.11290048185694246, 0.1006621176193202, 0.1295417799722377, 0.15923876945642412, 0.15224127239990193, 0.1651318344040158, 0.048541713492623484, 0.04853027482927352, 0.047244377143873306, 0.09609642251914119, 0.10769038398332986, 0.1052422501294421, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0021407282679910544, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06483490987564533, 0.037565314090751145, 0.057316185790077134, 0.029675205634133395, 0.004581862810127846, 0.005831934438239261, 0.04165003195526695, 0.03944294024416861, 0.039539068495501484, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005071090856561988, 0.02167359493121268, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14150633010593316, 0.14327723332668496, 0.13318140010818702, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0715151491394801, 0.07375174451432864, 0.06545188737703822, 0.1451628396974468, 0.14453838713892964, 0.14806871099552155, 0.08161782261242867, 0.08354825143547329, 0.08167723846598629, 0.13562374706766145, 0.12604150834284966, 0.1276215917942528, 0.13286262374636748, 0.03445295560284711, 0.08587716364060216, 0.055680197023282973, 0.07840706338105596, 0.09066833097083926, 0.05298733084517493, 0.07444504660414375, 0.057890806487976065, 0.1685239013422828, 0.16372448031846765, 0.16888797730502603, 0.0004444444444444695, 0.0025180082158794415, 0.003937587507097051, 0.04948844440881617, 0.034681540167154856, 0.0542225465267252, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0011920511401510847, 0.0004444444444444695, 0.002950292411980193, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08270508735229709, 0.0955512649750686, 0.07973320195450873, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05707105572555038, 0.0564540088361043, 0.07137429373384319, 0.11031414093469938, 0.10567155770292891, 0.12361466467311033, 0.05522438811852992, 0.0525435094774902, 0.058315365210584, 0.11421795394193857, 0.11100802500487261, 0.11118321934000897, 0.0004444444444444695, 0.08597389781778075, 0.0004444444444444695, 0.023187056834305775, 0.028858721035060486, 0.030755795908685157, 0.013929661784194969, 0.025643675189339188, 0.021095564484449936, 0.15524796920127293, 0.14444600371314487, 0.14133287311976805, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "2e27456a-5462-4b15-bfd4-8c3f28a3b3cb", "fitness": 0.05902952672500617, "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhance global and local search capabilities by integrating adaptive Gaussian mutation, elite retention, and self-adaptive control of population dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_gaussian_mutation(self, trial_vector, evaluations):\n        mutation_strength = 0.5 * (1 - evaluations / self.budget)\n        mutation = np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(trial_vector + mutation, self.lb, self.ub)\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        elite_best_position = np.copy(self.best_global_position)\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = x1 + self.F * (x2 - x3) + self.levy_flight(self.dim)\n                mutant_vector = self.adaptive_gaussian_mutation(mutant_vector, evaluations)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (elite_best_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Diversity-based restart mechanism\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05903 with standard deviation 0.08609.", "error": "", "parent_ids": ["f7f694bb-aaab-4dd4-bef6-916772588a8b"], "operator": null, "metadata": {"aucs": [0.1896431488125192, 0.1882845921812093, 0.18048371024612897, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04979727036597836, 0.06942589429129797, 0.040454121529217235, 0.03370118644664222, 0.03194901748230239, 0.06382725837992498, 0.17666183181519934, 0.9217547663949206, 0.1252130404742804, 0.061332782953929854, 0.08843494524924866, 0.07221272806255552, 0.1612019186849526, 0.133129215829365, 0.10836818173765117, 0.0004444444444444695, 0.052980057562612926, 0.0004444444444444695, 0.0048437662323566055, 0.044551005028112045, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10149640088607847, 0.0004444444444444695, 0.004434775748827335, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.2155032197078277, 0.20086727589573472, 0.18570926648808472, 0.03568735593440153, 0.06911807574118312, 0.03822677427968235, 0.12415887152021188, 0.11109885958644483, 0.13969202776728706, 0.17466922876649338, 0.17633135186052773, 0.1943220355523475, 0.1398132868383265, 0.1098687058043345, 0.16021442186416046, 0.1431178030668001, 0.15555614329285583, 0.1440342434185351, 0.167307474840651, 0.152149591045745, 0.1554555714833571, 0.1625333806222199, 0.1753721153136406, 0.120942287799225, 0.06359466493437882, 0.11574268424782153, 0.16440164663878454, 0.16496728634768798, 0.15618250279467305, 0.1582472718572948, 0.04239896773311158, 0.05129760678284234, 0.04239162662314755, 0.09794933163662856, 0.11028347165031316, 0.10630835302625752, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0020313791817443416, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03783503879833694, 0.03471085543979646, 0.0469814683881955, 0.005847273176195378, 0.006696966654003211, 0.020946265462952307, 0.040325529224750856, 0.026122765425995675, 0.033746485131609605, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011219708280225005, 0.015618079163941978, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13449211391777438, 0.15531441969072024, 0.1292621568437502, 0.004787954310120135, 0.0013783455531944933, 0.0004444444444444695, 0.06599529295823092, 0.07982847181660191, 0.09878439550559603, 0.12204724994838356, 0.12623482282028242, 0.13927390530779016, 0.09887401837884702, 0.0805566678265136, 0.07983348405701951, 0.13580161063646734, 0.12721311241791622, 0.12522959131915457, 0.14998076834445806, 0.12689723561112098, 0.0004444444444444695, 0.06161757486061048, 0.0943134379434547, 0.12142655158651128, 0.02664689785894192, 0.05094309439845646, 0.04086820305754635, 0.155710786077924, 0.1624965158918441, 0.1712898535387819, 0.001898736421952374, 0.002984438297588987, 0.003147611119642346, 0.04600893702128084, 0.03539968236272362, 0.04422219690995799, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0014347154835674392, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0023259124985633983, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08637374971640988, 0.07237669272741831, 0.06684506503527432, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.051685781427614264, 0.05817352396896236, 0.06286768189150138, 0.11146053882867901, 0.10417131097099164, 0.11580288552285345, 0.0651673995504558, 0.04855626687867054, 0.052589406998048704, 0.11597317902188653, 0.11120945400506721, 0.1144607256839073, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015376539547792056, 0.04336139267759609, 0.018022967816983093, 0.014605838790073933, 0.017706904241922783, 0.021165646516801195, 0.1395123920032325, 0.14674762514861117, 0.14208804977343203, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "30bfa00f-a1bf-4996-bd8f-e10320a5cdef", "fitness": 0.05840814163424687, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Incorporate a Gaussian mutation strategy to enhance local exploitation capabilities of the algorithm.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i]) + np.random.normal(0, 0.05, self.dim)  # Added Gaussian mutation here\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Diversity-based restart mechanism\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 28, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05841 with standard deviation 0.06371.", "error": "", "parent_ids": ["f7f694bb-aaab-4dd4-bef6-916772588a8b"], "operator": null, "metadata": {"aucs": [0.2038939020535384, 0.21948092093414062, 0.20608098348850634, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06139760733486499, 0.052609574502801126, 0.03352742122716845, 0.0449200632615262, 0.03683731243090205, 0.038694809283150944, 0.125762669519625, 0.19209009725167947, 0.19987507572671837, 0.08280853867204352, 0.10765648881082956, 0.08545905976904578, 0.10716061096920915, 0.1607439044020733, 0.10906748409246703, 0.0004444444444444695, 0.028379762899665817, 0.025144773721699765, 0.030281269283787604, 0.013530620923309922, 0.01339270863651254, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04933683288227464, 0.022869892407108794, 0.0185961805133249, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.2131157146155056, 0.198663868623971, 0.19555366144320807, 0.03872111076736917, 0.050242583383084516, 0.05439462292353503, 0.1146146571636657, 0.11463490622899508, 0.12680234255376355, 0.1793059074360338, 0.15621114719186546, 0.1821809538214748, 0.10362554339003682, 0.12022237600042784, 0.13141596708250103, 0.1797471591121269, 0.17341958076473674, 0.146007336969049, 0.1502060852743491, 0.14755370771509846, 0.14796392290293658, 0.1485796421181218, 0.11340686039867609, 0.22088373038135367, 0.0633650902483407, 0.10017577993006788, 0.11812089856438168, 0.15990145518624976, 0.17870058219017737, 0.14279202891686482, 0.04234912979946337, 0.06020818791950555, 0.039966421356465553, 0.12558454584510959, 0.12141676869808748, 0.1442628056451658, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01331675990522696, 0.0004444444444444695, 0.004864896510401451, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07793460999076218, 0.06015822420114336, 0.08261902635911045, 0.031121647815565923, 0.025390328211967295, 0.024361217556712278, 0.057242916929349574, 0.05892441086200051, 0.04258661042250844, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.019149512888183007, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13058387316225206, 0.16078467580568223, 0.1364419108202799, 0.0012321557035964714, 0.0015979191747578225, 0.0039931223529019455, 0.0863724138440104, 0.09590412687119154, 0.08267248211715639, 0.14145368974551764, 0.14652216331787937, 0.1353424636649535, 0.09216045564249675, 0.09235785302034638, 0.07706706328781088, 0.12138217800772066, 0.1249381464915027, 0.13211557451137657, 0.11570519262837575, 0.1265552756846262, 0.12371603660510178, 0.09996140223061467, 0.07046074949190007, 0.08132893250419171, 0.05986258082359264, 0.08552958777956443, 0.05401054084478163, 0.14978304424322308, 0.14757483138972272, 0.1658410616883711, 0.013699575896727989, 0.004528540180702034, 0.004421621818547772, 0.05684647713891677, 0.03621135795798203, 0.054021487234190646, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.006821907220702195, 0.0004444444444444695, 0.011577783953120813, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001113785962787217, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09578343915372822, 0.0899533158640905, 0.08232399609417895, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.058322513288627253, 0.06618982239287008, 0.05210559495981315, 0.11323745869739066, 0.11132863456127118, 0.11343584157713726, 0.060315266332052864, 0.05123730394883874, 0.052805502615193345, 0.1171589732515933, 0.11490839422678922, 0.11571097260553764, 0.0004444444444444695, 0.010732134397999582, 0.0004444444444444695, 0.027480658709055028, 0.024300370975592567, 0.02900909397640561, 0.015796652648816023, 0.017083733443195692, 0.019243577289820846, 0.14431519601453313, 0.15113118573355555, 0.14350244354072073, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "4ddac769-baf7-4714-92a2-00a035c277ba", "fitness": 0.061873395485125326, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Incorporate a learning factor for adaptive CR based on success rate and utilize stochastic restarts to enhance robustness.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 29, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06187 with standard deviation 0.08871.", "error": "", "parent_ids": ["f7f694bb-aaab-4dd4-bef6-916772588a8b"], "operator": null, "metadata": {"aucs": [0.21033832883664294, 0.20002482892755835, 0.20560758548374058, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.050763412800398644, 0.064702319451722, 0.039461753464061, 0.02677732314175163, 0.03057296656002184, 0.0314374722894174, 0.9343879117625572, 0.18317039900620324, 0.0883870876737286, 0.06741012429174875, 0.08878480129096455, 0.03353594146621375, 0.10345756685662444, 0.13548645688925287, 0.16142307839758985, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09083830298183038, 0.09463403215422617, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011006987416682823, 0.0016546940905579621, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.004264364498359763, 0.19375771529967045, 0.2052545618233953, 0.20146922648477705, 0.05964966722575349, 0.051487444554369044, 0.04611693983638809, 0.14167527051582784, 0.12764843008802473, 0.12496056490236696, 0.17267741095730438, 0.18674072728798397, 0.19142749329463926, 0.11640595681546784, 0.14158362985513007, 0.112899129986479, 0.1581873553949562, 0.20415556327011497, 0.1857283193614785, 0.16326595380530262, 0.15245931177669303, 0.1480865783231139, 0.1481253417648436, 0.22697059881556414, 0.17879211819625962, 0.07671858674845533, 0.0858961562827456, 0.23005564019793323, 0.1689727919188414, 0.14668851060092225, 0.1651318344040158, 0.05047603264402356, 0.05541557841973599, 0.04821504039068414, 0.12864069448948956, 0.0935593055264301, 0.11046688466595533, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01360762986485542, 0.0004444444444444695, 0.006768084506419747, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05598217708605868, 0.05240072467955059, 0.08241307088536576, 0.0013276616545491171, 0.017898188392385772, 0.01957849001769907, 0.03595670323100686, 0.017342543495058593, 0.04286096509265658, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011873399297762322, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13510745545724456, 0.1478385264607912, 0.14291169904649625, 0.001489877041743748, 0.0026857358065719428, 0.0049279673854984996, 0.08228281939102033, 0.07584506090859622, 0.06793605840702288, 0.15999437050159415, 0.16182999608570992, 0.1529475980908095, 0.08414017674600693, 0.08087454521939796, 0.07732280448808082, 0.12224549702520382, 0.131938382632943, 0.14140410297449357, 0.14055975043535707, 0.11527444581078228, 0.12366861101742765, 0.08798825441590408, 0.0748097851592483, 0.09004991150912911, 0.05412686619126483, 0.08404122013286519, 0.07428074458777156, 0.14892134568985638, 0.14924516971411184, 0.15581690704669382, 0.0037497809011397543, 0.010382704379580332, 0.007572965144289734, 0.06000575364544425, 0.033456487872950524, 0.05316327783241348, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09020979129869566, 0.08979796753651081, 0.07267132840772339, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04920758156123983, 0.059193969376252875, 0.04917052106889319, 0.11018683934362683, 0.1140672846041263, 0.12445038564863808, 0.05749614740124065, 0.05225840353456224, 0.055984573648392044, 0.11287433551300097, 0.11297952475090134, 0.12051229957854448, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.020075026155456088, 0.05520465289918808, 0.025039222917161763, 0.017389762863352698, 0.022831472847286483, 0.019084233619989788, 0.14832941863808569, 0.1508059937051649, 0.14031851107544258, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "145b81dc-b421-48a7-8f0b-8cf173db0b0f", "fitness": 0.06314583439733973, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Enhance adaptive learning rate by incorporating success rate to improve convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 30, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06315 with standard deviation 0.10257.", "error": "", "parent_ids": ["4ddac769-baf7-4714-92a2-00a035c277ba"], "operator": null, "metadata": {"aucs": [0.14886305539977374, 0.1767167539768053, 0.19359627308272032, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.051265074213650785, 0.04470841914209789, 0.043795242473878004, 0.03874707383642251, 0.02540690488843067, 0.9339241902520412, 0.9119149063394705, 0.10790341486550648, 0.08633286522770423, 0.08701385649848448, 0.07009793756910221, 0.08899257812576278, 0.1063138641020066, 0.1319660712549766, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04341163264086567, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04033632351891636, 0.02308852959317831, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013806984945705869, 0.19006033047107618, 0.20112473267194975, 0.21386765781275507, 0.04782644026416227, 0.055259266184732425, 0.03711787941453193, 0.13590702041128178, 0.08401349046620088, 0.09874770779406239, 0.1617514905410533, 0.1753963142890178, 0.18212215204890325, 0.11054900479537166, 0.1261537593652683, 0.11392275661932283, 0.15041016726336442, 0.19681388983902237, 0.16214611854476513, 0.146950307843988, 0.15832313077617755, 0.15243781307072335, 0.10725075410766993, 0.14109345755614744, 0.15086087375317092, 0.06304668946891268, 0.08182246978785623, 0.16666687541420777, 0.16105812858732083, 0.14135985375773574, 0.1471757530515736, 0.03907933493947857, 0.053203796211369836, 0.0522996366827706, 0.08862864097270584, 0.11442422132730767, 0.13520566390158528, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02498488769685192, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06938127307845854, 0.06339572446799424, 0.061128437419055714, 0.026216191947968315, 0.04264755771237816, 0.05379085739141254, 0.03864982155676544, 0.0587735777077113, 0.022767146599453336, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0034234025521205913, 0.03961788167626201, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13679469513105913, 0.13859584032325856, 0.004032750895289761, 0.006154783447653078, 0.0004444444444444695, 0.0847008243008135, 0.07349142918297202, 0.0805208306505305, 0.14801620821102324, 0.1351414260598336, 0.14420009909917064, 0.08296048011562052, 0.08006937634413647, 0.08265777027621635, 0.12320495062338821, 0.13755199360824188, 0.12453645796484325, 0.13850936468755837, 0.13773056100953762, 0.12613145071787768, 0.06136849212241213, 0.07293373569025463, 0.0970844478682521, 0.07534566999618497, 0.06046027299394985, 0.07858641726977067, 0.1508286489331292, 0.15631372346752115, 0.16006422746261983, 0.0004444444444444695, 0.0031925268721751943, 0.02146071551668527, 0.05594523333246615, 0.03672792449088247, 0.04291718237799225, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0871767578974032, 0.09213871387704986, 0.08418818248663673, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05829546410122044, 0.0564540088361043, 0.06389811124460942, 0.11947229782500757, 0.10841438140112647, 0.10647365540174447, 0.05670835625820392, 0.04669578073370617, 0.04959365720850417, 0.11469639094270578, 0.10813203700610663, 0.113737544618153, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04437039233564555, 0.06274950311017513, 0.023416946145567885, 0.016035938094756896, 0.02017165449739211, 0.02118311225645142, 0.14588060300340377, 0.14523837203673973, 0.14683943410329925, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "6a2e2a40-4159-4edb-8f80-0e0ac63ce662", "fitness": 0.06252880619477, "name": "AdaptiveDimensionalityReductionPSO_DE", "description": "Introducing adaptive dimensionality reduction and stochastic perturbations to enhance exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveDimensionalityReductionPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n        self.dim_reduction_factor = 0.1\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def dimensionality_reduction(self, vector):\n        reduction_indices = np.random.choice(self.dim, int(self.dim * self.dim_reduction_factor), replace=False)\n        reduced_vector = np.zeros_like(vector)\n        reduced_vector[reduction_indices] = vector[reduction_indices]\n        return reduced_vector\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                reduced_velocity = self.dimensionality_reduction(self.velocity[i])\n                self.velocity[i] = inertia_weight * reduced_velocity + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 31, "feedback": "The algorithm AdaptiveDimensionalityReductionPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06253 with standard deviation 0.06607.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.18211626693278193, 0.18969605907708142, 0.25147294370199613, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.061537340911936744, 0.0568975370480016, 0.04041201335009603, 0.03145594372456395, 0.04136131731131798, 0.04046829983302569, 0.11863350308753151, 0.07932323145166909, 0.1322148602936215, 0.1338848189475379, 0.08923535146103756, 0.1324537671144299, 0.13667343937558718, 0.13658946908583014, 0.1501256025855109, 0.05311002929108832, 0.00883145659752238, 0.04720167641681228, 0.05011935509751553, 0.025576931574693984, 0.058909333048284496, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06885427211932416, 0.04930178503963256, 0.03319993145716238, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.006374979070834619, 0.2447859734416754, 0.23501659245513118, 0.21246851492480467, 0.03344507891387527, 0.049383391086967654, 0.04049683800354675, 0.11517267483869009, 0.10949545826579676, 0.14162304256774472, 0.18673443435032888, 0.18494274056844573, 0.1782565398883844, 0.0996120637907415, 0.12374228983517521, 0.14144306664412498, 0.20055883359024196, 0.14046287970027738, 0.184192293737794, 0.1489704404985397, 0.15786950836726654, 0.15836965940750436, 0.13723718807254404, 0.21941672435988802, 0.1629949615261701, 0.17057487213865863, 0.07611473736334218, 0.133224086321034, 0.1629717548410149, 0.16341918939478595, 0.17036399473644637, 0.04733507087277111, 0.058135736975279406, 0.044953965391652084, 0.10874353074954302, 0.14159219972110215, 0.13318519094710168, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0031654886966248075, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.046231839325505564, 0.04877622687602223, 0.04783755988781113, 0.03721445447201044, 0.02510614805384348, 0.05126361704450355, 0.052759994159369605, 0.046068459211129564, 0.04899726686748462, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0035164166755227155, 0.004293978399432241, 0.025028698941573668, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1326939213372733, 0.15866522146790163, 0.15800974407679114, 0.010297283513177824, 0.00045273963393421823, 0.0004444444444444695, 0.07784784483776697, 0.08609158264195382, 0.08842457061757747, 0.14693659911769186, 0.14421795552487682, 0.147040496267265, 0.10205567770844759, 0.0897606408165591, 0.1026177047545277, 0.13591400868304104, 0.1310968839642177, 0.132675927381257, 0.1338475173602638, 0.1421882715882664, 0.13743602031351754, 0.04838372715055406, 0.10432339611284969, 0.15503331812714372, 0.07584934990245795, 0.07868034393186707, 0.06606899827149915, 0.1551867500366957, 0.1666160283522894, 0.17093310931607342, 0.0025479464598594515, 0.0076074181755779735, 0.004765393819324837, 0.058600775799509064, 0.03903416415980687, 0.05626092389123305, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007653907267625604, 0.0004444444444444695, 0.008633216415462441, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.009967787017338803, 0.0004444444444444695, 0.004586569326411327, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09689208507888558, 0.09586993115058029, 0.08792382174467517, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.051461800170177874, 0.06164677124636975, 0.06259755033430658, 0.11573654805220901, 0.11361927893496593, 0.10846806310249557, 0.05747979153738336, 0.05523545732696744, 0.04904085425129501, 0.11778445549376881, 0.12131009951002247, 0.12000256686762423, 0.0004444444444444695, 0.03522460597358601, 0.12270343645785708, 0.037115145108726044, 0.0313845841141972, 0.037862103614001, 0.03085332331817603, 0.04869409396523161, 0.025425651114938663, 0.1594555139314181, 0.14941326577696168, 0.13753153395906725, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "e917b028-806a-4fac-a19d-1c279f22c057", "fitness": 0.06024430795020415, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce dynamic mutation scaling based on function evaluation progress to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                dynamic_scale = 1 - (evaluations / self.budget)  # New dynamic scaling\n                mutant_vector = np.clip(x1 + dynamic_scale * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)  # Line updated\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 32, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06024 with standard deviation 0.08604.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.16490488124791314, 0.1767167539768053, 0.19413655669074437, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06983083840664162, 0.06982706700789798, 0.08252303318101273, 0.025698588704382352, 0.029322358043888386, 0.032949392681820955, 0.9338741265391246, 0.22069477100728396, 0.10743366353350348, 0.08594323891458888, 0.08655731381383136, 0.08100068284928497, 0.11514791651955536, 0.14240187787256886, 0.14724168271543114, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0539129601038163, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06612093845445255, 0.0004444444444444695, 0.0293307221113559, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.18370771029876876, 0.19014962711737515, 0.21171473360196835, 0.04566746457570725, 0.05959140216700487, 0.04164103948434217, 0.10675778750098375, 0.12544245119445518, 0.09834138448685892, 0.16371864889301524, 0.15449887445771682, 0.18629563628160528, 0.10733671196369199, 0.10905568605695481, 0.1253233904243083, 0.13852369481718718, 0.14621475449528376, 0.15548500788853803, 0.1467816176100074, 0.16290963334410968, 0.154468334774701, 0.11130740037247833, 0.1589225197485422, 0.15839711548714008, 0.06243196370106974, 0.1030291623169527, 0.16100431837600138, 0.1555980496310959, 0.17497562780617593, 0.17154633852440238, 0.043566769923830684, 0.03578661319128651, 0.04281885262772789, 0.12170156133189713, 0.12614560416874843, 0.1089161402746961, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01149321173905582, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.046814155738866825, 0.0290572578060736, 0.060105925654062586, 0.00417786908911999, 0.025136880929149674, 0.009857713894758868, 0.03911179007719312, 0.025636598072877548, 0.0330778521412588, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03673554817952551, 0.0004444444444444695, 0.003409991273977231, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13830376362480334, 0.1472940832255084, 0.0023344201940591613, 0.0004444444444444695, 0.004137141290258994, 0.09161062216915328, 0.07029520946983492, 0.0958337392458537, 0.14891920809470816, 0.1536975248769924, 0.13654321153900395, 0.08872335862767411, 0.08013737751806371, 0.08897371912296981, 0.125514034356369, 0.13161778566113858, 0.12799906230203906, 0.12835627504260005, 0.13613229447049047, 0.1212220719743583, 0.061890747962056736, 0.07806892178859748, 0.09499892849501346, 0.06332906580684172, 0.09022664930909163, 0.0656757223163772, 0.1661368118562837, 0.14731782987896413, 0.1713495620176102, 0.0004444444444444695, 0.006661542487654937, 0.0004444444444444695, 0.055331832993123164, 0.05073545832399884, 0.04544762690950377, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0017230721064326326, 0.00331771847495943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08618614343869957, 0.0964018565680399, 0.0864161179605043, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05997312379143027, 0.05817029500964599, 0.054481673426350685, 0.11453585034146418, 0.10650963644568079, 0.11505219028867819, 0.05372955105169441, 0.058015411486513235, 0.05688008429664604, 0.11609848247189913, 0.11295474547446693, 0.11246503889067239, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03291300938946651, 0.06706320942340571, 0.026245983925767713, 0.016416291743727496, 0.01692231936289501, 0.02640997632446085, 0.14206954777597192, 0.1440761106470052, 0.14022903778630502, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "91cfbd37-c3d4-4c49-b1a9-94f56c011df9", "fitness": 0.05113997190686084, "name": "AdvancedHybridPSO_DE_MultiSwarm", "description": "Integrate adaptive exploration-exploitation control with environment-inspired multi-swarm strategies to enhance convergence and diversity.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_DE_MultiSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_pop_size = 40\n        self.min_pop_size = 20\n        self.pop_size = self.initial_pop_size\n        self.vel = np.zeros((self.pop_size, dim))\n        self.best_pos = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.global_best_pos = self.best_pos[0]\n        self.global_best_val = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.success_rate = 0.0\n\n    def logistic_map(self, x):\n        return 3.9 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.pop_size\n\n        for i in range(self.pop_size):\n            if values[i] < self.global_best_val:\n                self.global_best_val = values[i]\n                self.global_best_pos = positions[i]\n\n        logistic_value = np.random.rand()\n        swarm_diversity_threshold = 1e-5\n        while evaluations < self.budget:\n            logistic_value = self.logistic_map(logistic_value)\n            self.pop_size = max(self.min_pop_size, self.pop_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.vel[i] = inertia_weight * self.vel[i] + \\\n                              (self.c1 * r1 * (self.best_pos[i] - positions[i]) + \\\n                               self.c2 * r2 * (self.global_best_pos - positions[i]))\n                positions[i] += self.vel[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.global_best_val:\n                        self.global_best_val = trial_value\n                        self.global_best_pos = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if np.std(values) < swarm_diversity_threshold:\n                    positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                    values = np.apply_along_axis(func, 1, positions)\n                    evaluations += self.pop_size\n                    self.global_best_val = np.inf\n\n        return self.global_best_val", "configspace": "", "generation": 33, "feedback": "The algorithm AdvancedHybridPSO_DE_MultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05114 with standard deviation 0.12105.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.12971558563849883, 0.13397951151090592, 0.11983970456568738, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015692323189592128, 0.015591834028476637, 0.025839326249953776, 0.011718046974047991, 0.0029169778233998356, 0.008303673685144508, 0.9834157112253286, 0.970569061322366, 0.9733560453009104, 0.04124910568114559, 0.057886407442884646, 0.0668780592716488, 0.05867232203630557, 0.07644222251721655, 0.12107149477388324, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.003836926399637397, 0.013157592518589167, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1749297743811834, 0.18600537660441185, 0.18806418051163176, 0.027922035887147256, 0.02201955112239251, 0.013607102932204684, 0.16218628635675836, 0.12573611884281788, 0.13597111141789842, 0.14425390835423124, 0.12353954536534861, 0.17470329564093523, 0.0830944880081178, 0.07400887765369668, 0.08471359305665105, 0.1100611627767949, 0.12141835776478915, 0.11532039385418202, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1205053547491548, 0.09614469311760698, 0.12081906206888737, 0.08538079692290312, 0.07385290307674197, 0.08880366662173445, 0.1695876205036072, 0.1532079524035861, 0.1604146549242309, 0.026524608038557607, 0.034335514002591605, 0.031821016908499145, 0.05265043501992639, 0.0632788429600557, 0.05005720985233575, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07213570783807033, 0.11986283357010885, 0.062346113397508174, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007316807119860713, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010704188688019145, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07887754737589281, 0.09661777415487083, 0.09183838226454177, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06940425692695174, 0.07532580365973629, 0.08219466661266173, 0.11025233694300995, 0.10598082891215077, 0.12114781921785556, 0.06158262908862544, 0.05453013656377437, 0.06278345404915364, 0.08920721514910934, 0.09002921607262049, 0.08631395255126861, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0335010850666303, 0.034312211033515894, 0.09180392761579503, 0.02664689785894192, 0.01553883599575101, 0.019706779518297468, 0.15465352430080626, 0.15457085024835937, 0.14639566887178745, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01092365016290342, 0.0004444444444444695, 0.01148146064491773, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02223260781713099, 0.004041695870512618, 0.028618774453353035, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.062966271609462, 0.04800313750525975, 0.06538533580850747, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04914990304437539, 0.060438721196501066, 0.0729200947642461, 0.09154177861090773, 0.09124479331930058, 0.0931885614743595, 0.030950487690125428, 0.04220406030573054, 0.037698406095433845, 0.06869354284724694, 0.05844850159656201, 0.06731983907948291, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.014115890629480043, 0.012810008897005454, 0.013954587565052079, 0.015378340134362234, 0.014466939474233054, 0.016422803491315974, 0.15643171882598772, 0.1462944827932523, 0.14158799498535424, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "6a33060d-90fd-40f9-a297-692c27faeea9", "fitness": 0.06093977920134841, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce adaptive chaotic map selection and dynamic population resizing to enhance exploration and convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 50\n        self.min_population_size = 15\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.3\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x, map_type='logistic'):\n        if map_type == 'logistic':\n            return 4 * x * (1 - x)\n        elif map_type == 'sine':\n            return np.sin(np.pi * x)\n        else:\n            return 4 * x * (1 - x)  # Default to logistic map\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        map_type = 'logistic'\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value, map_type)\n            map_type = 'sine' if evaluations % 2 == 0 else 'logistic'\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.7 - 0.4 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 34, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06094 with standard deviation 0.08927.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.2047057201624486, 0.20165866893523154, 0.19375834029296002, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04193531441178955, 0.0363806216995225, 0.039015216081058846, 0.03843718555934561, 0.03373681057589617, 0.041532031846511774, 0.989525043283905, 0.11870822160323191, 0.08406805199543543, 0.1027366152094008, 0.10863441412660368, 0.1156049948283222, 0.13191177739198157, 0.10376193402668588, 0.12605234494225104, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07282115231670494, 0.039603443577790665, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.012451915028180993, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.20160553264952863, 0.25048493219221335, 0.23319637517348424, 0.04642461341889936, 0.03249282311763879, 0.05720747008277838, 0.18824232001721108, 0.14322117293220715, 0.1424514109995041, 0.1585358345260015, 0.15134947247657382, 0.1578924687311003, 0.1292632929631713, 0.10190886741640615, 0.09176589373862087, 0.16648031602005475, 0.17304992268189123, 0.13787647489838661, 0.16002948084949786, 0.15088239782581703, 0.15574132078532477, 0.16186620102632165, 0.1505696112526982, 0.10985553943012727, 0.10304894150690291, 0.10799042461490693, 0.09382214853711257, 0.17335737711681642, 0.16574771855512926, 0.14929119971576799, 0.05937527279271715, 0.06346268149591039, 0.055674229852347046, 0.11663261244775691, 0.12993920187810548, 0.11157754773686024, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06581970493253397, 0.05864169592816004, 0.06702244613749397, 0.02371153742760379, 0.031949210261717265, 0.026038520726387238, 0.07035636160534364, 0.04755106164296097, 0.039493726823141784, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.022462147258745402, 0.0023034840537198287, 0.002451979074502675, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12871519248142027, 0.13266361357049816, 0.13649568285818392, 0.0004444444444444695, 0.0012805177002782608, 0.012557036740859617, 0.06947623226438193, 0.07042608541027318, 0.08960130534736854, 0.1578126923640324, 0.1377093561696151, 0.14395302774094743, 0.08767630101703683, 0.09242511206792636, 0.07312620333683906, 0.1207952937120641, 0.12163015948275802, 0.1297924565016514, 0.13744263942051482, 0.12903333846756493, 0.11770746737303073, 0.07511975208856647, 0.08966845116330013, 0.1251755386796507, 0.026684307290103515, 0.0771879779741772, 0.06337035355261977, 0.1777752123130777, 0.1463604818067722, 0.15359043761380586, 0.00511712847595458, 0.0013447145817515604, 0.016429379255742727, 0.04179021552923812, 0.044823768070998415, 0.04261111259328265, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010592590521239065, 0.006207565902459078, 0.0014202080010208284, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0789578438299613, 0.08910001291858372, 0.0867083756114363, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05189754736847296, 0.0565407406728633, 0.07132443754575313, 0.11959610629958928, 0.113112332356604, 0.11607840051293539, 0.05956726856342642, 0.048996136356448505, 0.05491849143981342, 0.11192993083778735, 0.11206197884074776, 0.11163870820931954, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016600493272514227, 0.02347800580716808, 0.031986439951571244, 0.016805837768539833, 0.021268757415920048, 0.03128492412278294, 0.1464799916396754, 0.14137048275813857, 0.14076758094905717, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "eee68d79-30cf-484b-98f9-f9bd5d7dbb03", "fitness": 0.06314583439733973, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce a refined chaotic map to enhance global search capability.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        # Replaced logistic map with sinusoidal map for enhanced search\n        return np.sin(np.pi * x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 35, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06315 with standard deviation 0.10257.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.14886305539977374, 0.1767167539768053, 0.19359627308272032, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.051265074213650785, 0.04470841914209789, 0.043795242473878004, 0.03874707383642251, 0.02540690488843067, 0.9339241902520412, 0.9119149063394705, 0.10790341486550648, 0.08633286522770423, 0.08701385649848448, 0.07009793756910221, 0.08899257812576278, 0.1063138641020066, 0.1319660712549766, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04341163264086567, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04033632351891636, 0.02308852959317831, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013806984945705869, 0.19006033047107618, 0.20112473267194975, 0.21386765781275507, 0.04782644026416227, 0.055259266184732425, 0.03711787941453193, 0.13590702041128178, 0.08401349046620088, 0.09874770779406239, 0.1617514905410533, 0.1753963142890178, 0.18212215204890325, 0.11054900479537166, 0.1261537593652683, 0.11392275661932283, 0.15041016726336442, 0.19681388983902237, 0.16214611854476513, 0.146950307843988, 0.15832313077617755, 0.15243781307072335, 0.10725075410766993, 0.14109345755614744, 0.15086087375317092, 0.06304668946891268, 0.08182246978785623, 0.16666687541420777, 0.16105812858732083, 0.14135985375773574, 0.1471757530515736, 0.03907933493947857, 0.053203796211369836, 0.0522996366827706, 0.08862864097270584, 0.11442422132730767, 0.13520566390158528, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02498488769685192, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06938127307845854, 0.06339572446799424, 0.061128437419055714, 0.026216191947968315, 0.04264755771237816, 0.05379085739141254, 0.03864982155676544, 0.0587735777077113, 0.022767146599453336, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0034234025521205913, 0.03961788167626201, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13679469513105913, 0.13859584032325856, 0.004032750895289761, 0.006154783447653078, 0.0004444444444444695, 0.0847008243008135, 0.07349142918297202, 0.0805208306505305, 0.14801620821102324, 0.1351414260598336, 0.14420009909917064, 0.08296048011562052, 0.08006937634413647, 0.08265777027621635, 0.12320495062338821, 0.13755199360824188, 0.12453645796484325, 0.13850936468755837, 0.13773056100953762, 0.12613145071787768, 0.06136849212241213, 0.07293373569025463, 0.0970844478682521, 0.07534566999618497, 0.06046027299394985, 0.07858641726977067, 0.1508286489331292, 0.15631372346752115, 0.16006422746261983, 0.0004444444444444695, 0.0031925268721751943, 0.02146071551668527, 0.05594523333246615, 0.03672792449088247, 0.04291718237799225, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0871767578974032, 0.09213871387704986, 0.08418818248663673, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05829546410122044, 0.0564540088361043, 0.06389811124460942, 0.11947229782500757, 0.10841438140112647, 0.10647365540174447, 0.05670835625820392, 0.04669578073370617, 0.04959365720850417, 0.11469639094270578, 0.10813203700610663, 0.113737544618153, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04437039233564555, 0.06274950311017513, 0.023416946145567885, 0.016035938094756896, 0.02017165449739211, 0.02118311225645142, 0.14588060300340377, 0.14523837203673973, 0.14683943410329925, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "0904d0ca-4c92-4a98-8b70-53cde766aad9", "fitness": 0.06145260642539053, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce an adaptive mutation factor based on the success rate to further enhance convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) * (1 + self.success_rate) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 36, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06145 with standard deviation 0.10298.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.16527390903175154, 0.18670656899212812, 0.1631770071054751, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03948013282476737, 0.049947370235295496, 0.040266035877501216, 0.03420468961289391, 0.03261583631589282, 0.03758814399639698, 0.9350173402255001, 0.9399262508732085, 0.11239029286298607, 0.11326090942145595, 0.09731239700701144, 0.09008952077895349, 0.08899257812576278, 0.12383965101778549, 0.12322535771034027, 0.035471145002905824, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.009988358263955943, 0.09631007000726521, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02746814329800651, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005922387931005746, 0.1670844621489359, 0.17569259580901264, 0.19738778938531654, 0.04530026916636454, 0.05454207005100664, 0.03928804029381783, 0.108761059871047, 0.10212143434449217, 0.11685007317329488, 0.19821605489115457, 0.14959123338954428, 0.16995133068076285, 0.10849559095606354, 0.11375073368910193, 0.121379250131748, 0.14760654773726756, 0.14079297897663767, 0.143425983968408, 0.13038672044589195, 0.14432825562895824, 0.14618691060905709, 0.15801680553247754, 0.11181229777623725, 0.1122625772259187, 0.15055112422432138, 0.10032484906117634, 0.07338108239632168, 0.15170292232443194, 0.17693576306846204, 0.15693818541569104, 0.06531749614539673, 0.04953907021402559, 0.04004421855466389, 0.10162160072791648, 0.11013916890624298, 0.1021165378305009, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0038685739976576095, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06488016918898254, 0.046178663107873774, 0.08405503664092229, 0.024656159741510142, 0.02741367612404344, 0.013498986591796824, 0.045517994530240524, 0.018409435841054145, 0.047956056234111255, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0049728746776667165, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15650032719653828, 0.16318395177289058, 0.14227480397331682, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08346462194513349, 0.07902134926785953, 0.08131395526490959, 0.1396006562502472, 0.13307728716084788, 0.1362048303248189, 0.10100994738870195, 0.08822628730167204, 0.07702360975214151, 0.12299484626302915, 0.1349576078147825, 0.12377876020440015, 0.12756252298968362, 0.10378633287095851, 0.009670112869311853, 0.06600985423083527, 0.07636992991824099, 0.099773607528305, 0.029440057165515454, 0.08088203862849752, 0.059469266564385004, 0.15408276525477915, 0.1534422621187459, 0.14750921167668318, 0.012997811127244407, 0.0016105427664001581, 0.0022824842773550014, 0.05756811590675104, 0.03832118176245769, 0.046686164867202784, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.014374350873531672, 0.0004444444444444695, 0.0045892640330503776, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.009317622820593674, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08289800072156972, 0.09194807519256287, 0.07618317489722826, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05122175389250738, 0.0564540088361043, 0.05206537224840313, 0.10525149553901614, 0.10930333508040702, 0.11150878452195523, 0.049794284151388424, 0.05343132545578155, 0.04851128799735471, 0.1122669991297276, 0.11263502870354047, 0.11737519647438177, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.043386582675208896, 0.05587020485823935, 0.02328190431398136, 0.02991032256310422, 0.01870198596948469, 0.024529682275128528, 0.14357629955074747, 0.15728095571160117, 0.13805155482511322, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "611d8f4b-9282-4a44-a954-02031643a1b9", "fitness": 0.054828314272695106, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce a dynamic adjustment of the learning rate based on the chaotic map to support exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Updated line with dynamic learning rate\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  chaotic_value * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 37, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05483 with standard deviation 0.11767.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.11093075733646895, 0.18316690482016085, 0.12906308330627725, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008298614648340918, 0.05448807912817233, 0.01269863751425404, 0.0004444444444444695, 0.024837939971053213, 0.020272244183006882, 0.9359304727893655, 0.9387835489743374, 0.9485321786907001, 0.07917493137050646, 0.07708767522930549, 0.013996832332308307, 0.052479657884639264, 0.11153072255690477, 0.09402500897069155, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.16859436198042954, 0.1695136800526046, 0.14443163428730565, 0.027922035887147256, 0.02201955112239251, 0.01751566507065261, 0.10675778750098375, 0.10790828022417354, 0.11344465713734286, 0.12926688450333157, 0.13788919532897004, 0.15653485070237394, 0.07914833019805878, 0.10401981204136046, 0.11859830020505524, 0.10882154789888754, 0.1345553661853608, 0.11371268229623155, 0.0004444444444444695, 0.14890006001803469, 0.0004444444444444695, 0.09276941701862662, 0.17991133340993204, 0.08553319499050871, 0.06071948527153659, 0.08062398610622712, 0.09354129872488381, 0.16778080229702164, 0.16195014981240674, 0.1520792956140642, 0.030926499002346786, 0.03056461394376797, 0.02939304925012909, 0.06975500349726826, 0.08870736313212146, 0.10440054365291673, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007881060792040206, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09163357027961094, 0.0721605388546731, 0.11022489466125529, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.033565233359458935, 0.015087346854713024, 0.00648793320358565, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10098353597828769, 0.13228494160369508, 0.10672158198343928, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05899979024533741, 0.07608399116403997, 0.0678080119819442, 0.11555910014958659, 0.10598082891215077, 0.10655088400058521, 0.06524133070005156, 0.06557338821769387, 0.05683981315876008, 0.11271910323448775, 0.10724622213656054, 0.09739452872175514, 0.025325403366427413, 0.0004444444444444695, 0.0004444444444444695, 0.04923729878772676, 0.10643613875301117, 0.053237573777782266, 0.02664689785894192, 0.08218836868730328, 0.03685315109329268, 0.15751139215937093, 0.16843471938795473, 0.15130791689396417, 0.0004444444444444695, 0.005157215335770737, 0.0004444444444444695, 0.04438901180642907, 0.03443136171255412, 0.03573273183864589, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.017412651633791243, 0.0009674558484186191, 0.0028125044365123752, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08297623817819055, 0.08318640774058317, 0.07373082332755299, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.055301872520267525, 0.0564540088361043, 0.05495348180220172, 0.10332331890393975, 0.1129188781139312, 0.10758692107218115, 0.045419107181939866, 0.05112753357882749, 0.037698406095433845, 0.10227421157315153, 0.11423756974547883, 0.09164636872294163, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02108248287317349, 0.03996978894742986, 0.032707606520942956, 0.015126781423439928, 0.01853782434313933, 0.018291686049857314, 0.14377619967351185, 0.14355637070345584, 0.14708122999857198, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "465fa5ed-7c75-4b64-b2b8-a50927c3c58a", "fitness": 0.05279927223670424, "name": "EnhancedHybridMetaheuristic", "description": "Integrate adaptive differential evolution with chaotic maps and periodic restart strategies for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 50\n        self.min_population_size = 25\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.positions = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_position = np.copy(self.positions)\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.6  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        values = np.apply_along_axis(func, 1, self.positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = self.positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Linear decay\n            self.F = chaotic_value * (0.5 - 0.25 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_position[i] - self.positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - self.positions[i])\n                self.positions[i] += self.velocity[i]\n                self.positions[i] = np.clip(self.positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, self.positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    self.positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n            if np.std(values) < 1e-5:\n                self.positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, self.positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05280 with standard deviation 0.10493.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.13883225431679702, 0.15664600706124432, 0.1493761714952686, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04481767750208665, 0.023695308167065, 0.0319125734578245, 0.009349242639737576, 0.01695679577294018, 0.00913644049213791, 0.20648931054228026, 0.964637784615628, 0.9730330683569164, 0.060946000499126796, 0.06045721436504636, 0.022021907672697516, 0.0923362719203803, 0.13111519333530997, 0.06973811345961456, 0.014562841533154125, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.002564869108404255, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.18061569810261513, 0.1548621512371785, 0.17771296684009408, 0.04222174147931457, 0.028728566434413016, 0.03142054580449738, 0.10637511489216644, 0.10701908578159836, 0.11681192521925754, 0.1649657988077925, 0.13120037091973324, 0.16484717819538675, 0.10220062414384001, 0.08724907964944562, 0.10280583421899403, 0.12273113104410727, 0.11772473385116933, 0.12461510548982246, 0.0004444444444444695, 0.137884330298361, 0.1352273569870207, 0.15081880995392372, 0.11210238578041187, 0.194499451084008, 0.10335473837860865, 0.1116476386999945, 0.08248669731003244, 0.17075197084335458, 0.1615076918901247, 0.15137960409138695, 0.03731226517083919, 0.06292346433227347, 0.02803260545692643, 0.09017902551670043, 0.09404582853697352, 0.07522429466758496, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1958387830824052, 0.08146387270428868, 0.08305756874639636, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.023653444576411498, 0.034026068467986614, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01517514482328064, 0.0023192050659007757, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12678298793283316, 0.09163832137991013, 0.09968670932913459, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0818192399600135, 0.07975908997681613, 0.10328360499890588, 0.12221388205234751, 0.13682357131845713, 0.1281976140432407, 0.08171979360474324, 0.05959141654965627, 0.055233979083836315, 0.10233871697228847, 0.08669009490606006, 0.09512031325435033, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03794194443099186, 0.04143528526788076, 0.07527785751742666, 0.02616304787253587, 0.021933658076766505, 0.02987609578776429, 0.15158195598278879, 0.17402254477969703, 0.1525215644556066, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.022721631210229076, 0.009290681806172318, 0.008064111005660624, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.012490552421621004, 0.013982381067642935, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04970752691117719, 0.06788270478116365, 0.054308686504757286, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05578499597507769, 0.05793079407155566, 0.057434920270245104, 0.10301510041075246, 0.09967256101856459, 0.09987617965744988, 0.053456302570127345, 0.03701163505890148, 0.04905995675435626, 0.07838095705325299, 0.07227126852671806, 0.09485784593183, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.018461244633409146, 0.018624170328518153, 0.016309366950056248, 0.016622952227955512, 0.01135359234869171, 0.0110106580835867, 0.14172442825380205, 0.14626710678423305, 0.14288136719738387, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "31fc929d-2532-4f95-8197-7e2c6e47a021", "fitness": 0.05282507841896646, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce dynamic population resizing and enhanced local search mechanism for improved convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 50  # Increased initial population size\n        self.min_population_size = 10  # Decreased minimum population size\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            new_population_size = int(self.min_population_size + (self.initial_population_size - self.min_population_size) * (1 - evaluations / self.budget))\n            if new_population_size != self.population_size:\n                self.velocity = self.velocity[:new_population_size]\n                self.best_position = self.best_position[:new_population_size]\n                positions = positions[:new_population_size]\n                values = values[:new_population_size]\n                self.population_size = new_population_size\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.15 * (self.best_global_position - positions[i]) + self.levy_flight(self.dim)\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 39, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05283 with standard deviation 0.06079.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.16623521644261352, 0.19459665520380598, 0.14556312566870633, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04253498098716735, 0.039291598278874296, 0.04539809560753327, 0.037966493148767544, 0.02097616759824128, 0.02803331379969498, 0.17258883225721466, 0.1649099348515507, 0.19927812287717173, 0.07335434695471266, 0.04036509098322594, 0.08127558151871406, 0.11907100255664171, 0.11338414657996054, 0.111185892116484, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.040440459447792065, 0.010006062902341628, 0.06897805246696609, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.009716660762216, 0.03698352118048753, 0.05186270041819041, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.029269745420544502, 0.0004444444444444695, 0.0004444444444444695, 0.19637933724131962, 0.18608213800385554, 0.18527412122159126, 0.047293574485585466, 0.03260922070576877, 0.05190889285712541, 0.13524527249055152, 0.12369191649598199, 0.0868291383984019, 0.2026425849544976, 0.18767161235835972, 0.14987348187851646, 0.12507423905970494, 0.09045318827376359, 0.12728862011532627, 0.14316023529226152, 0.1610395314459293, 0.15910272879464749, 0.1325021640828612, 0.14499645418521667, 0.15182615307531178, 0.17101186623149223, 0.1666241702324316, 0.15888235061476508, 0.11010024014608721, 0.10695063137171967, 0.1117214670161617, 0.18285020317362977, 0.151948993064826, 0.15247699414424887, 0.047294512141569545, 0.05334020700891129, 0.05208029578341544, 0.11808011782010619, 0.08074205002672108, 0.09126198409891528, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04862173340791376, 0.060696573820566146, 0.07322502786486718, 0.0259905322263706, 0.024250615738001247, 0.0013072696265772343, 0.03900383113507899, 0.03254094348399339, 0.03365841679625681, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12928248423387656, 0.12918531258485333, 0.15079721435963733, 0.0004444444444444695, 0.001881879644960338, 0.0004444444444444695, 0.06519351001416884, 0.06779978540315212, 0.07539460757264815, 0.14659407849073458, 0.12759219580293368, 0.1282448983930281, 0.07193649439799488, 0.06448157318153247, 0.07119583610762936, 0.1142721914562419, 0.11396931254733456, 0.10502065422809892, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.043834071322619295, 0.0657872143988647, 0.07436550535396458, 0.026684307290103515, 0.059303149618219364, 0.05875791713869083, 0.15166381865702372, 0.15674734262450596, 0.15701436413871228, 0.001232630025080006, 0.0011650847754143268, 0.0004444444444444695, 0.048320050649980906, 0.04073108174498141, 0.05174174372022, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007320416404507091, 0.0004444444444444695, 0.00953879112577749, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09008167525589916, 0.0996784095347718, 0.10853096431528775, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05215443343482484, 0.06679586773783641, 0.06064260435654367, 0.13018803651163258, 0.12156076197991439, 0.11121538763727368, 0.05840162555348394, 0.04385460753255921, 0.05175583343217982, 0.10395323393982892, 0.09795234652310947, 0.09958586727559449, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.019585954194502042, 0.02979498969469352, 0.021715451018566867, 0.028392884904533733, 0.03183866631347332, 0.025805892245593376, 0.14478228845035712, 0.15052451478252304, 0.14550369204345748, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "27442b78-34a5-48aa-b696-16d443cd8e44", "fitness": 0.05952840159800598, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Enhance convergence by incorporating an adaptive Levy flight step scale and refined success rate update strategy.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.1\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step * (1 + self.success_rate)  # Adaptive Levy flight step scale\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 40, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.08596.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.16813617599873776, 0.23317274936961252, 0.15007577059788213, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.052290580224470085, 0.09853526125424927, 0.0364821285578778, 0.04191480870178177, 0.03461303780617775, 0.04002592279176298, 0.933143590345897, 0.26953217349821235, 0.09833678946908508, 0.08760034036652242, 0.08189256081776153, 0.06476720864531249, 0.13731598895731356, 0.13286772733278773, 0.09254049967606903, 0.0004444444444444695, 0.0004444444444444695, 0.0022126528767251186, 0.015382685637615245, 0.040201774677603885, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008248407996152896, 0.01866338253411093, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015418826955755582, 0.17796535213006304, 0.19127023067757631, 0.1868626826220101, 0.037460181852731034, 0.052587684829034864, 0.04214289715328157, 0.122770779407812, 0.10129656203573556, 0.11782872530008914, 0.16722618573136905, 0.1681762157913903, 0.1660953093921418, 0.10292021880572877, 0.12916298245217717, 0.13147222350087073, 0.1623935588656389, 0.1550810649135551, 0.17119739822533842, 0.14134396199804156, 0.1529363081617885, 0.1521912263681996, 0.11748198336018423, 0.123745485696935, 0.08971771807556883, 0.11849292948171974, 0.09717937196969739, 0.06932511242166017, 0.16570024721399024, 0.15540899068824787, 0.18290058334675374, 0.04894625371412353, 0.044362090654604724, 0.03935309332019121, 0.12274318163679876, 0.10426272102995149, 0.10870270738395538, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0017917011250219161, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04986513693341432, 0.05204378855507563, 0.07458289101319171, 0.01972921751511525, 0.014183623450026883, 0.03074244946905247, 0.03733526567016676, 0.055132065559473586, 0.043091078459384646, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010749150026149179, 0.004534271762541842, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1583578215373752, 0.14009273600896543, 0.14921152132797555, 0.0004444444444444695, 0.0004444444444444695, 0.006626086257278452, 0.08347296749181587, 0.07007993720637329, 0.08523011839065131, 0.1432015331760801, 0.14442464458207316, 0.15121857651764536, 0.08281354818877218, 0.10439637249474598, 0.08202110219993386, 0.13133942992262182, 0.13004346391559474, 0.12492914948260347, 0.12068762009547096, 0.13613138773307487, 0.11606343053393542, 0.05732848308403804, 0.09604101667761455, 0.09611314757417977, 0.05361764599009622, 0.08678320166368392, 0.06985720910425885, 0.17085885588901428, 0.14562547749996857, 0.15671843427091747, 0.0004444444444444695, 0.0029597163813438465, 0.0004444444444444695, 0.06171826879060427, 0.04548705238836914, 0.043348340851184664, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.009856045830889948, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0018006701750380438, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08385943591684775, 0.08704654307203719, 0.09113868792031843, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0554995705042679, 0.058995014404136126, 0.05621842256204779, 0.12825286635983002, 0.10578884955383894, 0.11267018834149245, 0.06474564390641735, 0.0505180433265503, 0.051873847901095615, 0.11363601704088733, 0.11317087975160911, 0.1106587283352789, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04079209478902868, 0.055747953843902964, 0.02117041718536028, 0.017537865018410592, 0.016397259233093542, 0.017791273180249867, 0.14587968254145456, 0.15546249128088485, 0.14074982890679, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "99c75d61-206d-4a61-ae0a-73427f2350e5", "fitness": 0.06314583439733973, "name": "RefinedEnhancedHybridPSO_DE_RegionClustering", "description": "Integrate a region-based clustering mechanism to dynamically adjust exploration and exploitation phases for enhanced convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_RegionClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n        self.cluster_threshold = 0.1\n    \n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            # Clustering mechanism\n            mean_position = np.mean(positions, axis=0)\n            cluster_radius = np.mean(np.linalg.norm(positions - mean_position, axis=1))\n            explore_phase = cluster_radius > self.cluster_threshold\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if explore_phase:\n                    self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                      self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                      self.c2 * r2 * (self.best_global_position - positions[i]))\n                else:\n                    self.velocity[i] = inertia_weight * self.velocity[i] * self.success_rate\n                \n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 41, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_RegionClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06315 with standard deviation 0.10257.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.14886305539977374, 0.1767167539768053, 0.19359627308272032, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.051265074213650785, 0.04470841914209789, 0.043795242473878004, 0.03874707383642251, 0.02540690488843067, 0.9339241902520412, 0.9119149063394705, 0.10790341486550648, 0.08633286522770423, 0.08701385649848448, 0.07009793756910221, 0.08899257812576278, 0.1063138641020066, 0.1319660712549766, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04341163264086567, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04033632351891636, 0.02308852959317831, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013806984945705869, 0.19006033047107618, 0.20112473267194975, 0.21386765781275507, 0.04782644026416227, 0.055259266184732425, 0.03711787941453193, 0.13590702041128178, 0.08401349046620088, 0.09874770779406239, 0.1617514905410533, 0.1753963142890178, 0.18212215204890325, 0.11054900479537166, 0.1261537593652683, 0.11392275661932283, 0.15041016726336442, 0.19681388983902237, 0.16214611854476513, 0.146950307843988, 0.15832313077617755, 0.15243781307072335, 0.10725075410766993, 0.14109345755614744, 0.15086087375317092, 0.06304668946891268, 0.08182246978785623, 0.16666687541420777, 0.16105812858732083, 0.14135985375773574, 0.1471757530515736, 0.03907933493947857, 0.053203796211369836, 0.0522996366827706, 0.08862864097270584, 0.11442422132730767, 0.13520566390158528, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02498488769685192, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06938127307845854, 0.06339572446799424, 0.061128437419055714, 0.026216191947968315, 0.04264755771237816, 0.05379085739141254, 0.03864982155676544, 0.0587735777077113, 0.022767146599453336, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0034234025521205913, 0.03961788167626201, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13679469513105913, 0.13859584032325856, 0.004032750895289761, 0.006154783447653078, 0.0004444444444444695, 0.0847008243008135, 0.07349142918297202, 0.0805208306505305, 0.14801620821102324, 0.1351414260598336, 0.14420009909917064, 0.08296048011562052, 0.08006937634413647, 0.08265777027621635, 0.12320495062338821, 0.13755199360824188, 0.12453645796484325, 0.13850936468755837, 0.13773056100953762, 0.12613145071787768, 0.06136849212241213, 0.07293373569025463, 0.0970844478682521, 0.07534566999618497, 0.06046027299394985, 0.07858641726977067, 0.1508286489331292, 0.15631372346752115, 0.16006422746261983, 0.0004444444444444695, 0.0031925268721751943, 0.02146071551668527, 0.05594523333246615, 0.03672792449088247, 0.04291718237799225, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0871767578974032, 0.09213871387704986, 0.08418818248663673, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05829546410122044, 0.0564540088361043, 0.06389811124460942, 0.11947229782500757, 0.10841438140112647, 0.10647365540174447, 0.05670835625820392, 0.04669578073370617, 0.04959365720850417, 0.11469639094270578, 0.10813203700610663, 0.113737544618153, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04437039233564555, 0.06274950311017513, 0.023416946145567885, 0.016035938094756896, 0.02017165449739211, 0.02118311225645142, 0.14588060300340377, 0.14523837203673973, 0.14683943410329925, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "d2ed8b18-14b2-4cd8-bc01-e5deb2ce4bef", "fitness": 0.06314583439733973, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Enhance exploration by modifying the chaotic map's influence on the DE scaling factor.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * 0.7  # Non-linear scaling factor, previously was: chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget)) \n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 42, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06315 with standard deviation 0.10257.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.14886305539977374, 0.1767167539768053, 0.19359627308272032, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.051265074213650785, 0.04470841914209789, 0.043795242473878004, 0.03874707383642251, 0.02540690488843067, 0.9339241902520412, 0.9119149063394705, 0.10790341486550648, 0.08633286522770423, 0.08701385649848448, 0.07009793756910221, 0.08899257812576278, 0.1063138641020066, 0.1319660712549766, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04341163264086567, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04033632351891636, 0.02308852959317831, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013806984945705869, 0.19006033047107618, 0.20112473267194975, 0.21386765781275507, 0.04782644026416227, 0.055259266184732425, 0.03711787941453193, 0.13590702041128178, 0.08401349046620088, 0.09874770779406239, 0.1617514905410533, 0.1753963142890178, 0.18212215204890325, 0.11054900479537166, 0.1261537593652683, 0.11392275661932283, 0.15041016726336442, 0.19681388983902237, 0.16214611854476513, 0.146950307843988, 0.15832313077617755, 0.15243781307072335, 0.10725075410766993, 0.14109345755614744, 0.15086087375317092, 0.06304668946891268, 0.08182246978785623, 0.16666687541420777, 0.16105812858732083, 0.14135985375773574, 0.1471757530515736, 0.03907933493947857, 0.053203796211369836, 0.0522996366827706, 0.08862864097270584, 0.11442422132730767, 0.13520566390158528, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02498488769685192, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06938127307845854, 0.06339572446799424, 0.061128437419055714, 0.026216191947968315, 0.04264755771237816, 0.05379085739141254, 0.03864982155676544, 0.0587735777077113, 0.022767146599453336, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0034234025521205913, 0.03961788167626201, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13679469513105913, 0.13859584032325856, 0.004032750895289761, 0.006154783447653078, 0.0004444444444444695, 0.0847008243008135, 0.07349142918297202, 0.0805208306505305, 0.14801620821102324, 0.1351414260598336, 0.14420009909917064, 0.08296048011562052, 0.08006937634413647, 0.08265777027621635, 0.12320495062338821, 0.13755199360824188, 0.12453645796484325, 0.13850936468755837, 0.13773056100953762, 0.12613145071787768, 0.06136849212241213, 0.07293373569025463, 0.0970844478682521, 0.07534566999618497, 0.06046027299394985, 0.07858641726977067, 0.1508286489331292, 0.15631372346752115, 0.16006422746261983, 0.0004444444444444695, 0.0031925268721751943, 0.02146071551668527, 0.05594523333246615, 0.03672792449088247, 0.04291718237799225, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0871767578974032, 0.09213871387704986, 0.08418818248663673, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05829546410122044, 0.0564540088361043, 0.06389811124460942, 0.11947229782500757, 0.10841438140112647, 0.10647365540174447, 0.05670835625820392, 0.04669578073370617, 0.04959365720850417, 0.11469639094270578, 0.10813203700610663, 0.113737544618153, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04437039233564555, 0.06274950311017513, 0.023416946145567885, 0.016035938094756896, 0.02017165449739211, 0.02118311225645142, 0.14588060300340377, 0.14523837203673973, 0.14683943410329925, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "7b44c859-f617-4d97-9125-a58154de3ed2", "fitness": 0.06314583439733973, "name": "AdaptiveChaoticLevyPSO_DE", "description": "Utilize adaptive chaotic dynamics with Levy flights for improved exploration and dynamic learning rates for accelerated convergence.", "code": "import numpy as np\n\nclass AdaptiveChaoticLevyPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveChaoticLevyPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06315 with standard deviation 0.10257.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.14886305539977374, 0.1767167539768053, 0.19359627308272032, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.051265074213650785, 0.04470841914209789, 0.043795242473878004, 0.03874707383642251, 0.02540690488843067, 0.9339241902520412, 0.9119149063394705, 0.10790341486550648, 0.08633286522770423, 0.08701385649848448, 0.07009793756910221, 0.08899257812576278, 0.1063138641020066, 0.1319660712549766, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04341163264086567, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04033632351891636, 0.02308852959317831, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013806984945705869, 0.19006033047107618, 0.20112473267194975, 0.21386765781275507, 0.04782644026416227, 0.055259266184732425, 0.03711787941453193, 0.13590702041128178, 0.08401349046620088, 0.09874770779406239, 0.1617514905410533, 0.1753963142890178, 0.18212215204890325, 0.11054900479537166, 0.1261537593652683, 0.11392275661932283, 0.15041016726336442, 0.19681388983902237, 0.16214611854476513, 0.146950307843988, 0.15832313077617755, 0.15243781307072335, 0.10725075410766993, 0.14109345755614744, 0.15086087375317092, 0.06304668946891268, 0.08182246978785623, 0.16666687541420777, 0.16105812858732083, 0.14135985375773574, 0.1471757530515736, 0.03907933493947857, 0.053203796211369836, 0.0522996366827706, 0.08862864097270584, 0.11442422132730767, 0.13520566390158528, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02498488769685192, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06938127307845854, 0.06339572446799424, 0.061128437419055714, 0.026216191947968315, 0.04264755771237816, 0.05379085739141254, 0.03864982155676544, 0.0587735777077113, 0.022767146599453336, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0034234025521205913, 0.03961788167626201, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13679469513105913, 0.13859584032325856, 0.004032750895289761, 0.006154783447653078, 0.0004444444444444695, 0.0847008243008135, 0.07349142918297202, 0.0805208306505305, 0.14801620821102324, 0.1351414260598336, 0.14420009909917064, 0.08296048011562052, 0.08006937634413647, 0.08265777027621635, 0.12320495062338821, 0.13755199360824188, 0.12453645796484325, 0.13850936468755837, 0.13773056100953762, 0.12613145071787768, 0.06136849212241213, 0.07293373569025463, 0.0970844478682521, 0.07534566999618497, 0.06046027299394985, 0.07858641726977067, 0.1508286489331292, 0.15631372346752115, 0.16006422746261983, 0.0004444444444444695, 0.0031925268721751943, 0.02146071551668527, 0.05594523333246615, 0.03672792449088247, 0.04291718237799225, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0871767578974032, 0.09213871387704986, 0.08418818248663673, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05829546410122044, 0.0564540088361043, 0.06389811124460942, 0.11947229782500757, 0.10841438140112647, 0.10647365540174447, 0.05670835625820392, 0.04669578073370617, 0.04959365720850417, 0.11469639094270578, 0.10813203700610663, 0.113737544618153, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04437039233564555, 0.06274950311017513, 0.023416946145567885, 0.016035938094756896, 0.02017165449739211, 0.02118311225645142, 0.14588060300340377, 0.14523837203673973, 0.14683943410329925, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "35d053c2-03c4-4724-9e35-230a2b1d6fad", "fitness": 0.05998683791153957, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Integrate a Gaussian noise perturbation to enhance exploration in the velocity update step.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i])) + np.random.normal(0, 0.01, self.dim)  # Gaussian noise added\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 44, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05999 with standard deviation 0.08644.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.18141179391672602, 0.18924176279624882, 0.18973139217172152, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.042204724965609786, 0.06009662958148243, 0.07624390274962412, 0.03147973725866848, 0.02922263301980843, 0.033513694538578775, 0.204098070202001, 0.9256871986358037, 0.14237027576094397, 0.0850477355222401, 0.08491817945045455, 0.0847765503148753, 0.17046620552903735, 0.1242536553904322, 0.109766181751206, 0.0004444444444444695, 0.012618030791447632, 0.0004444444444444695, 0.0052770843303795445, 0.01918159871921976, 0.06040235425461349, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.012256210827945369, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.18914977270625033, 0.23753643796728285, 0.21533476485976022, 0.03670328046658056, 0.03629611057769322, 0.05035597465993613, 0.11208348249904765, 0.09248112688614474, 0.13017823595962685, 0.16875517866135026, 0.1729260070932832, 0.17876452479378724, 0.10643092530339948, 0.13031730499398275, 0.13308165438893582, 0.19360169190819443, 0.15709047328310832, 0.14079254477173653, 0.14598462374832466, 0.1467481776332854, 0.161275275807783, 0.13148620712508652, 0.1645530408396454, 0.11796499117484771, 0.09479457541009739, 0.10757925443678074, 0.12239278349401717, 0.19125724001427113, 0.16020969237297134, 0.19268510716818843, 0.04758896985208816, 0.0590259348033384, 0.052243919692482654, 0.10924528635406927, 0.11256897904495655, 0.1288719954886155, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001991235827199289, 0.0004444444444444695, 0.0027056009360888478, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07299070513116201, 0.06323515221401732, 0.05400037135011371, 0.02998363274675242, 0.038554149236554314, 0.02892851783071737, 0.04444650362387059, 0.06445556989841739, 0.06540977148954208, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.021901294119765047, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1701033714231227, 0.14579944070910011, 0.15415060291696525, 0.002996231342405342, 0.0004444444444444695, 0.0004444444444444695, 0.06152444860084627, 0.06878640784053136, 0.08333298310923787, 0.14650423604722362, 0.14490133466255095, 0.12967884658354345, 0.09834346362874224, 0.09159524026764476, 0.07376020913587267, 0.11943065846167522, 0.12876059173403143, 0.12849774719841056, 0.12410962889375732, 0.012250021099713182, 0.03950193280271175, 0.08680685723019632, 0.06895217343531457, 0.09328553312883081, 0.08752720507206202, 0.08369820933225225, 0.05345843726321742, 0.14493787684356874, 0.1532418968999898, 0.15844701185132104, 0.004981777758059858, 0.0004444444444444695, 0.005014770437300586, 0.05481462044888419, 0.04504057028165531, 0.045937611043659565, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0030976018927406646, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08495054903857757, 0.0873539524307756, 0.08439099117571236, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.050821768072092155, 0.0582137090833561, 0.05706897860069349, 0.11734296864567695, 0.10911674140163774, 0.10884688408974508, 0.05383888177961427, 0.04849274941404513, 0.05093069487586799, 0.11676649448766796, 0.11607287439102199, 0.11640834469242167, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01957564741223905, 0.025239191466611133, 0.02141792466442627, 0.020771475339059986, 0.01761145092555816, 0.021629247642346194, 0.14602256725068619, 0.1389883034766073, 0.14212472936807874, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "0d9c28e3-a2a0-42b7-9781-f182c0f6d137", "fitness": 0.06033961676903275, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Fine-tune the success rate impact and mutation step in hybrid PSO-DE for enhanced convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + 1.2 * self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + 0.9*np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 45, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06034 with standard deviation 0.08532.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.16631188939691988, 0.1756160659283853, 0.17216248307428061, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04285098497797679, 0.056526768303321706, 0.05217530098358247, 0.0375076968472311, 0.05457744115081853, 0.043798534539965406, 0.9338228392148121, 0.22871737588904484, 0.09908911620736605, 0.05477361573073192, 0.08947067553691113, 0.06958247804324491, 0.12733903690871073, 0.1091545032116531, 0.1414441295037544, 0.0004444444444444695, 0.006327072091801167, 0.0004444444444444695, 0.06653737281322392, 0.030314764933207505, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.050712937900946886, 0.05591305419431514, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015180074553706513, 0.17350192207821247, 0.20425380888904687, 0.21870028215756787, 0.044928482696715566, 0.06643055610022586, 0.04885427343122539, 0.10675778750098375, 0.10922955529905809, 0.1072137122230209, 0.17918577736740304, 0.15882195279613953, 0.18308418910262725, 0.14357440745973493, 0.1317783334125141, 0.10539051844788627, 0.14555969842179772, 0.15967678251639206, 0.12950423804263134, 0.1444207210030204, 0.1495680712951598, 0.15141974088914245, 0.10686667832885344, 0.12275269861103921, 0.11856900113276958, 0.06129195185489278, 0.09166842726333102, 0.16243892855620612, 0.16201777818090224, 0.19032173329718072, 0.158446835825226, 0.06880188235498386, 0.048958984192096766, 0.054429546122189754, 0.11421370359546557, 0.11322377621244772, 0.10826670881701173, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001992154812364255, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12716318036707008, 0.057540000912726263, 0.06527222088244444, 0.018554685359373213, 0.014280838273798557, 0.051154361795928915, 0.040590933937310836, 0.05828219534050327, 0.022185155276479573, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03566997923120507, 0.0004444444444444695, 0.0031275431507961082, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1513421662620139, 0.1451610043211763, 0.13506456773426367, 0.0004444444444444695, 0.0004444444444444695, 0.02603358526322397, 0.08291594090628296, 0.08098439684858205, 0.07474003916965333, 0.13352773412845798, 0.12298738400505849, 0.14262673347830135, 0.08264579964549135, 0.08214815705615164, 0.07713716888629196, 0.1260962075265134, 0.12009230355541112, 0.126702781390869, 0.11741583897361285, 0.1376606019112322, 0.12780331036926262, 0.05968730659389232, 0.07314936833664065, 0.07291478909450277, 0.04900220634866692, 0.08940142553223696, 0.07673623535139251, 0.15742979414037372, 0.1765256240790306, 0.16754198647339524, 0.0004444444444444695, 0.0004444444444444695, 0.006349008635776254, 0.05773512750441656, 0.0368213964566233, 0.041413041714649435, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.006354029914932169, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08769366974434889, 0.09659168952122177, 0.07648724997241152, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05611355242658389, 0.0663980093891613, 0.06210529058610903, 0.11161730148970173, 0.10710349702521182, 0.11867163686378523, 0.05901340349985462, 0.059176757147684445, 0.05641390548992842, 0.1141038989835238, 0.11512015705947665, 0.11320954274299477, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.032230566234332514, 0.038609706814882294, 0.023158818587293184, 0.020599279657095182, 0.02010818007766968, 0.02178607424843959, 0.147318206304198, 0.14110929286721652, 0.16596090035188715, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "9477a62f-4791-45ea-aaee-eef119cd2463", "fitness": 0.06013015909543303, "name": "ParetoFrontBasedHybridPSO_DE", "description": "Introducing a Pareto-front-based adaptive mechanism that balances exploration and exploitation using multi-strategy updates.", "code": "import numpy as np\n\nclass ParetoFrontBasedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.pareto_front = []\n        self.F = 0.5  \n        self.CR = 0.9  \n        self.c1, self.c2 = 2.0, 2.0  \n        self.w_max, self.w_min = 0.9, 0.4  \n        self.learning_rate = 0.1 \n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def update_pareto_front(self, candidate_position, candidate_value):\n        self.pareto_front.append((candidate_position, candidate_value))\n        self.pareto_front.sort(key=lambda x: x[1])\n        if len(self.pareto_front) > 10:\n            self.pareto_front.pop(-1)\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                    self.update_pareto_front(trial_vector, trial_value)\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 46, "feedback": "The algorithm ParetoFrontBasedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06013 with standard deviation 0.08566.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.14576659676850967, 0.17690896870060124, 0.1927415678263612, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07367888775526987, 0.06685464942128116, 0.05548653921336277, 0.034995337691177464, 0.03495595226449666, 0.024578784276802712, 0.9339066086777805, 0.24781391605253944, 0.11092746745656723, 0.0803531314407131, 0.0767015930816154, 0.06506890848096147, 0.09447171667875898, 0.11184715477495433, 0.14915142786065416, 0.0004444444444444695, 0.0004444444444444695, 0.013376238610351976, 0.05096305403938273, 0.009242999407159558, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05642952733462858, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016596463565006436, 0.17207565145945614, 0.20092929965373285, 0.21048823463778854, 0.04031200798781098, 0.05462023765434765, 0.054870623088158266, 0.10675778750098375, 0.0957651573411672, 0.11895188543554969, 0.1618322517151004, 0.17449290966913533, 0.1773591021264953, 0.1122396703307218, 0.12055415081370957, 0.10313245014282035, 0.14445847490401997, 0.15554470760797545, 0.13686492772852676, 0.14158606743727564, 0.16521850062447718, 0.14539322811020694, 0.09970660702368384, 0.1344149802336907, 0.1295773786892993, 0.06447656263142476, 0.09036279437871786, 0.1628770165464134, 0.16308171140350824, 0.16144637646944804, 0.15550932154394537, 0.041530146826638026, 0.03773416002257368, 0.05233754421419645, 0.10238668094845071, 0.13625115852404734, 0.11638371435429207, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.00099800994678223, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05442810365513917, 0.05363121860380915, 0.09216151970481512, 0.017234471225276327, 0.013363759647928353, 0.021025802238731184, 0.04739929299086154, 0.022654463614776077, 0.035221332865936095, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03649082725964137, 0.007804360265609711, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15331331204708043, 0.14238091738159397, 0.14682384590953512, 0.0004444444444444695, 0.012296678563607166, 0.004616098941742197, 0.07290322673822969, 0.07330624774339811, 0.060886393364905866, 0.14417520180542998, 0.13077795681924564, 0.15164988194197715, 0.09798542797069154, 0.07951573874386197, 0.08814091467070972, 0.12148113330822452, 0.1264092475847911, 0.14907040101701485, 0.13891298748911152, 0.14222892721090286, 0.11204312186266807, 0.07135537273530745, 0.09484043595802139, 0.1423508388286424, 0.05620820387119041, 0.05968542710690783, 0.10476469480364914, 0.17673316695127506, 0.1675553274128384, 0.1527717734288513, 0.004018464026687041, 0.0004444444444444695, 0.002241639659942507, 0.05219781370349741, 0.04084533305473881, 0.045883794703000635, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.006564997190559474, 0.0007342559170298024, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0922467830738335, 0.09100764324936972, 0.08329137326856506, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.055261651831219005, 0.060106466841289174, 0.06775958014409544, 0.11643026507816145, 0.10676460927974185, 0.11200490248670514, 0.06479642982742595, 0.045871040836805266, 0.051430295360293976, 0.11322594564352428, 0.11802581682373914, 0.11408377645322454, 0.032293923555983706, 0.007679180725262191, 0.0004444444444444695, 0.04518281920515321, 0.05017958304997572, 0.022445019274124567, 0.015630516428081997, 0.020853027228814547, 0.034137898111513354, 0.14588060300340377, 0.14657936482717904, 0.14363362647226652, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "b0c37393-8303-4749-97b6-f53f341cc2d6", "fitness": 0.05562510399559132, "name": "RefinedEnhancedHybridPSO_DE_Improved_V2", "description": "Introduce adaptive scaling in DE and integrate a self-adaptive learning strategy to enhance convergence speed.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.tanh(evaluations / self.budget))  # More adaptive inertia weight\n            self.F = 0.4 + 0.3 * chaotic_value * np.cos(np.pi * (evaluations / self.budget))  # Adaptive scaling factor\n            adaptive_CR = self.CR * (1 + 0.2 * (1 - self.success_rate))  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                # Local search for diversity\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i]) * np.random.rand()\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Restart mechanism with adaptive threshold\n            if np.std(values) < 1e-5 or evaluations % (self.population_size * 2) == 0:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 47, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05563 with standard deviation 0.08259.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.16130671420086917, 0.1800716557021126, 0.23447120034752067, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.048369475845258636, 0.04115419809363119, 0.03545898238724521, 0.030211849158081616, 0.03545197900498154, 0.04564446433994174, 0.11285350606136191, 0.12189452187246552, 0.9054785210165658, 0.08550491245047309, 0.06453177941960953, 0.07111338356754437, 0.10617528315196234, 0.1618397477922613, 0.09918639843665955, 0.006596432460543755, 0.0004444444444444695, 0.0004444444444444695, 0.014495396754783063, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016493086375235055, 0.000951065232104531, 0.04375230994095025, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005910207660501765, 0.17614637674926237, 0.21952770477670136, 0.20235633886133297, 0.05729377681929715, 0.04848208443214774, 0.049003334376516605, 0.10845019998196126, 0.10184094893625173, 0.10867834406952781, 0.14354209100809878, 0.13584665265695173, 0.1405316716009697, 0.12570420695633366, 0.12047778463654224, 0.10225386497157729, 0.18486383916589566, 0.13554476808670934, 0.14408431059690885, 0.14829730884381465, 0.15874166804586176, 0.14197013566414918, 0.10418099005453063, 0.14222385922862624, 0.13330420761913397, 0.10387154390927422, 0.07232322742589026, 0.10222079314929378, 0.15944734625816492, 0.18371210258547388, 0.16029858441501887, 0.04086534467264913, 0.04674194985374058, 0.059911735541296585, 0.09509406060708936, 0.10080694614104924, 0.12334176585429668, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0026924923378113252, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08060337998414879, 0.03670175751590832, 0.06663867915301291, 0.01977274815304897, 0.0004444444444444695, 0.015242281158368565, 0.05321858016730807, 0.04879052565678321, 0.051539147029151855, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008070923450152256, 0.0004444444444444695, 0.014493628849025608, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13726162193408276, 0.12325893631127072, 0.1291446186407017, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07842621560094531, 0.07562094557366794, 0.06847873968091522, 0.14080706239425445, 0.12292094332575876, 0.1409288558016598, 0.09021658873827987, 0.07612050798302095, 0.08455319411847828, 0.11694384325904084, 0.13743985912045975, 0.12334270951427684, 0.03865863615676146, 0.02934479845348037, 0.0004444444444444695, 0.0725729627129792, 0.08332032759299102, 0.07443482244121857, 0.03915043310572497, 0.09703115119436712, 0.04987906658801311, 0.17286784257245413, 0.15498256254581677, 0.15242049245318645, 0.0013889771007817853, 0.0004444444444444695, 0.018326571697004024, 0.040025508606172155, 0.03060909989994276, 0.047100498412982694, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016406581503347173, 0.0004444444444444695, 0.008257155023875584, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07812257188256222, 0.08589584814180506, 0.07147340369812749, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.056971700416156734, 0.0564540088361043, 0.05757663198794927, 0.1083194161532629, 0.10693232832630095, 0.11430045455536386, 0.05376327144332915, 0.0526845836687474, 0.04694511989503536, 0.1124493280951201, 0.10452962074787586, 0.10972843484684136, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03729835827862127, 0.021973568384294317, 0.028920568439419925, 0.016485709105478086, 0.025647746186540088, 0.02454254291218505, 0.1420965841204157, 0.14007723877973877, 0.14181709969770073, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "8391be2d-0252-4563-8b57-ea9502ae9953", "fitness": 0.05650161864609915, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Enhance exploration and exploitation balance by integrating multi-phase adaptive strategies with chaotic perturbations.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        phase_switch = self.budget // 3  # Divide the budget into three adaptive phases\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            phase = evaluations // phase_switch\n            if phase == 1:\n                self.population_size = max(self.min_population_size, self.population_size - 2)\n            elif phase == 2:\n                self.population_size = self.initial_population_size\n\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 48, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05650 with standard deviation 0.06237.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.1933323589501985, 0.164958729887123, 0.1796793335499438, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.058928372738038526, 0.05976852101339525, 0.05454805511655181, 0.03465534645963775, 0.040452081372784554, 0.0484469261256808, 0.11232017096978941, 0.19308305231240486, 0.19043767396233446, 0.11734963612671101, 0.08984665426202476, 0.15287005021407196, 0.11814731965059855, 0.1314444517687251, 0.12988933194273278, 0.0004444444444444695, 0.018773650209501724, 0.0004444444444444695, 0.0004444444444444695, 0.03906318869115699, 0.04418665647786535, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04615563882947571, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005581029722526942, 0.0004444444444444695, 0.0004444444444444695, 0.19384981011403213, 0.22149887114632616, 0.19294074602822997, 0.04446684597648631, 0.039038642599528384, 0.04078819503696385, 0.10675778750098375, 0.11043205452040084, 0.11608796283204625, 0.15171749531347356, 0.16714345819610565, 0.19225822781728708, 0.11597958068241032, 0.09875444294049363, 0.10593005479270245, 0.14577109667394927, 0.1686124653054928, 0.13596108256524841, 0.14251070749078654, 0.15609682540966652, 0.14773026400827916, 0.12605421832067643, 0.22735424978646168, 0.11288573303324334, 0.1053455526479331, 0.11194950073304388, 0.10195960346089128, 0.16930520751122657, 0.1750100219152484, 0.172998663080134, 0.04797976022131156, 0.04966703191913624, 0.04527323391206284, 0.10275504861607743, 0.09876336993251134, 0.11028795114729151, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010297754195879527, 0.0004444444444444695, 0.0004444444444444695, 0.009473872093823, 0.0004444444444444695, 0.07282208780557242, 0.04749095009711246, 0.057120748930362675, 0.005815768650741071, 0.011912976710680367, 0.02642993393225168, 0.040900125161185574, 0.04106340919673934, 0.035525397704581185, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01703996203322944, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14517475326445495, 0.13426952136974657, 0.143959648359397, 0.00671559126637622, 0.010578217579204852, 0.004529879234428047, 0.09083205565925345, 0.06494770356022006, 0.0790310650772098, 0.14349990733967133, 0.13664797548669005, 0.14164649834471876, 0.08717965549404838, 0.07452225908683408, 0.07826160044519037, 0.11374733818702654, 0.12340301608264703, 0.13173439670014275, 0.13603100503611576, 0.12213597866752912, 0.1116805291065387, 0.05469996205183569, 0.05384332340303544, 0.10952930004894912, 0.040506360428831045, 0.08493965180922936, 0.0741847390176863, 0.15649122515925618, 0.16436273467021878, 0.15863407848878508, 0.0026663234085588794, 0.011073919199039217, 0.009436693042091826, 0.056181512650034016, 0.0308740100370839, 0.06066095810582328, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0022862537462282617, 0.0004444444444444695, 0.005009618924067039, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08885931285617232, 0.08797742270597719, 0.08249956044980411, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.050936741325615986, 0.05649431050750986, 0.054891262549190745, 0.11616255182394886, 0.10502081308062683, 0.11381334717840541, 0.0532827331128527, 0.05302703968589495, 0.037698406095433845, 0.11454979498280204, 0.11500020974172342, 0.11791653869285301, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.020428465390469386, 0.05057917728497907, 0.0410198092444104, 0.02227169957627484, 0.015164711068538117, 0.033307057345766, 0.1423745131892148, 0.14112926823663452, 0.14541975295165432, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "4fe76ae2-bcdb-4130-b9dc-7c879e706e42", "fitness": 0.060742547942785746, "name": "RefinedDynamicHybridOptimizer", "description": "Integrate dynamic population resizing and adaptive mutation intensity based on convergence speed to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedDynamicHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 10\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.initial_population_size - int((evaluations / self.budget) * (self.initial_population_size - self.min_population_size)))\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n            mutation_intensity = 0.2 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) * mutation_intensity, self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 49, "feedback": "The algorithm RefinedDynamicHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06074 with standard deviation 0.06388.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.21253261516957855, 0.20848949028000385, 0.21304021071001222, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05457701268126358, 0.04490531383693408, 0.05147130184807491, 0.056462242726097345, 0.04436333175786178, 0.02980062807100392, 0.13129004833121372, 0.09165856804777606, 0.09447186488632264, 0.11090682462308621, 0.1068812013463275, 0.09046830574847675, 0.12639532797626085, 0.12335120972208169, 0.14197888644153422, 0.0004444444444444695, 0.013179788346603827, 0.02882198939676972, 0.0016889985965390375, 0.06731899608478753, 0.026041707737940456, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08951764187210776, 0.047273354947375834, 0.03824741895616479, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.22286609087144016, 0.20102602448529194, 0.21937431391210938, 0.059806614810942405, 0.058774852413243095, 0.038215948885009454, 0.14767612922988715, 0.10233490101248655, 0.12222191588960363, 0.17595835566310614, 0.17021524158730816, 0.1724090410172393, 0.10217258355690628, 0.12167353801772662, 0.13856221134765145, 0.2043828817637281, 0.14089271385080715, 0.24635697663971456, 0.14768759540941578, 0.15562026818280694, 0.15249498871555578, 0.12648744693382763, 0.1763248080741675, 0.11916540607156634, 0.14495429302635, 0.0863522837207007, 0.0715317050080917, 0.1613186032852837, 0.15124131976079425, 0.17608218251591823, 0.0709887049472262, 0.05713274942482227, 0.041621639297102275, 0.11439067848645568, 0.11538611278112731, 0.11920689194218259, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007665521004352471, 0.0060256753754919234, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015403912979446988, 0.04557302681119002, 0.04337439311719349, 0.05962295588685873, 0.029568975318211566, 0.04036141209021504, 0.03318970470080296, 0.05591476086102132, 0.06843880820109327, 0.06579460845280882, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013071709792694342, 0.007595776163424772, 0.010062977861652223, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1334460556246232, 0.17198821744513604, 0.16329740188102204, 0.005764632437745165, 0.001931691709204153, 0.015220463903835468, 0.07433407505738332, 0.07376532953250114, 0.09622873790732223, 0.16197574427299288, 0.13166710004073645, 0.15252799409494133, 0.11059388237402223, 0.0822170752353979, 0.08588754982200686, 0.129561134258101, 0.1314526137445695, 0.13821101545655645, 0.12594139034781626, 0.1414644860236215, 0.13590586367478374, 0.07285012688186543, 0.08050665045554728, 0.10040761646812468, 0.08750322275994726, 0.08983322234073676, 0.0624156516544252, 0.1473783563617267, 0.1595668985037646, 0.1442357673531831, 0.005775641286661637, 0.010254755604457433, 0.006172180798078353, 0.05553419062599718, 0.057105171884252015, 0.07600574334257781, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0018582227528733952, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.1134532316787511, 0.09369081258673095, 0.0965276390870935, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05440179337507878, 0.06005554978763472, 0.05496761001480688, 0.11785368505964733, 0.10916352662710804, 0.1113549913122357, 0.05370925039798269, 0.0532512554866581, 0.05074997997187369, 0.11226036147139484, 0.11298693945063465, 0.11628957394341755, 0.0004444444444444695, 0.08622901740657551, 0.0004444444444444695, 0.0363305271865918, 0.0727146896953258, 0.05653758075511661, 0.03529342654172718, 0.026766928344804874, 0.02617517257831281, 0.14696666750507514, 0.1370495611793019, 0.15089597676082744, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "556a0152-0552-4c02-93ea-7dfe9ac56ebb", "fitness": 0.0643212166409589, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Incorporate adaptive Gaussian noise scaling to enhance the exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)  # Adaptive noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 50, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06432 with standard deviation 0.10318.", "error": "", "parent_ids": ["145b81dc-b421-48a7-8f0b-8cf173db0b0f"], "operator": null, "metadata": {"aucs": [0.1476086656590937, 0.1767167539768053, 0.19405039588343354, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.044081231109012964, 0.03794337227725897, 0.043795242473878004, 0.040404983208650935, 0.04031652415132203, 0.9339255286112338, 0.9119219790732029, 0.10754729414520903, 0.08819832685376783, 0.07474654520909907, 0.07139812778633314, 0.13006696669376494, 0.14245036937304756, 0.11664961018204101, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05696759501025617, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10756254596524628, 0.07386911459320855, 0.002973343863048483, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.014703932870164915, 0.19044164668633445, 0.20240202434614596, 0.2136928440644863, 0.03805576165072311, 0.059358270660124446, 0.053503769986934735, 0.1137118432259061, 0.08612486268351294, 0.10284696549923333, 0.17665582146980463, 0.1808722618274614, 0.16919822748414082, 0.11740528761064872, 0.10071642411108017, 0.11303390558451376, 0.1801887360558153, 0.18482241377447628, 0.15575349531324734, 0.14738203167124042, 0.15766037277228118, 0.15210885683718633, 0.10851517323808757, 0.15205458325951304, 0.14510776736728115, 0.09218984837535871, 0.11232050586621367, 0.16777425721132955, 0.1544322627389243, 0.16631470331698983, 0.161491054984647, 0.05673484628396641, 0.06505321264521446, 0.044790827236030784, 0.09162099505697097, 0.11451958511735383, 0.12323569985075755, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06846172387001837, 0.02940697971801376, 0.06375287179378286, 0.010061243391863761, 0.04282134048299502, 0.0536191488158394, 0.04984848081749871, 0.04573788676545554, 0.033634329565662924, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.003055409287953448, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13955560329944583, 0.13852476959587712, 0.0004444444444444695, 0.003552209211064361, 0.0031539816378642893, 0.08166924082209415, 0.07525152687363157, 0.06363717653514223, 0.14396584023414338, 0.1423941228914699, 0.14588971095309367, 0.08962544647312021, 0.08796791709596075, 0.08395228512072184, 0.11998987749404955, 0.13298378512364795, 0.12377876020440015, 0.13867050490561195, 0.13782704195591255, 0.12470241577463059, 0.05687081359270352, 0.07302773718754096, 0.13675938456682646, 0.07210143668515268, 0.06043151458699425, 0.0781286939588095, 0.16803936407861975, 0.15865776633218875, 0.1572959580378015, 0.006435609003464515, 0.010056851835735015, 0.0038549612143384815, 0.06189962151088024, 0.04010997767779512, 0.042916297817772175, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001857420192985959, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08583715954314342, 0.09698418405542164, 0.08419582228288347, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0567152009952816, 0.05676732489357483, 0.053807329059511355, 0.11856776754488296, 0.10877016710021037, 0.11207245200522509, 0.05793814780711326, 0.06078586976109035, 0.04964708501445403, 0.11876557513320185, 0.11366598453792454, 0.11244206836223036, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04455130042824085, 0.0627435979331652, 0.024768658392798293, 0.016012488842833683, 0.020171263086791402, 0.019424292495480944, 0.14225357097367042, 0.13961458449062514, 0.14914857872934895, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "db78a118-a6bb-42be-8695-501117f1f366", "fitness": 0.06012816774408042, "name": "AdvancedHybridPSO_DE_Elite", "description": "Integrate an adaptive multi-strategy approach combining chaotic maps, Levy flights, and Gaussian noise with a dynamic elite preservation mechanism to enhance global and local search capabilities.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_DE_Elite:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 50\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n        self.elite_threshold = 0.1  # Proportion of elite individuals\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        elite_size = max(1, int(self.elite_threshold * self.population_size))\n        \n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n            \n            elite_indices = np.argsort(values)[:elite_size]\n            elite_positions = positions[elite_indices]\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                if len(elite_positions) > 0:\n                    positions[:elite_size] = elite_positions\n                else:\n                    positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 51, "feedback": "The algorithm AdvancedHybridPSO_DE_Elite got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06013 with standard deviation 0.08896.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.20607496849212592, 0.20106211335076174, 0.1908575510127717, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03969214442465008, 0.040124257845892464, 0.033502769397054655, 0.038450791700378906, 0.033691969891924245, 0.03996819732386758, 0.989525043283905, 0.11919799255937336, 0.08417770413186831, 0.1170322359400271, 0.10674898310249192, 0.10142449533216502, 0.1621213831127868, 0.10277617048694199, 0.12605234494225104, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03885897370415503, 0.0334265466903515, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02590714742376865, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.2009110644443851, 0.2500984148977027, 0.2202703964014805, 0.03131706870406192, 0.04364688011413109, 0.03888260914415065, 0.11866300185393386, 0.10170034911396697, 0.11253698525673195, 0.17652848106641705, 0.14502410807486332, 0.16484122287412473, 0.12292532354070207, 0.11170841168974288, 0.13947996252187633, 0.16020703326932761, 0.1844188927889603, 0.15369068040752887, 0.1558612058953741, 0.15088239782581703, 0.15192556286829817, 0.12407092430190081, 0.1646812408098427, 0.10976882716779435, 0.10324685480354123, 0.11475857226368913, 0.10742962098441555, 0.15204082584907153, 0.15735749305917257, 0.17804005304576997, 0.0475428461058911, 0.04958073649045769, 0.0528506426687676, 0.11582368498882945, 0.12942674812357147, 0.11036066323951554, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0007114128949514686, 0.0004444444444444695, 0.06344836190772529, 0.053704155033828416, 0.06746051184251534, 0.02787198383145617, 0.03429598937249512, 0.025956807128754367, 0.06432250069032452, 0.04550641753299489, 0.05757834876395751, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007432721740570081, 0.0004444444444444695, 0.004288804564391402, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12910668534028535, 0.14245292680541632, 0.1357109593017376, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07333568080879826, 0.06697278721434996, 0.0695555671164012, 0.14268844160080418, 0.1405117922220882, 0.13177971592210147, 0.08701297679823217, 0.07616186969147021, 0.08457706923760167, 0.13713507688639526, 0.12263058046157194, 0.13054658556919918, 0.131955466791413, 0.12852327804257102, 0.10325576914787482, 0.050338853979094544, 0.09042421978789461, 0.12194050168445658, 0.05103737031406308, 0.07403570046712937, 0.06702403487246678, 0.1466433919493466, 0.16457722895300286, 0.16664980908732552, 0.002442319141056748, 0.0004444444444444695, 0.0018187991184612784, 0.04244335096774432, 0.04840141212792781, 0.04317346557542501, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0076108580452395325, 0.0004444444444444695, 0.0015607303086692115, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07894944220459421, 0.08995324940526128, 0.08975770630002522, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05655495840521807, 0.05719688739866313, 0.05557892164667322, 0.11061293026311458, 0.1092068191700295, 0.11730185119927028, 0.05309050744989019, 0.058912535853589354, 0.04956424756234834, 0.11885282594673419, 0.12225352918036592, 0.12167348418596058, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.032374904749460476, 0.04391706111600069, 0.026639068611776007, 0.016654990683758863, 0.02707396837450826, 0.028523788204575684, 0.14460863332512797, 0.1409169507727589, 0.14817255370920657, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "ac609b23-16d0-4a92-93d0-5464fe5f3bd4", "fitness": 0.06427718506887287, "name": "AdvancedHybridPSO_DE", "description": "Integrate a multi-phase exploration-exploitation cycle with adaptive elite selection and diversity maintenance for enhanced convergence.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 50\n        self.min_population_size = 15\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.7  # Initial DE scaling factor\n        self.CR = 0.8  # Initial crossover probability for DE\n        self.c1, self.c2 = 1.5, 1.5  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n        self.elite_rate = 0.1  # Fraction of population considered as elites\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.cos(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.7 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            elite_count = int(self.elite_rate * self.population_size)\n            elite_indices = np.argsort(values)[:elite_count]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if i in elite_indices:\n                    self.velocity[i] *= 0.5\n                else:\n                    self.velocity[i] = (inertia_weight * self.velocity[i] + \n                                        self.learning_rate * (1 + self.success_rate) * \n                                        (self.c1 * r1 * (self.best_position[i] - positions[i]) +\n                                         self.c2 * r2 * (self.best_global_position - positions[i])))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.15 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 52, "feedback": "The algorithm AdvancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06428 with standard deviation 0.06643.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.23648377944939636, 0.2279679740521, 0.1910434953417064, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03590969196344662, 0.06056926312491928, 0.054000001244196794, 0.03783538657669305, 0.08249584278242184, 0.035201429972949616, 0.11908164855351266, 0.07531130028996691, 0.0627248478650444, 0.12168695960846687, 0.10899744474148221, 0.10168458853923501, 0.14539233900626458, 0.14775409553062757, 0.1580565278699254, 0.0004444444444444695, 0.0004444444444444695, 0.01584780118533713, 0.04652496836640929, 0.07373042891914583, 0.01166923676977416, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02402923445024474, 0.005942974858806793, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.013354228276593272, 0.21297186642197108, 0.22782507206694325, 0.2403029925629817, 0.05083244024026157, 0.06647201104532141, 0.06239502911052319, 0.10157211232464614, 0.10641933737712583, 0.10316194237841003, 0.18958578709675145, 0.17570703665067156, 0.15714918850485837, 0.12047566770965545, 0.10321305603140773, 0.11959685847994783, 0.15415416213714372, 0.18316485087790557, 0.1684469071448278, 0.16222133902828206, 0.14715635060062981, 0.16778132829089187, 0.14111309889822676, 0.16361467934880936, 0.1611058208561058, 0.08599538407337803, 0.14649364186888691, 0.21514536664399664, 0.14777080252587216, 0.14976891861025132, 0.1569453029717317, 0.056801769669689306, 0.0667741771479834, 0.048682585074261375, 0.16214636574253605, 0.14228514489044963, 0.14807443786896246, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0025474285206944502, 0.0004444444444444695, 0.006617892124940683, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02637476123982785, 0.03621107718879102, 0.030663431535894126, 0.043249854581868474, 0.036856108108135444, 0.05633550877288995, 0.08107140595063422, 0.0731598392792091, 0.05695420166854048, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.020625902979738542, 0.01375482897961633, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.19223579190643103, 0.14523897397912022, 0.19164752272315466, 0.0036999032218568706, 0.013030004023298236, 0.006317783203863447, 0.07398744590188289, 0.07027293552488001, 0.06896561596948347, 0.15785780843977448, 0.1304684134395595, 0.15116448184789177, 0.11430624301815784, 0.10066514450254394, 0.09995556067721478, 0.1264873455190133, 0.12217381144810169, 0.12815948436953006, 0.13701813097242466, 0.14232246267686355, 0.14298839361274196, 0.14078613786017435, 0.1037089705005757, 0.12604982462857584, 0.10041465255051596, 0.1200686311948409, 0.10071205653871673, 0.14957647699022847, 0.16876005806459726, 0.15001874169261864, 0.011964635145570557, 0.022525674555387787, 0.012435021416984604, 0.08377725221976673, 0.059917833409502186, 0.0750002813939965, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010988993517056067, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10800982701140327, 0.11423214718574615, 0.0945895847714906, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05455795412102815, 0.07101489690156815, 0.052393540077534384, 0.12289996288122884, 0.11139964140996406, 0.11482380200196896, 0.06319249780490155, 0.0573105739544586, 0.05906583296814161, 0.11620011821364162, 0.11621732518462613, 0.11661251674305118, 0.062244659213775866, 0.11599955266994055, 0.10248631633437677, 0.030304198948764238, 0.0780724273888942, 0.062315611798199, 0.03887631856814311, 0.05131755893910139, 0.039229335645179164, 0.1564024851185305, 0.13719939622304, 0.1555281649325283, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "4b532b0c-e4b4-488f-9a6e-f93bc12283ac", "fitness": 0.047132248662957905, "name": "AdvancedHybridPSO_DE", "description": "Introduce a dynamic leader selection mechanism with multi-elitism and adaptive mutation for enhanced convergence and diversity control.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.positions = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_positions = self.positions.copy()\n        self.global_leaders = self.positions[np.argsort([np.inf] * self.population_size)[:3]]\n        self.global_best_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.mutation_rate = 0.1\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        values = np.apply_along_axis(func, 1, self.positions)\n        evaluations += self.population_size\n\n        if evaluations >= self.budget:\n            return self.global_best_value\n\n        self.update_global_leaders(values)\n\n        while evaluations < self.budget:\n            chaotic_value = np.random.rand()\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                leader = self.global_leaders[np.random.randint(3)]\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.c1 * r1 * (self.best_positions[i] - self.positions[i]) + \\\n                                  self.c2 * r2 * (leader - self.positions[i])\n                self.positions[i] += self.velocity[i]\n                self.positions[i] = np.clip(self.positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, self.positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    self.positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.update_global_leaders(values)\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                if evaluations < self.budget:\n                    local_search_vector = self.positions[i] + self.mutation_rate * (self.global_leaders[0] - self.positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        self.positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.global_best_value:\n                            self.global_best_value = local_value\n                            self.update_global_leaders(values)\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                self.positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, self.positions)\n                evaluations += self.population_size\n                self.global_best_value = np.inf\n                self.update_global_leaders(values)\n\n        return self.global_best_value\n\n    def update_global_leaders(self, values):\n        sorted_indices = np.argsort(values)\n        self.global_leaders = self.positions[sorted_indices[:3]]\n        self.global_best_value = values[sorted_indices[0]]", "configspace": "", "generation": 53, "feedback": "The algorithm AdvancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04713 with standard deviation 0.05874.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.1624707943622804, 0.1392673285190833, 0.23803662016097316, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04251314837225961, 0.023189432029571688, 0.04196999768474097, 0.01656567889424454, 0.026421433601371946, 0.020136027097284015, 0.15324390171323532, 0.1677709064499917, 0.12904219486321722, 0.06513387675536131, 0.05159181216692055, 0.06085696487308834, 0.13838219759199266, 0.10817014758972665, 0.09811878030169341, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0026564256159775645, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14995781245418804, 0.1774333548901862, 0.20514323050058392, 0.0325133108449861, 0.029177951147690506, 0.04148498884809648, 0.10389777158102653, 0.13619131335051538, 0.1125330130602985, 0.15632691744209037, 0.1493562089460302, 0.15105810352204396, 0.09338396564912455, 0.10298355674195103, 0.09517322699824238, 0.15783054917861916, 0.16267831662248355, 0.13407026541082168, 0.1454473766980553, 0.1398303450148033, 0.13860154277945824, 0.174729066590256, 0.15579541022879984, 0.09216006514291608, 0.09942085468164086, 0.10266783779233546, 0.15804163322556275, 0.15304334019578258, 0.1695690272089584, 0.1635429087289868, 0.04468783664657794, 0.03433062868772019, 0.04266963028103943, 0.07543962259506487, 0.06761244480129935, 0.07273848830782825, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08595808159424634, 0.11171098550640479, 0.08985090828931619, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011785302905091943, 0.018773497007604556, 0.00585925111147545, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12239604556339578, 0.10837095127877538, 0.12884116212533503, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07668538298976091, 0.09099339453570254, 0.07116119624999173, 0.12769155507180585, 0.12573782087898044, 0.11951743136781601, 0.07056597459850333, 0.0620706794890612, 0.05491511141661287, 0.09781601544486807, 0.09963954692085664, 0.09685435472163306, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05959484325261977, 0.06354991848312364, 0.0572272555856036, 0.052832602278086505, 0.04711702303168974, 0.03834558522460929, 0.16144273309256296, 0.16170610047438527, 0.17232175418612727, 0.0004444444444444695, 0.0004444444444444695, 0.0009149325656431229, 0.029308786866187986, 0.014060360092054136, 0.017005783694445165, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008656852969583295, 0.002781508516500053, 0.010519484926589384, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04784083508854786, 0.05774203062083705, 0.04974692971921524, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.054977398284938084, 0.05581054064057389, 0.050624379204293746, 0.10547254125173888, 0.09891085888474571, 0.09677223956194403, 0.04842358382186607, 0.059461730944456614, 0.04051685449174769, 0.08462467734570323, 0.07776722483449161, 0.0827417169387259, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016734861029155335, 0.020096466006426117, 0.016101210028432567, 0.01272263590992695, 0.013540387964291689, 0.02095802989828366, 0.14699974608592048, 0.14964172224602768, 0.14625290620604403, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "daf6dd16-b06d-4358-919a-49b65eeb6744", "fitness": 0.059168475759054075, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce a dual-strategy mutation with adversarial-inspired local search to refine global exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5\n        self.CR = 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_max, self.w_min = 0.9, 0.4\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))\n            adaptive_CR = self.CR * (1 - self.success_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                \n                # Dual-strategy mutation\n                x4 = positions[np.random.choice(self.population_size)]\n                mutant_vector_alternative = x1 + self.F * (self.best_global_position - x4)\n                \n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n                alternative_vector = np.where(crossover, mutant_vector_alternative, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate\n\n                # Adversarial-inspired local search\n                if evaluations < self.budget:\n                    adversarial_vector = positions[i] + 0.18 * (self.best_global_position - positions[i]) - 0.05 * (x1 - x2)\n                    adversarial_vector = np.clip(adversarial_vector, self.lb, self.ub)\n                    local_value = func(adversarial_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = adversarial_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = adversarial_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 54, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05917 with standard deviation 0.08303.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.12775070096439944, 0.23220043595401052, 0.175016840442349, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05051611502370845, 0.06032312557081809, 0.04660783871022267, 0.04523426880144643, 0.025214201976697104, 0.035302815108539054, 0.11386095385061157, 0.901675094536773, 0.11058699837370489, 0.0811904208555827, 0.05966881090772225, 0.08773881243910542, 0.11997421520141205, 0.12396517567601117, 0.10957539118357151, 0.0004444444444444695, 0.0004444444444444695, 0.08807292234053343, 0.043088776904070536, 0.018074776825635963, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08144178090651055, 0.05615074932406705, 0.020277194291238865, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.18936292519902265, 0.18379425985642117, 0.21218303485426737, 0.05791184341936628, 0.04247041742253477, 0.050353674370934964, 0.10675778750098375, 0.11573013245350083, 0.11260187085625772, 0.1801189093851182, 0.1515776893739973, 0.17094539561785183, 0.12491712833642565, 0.11214331259692678, 0.09840812925837805, 0.1544194140489613, 0.15170641670958873, 0.17962726294037779, 0.14877754906772878, 0.1486975997363953, 0.1488784729685233, 0.13280813349100784, 0.20821878018526252, 0.12165945176511195, 0.10790645000911314, 0.09371078712467529, 0.13308842384999908, 0.1548570486208224, 0.16689364374560645, 0.16291437115093133, 0.04672750416571558, 0.04315200756083082, 0.05441692602255632, 0.10157173208858528, 0.14784584150485203, 0.1145855831902165, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.007314697821534044, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07447223241757372, 0.04709781482402231, 0.0590030614021968, 0.0004444444444444695, 0.04279398068564988, 0.051896303822233425, 0.04673262079324236, 0.020802647561946275, 0.028890855208185795, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0153328797736485, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.12406079580675922, 0.13240693338247667, 0.14395415530103428, 0.0004444444444444695, 0.0004444444444444695, 0.0008703083874226358, 0.0643841511159794, 0.07844519683943407, 0.07708382561911542, 0.13866636372190622, 0.128602448775193, 0.1457532243478319, 0.10826996734068373, 0.08136908785790664, 0.0787871948206812, 0.1417501429663245, 0.12490662962768595, 0.11912511337925535, 0.1360450987727132, 0.06022354880915248, 0.1299282876599699, 0.07054468849065032, 0.04407305923095095, 0.08066085475591822, 0.06645429895031196, 0.07668430123440362, 0.06760056567630213, 0.14904346887520814, 0.15474286571522433, 0.15267600084536637, 0.0004444444444444695, 0.0019247857729594031, 0.004568140265696963, 0.044460111253663004, 0.03396365588397965, 0.0397531374391239, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008771180981270943, 0.0036467421295502955, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.008744147723815376, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08318084953761318, 0.08340638199149386, 0.07838287077171924, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05005350663819874, 0.058192885949707285, 0.059375659748874265, 0.11048886049510398, 0.10412460969216664, 0.11763560815480822, 0.05550510366629735, 0.04994822170286717, 0.05589954161231925, 0.11171440995114368, 0.11556664179437959, 0.11358078913338754, 0.0004444444444444695, 0.036953689381337695, 0.0004444444444444695, 0.04215824707212934, 0.023850926179174836, 0.035931070118562114, 0.02928071363924467, 0.01774722245649296, 0.028573346883763562, 0.13946671564386492, 0.1406157139156754, 0.13844949936383033, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "b2c736e7-bd4d-4c95-bcf0-e9099921864b", "fitness": 0.05934427109921237, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce a dynamic learning rate for velocity updates to refine adaptive exploration.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  (0.1 + 0.9 * self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)  # Adaptive noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 55, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05934 with standard deviation 0.10298.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.14048513971341126, 0.15365968459298607, 0.19183926300476772, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.036344569074464705, 0.02376987544379683, 0.025880931454224543, 0.029591716538631907, 0.01786864481471051, 0.011636439740336901, 0.9338245598563225, 0.9498025788889071, 0.17233575475066143, 0.04124910568114559, 0.06175225902811654, 0.06969435056024409, 0.09623853789072856, 0.09336001674937344, 0.0872200027223019, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02245218041275665, 0.032833592682836144, 0.013866845197265998, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15890975938383833, 0.1695136800526046, 0.18900077980779528, 0.027922035887147256, 0.04927088445673122, 0.03580232570979913, 0.10675778750098375, 0.10481898135656231, 0.10620762269873207, 0.1722308299966444, 0.14987863305559146, 0.1622656316922163, 0.09857538926400478, 0.11335325352647019, 0.08237835720423203, 0.1471801691586886, 0.13208756123417997, 0.12021114232703067, 0.13398104480598372, 0.14121681540336517, 0.15487617178018687, 0.13499008445385208, 0.12613753491812718, 0.10375201733799211, 0.10436020083628139, 0.16078802184144492, 0.11833493076109391, 0.15532369178926575, 0.16646064802866678, 0.14947581903712626, 0.048376685619730964, 0.041199616484645096, 0.030410425272960784, 0.10118290427985632, 0.09371695485191056, 0.10959722092476087, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0008761192564634701, 0.004599167349929378, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10398874781729783, 0.07522703428473243, 0.059100006465601984, 0.03879578527441219, 0.02810485004196317, 0.011336977992725372, 0.06611673658938544, 0.03226350891232299, 0.03746341062134384, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01542074940333904, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14305704532158103, 0.13858027657813776, 0.12958965237674647, 0.0052316670668003384, 0.0004444444444444695, 0.007449139342824651, 0.07572627969571843, 0.07182865765193691, 0.07762078225442037, 0.13758895895764411, 0.1313860318426744, 0.12969188240018426, 0.0867077752647264, 0.0754882101688521, 0.08622476628576281, 0.1369826009405507, 0.11897496578791267, 0.12539627701566392, 0.13400200264614515, 0.0004444444444444695, 0.11793592178565859, 0.10818206851807044, 0.06500648701005851, 0.1096953557481205, 0.07084177370769407, 0.07051799817827731, 0.0576834329866005, 0.17804109944441826, 0.16349592280997216, 0.1578681780324369, 0.0004444444444444695, 0.007025958594515824, 0.007897762415311815, 0.05540414015077133, 0.02962946012377421, 0.03927431721428809, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010692065820769314, 0.0038285821425789734, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08285924205367379, 0.08613010205976812, 0.07756573405057199, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.057627526340407687, 0.05762624967983865, 0.06411255819406025, 0.11030403550051071, 0.1093894042277469, 0.12064718490172288, 0.055400743997695234, 0.05695157180256749, 0.04422394603324009, 0.1128273171923394, 0.11002440735067442, 0.11135180451937954, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.03621259878588878, 0.0260926001816556, 0.02709493671368224, 0.015172716498604077, 0.01859146287398672, 0.021974108766611766, 0.14634824041982275, 0.14403672814477408, 0.1425939741999247, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "bf53bec5-0546-4e64-afdd-5a14eb56548a", "fitness": 0.058916217130674076, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Enhance the adaptive crossover probability by incorporating fitness variance as a dynamic adjustment factor.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            fitness_variance = np.var(values)\n            adaptive_CR = self.CR * (1 - self.success_rate) * (1 + fitness_variance)  # Adaptive CR incorporating fitness variance\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)  # Adaptive noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 56, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05892 with standard deviation 0.06421.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.16488481083038453, 0.18783384405162218, 0.1961181671477762, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04998315905700268, 0.0437240433417867, 0.04684411161440727, 0.03133684114987756, 0.02972008707786411, 0.03066380131098856, 0.13446060412638627, 0.14208738468982818, 0.08567989761306649, 0.08606168379194845, 0.08636882943559165, 0.08825484547041618, 0.11004978291722689, 0.11462203793889103, 0.15381486988921989, 0.0004444444444444695, 0.006500363288188149, 0.0004444444444444695, 0.00867179616178837, 0.031433789969516734, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.005449277496428762, 0.08421084850427485, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.015908843855639954, 0.23665304457772562, 0.19108901123658084, 0.18815395235683052, 0.04079820693222003, 0.046795260099093294, 0.050148077786336454, 0.1152402235009351, 0.11155121987074668, 0.11398955853047521, 0.18077983229609262, 0.1714487193537121, 0.1782811089940156, 0.10916070958446011, 0.12263858291432628, 0.10968098649523528, 0.1273049818462042, 0.1674580168722889, 0.16182081409170035, 0.15268768240256747, 0.1563223832381253, 0.15125999803525458, 0.11085015054119707, 0.22322298342157987, 0.1092394852673777, 0.13476246263632174, 0.15847408985548117, 0.1136846892154213, 0.15389336033938195, 0.15176294728689588, 0.17412213227757234, 0.0705363733883334, 0.056312225199578014, 0.04473559086143519, 0.11899832377302855, 0.1162807098290699, 0.1459164776850742, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0016725704143932818, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04970884322871438, 0.0359916511408529, 0.06440547461924162, 0.016667125334334676, 0.012737852290711671, 0.02537565003594422, 0.039837102065007124, 0.051045930880383006, 0.051638420053051304, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01133218477040765, 0.019682634148152967, 0.01515190107078157, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.13527554204077374, 0.18224367862498758, 0.139507129043988, 0.0004444444444444695, 0.0004444444444444695, 0.0006504296309814972, 0.07019105511236579, 0.07309826351226989, 0.07811108511697606, 0.16111242008992088, 0.14331493573404686, 0.15219120049620527, 0.09165070405867592, 0.09525879433461903, 0.0880476804756466, 0.12834031093757303, 0.1293375282150715, 0.13202167075328164, 0.14323270728697735, 0.14729108158085258, 0.1371218410299292, 0.06796219724346353, 0.14127326254902417, 0.1779892741019934, 0.0912634299251015, 0.10331023252137139, 0.08674493082350287, 0.1823097212492385, 0.1636256086862543, 0.16994620570353713, 0.001338658850697061, 0.020313887318776702, 0.010059655425162628, 0.06483997328529911, 0.04166474354794647, 0.045675587595595424, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.016651344013145275, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09415108588921595, 0.0906171671262267, 0.08999196329105752, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06736912917007187, 0.060874619703634614, 0.053772837267715645, 0.10979311166589412, 0.13002899330546702, 0.10662685133262084, 0.053777425708145365, 0.06370324267990712, 0.05324521598395504, 0.11890065046083709, 0.11194040285056617, 0.11450617871079438, 0.0004444444444444695, 0.0004444444444444695, 0.03154318613235951, 0.04980514248463275, 0.028654521273256073, 0.028857479617867665, 0.0174291938815061, 0.03760153427626112, 0.020331244093722334, 0.15171201317658878, 0.14723261079874728, 0.1475960061656333, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "e7e1182a-fd11-4bc9-a647-fab7a87076f7", "fitness": 0.06302898673681341, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Slightly increase the learning rate to improve exploration during optimization.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.12  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)  # Adaptive noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 57, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06303 with standard deviation 0.10400.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.13331005724869482, 0.17951275210412743, 0.17206630742263362, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.033212411347820936, 0.04303953796278437, 0.03703996060106263, 0.021588851491647576, 0.03487947442392436, 0.029651264491136753, 0.9336243192410003, 0.9383729731686771, 0.12449395950525632, 0.058689377424493094, 0.0896442119264712, 0.08671638796803505, 0.1807243133736488, 0.11692055906198162, 0.1394964223534345, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0240883564630896, 0.038943054536471955, 0.0005301774681869542, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.011324503231545213, 0.0471573390648411, 0.01594708424127589, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.006625840625953061, 0.17596950595863192, 0.19678364850115415, 0.200779012769298, 0.039610674096738685, 0.06818775936584398, 0.03972713603241107, 0.10675778750098375, 0.14841439923149402, 0.10056279389829659, 0.17847620610256154, 0.1651055077413236, 0.14790721195807477, 0.10829140243976709, 0.10642789754362847, 0.10341685503131515, 0.17728437620674176, 0.16014650283474985, 0.13718859874552014, 0.13822589422700549, 0.16065498286277824, 0.1452566093402642, 0.11321768393988574, 0.11809902633724711, 0.12670368535521415, 0.08103956102513821, 0.08106492380516894, 0.23558670906052492, 0.1969554041292999, 0.16024762225857858, 0.18292774889067298, 0.03776804556233848, 0.0487705145324433, 0.04675024751388768, 0.1047235851877919, 0.12223541421010065, 0.10377330703982501, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09433566195826826, 0.04559353867662119, 0.07168101987283382, 0.004568657238389728, 0.02707352480808589, 0.021045696390178725, 0.04654775322958793, 0.03688529551016695, 0.031245241633013343, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.019572766072011305, 0.003746794701131262, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15405944799023075, 0.13989601887983705, 0.13123842042837996, 0.00467023998080085, 0.00313746219394917, 0.005931440692601986, 0.0751498321067332, 0.0828823766675938, 0.08364090843506411, 0.1410356629155487, 0.1282998458230178, 0.1342975552016954, 0.07803144378907179, 0.09665196611238669, 0.0980536136320237, 0.12229830429724375, 0.1244066362272277, 0.13206817284837702, 0.12540260822775584, 0.05927651635136577, 0.1245125216267362, 0.06704543582603684, 0.07956304363347977, 0.08958134866084178, 0.0699407915021717, 0.06704684734896005, 0.10089590542589855, 0.16260161194981493, 0.15793495991547268, 0.15143215548362443, 0.0004444444444444695, 0.010754195689838153, 0.004977439715371568, 0.05114770837069971, 0.0402033112033201, 0.050619448361508446, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08824255686532279, 0.08719188846009074, 0.07522730256381771, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05095736472495471, 0.062052119831565666, 0.05349560504591078, 0.12106098260390119, 0.11285019515181782, 0.11094530426055438, 0.05782921187544954, 0.04883980880593708, 0.04960062287299705, 0.11932639080214502, 0.11798409770719986, 0.12450684237993115, 0.04722815794075197, 0.0004444444444444695, 0.0004444444444444695, 0.049983088498527284, 0.07676238708082117, 0.0189610429442425, 0.0162606008842896, 0.021476295862958295, 0.019659248909565163, 0.1416992139383304, 0.14711005403705146, 0.1440585321803658, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "5e91d8a5-6baa-438e-a0b7-73edf3930f70", "fitness": 0.0622454288098247, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce a random restart condition when success rate falls below a threshold to improve solution diversity.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)  # Adaptive noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5 or self.success_rate < 0.1:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 58, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06225 with standard deviation 0.10303.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.16734899400829573, 0.1767167539768053, 0.19405039588343354, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.044081231109012964, 0.03794337227725897, 0.043795242473878004, 0.040404983208650935, 0.04355670620739205, 0.9339255286112338, 0.9119219790732029, 0.10754729414520903, 0.08819832685376783, 0.07474654520909907, 0.07139812778633314, 0.1422412194888194, 0.14245036937304756, 0.11664961018204101, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05696759501025617, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10756254596524628, 0.07386911459320855, 0.002973343863048483, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.014703932870164915, 0.1724913587175031, 0.20240202434614596, 0.18867218305453348, 0.037464018203398175, 0.059358270660124446, 0.05086895615919318, 0.1137118432259061, 0.1027041195328171, 0.10284696549923333, 0.1674512838974227, 0.1808722618274614, 0.16919822748414082, 0.11740528761064872, 0.10535150773226076, 0.11303390558451376, 0.1801887360558153, 0.18482241377447628, 0.15887255831642066, 0.14738203167124042, 0.1496478742615347, 0.15210885683718633, 0.10533696053605546, 0.15205458325951304, 0.14510776736728115, 0.09218984837535871, 0.11837800574849233, 0.16777425721132955, 0.15442273833724707, 0.16631470331698983, 0.16523087845908346, 0.05673484628396641, 0.06505321264521446, 0.044790827236030784, 0.08865677074377198, 0.0946135574205963, 0.10197994229570095, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04048372682322687, 0.05210163885829211, 0.06131746520218828, 0.004717199839509245, 0.019048412550417004, 0.009931670286055017, 0.057308137011194304, 0.029863809207533176, 0.03883305290196404, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13673546245358503, 0.1260026042198078, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07102321058539185, 0.07469104982829577, 0.0623705721744916, 0.1405417501041739, 0.1324752402382674, 0.1367837637230197, 0.08129861666625438, 0.07154516832874858, 0.08245456641437887, 0.1304489493832196, 0.13298378512364795, 0.12377876020440015, 0.13867050490561195, 0.12878478916681724, 0.0004444444444444695, 0.05116982324317765, 0.07153739457607156, 0.07736348847517127, 0.06811810071831836, 0.06460419889289004, 0.05955137486621809, 0.16803936407861975, 0.14923582968124183, 0.1632115927814357, 0.006758557321348113, 0.00104081686237123, 0.0004444444444444695, 0.0474525036102017, 0.04561838499080051, 0.0486707586561933, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0017030010813279262, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0042683975890431824, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08647182317151536, 0.08532369370441983, 0.0863583897284168, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.055379132739332704, 0.0564540088361043, 0.0529515808324148, 0.11760883861788751, 0.11821705629376711, 0.11436415416335166, 0.06420563527975476, 0.05216840545245216, 0.04985524659442242, 0.12006826668009063, 0.10734673541306072, 0.11691734846337287, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.02259907334678568, 0.023112130330990688, 0.038080820224727696, 0.016777110869939604, 0.017656843561782987, 0.021500738883273418, 0.1671284659916391, 0.13956153095584334, 0.16023583837165112, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "5a85a6c1-d31c-42ba-8115-aa6dda6c6d44", "fitness": 0.058885508236461534, "name": "EnhancedDynamicGaussianHybridPSO_DE", "description": "Enhance global exploration by integrating a dynamic Gaussian distribution mechanism to diversify the evolutionary paths.", "code": "import numpy as np\n\nclass EnhancedDynamicGaussianHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def dynamic_gaussian(self, evaluations):\n        base_stddev = 0.1\n        scale_factor = 1 - evaluations / self.budget\n        return np.random.normal(0, base_stddev * scale_factor, self.dim)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        while evaluations < self.budget:\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = 0.5 * (1 - np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i] + self.dynamic_gaussian(evaluations)\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedDynamicGaussianHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05889 with standard deviation 0.06219.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.16117255067251368, 0.1854049734350457, 0.21303941757319111, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04413637158161143, 0.06370064633512629, 0.05000979195609756, 0.05615508971400773, 0.04687741125653078, 0.07249297739278138, 0.11579721443250268, 0.10269621071660973, 0.09603610577641997, 0.11637217345466477, 0.09958672263350443, 0.08329130487237635, 0.10529560325132536, 0.16388056675732565, 0.13416599338448598, 0.04172105671427395, 0.0004444444444444695, 0.019426315138597938, 0.04409998304637719, 0.009953011248695631, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04848763866041772, 0.0004444444444444695, 0.0645923431586446, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.24419337515825124, 0.2120532352781559, 0.22769842934702866, 0.053912787494592274, 0.06130767650020019, 0.041712910010197835, 0.10675778750098375, 0.08918529425154842, 0.1123334677452722, 0.1711310639271808, 0.16669987077361936, 0.1631336873566651, 0.11256389158382796, 0.0918689689356672, 0.12187100244376858, 0.16400345861291632, 0.16588528911704448, 0.14896132537900564, 0.14496879811581687, 0.1640421311832052, 0.15596731748265136, 0.1847604566693548, 0.10372389654547332, 0.14632522557350847, 0.10509155073262855, 0.10953462273380221, 0.10944891272468893, 0.15321480603914284, 0.17459365089152368, 0.17324045980851654, 0.04850364878703883, 0.06099552224416549, 0.05257285224669961, 0.09185565404554896, 0.12219074092499049, 0.12982902873438884, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001580689472959973, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04965866567332866, 0.0828212729347999, 0.06534529902948494, 0.03404563914687486, 0.0309142317601957, 0.022642676903192216, 0.05819179393227247, 0.045646951771733946, 0.03201357842626107, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01095869327402521, 0.00859245464546421, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.14440433812340392, 0.15550035195770218, 0.14267383798457445, 0.0004444444444444695, 0.0004444444444444695, 0.007850003086031121, 0.06369376354171985, 0.06871527673953215, 0.07335268275982743, 0.14248590071726153, 0.13591638242557702, 0.13508913060248795, 0.08225929557564993, 0.08541650100908671, 0.07484803088528291, 0.13106641428767296, 0.14265980338978645, 0.1278007436885481, 0.12408044479773994, 0.13055922883213877, 0.1264968977978279, 0.09289346862279757, 0.10229509312130092, 0.11109894872629777, 0.05718138640143622, 0.10280634326682325, 0.07794740590833804, 0.15761209614484284, 0.16475527932790401, 0.1718401188385814, 0.006158206073732964, 0.004687448877978895, 0.0032136581460888713, 0.06367876684870621, 0.032666857387437465, 0.061198234372956795, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0036874884715850653, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09387923222248862, 0.09462904158823426, 0.10094804586866346, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.055565951699795835, 0.06328544590275631, 0.06576867881277815, 0.11265848207017093, 0.11007231014888386, 0.11259407916778308, 0.05484892139607456, 0.058407576231871206, 0.050955871729668534, 0.11892625861752437, 0.12580792355238324, 0.11217213688783279, 0.0004444444444444695, 0.051500360476854135, 0.055900139382426994, 0.07292777537419659, 0.029254479534197686, 0.030760616854416112, 0.03367129044788131, 0.029683081067420236, 0.0446128879103691, 0.141198056575073, 0.14406975594683147, 0.14275644494877293, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "1b109548-aa4c-40d0-adcf-04142ae945dc", "fitness": 0.06185706559605303, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Introduce adaptive inertia weight to enhance convergence speed and exploration.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)  # Adaptive inertia weight\n            self.F = chaotic_value * (0.6 - 0.3 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)  # Adaptive noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 60, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06186 with standard deviation 0.08612.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.14482752382832864, 0.1769125296112979, 0.1932171850697636, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.07717706632298804, 0.08651172762650561, 0.03034481741078543, 0.03511583708805621, 0.029322358043888386, 0.053106992354471805, 0.9339081765266871, 0.2495367711090939, 0.10999852589522119, 0.08544956740461729, 0.07674638992885752, 0.0658022889811295, 0.1318985044799773, 0.11184715477495433, 0.14553074205515226, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.046386060051768596, 0.009242999407159558, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10756254596524628, 0.07386911459320855, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.01698579425942326, 0.17178241998013644, 0.201313662217534, 0.20338289557969613, 0.04699856993113383, 0.04375351742119937, 0.04522883082042506, 0.10998003183663363, 0.09850630170354979, 0.11353718718775274, 0.16273803135041387, 0.15604072127959845, 0.16374178786838067, 0.11686914153406802, 0.13969348034340212, 0.10093690133267397, 0.15837521872394333, 0.18714546534090482, 0.15119725898930603, 0.1563908235570921, 0.17169195602176135, 0.14822766661218645, 0.1095789696488757, 0.15288123748384552, 0.13133530764365398, 0.08634021337801134, 0.10717349287838407, 0.16438202581574635, 0.16250778545231293, 0.14628873219438543, 0.14921159729316213, 0.06690187701493377, 0.05134606939862052, 0.06774675490069526, 0.10239650362500308, 0.1356737511591979, 0.11653990011040671, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.010675503636233818, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.053999529587070993, 0.08694853278624493, 0.08517941443820387, 0.017293962676593888, 0.03530781730571608, 0.03814037256835201, 0.05249349890495225, 0.053006900255033296, 0.02874183605069147, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0021068814666682645, 0.0004444444444444695, 0.03414013158483853, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15331331204708043, 0.14203762437405887, 0.1469673165425257, 0.004956641703686038, 0.0004444444444444695, 0.009166937114241769, 0.06576760743649801, 0.07466759530385081, 0.07197902864687256, 0.15093158767536796, 0.12753202323739066, 0.16024541838512163, 0.10076251024179428, 0.08507028461700084, 0.08933836200873624, 0.1410710775415096, 0.1384856047030083, 0.14504731921885394, 0.13901263826046562, 0.14191971243011559, 0.1124927769039803, 0.06633660640083949, 0.09527572448608945, 0.14307160193331558, 0.028562275406962767, 0.059440389666935545, 0.10490476752507771, 0.14584550861732148, 0.16887895590129387, 0.15927032761125526, 0.0004444444444444695, 0.0013009567880148953, 0.011522929237338109, 0.052231674737186595, 0.04086045524698256, 0.04552526057942441, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0051444356504899424, 0.0004444444444444695, 0.01006764274607086, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0007315734626192061, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.09219745428712023, 0.09099941142430468, 0.08329507611452125, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04997898272121404, 0.05733313729612144, 0.056735548697933846, 0.11049511745312446, 0.11149525217836453, 0.10737262272734005, 0.05974372577550602, 0.05149225789917966, 0.05078453856624421, 0.11409005013126405, 0.11431102818532757, 0.11643582672804575, 0.0004444444444444695, 0.007352966868458322, 0.0004444444444444695, 0.04366219429384566, 0.050195904030863936, 0.0224075570245168, 0.015418819430782604, 0.020886161415938354, 0.03430445320810316, 0.14225357097367042, 0.14796717705054185, 0.1461208393086455, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
{"id": "62c6d9ed-ef31-44ae-b96f-03dcc5da3c36", "fitness": 0.0643212166409589, "name": "RefinedEnhancedHybridPSO_DE_Improved", "description": "Enhance exploration by modifying the chaotic map's influence on DE scaling factor.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb, self.ub = -5.0, 5.0\n        self.initial_population_size = 40\n        self.min_population_size = 20\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.best_position = np.random.uniform(self.lb, self.ub, (self.population_size, dim))\n        self.best_global_position = self.best_position[0]\n        self.best_global_value = np.inf\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial crossover probability for DE\n        self.c1, self.c2 = 2.0, 2.0  # PSO cognitive and social coefficients\n        self.w_max, self.w_min = 0.9, 0.4  # Max and min inertia weights\n        self.learning_rate = 0.1  # Adaptive learning rate for PSO updates\n        self.success_rate = 0.0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        values = np.apply_along_axis(func, 1, positions)\n        evaluations += self.population_size\n\n        for i in range(self.population_size):\n            if values[i] < self.best_global_value:\n                self.best_global_value = values[i]\n                self.best_global_position = positions[i]\n\n        chaotic_value = np.random.rand()\n        while evaluations < self.budget:\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.population_size = max(self.min_population_size, self.population_size - 1)\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * np.sin(np.pi * (evaluations / self.budget)))  # Dynamic inertia weight\n            self.F = chaotic_value * (0.7 - 0.2 * np.tanh(evaluations / self.budget))  # Non-linear scaling factor\n            adaptive_CR = self.CR * (1 - self.success_rate)  # Adaptive CR based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                  self.learning_rate * (1 + self.success_rate) * (self.c1 * r1 * (self.best_position[i] - positions[i]) + \\\n                                  self.c2 * r2 * (self.best_global_position - positions[i]))  # Updated learning rate\n                positions[i] += self.velocity[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n\n                fitness_variance = np.var(values)\n                self.F = 0.5 + 0.5 * np.tanh(fitness_variance + 0.1)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                gaussian_noise_scale = 0.1 * (1 - evaluations / self.budget) * (1 + self.success_rate)  # Adaptive noise scaling\n                mutant_vector = np.clip(x1 + self.F * (x2 - x3) + self.levy_flight(self.dim) + np.random.normal(0, gaussian_noise_scale, self.dim), self.lb, self.ub)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n                if trial_value < values[i]:\n                    positions[i] = trial_vector\n                    values[i] = trial_value\n                    self.success_rate = 0.9 * self.success_rate + 0.1 * 1  # Update success rate\n                    if trial_value < self.best_global_value:\n                        self.best_global_value = trial_value\n                        self.best_global_position = trial_vector\n                else:\n                    self.success_rate = 0.9 * self.success_rate  # Update success rate\n\n                if evaluations < self.budget:\n                    local_search_vector = positions[i] + 0.18 * (self.best_global_position - positions[i])\n                    local_search_vector = np.clip(local_search_vector, self.lb, self.ub)\n                    local_value = func(local_search_vector)\n                    evaluations += 1\n                    if local_value < values[i]:\n                        positions[i] = local_search_vector\n                        values[i] = local_value\n                        if local_value < self.best_global_value:\n                            self.best_global_value = local_value\n                            self.best_global_position = local_search_vector\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic restart mechanism for diversity\n            if np.std(values) < 1e-5:\n                positions = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                values = np.apply_along_axis(func, 1, positions)\n                evaluations += self.population_size\n                self.best_global_value = np.inf\n\n        return self.best_global_value", "configspace": "", "generation": 61, "feedback": "The algorithm RefinedEnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06432 with standard deviation 0.10318.", "error": "", "parent_ids": ["556a0152-0552-4c02-93ea-7dfe9ac56ebb"], "operator": null, "metadata": {"aucs": [0.1476086656590937, 0.1767167539768053, 0.19405039588343354, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06951148309700628, 0.044081231109012964, 0.03794337227725897, 0.043795242473878004, 0.040404983208650935, 0.04031652415132203, 0.9339255286112338, 0.9119219790732029, 0.10754729414520903, 0.08819832685376783, 0.07474654520909907, 0.07139812778633314, 0.13006696669376494, 0.14245036937304756, 0.11664961018204101, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.05696759501025617, 0.009988358263955943, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.10756254596524628, 0.07386911459320855, 0.002973343863048483, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.014703932870164915, 0.19044164668633445, 0.20240202434614596, 0.2136928440644863, 0.03805576165072311, 0.059358270660124446, 0.053503769986934735, 0.1137118432259061, 0.08612486268351294, 0.10284696549923333, 0.17665582146980463, 0.1808722618274614, 0.16919822748414082, 0.11740528761064872, 0.10071642411108017, 0.11303390558451376, 0.1801887360558153, 0.18482241377447628, 0.15575349531324734, 0.14738203167124042, 0.15766037277228118, 0.15210885683718633, 0.10851517323808757, 0.15205458325951304, 0.14510776736728115, 0.09218984837535871, 0.11232050586621367, 0.16777425721132955, 0.1544322627389243, 0.16631470331698983, 0.161491054984647, 0.05673484628396641, 0.06505321264521446, 0.044790827236030784, 0.09162099505697097, 0.11451958511735383, 0.12323569985075755, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.06846172387001837, 0.02940697971801376, 0.06375287179378286, 0.010061243391863761, 0.04282134048299502, 0.0536191488158394, 0.04984848081749871, 0.04573788676545554, 0.033634329565662924, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.003055409287953448, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.15408562357123856, 0.13955560329944583, 0.13852476959587712, 0.0004444444444444695, 0.003552209211064361, 0.0031539816378642893, 0.08166924082209415, 0.07525152687363157, 0.06363717653514223, 0.14396584023414338, 0.1423941228914699, 0.14588971095309367, 0.08962544647312021, 0.08796791709596075, 0.08395228512072184, 0.11998987749404955, 0.13298378512364795, 0.12377876020440015, 0.13867050490561195, 0.13782704195591255, 0.12470241577463059, 0.05687081359270352, 0.07302773718754096, 0.13675938456682646, 0.07210143668515268, 0.06043151458699425, 0.0781286939588095, 0.16803936407861975, 0.15865776633218875, 0.1572959580378015, 0.006435609003464515, 0.010056851835735015, 0.0038549612143384815, 0.06189962151088024, 0.04010997767779512, 0.042916297817772175, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.001857420192985959, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.08583715954314342, 0.09698418405542164, 0.08419582228288347, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.0567152009952816, 0.05676732489357483, 0.053807329059511355, 0.11856776754488296, 0.10877016710021037, 0.11207245200522509, 0.05793814780711326, 0.06078586976109035, 0.04964708501445403, 0.11876557513320185, 0.11366598453792454, 0.11244206836223036, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695, 0.04455130042824085, 0.0627435979331652, 0.024768658392798293, 0.016012488842833683, 0.020171263086791402, 0.019424292495480944, 0.14225357097367042, 0.13961458449062514, 0.14914857872934895, 0.0004444444444444695, 0.0004444444444444695, 0.0004444444444444695]}}
