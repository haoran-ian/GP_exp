{"id": "6490abaa-4c3e-4260-8c55-efee8a192a0a", "fitness": 0.11622421342706521, "name": "NovelMetaheuristicOptimizer", "description": "A population-based dynamic velocity adjustment algorithm inspired by particle swarm optimization and simulated annealing to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)  # Adjust population size based on budget\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0  # Initial temperature for annealing\n        self.cooling_rate = 0.99  # Cooling rate for annealing\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        # Initialize positions and velocities\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with dynamic inertia weight\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Keep within bounds\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Cool down temperature\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11622 with standard deviation 0.03633.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.09526221214638408, 0.14972829302922708, 0.07609213962338135, 0.1515235513363209, 0.16610614381970956, 0.15582460717584745, 0.09245632043761376, 0.08792764049078683, 0.0710970127843159]}}
{"id": "7a6d17b2-f265-49d2-abab-1896721f0278", "fitness": 0.09870783554796232, "name": "EnhancedMetaheuristicOptimizer", "description": "An enhanced population-based algorithm combining adaptive inertia weight tuning and rank-based selection to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)\n        self.inertia_weight = 0.9  # Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_temp = 100.0\n        self.min_temp = 1.0\n        self.temperature = self.max_temp\n        self.cooling_rate = 0.95\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Rank-based selection for best positions\n            scores = np.array([func(pos) for pos in positions])\n            sorted_indices = np.argsort(scores)\n            top_indices = sorted_indices[:self.population_size // 2]\n            bottom_indices = sorted_indices[self.population_size // 2:]\n\n            for i in range(self.population_size):\n                # Adaptive inertia weight based on rank\n                rank = np.where(sorted_indices == i)[0][0] / self.population_size\n                dynamic_inertia_weight = self.inertia_weight * (1 - rank)\n\n                inertia = dynamic_inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if i in top_indices:\n                    self.temperature = max(self.min_temp, self.temperature * self.cooling_rate)\n                else:\n                    self.temperature = self.max_temp  # Reset temperature for exploration\n\n            # Rank-based velocity modification for added diversity\n            for i in bottom_indices:\n                velocities[i] *= np.random.rand() * 2\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09871 with standard deviation 0.03833.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.06764093234486235, 0.09315212150143093, 0.049209953226708736, 0.13906076190288819, 0.16610614381970956, 0.14268555195448063, 0.08594193586186327, 0.07980371841809186, 0.06476940090162542]}}
{"id": "addd668d-28b6-42ef-a894-161b4ea8ea5f", "fitness": 0.10823634489106147, "name": "NovelMetaheuristicOptimizer", "description": "Enhanced dynamic exploration via Lévy flight-inspired perturbations in the velocity update mechanism for improved search efficiency.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n\n                # Introduce Lévy flight-inspired perturbation\n                levy_flight = np.random.standard_cauchy(self.dim) * 0.01 * search_space\n                velocities[i] = inertia + cognitive_component + social_component + levy_flight\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10824 with standard deviation 0.03478.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.06996729528556811, 0.1072405167646393, 0.09554180665185963, 0.1495124746797678, 0.16610614381970956, 0.1474395473687914, 0.08594193586186327, 0.08389503676277876, 0.06848234682457544]}}
{"id": "4e29f728-c45c-49a9-8dd1-0b2b170bcc30", "fitness": 0.09590574233645742, "name": "EnhancedMetaheuristicOptimizer", "description": "A hybrid algorithm integrating adaptive differential evolution with dynamic velocity adjustment and simulated annealing to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.differential_weight = 0.8\n        self.crossover_prob = 0.9\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                rand_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = positions[rand_indices]\n                mutant_vector = a + self.differential_weight * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, positions[i])\n\n                trial_vector = np.clip(trial_vector, bounds[0], bounds[1])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < np.exp(-abs(trial_score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09591 with standard deviation 0.04814.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.05024528567136488, 0.04854568818638538, 0.05106456479711674, 0.1564791320645299, 0.16610614381970956, 0.1626363068337605, 0.08594193586186327, 0.07940004781166177, 0.06273257598172477]}}
{"id": "4143cfff-219d-4197-89ba-e17cb7ef83cc", "fitness": 0.10657447029970717, "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive coefficients for cognitive and social components to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)  # Adjust population size based on budget\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0  # Initial temperature for annealing\n        self.cooling_rate = 0.99  # Cooling rate for annealing\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        # Initialize positions and velocities\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with dynamic inertia weight\n                inertia = self.inertia_weight * velocities[i]\n                # Adaptive cognitive and social coefficients\n                adaptive_cognitive_coeff = self.cognitive_coeff * (1 - evaluations / self.budget)\n                adaptive_social_coeff = self.social_coeff * (evaluations / self.budget)\n                cognitive_component = adaptive_cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = adaptive_social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Keep within bounds\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Cool down temperature\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10657 with standard deviation 0.03581.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.07760166400868262, 0.09494574158166169, 0.05956220678505586, 0.14601383036211457, 0.1662100748896469, 0.15172826473730916, 0.09020581673974137, 0.09436032099579117, 0.07854231259736111]}}
{"id": "04ecaed8-cc60-4c8d-8fe9-2d717b922aab", "fitness": 0.12272654525990519, "name": "NovelMetaheuristicOptimizer", "description": "Enhanced velocity update by adding a learning factor to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)  # Adjust population size based on budget\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9  # New parameter to tweak velocity\n        self.temperature = 100.0  # Initial temperature for annealing\n        self.cooling_rate = 0.99  # Cooling rate for annealing\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        # Initialize positions and velocities\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with dynamic inertia weight\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor  # Apply learning factor\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Keep within bounds\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Cool down temperature\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12273 with standard deviation 0.03114.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.09496057854859552, 0.16639798920783477, 0.08911507576655109, 0.14567626025027358, 0.16610614381970956, 0.14762418714468772, 0.10313946349233205, 0.09049998850952079, 0.10101922059964163]}}
{"id": "e932fca9-d5a8-47f1-8f96-6624ed04462f", "fitness": 0.12282094622928295, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce adaptive population size and dynamic cooling rate to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12282 with standard deviation 0.03073.", "error": "", "parent_ids": ["04ecaed8-cc60-4c8d-8fe9-2d717b922aab"], "operator": null, "metadata": {"aucs": [0.09477432372460193, 0.16568601397047533, 0.08950094821946686, 0.14036885596159265, 0.16767864917434439, 0.1497678232937366, 0.10062198592425087, 0.09384962467523117, 0.10314029111984657]}}
{"id": "0b338993-e5f7-4fe5-a300-39dafb44cfe1", "fitness": 0.11403385321312756, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce a dynamic cognitive coefficient based on iteration progress to enhance personal best convergence.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                progress_ratio = evaluations / self.budget  # New dynamic cognitive coefficient\n                cognitive_component = (self.cognitive_coeff * (1 - progress_ratio) + 1) * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11403 with standard deviation 0.03399.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.08501249809471545, 0.1398900545102838, 0.07288406354558719, 0.14692774390199614, 0.16610614381970956, 0.14931916490922903, 0.10027889640797094, 0.08698375631985034, 0.07890235740880547]}}
{"id": "a7575ada-3ea3-4114-9d65-b7e3f4aa3f08", "fitness": 0.09842685034611265, "name": "EnhancedAdaptiveOptimizer", "description": "Enhance the adaptive algorithm by integrating differential evolution mutation and selection mechanisms for improved convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = positions[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), bounds[0], bounds[1])\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_prob\n                trial = np.where(cross_points, mutant, positions[i])\n                \n                score = func(trial)\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = score\n                \n                if score < global_best_score:\n                    global_best_position = trial\n                    global_best_score = score\n\n                # Particle Swarm Optimization inspired update\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09843 with standard deviation 0.04266.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.07616282000037489, 0.04899743112315358, 0.07088843383546717, 0.15104074026492909, 0.16610614381970956, 0.1524564591432448, 0.08594193586186327, 0.07940004781166177, 0.054847641254609725]}}
{"id": "753d1fd4-8ea1-4cda-9365-c6af9b88c071", "fitness": 0.1174162858237028, "name": "RefinedMetaheuristicOptimizer", "description": "Enhance the balance between exploration and exploitation by modifying the velocity update formula.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component + np.random.randn(self.dim) * 0.01 * search_space  # Slight random perturbation\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11742 with standard deviation 0.03587.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.10014715782005934, 0.09656659689751157, 0.0918882963985429, 0.16045954472592938, 0.16610614381970956, 0.17461189891477635, 0.10254743249041531, 0.08312101867685351, 0.08129848266952733]}}
{"id": "a0ff137c-e565-4419-bed2-41b44d04d47a", "fitness": 0.11569626996908935, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance exploration-exploitation balance by introducing a mutation-based diversification and elitist selection mechanism.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                if np.random.rand() < 0.1:  # Mutation-based diversification\n                    velocities[i] += np.random.randn(self.dim) * 0.1 * search_space\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                sorted_indices = np.argsort(personal_best_scores)\n                positions = positions[sorted_indices[:population_size]]\n                velocities = velocities[sorted_indices[:population_size]]\n                personal_best_positions = personal_best_positions[sorted_indices[:population_size]]\n                personal_best_scores = personal_best_scores[sorted_indices[:population_size]]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11570 with standard deviation 0.03347.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.08874681905832316, 0.10975132628022544, 0.08682892143526588, 0.1581848187587186, 0.16610614381970956, 0.16083026263126277, 0.09091578600578454, 0.09908251091481246, 0.08081984081770166]}}
{"id": "3ef5c34a-f292-42bc-a19d-f67eda212e90", "fitness": 0.10371106067402835, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate multi-swarm dynamics and hybrid mutation strategies to diversify search and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.num_swarms = 3  # Number of swarms for multi-swarm dynamics\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        # Initialize swarms\n        swarms = []\n        for _ in range(self.num_swarms):\n            positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n            velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n            personal_best_positions = np.copy(positions)\n            personal_best_scores = np.array([func(pos) for pos in positions])\n            global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n            global_best_score = np.min(personal_best_scores)\n            swarms.append((positions, velocities, personal_best_positions, personal_best_scores, global_best_position, global_best_score))\n        \n        evaluations = population_size * self.num_swarms\n\n        while evaluations < self.budget:\n            for swarm in swarms:\n                positions, velocities, personal_best_positions, personal_best_scores, global_best_position, global_best_score = swarm\n                for i in range(population_size):\n                    inertia = self.inertia_weight * velocities[i]\n                    cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                    velocities[i] = inertia + cognitive_component + social_component\n                    velocities[i] *= self.learning_factor\n                    positions[i] += velocities[i]\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                    \n                    if np.random.rand() < 0.1:  # Mutation strategy\n                        positions[i] += np.random.randn(self.dim) * search_space * 0.05\n\n                    score = func(positions[i])\n                    evaluations += 1\n\n                    if score < personal_best_scores[i]:\n                        personal_best_positions[i] = positions[i]\n                        personal_best_scores[i] = score\n\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n                    if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                        velocities[i] *= np.random.rand() * 2\n\n                if evaluations / self.budget > 0.5:\n                    population_size = max(self.min_population_size, population_size - 1)\n                    positions = positions[:population_size]\n                    velocities = velocities[:population_size]\n                    personal_best_positions = personal_best_positions[:population_size]\n                    personal_best_scores = personal_best_scores[:population_size]\n\n                temperature *= self.cooling_rate\n\n        best_swarm = min(swarms, key=lambda s: s[5])  # Find the best swarm based on global best score\n        return best_swarm[4], best_swarm[5]", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10371 with standard deviation 0.03923.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.07142335622909313, 0.08290028698629492, 0.06310944433823829, 0.1579320826090067, 0.16610614381970956, 0.15067272715283653, 0.086218899253371, 0.07940004781166177, 0.07563655786604329]}}
{"id": "57aa6c7c-3cd9-48f1-bf40-41b9aa63c8dc", "fitness": 0.12097456129689224, "name": "RefinedMetaheuristicOptimizer", "description": "Incorporate momentum into velocity updates to enhance convergence speed.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n        self.momentum = 0.1  # Incorporate momentum\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component + self.momentum * velocities[i] # Add momentum\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12097 with standard deviation 0.03510.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.08839955799165566, 0.14468858659779948, 0.09224907043508224, 0.17049173561774655, 0.16610614381970956, 0.15623112424387708, 0.09524255596222264, 0.08394430874024505, 0.09141796826369175]}}
{"id": "187803ba-81b9-47db-863e-5ae837c22edb", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Leverage self-adaptive mutation rates and neighborhood search to enhance convergence speed and solution diversity.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 10\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.mutation_rate = 0.1\n        self.neighborhood_size = min(5, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                \n                # Adaptive mutation rate\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = (np.random.randn(self.neighborhood_size) * (search_space / 10))\n                    indices = np.random.choice(self.dim, self.neighborhood_size, replace=False)\n                    positions[i, indices] += mutation_vector\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n            self.mutation_rate *= 0.95  # Reduce mutation over time\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (5,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (5,) (10,) ')", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {}}
{"id": "7e8fb108-105f-4412-aac0-32459af51b31", "fitness": 0.10830078396554461, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce a multi-phase strategy with adaptive crossover and mutation operations to strengthen genetic diversity and convergence quality.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(60, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.99\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Phase 1: Particle Swarm Optimization\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            # Phase 2: Genetic Operations\n            if np.random.rand() < self.crossover_rate:\n                parent1, parent2 = np.random.choice(range(population_size), 2, replace=False)\n                crossover_point = np.random.randint(1, self.dim)\n                offspring = np.concatenate((positions[parent1][:crossover_point], positions[parent2][crossover_point:]))\n                offspring_score = func(offspring)\n                evaluations += 1\n\n                if offspring_score < personal_best_scores[parent1]:\n                    positions[parent1] = offspring\n                    personal_best_scores[parent1] = offspring_score\n\n                if offspring_score < global_best_score:\n                    global_best_position = offspring\n                    global_best_score = offspring_score\n\n            for i in range(population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.randn(self.dim) * 0.1 * search_space\n                    positions[i] += mutation\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                    score = func(positions[i])\n                    evaluations += 1\n\n                    if score < personal_best_scores[i]:\n                        personal_best_positions[i] = positions[i]\n                        personal_best_scores[i] = score\n\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10830 with standard deviation 0.03741.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.11085689290401324, 0.07133087667316318, 0.07386705570212448, 0.1540510655686469, 0.16610614381970956, 0.15558041940895995, 0.08728506631258681, 0.0835847436194661, 0.07204479168123135]}}
{"id": "e1bf9608-bc07-45fa-8d21-a9b2fdb33d4b", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Integrate Lévy flight mechanism and adaptive mutation strategies to enhance exploration and intensification in the solution space.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < 0.1:  # Apply Lévy flight with a low probability\n                    positions[i] += self.levy_flight(self.dim) * search_space\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {}}
{"id": "d42d7d00-d1b8-47e0-8582-f95106cc53e6", "fitness": 0.1275485407896941, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate variable inertia for better adaptability in velocity updates.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12755 with standard deviation 0.03516.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.145688643170078, 0.1563068222001598, 0.053527371608239394, 0.15058453177622944, 0.16680044494771773, 0.15679205183757017, 0.11498905080290645, 0.10717009078032214, 0.09607785998402374]}}
{"id": "51087c34-b2bd-4706-a8c8-dcfdcbb3c638", "fitness": 0.1107112215484275, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance exploration-exploitation trade-off using adaptive coefficients and Levy flights.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + L) * np.sin(np.pi * L / 2) / \n                 (np.math.gamma((1 + L) / 2) * L * 2**((L - 1) / 2)))**(1 / L)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        return u / abs(v)**(1 / L)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            inertia_weight_adaptive = self.inertia_weight * (1 - evaluations / self.budget)\n            for i in range(population_size):\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (inertia_weight_adaptive * velocities[i] +\n                                 cognitive_component + social_component) * self.learning_factor\n\n                if np.random.rand() < 0.3:\n                    velocities[i] += self.levy_flight(1.5) * 0.1 * search_space\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                \n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11071 with standard deviation 0.03818.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.08657433943089599, 0.11816511686088904, 0.06258194342856915, 0.16324054397226706, 0.16752993071808653, 0.1511692148583833, 0.08815838193058956, 0.08582287472313122, 0.07315864801303562]}}
{"id": "93629999-ed95-4a58-a99e-520ca83ce188", "fitness": 0.11862312508188556, "name": "RefinedMetaheuristicOptimizer", "description": "Incorporate adaptive cognitive and social coefficients based on performance improvements.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    self.cognitive_coeff = min(2.0, self.cognitive_coeff * 1.05)  # Adaptive cognitive coefficient\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n                    self.social_coeff = min(2.0, self.social_coeff * 1.05)  # Adaptive social coefficient\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11862 with standard deviation 0.03777.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09388355784206659, 0.15172086775738036, 0.057094084489633934, 0.15531184148107013, 0.1667377258819528, 0.16057663026738522, 0.0957673089076394, 0.08560444204517925, 0.10091166706466226]}}
{"id": "e47a4526-88fe-4cc5-b40b-79f024960a20", "fitness": 0.11743390312523488, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce position perturbation to enhance local exploration in adaptive velocity updates.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                positions[i] += np.random.randn(self.dim) * 0.01 * search_space  # Added perturbation\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11743 with standard deviation 0.03084.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.10122331235039517, 0.10135632217401491, 0.09340264606734261, 0.14966965468351445, 0.16964241039869976, 0.15813018599409256, 0.11064461370816658, 0.09238277488097635, 0.08045320786991161]}}
{"id": "e7df51e8-1773-4db3-a44c-5da98210e718", "fitness": 0.1185468420194069, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive learning rate and diversity preservation to enhance global exploration and convergence speed.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.learning_factor_decrease_rate = 0.995\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        learning_factor = self.initial_learning_factor\n        population_size = self.initial_population_size\n\n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity with adaptive learning factor\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing with adaptive exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= (np.random.rand() * 2)\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature and adapt learning factor\n            temperature *= self.cooling_rate\n            learning_factor *= self.learning_factor_decrease_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11855 with standard deviation 0.03629.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09709325578953465, 0.15624272152555208, 0.05418743727939179, 0.15885197293883757, 0.16629974977406647, 0.14236574561162474, 0.0957942888446719, 0.09712447532801127, 0.09896193108297158]}}
{"id": "92ad3f36-d6c6-426a-8241-6a40c078ee38", "fitness": 0.11978762942752136, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce dynamic learning and diversity preservation mechanisms to enhance exploration and robustness in optimization.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.diversity_factor = 0.01  # To maintain population diversity\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update dynamic learning factor based on diversity\n                current_diversity = np.std(positions, axis=0).mean() / search_space.mean()\n                dynamic_learning_factor = self.learning_factor + self.diversity_factor * current_diversity\n\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= dynamic_learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11979 with standard deviation 0.03941.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.0966999833284653, 0.15712695741053107, 0.05537473145912053, 0.15983685230578626, 0.16693123662766474, 0.16012254841256024, 0.11007742912196405, 0.09156554177866971, 0.08035338440293016]}}
{"id": "23d8fe58-938d-4c5c-8c30-fd293ffe27f0", "fitness": 0.11605442611089985, "name": "AdvancedMetaheuristicOptimizer", "description": "Enhance adaptivity by dynamically adjusting cognitive and social components based on performance trends.", "code": "import numpy as np\n\nclass AdvancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        previous_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                \n                # Dynamic adjustment of coefficients\n                progress = (previous_global_best_score - global_best_score) / max(1e-10, previous_global_best_score)\n                self.cognitive_coeff = 1.5 + 0.5 * (1 - progress)\n                self.social_coeff = 1.5 + 0.5 * progress\n\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    previous_global_best_score = global_best_score\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm AdvancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11605 with standard deviation 0.03797.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09639237819277635, 0.1620797086283431, 0.052046345782084114, 0.14971309799667631, 0.16754670070566247, 0.14237116415388384, 0.0966120223881457, 0.08440012584064283, 0.09332829130988407]}}
{"id": "52d57958-441b-44e8-bedd-5298768cf14b", "fitness": 0.11392894984151665, "name": "EnhancedMetaheuristicOptimizer", "description": "Combine dynamic inertia with stochastic mutation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update inertia dynamically\n                inertia_weight = self.inertia_weight * (1 - evaluations / self.budget)\n                \n                # Update velocity\n                inertia = inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Stochastic mutation for exploration\n                if np.random.rand() < 0.1:\n                    mutation = np.random.randn(self.dim) * 0.1 * search_space\n                    velocities[i] += mutation\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11393 with standard deviation 0.03669.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.08641714492102781, 0.11625731739160017, 0.07978282520779456, 0.15658072160751657, 0.16657318878219318, 0.16500905078992456, 0.09575465035174158, 0.09147857834947459, 0.06750707117237686]}}
{"id": "99a86bf7-f4e6-470b-bd10-0596505fa62b", "fitness": 0.12494608806718269, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce adaptive velocity scaling for dynamic control of exploitation-exploration balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor * (1 + np.random.rand() * (evaluations / self.budget))  # Adaptive velocity scaling\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12495 with standard deviation 0.03132.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09756584781318978, 0.15334825429573784, 0.12468544198764919, 0.15710544645173619, 0.16610614381970956, 0.15212978011424927, 0.10522076913747658, 0.09087032800471995, 0.07748278098017602]}}
{"id": "0c5e3edb-7703-45db-911b-eaa2f1862499", "fitness": 0.1149453661057562, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate dynamic diversity preservation to enhance convergence stability by adjusting exploration and exploitation during optimization.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.diversity_threshold = 0.1  # Threshold for diversity adjustment\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                if np.random.rand() < self.diversity_threshold:\n                    velocities[i] += np.random.randn(self.dim) * 0.1 * search_space\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11495 with standard deviation 0.03160.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.10187080264636938, 0.09047567835590375, 0.12477505368598607, 0.15092954684967197, 0.16610614381970956, 0.14790814508781058, 0.0917433145636456, 0.09013954347123843, 0.0705600664714704]}}
{"id": "04892beb-09ee-413e-aa0d-b8c58e8365c1", "fitness": 0.11965855128412407, "name": "EnhancedMetaheuristicOptimizer", "description": "Utilize adaptive inertia and multi-population strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.population_fractions = [0.6, 0.4]  # Use two subpopulations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        evaluations = 0\n\n        # Initialize subpopulations\n        subpopulations = [int(population_size * f) for f in self.population_fractions]\n        positions = [np.random.rand(s, self.dim) * search_space + bounds[0] for s in subpopulations]\n        velocities = [np.random.randn(s, self.dim) * 0.1 * search_space for s in subpopulations]\n        personal_best_positions = [np.copy(p) for p in positions]\n        personal_best_scores = [np.array([func(pos) for pos in p]) for p in positions]\n\n        global_best_position = np.array(min((p[np.argmin(s)] for p, s in zip(personal_best_positions, personal_best_scores)), key=func))\n        global_best_score = func(global_best_position)\n\n        evaluations += sum(subpopulations)\n\n        while evaluations < self.budget:\n            for k in range(len(positions)):\n                for i in range(subpopulations[k]):\n                    # Update velocity with adaptive inertia\n                    velocity_inertia = self.inertia_weight * (1 - evaluations / self.budget) * velocities[k][i]\n                    cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[k][i] - positions[k][i])\n                    social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[k][i])\n                    velocities[k][i] = velocity_inertia + cognitive_component + social_component\n                    velocities[k][i] *= self.learning_factor\n\n                    # Update position\n                    positions[k][i] += velocities[k][i]\n                    positions[k][i] = np.clip(positions[k][i], bounds[0], bounds[1])\n\n                    # Evaluate new position\n                    score = func(positions[k][i])\n                    evaluations += 1\n\n                    # Update personal and global bests\n                    if score < personal_best_scores[k][i]:\n                        personal_best_positions[k][i] = positions[k][i]\n                        personal_best_scores[k][i] = score\n\n                    if score < global_best_score:\n                        global_best_position = positions[k][i]\n                        global_best_score = score\n\n                    # Simulated annealing inspired exploration-exploitation balance\n                    if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                        velocities[k][i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                for k in range(len(subpopulations)):\n                    subpopulations[k] = max(self.min_population_size, subpopulations[k] - 1)\n                    positions[k] = positions[k][:subpopulations[k]]\n                    velocities[k] = velocities[k][:subpopulations[k]]\n                    personal_best_positions[k] = personal_best_positions[k][:subpopulations[k]]\n                    personal_best_scores[k] = personal_best_scores[k][:subpopulations[k]]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11966 with standard deviation 0.02961.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09440705851784925, 0.14683262482018156, 0.09258880947765524, 0.14570948379043336, 0.16619254961847518, 0.14862290531311773, 0.09717505393280701, 0.10107904383887378, 0.08431943224772354]}}
{"id": "28972996-d3fc-47de-96a2-fc2463ab6d8e", "fitness": 0.12225268552957422, "name": "RefinedMetaheuristicOptimizer", "description": "Implement adaptive inertia weighting to enhance convergence speed and precision.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget) * (0.5 + 0.5 * np.random.rand())  # Change: adaptive inertia weight\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12225 with standard deviation 0.03703.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.10046956825459608, 0.1623271843666646, 0.0739067143212816, 0.141216227416332, 0.18653761297097327, 0.1530886262927872, 0.10037607356066125, 0.09712450333709788, 0.08522765924577425]}}
{"id": "449ad4b5-4d8e-4ab9-89c1-922bd4909be7", "fitness": 0.13127313015215872, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive learning rates and dimension-wise exploration strategies to enhance convergence and adaptability.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13127 with standard deviation 0.02904.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09729165001525764, 0.15754443097396675, 0.13541611334674497, 0.1630885000804353, 0.16994204940327418, 0.15270886828559704, 0.11165324183297787, 0.0994988891844818, 0.094314428246693]}}
{"id": "5289c87f-337e-4dcc-96dc-2bf55f8954b2", "fitness": 0.11846673749692312, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate dynamic exploration-exploitation balance through nonlinear adaptive parameters and hybrid local search to enhance robustness and convergence.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.exploration_factor = 0.7\n        self.exploitation_factor = 0.3\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            exploration_exploitation_ratio = (self.exploration_factor - self.exploitation_factor) * (1 - (evaluations/self.budget)**2) + self.exploitation_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia * exploration_exploitation_ratio + cognitive_component + social_component\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            if evaluations / self.budget > 0.7:\n                for j in range(population_size):\n                    local_search_step = np.random.uniform(-0.1, 0.1, self.dim) * search_space\n                    candidate_position = np.clip(positions[j] + local_search_step, bounds[0], bounds[1])\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    if candidate_score < personal_best_scores[j]:\n                        personal_best_positions[j] = candidate_position\n                        personal_best_scores[j] = candidate_score\n                        if candidate_score < global_best_score:\n                            global_best_position = candidate_position\n                            global_best_score = candidate_score\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11847 with standard deviation 0.03997.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.08109828155404308, 0.16924489000025766, 0.05221822652292363, 0.1453640691024367, 0.16846895089976666, 0.15525884219566222, 0.10984699895469474, 0.09305546275778132, 0.09164491548474218]}}
{"id": "0abf3f1a-4c62-4a65-bfce-1ae2e0c96227", "fitness": 0.10261304085487408, "name": "DynamicMomentumOptimizer", "description": "Incorporate dynamic diversification and intensification strategies with adaptive momentum to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicMomentumOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n        self.diversification_factor = 1.2\n        self.intensification_factor = 0.8\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.99\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            alpha = evaluations / self.budget\n            momentum_factor = self.diversification_factor if alpha < 0.5 else self.intensification_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * momentum_factor\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                velocities *= np.random.rand(population_size, self.dim) * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm DynamicMomentumOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10261 with standard deviation 0.03844.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.07327843175714, 0.07878812790429957, 0.05113260580097023, 0.14866438324275255, 0.16610614381970956, 0.14925426930693275, 0.08741967786333704, 0.08472850201105031, 0.08414522598767471]}}
{"id": "f24f768a-e77f-4b1a-9557-6ee37d3a4271", "fitness": 0.12472176815341657, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive mutation and survival strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n            \n            # Mutate a random individual's position to explore new areas in the search space\n            if np.random.rand() < 0.1:  # Change 1\n                random_idx = np.random.randint(0, population_size)  # Change 2\n                positions[random_idx] = np.random.rand(self.dim) * search_space + bounds[0]  # Change 3\n\n            # Elitism: Retain the best solution found so far in the population\n            positions[0] = global_best_position  # Change 4\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12472 with standard deviation 0.03387.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.0970201267526577, 0.16992740392524208, 0.09331551603417254, 0.155512142169288, 0.1679624804985621, 0.1484513782660739, 0.10481010493684595, 0.11153712135173388, 0.0739596394461729]}}
{"id": "57d372eb-e5a7-41cc-8940-17c9eac4f688", "fitness": 0.08756529621269665, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate dynamic neighborhood structures and adaptive inertia to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 10\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            inertia_weight = ((self.inertia_max - self.inertia_min) * \n                              (1 - evaluations / self.budget) + self.inertia_min)\n            learning_factor = ((self.initial_learning_factor - self.final_learning_factor) * \n                               (1 - evaluations / self.budget) + self.final_learning_factor)\n\n            for i in range(population_size):\n                neighborhood = positions[np.random.choice(population_size, 5, replace=False)]\n                local_best_position = neighborhood[np.argmin([func(n) for n in neighborhood])]\n                \n                inertia = inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (local_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08757 with standard deviation 0.04802.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.04511903121279115, 0.027149537422416326, 0.03872299956887759, 0.13861816939614324, 0.16610614381970956, 0.144659957660638, 0.08594193586186327, 0.08353643847630288, 0.058233452495527915]}}
{"id": "a79119c2-642c-4ff1-b861-6a7c21b99f4c", "fitness": 0.12812846574441544, "name": "EnhancedMetaheuristicOptimizer", "description": "Refine learning dynamics by adjusting inertia weight decay and temperature handling to enhance solution exploration.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (0.5 - evaluations / self.budget)  # Adjusted inertia weight decay\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / (temperature + 1e-8)):  # Added small value to temperature\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12813 with standard deviation 0.03136.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.09791528733453192, 0.13766625822388068, 0.07674222865231539, 0.1709479764511438, 0.16677039903226665, 0.15578853602023268, 0.10841437578077362, 0.10247276695312613, 0.1364383632514683]}}
{"id": "cb82eb4d-d8a2-4fcf-8269-56a70d36f9a8", "fitness": 0.11005167775373813, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce probabilistic mutation and elitism to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_probability = 0.1  # Added mutation probability\n        self.elite_fraction = 0.1  # Added elite fraction\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < self.mutation_probability:  # Added mutation logic\n                    positions[i] += np.random.randn(self.dim) * 0.05 * search_space\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n            elite_size = int(self.elite_fraction * population_size)  # Added elitism logic\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            positions = np.concatenate((personal_best_positions[elite_indices], positions))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11005 with standard deviation 0.03436.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.09376744184128416, 0.07785359726095187, 0.11032268615439411, 0.15221635427753943, 0.16610614381970956, 0.1501880090477895, 0.08594193586186327, 0.08096041665614984, 0.07310851486396142]}}
{"id": "edca328a-c7b4-45ca-8b45-d498c62bc00f", "fitness": 0.10327476865967339, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate a multi-swarm strategy with adaptive diversity maintenance and dynamic search space partitioning to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        swarms = [\n            {\n                'positions': np.random.rand(population_size, self.dim) * search_space + bounds[0],\n                'velocities': np.random.randn(population_size, self.dim) * 0.1 * search_space,\n                'personal_best_positions': np.empty((population_size, self.dim)),\n                'personal_best_scores': np.full(population_size, np.inf),\n                'global_best_position': None,\n                'global_best_score': np.inf\n            } for _ in range(self.num_swarms)\n        ]\n\n        for swarm in swarms:\n            swarm['personal_best_positions'] = np.copy(swarm['positions'])\n            swarm['personal_best_scores'] = np.array([func(pos) for pos in swarm['positions']])\n            best_idx = np.argmin(swarm['personal_best_scores'])\n            swarm['global_best_position'] = swarm['personal_best_positions'][best_idx]\n            swarm['global_best_score'] = swarm['personal_best_scores'][best_idx]\n\n        evaluations = population_size * self.num_swarms\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            \n            for swarm in swarms:\n                for i in range(population_size):\n                    inertia = self.inertia_weight * swarm['velocities'][i] * (1 - evaluations / self.budget)\n                    cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (swarm['personal_best_positions'][i] - swarm['positions'][i])\n                    social_component = self.social_coeff * np.random.rand(self.dim) * (swarm['global_best_position'] - swarm['positions'][i])\n                    swarm['velocities'][i] = inertia + cognitive_component + social_component\n                    swarm['velocities'][i] *= learning_factor\n\n                    swarm['positions'][i] += swarm['velocities'][i]\n                    swarm['positions'][i] = np.clip(swarm['positions'][i], bounds[0], bounds[1])\n\n                    score = func(swarm['positions'][i])\n                    evaluations += 1\n\n                    if score < swarm['personal_best_scores'][i]:\n                        swarm['personal_best_positions'][i] = swarm['positions'][i]\n                        swarm['personal_best_scores'][i] = score\n\n                    if score < swarm['global_best_score']:\n                        swarm['global_best_position'] = swarm['positions'][i]\n                        swarm['global_best_score'] = score\n\n                    if np.random.rand() < np.exp(-abs(score - swarm['global_best_score']) / temperature):\n                        swarm['velocities'][i] *= np.random.rand() * 2\n\n                if evaluations / self.budget > 0.5:\n                    population_size = max(self.min_population_size, population_size - 1)\n                    swarm['positions'] = swarm['positions'][:population_size]\n                    swarm['velocities'] = swarm['velocities'][:population_size]\n                    swarm['personal_best_positions'] = swarm['personal_best_positions'][:population_size]\n                    swarm['personal_best_scores'] = swarm['personal_best_scores'][:population_size]\n\n            temperature *= self.cooling_rate\n\n        best_swarm = min(swarms, key=lambda s: s['global_best_score'])\n        return best_swarm['global_best_position'], best_swarm['global_best_score']", "configspace": "", "generation": 35, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10327 with standard deviation 0.03673.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.08427473144349373, 0.0750493426472214, 0.07759972008095517, 0.14748957050290323, 0.1669695985602263, 0.14752926926780863, 0.08597458556383042, 0.08051029761438122, 0.06407580225624032]}}
{"id": "e8d61c38-6757-4ecf-8b6a-fffd6903e04e", "fitness": 0.11109072380443129, "name": "AdaptiveMetaheuristicOptimizer", "description": "Integrate self-adaptive mutation and crossover mechanisms alongside adaptive learning rates to boost exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < self.crossover_rate:\n                    partner_idx = np.random.randint(population_size)\n                    crossover_mask = np.random.rand(self.dim) > 0.5\n                    positions[i][crossover_mask] = personal_best_positions[partner_idx][crossover_mask]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutate_dim = np.random.randint(self.dim)\n                    positions[i][mutate_dim] += np.random.randn() * (bounds[1][mutate_dim] - bounds[0][mutate_dim]) * 0.1\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11109 with standard deviation 0.03499.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.10050854074820903, 0.11672772582717061, 0.068087043625768, 0.15439523619240536, 0.16759267023829671, 0.1472766924239748, 0.08595475143352205, 0.08407282835018837, 0.07520102540034668]}}
{"id": "36c35325-d27a-4497-bf10-2929e152c8f3", "fitness": 0.11583870931427977, "name": "EnhancedMetaheuristicOptimizer", "description": "Integrate adaptive mutation and dynamic population resizing strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_prob = 0.1\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                mutation = np.random.rand(self.dim) * np.where(np.random.rand(self.dim) < self.mutation_prob, search_space * 0.05, 0)\n                velocities[i] = inertia + cognitive_component + social_component + mutation\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            temperature *= self.cooling_rate\n            if evaluations / self.budget > 0.5 and population_size > self.min_population_size:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11584 with standard deviation 0.03484.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.10524015525702624, 0.0970690748257248, 0.06652516888827176, 0.1593188963192601, 0.17084143416963682, 0.15678200908217488, 0.10591153906685391, 0.09527143961858175, 0.08558866660098763]}}
{"id": "da06dbb2-0756-48eb-a332-8ae60aaffd87", "fitness": 0.1041907005392782, "name": "AdvancedMetaheuristicOptimizer", "description": "Enhance exploration by introducing differential mutation and crossover from DE to improve diversity and convergence.", "code": "import numpy as np\n\nclass AdvancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(60, self.budget // 4)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.3\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 15\n        self.differential_weight = 0.8\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            \n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                # Differential mutation and crossover\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = positions[indices[0]], positions[indices[1]], positions[indices[2]]\n                mutant_vector = a + self.differential_weight * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, positions[i])\n                trial_vector = np.clip(trial_vector, bounds[0], bounds[1])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n            temperature *= self.cooling_rate\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = np.resize(positions, (population_size, self.dim))\n                velocities = np.resize(velocities, (population_size, self.dim))\n                personal_best_positions = np.resize(personal_best_positions, (population_size, self.dim))\n                personal_best_scores = np.resize(personal_best_scores, population_size)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm AdvancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10419 with standard deviation 0.03857.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.06869188759626743, 0.09683062267195797, 0.07836558604751698, 0.15344001891382753, 0.16610614381970956, 0.15030779998687094, 0.08594193586186327, 0.07940004781166177, 0.05863226214382844]}}
{"id": "86ab4703-2b26-40af-935c-1141bc42bec1", "fitness": 0.0943412627592115, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate differential evolution strategies with adaptive temperature control to enhance global exploration and convergence accuracy.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(60, self.budget // 4)\n        self.inertia_weight = 0.4\n        self.cognitive_coeff = 1.2\n        self.social_coeff = 1.8\n        self.initial_learning_factor = 0.8\n        self.final_learning_factor = 0.3\n        self.initial_temperature = 150.0\n        self.cooling_rate = 0.996\n        self.min_population_size = 8\n        self.differential_weight = 0.7\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = personal_best_positions[a] + self.differential_weight * (personal_best_positions[b] - personal_best_positions[c])\n                trial_vector = np.array([mutant_vector[j] if np.random.rand() < self.crossover_rate else positions[i, j] for j in range(self.dim)])\n                trial_vector = np.clip(trial_vector, bounds[0], bounds[1])\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < np.exp(-abs(trial_score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09434 with standard deviation 0.04972.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.044681244019687094, 0.0371059733302852, 0.04241079416469673, 0.1600312075718382, 0.16610614381970956, 0.15558374859694557, 0.08716796120748527, 0.07940004781166177, 0.07658424431059407]}}
{"id": "fa2c6696-b80f-439f-b39d-9bb13a2777a1", "fitness": 0.11987932844352474, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate nonlinear cooling and adaptive inertia for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (0.5 - evaluations / self.budget) ** 2\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate ** np.sqrt(evaluations / self.budget)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11988 with standard deviation 0.03728.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.09954729037528565, 0.14056721697106067, 0.05556517445088627, 0.15894785441309356, 0.1787412583114919, 0.14941484383713333, 0.11332163292096487, 0.09005416369072738, 0.09275452102107906]}}
{"id": "e9695a05-30e2-49e6-b357-c6cf3d1bea52", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance exploration by adjusting temperature dynamically based on evaluations to improve convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / (temperature * (1 - evaluations / self.budget))):  # Adjusted\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "An exception occurred: ZeroDivisionError('float division by zero').", "error": "ZeroDivisionError('float division by zero')", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {}}
{"id": "77a32b2a-7b28-4ce0-95d6-45f75ead8408", "fitness": 0.2287364268625413, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce inertia weight decay for better exploitation as the optimization progresses.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22874 with standard deviation 0.27419.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [1.0, 0.16443675194623264, 0.1386531955373912, 0.14302923767139175, 0.16858264087696895, 0.155991746173881, 0.11176460151977774, 0.09086898748588956, 0.08530068055133899]}}
{"id": "0ec698be-b188-4573-89f3-d2bb35072ee9", "fitness": 0.11007218874633046, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive cognitive and social coefficients based on convergence rate for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            self.cognitive_coeff = 2 - (evaluations / self.budget)  # Adaptive cognitive coefficient\n            self.social_coeff = 1 + (evaluations / self.budget)  # Adaptive social coefficient\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11007 with standard deviation 0.03172.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10095385911141574, 0.07701163784046694, 0.08807728166990014, 0.1472447886665178, 0.1668689154086973, 0.14548977738095148, 0.0954288340217253, 0.08936386347645864, 0.08021074114084081]}}
{"id": "3f7c2440-029f-4a14-9f76-ebb34aaf182f", "fitness": 0.11897301782973733, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive inertia weight for balanced exploration and exploitation.  ", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11897 with standard deviation 0.03507.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.0838613974181941, 0.15966576139248423, 0.07367620730577262, 0.1532091687373931, 0.16616801383372926, 0.14639498432186526, 0.10256325780998987, 0.10517423949404503, 0.08004413015416267]}}
{"id": "7c50798a-ecd9-4175-ac00-e47e17360c00", "fitness": 0.12481440223535471, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce adaptive population size scaling and dynamic social coefficient adjustment for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.initial_social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            social_coeff = self.initial_social_coeff * (1 - evaluations / self.budget)  # Dynamic social coefficient\n\n            # Adaptive population size scaling\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, int(self.initial_population_size * (1 - evaluations / self.budget)))\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12481 with standard deviation 0.03237.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.08588279324005121, 0.15481582474212674, 0.13726413462654374, 0.14547665063133208, 0.16615260288996914, 0.15973496529628184, 0.0999207072772118, 0.09082082910319378, 0.08326111231148203]}}
{"id": "e4087313-696e-4ef1-8be5-d0257363e444", "fitness": 0.10921444291922086, "name": "RefinedMetaheuristicOptimizer", "description": "Combine adaptive learning rates with dynamic swarm diversity to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.6\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                # Adjust the learning factor dynamically\n                learning_factor = 0.5 + 0.5 * np.abs(np.sin(evaluations / self.budget * np.pi))\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                diversity = np.std(positions, axis=0).mean()\n                if diversity < 0.01:  # Reinitialize some particles if the swarm is too homogenous\n                    positions += np.random.randn(population_size, self.dim) * 0.1 * search_space\n\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10921 with standard deviation 0.03602.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.0959182678016437, 0.06614821419688055, 0.07595564576711833, 0.143157711005082, 0.16610614381970956, 0.16287138079095642, 0.10423813493343026, 0.08501915048586683, 0.08351533747230011]}}
{"id": "2961bb14-64ac-48eb-9d99-16181bbb1608", "fitness": 0.1288026270438297, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive population resizing and elite selection for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.elite_fraction = 0.2\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            elite_count = max(1, int(self.elite_fraction * population_size))\n            elite_positions = positions[np.argsort(personal_best_scores)[:elite_count]]\n            elite_score = np.min(personal_best_scores)\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12880 with standard deviation 0.03038.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10059580163159532, 0.16443675194623264, 0.1386531955373912, 0.14302923767139175, 0.16858264087696895, 0.155991746173881, 0.11176460151977774, 0.09086898748588956, 0.08530068055133899]}}
{"id": "c45a5ff2-688a-40ab-a8a0-616ec46bdebe", "fitness": 0.125435867023875, "name": "AdaptiveMetaheuristicOptimizer", "description": "Introduce self-adaptive parameter control and dynamic population resizing for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 10\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress_ratio) + self.final_learning_factor\n            self.inertia_weight *= (0.5 + 0.5 * np.tanh(2 * (0.5 - progress_ratio)))  # Adaptive inertia weight\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12544 with standard deviation 0.03024.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.08691445939728049, 0.15477214243090698, 0.08683649200197552, 0.15644098367350434, 0.16708883641592165, 0.15111544932474974, 0.11390060170969829, 0.09744341531540524, 0.11441042294543258]}}
{"id": "32e22759-d6e6-4110-90ff-5f881deb08ea", "fitness": 0.12877631829453565, "name": "EnhancedMetaheuristicOptimizer", "description": "Adjust the cooling rate dynamically based on progress to improve convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate * (1 - evaluations / self.budget)  # Change line\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12878 with standard deviation 0.02999.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09836041639762505, 0.15222480022654128, 0.13395060207257548, 0.14867697813409708, 0.1672496260631079, 0.16694315598735987, 0.1079923510981804, 0.0985431354532802, 0.08504579921805355]}}
{"id": "ba5e00c8-3227-4f3a-9685-a3aceae26d0e", "fitness": 0.11040458563665964, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance global exploration by adapting cognitive and social coefficients dynamically during optimization.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            # Dynamic adjustment of coefficients\n            self.cognitive_coeff = 1.5 + 0.5 * (1 - evaluations / self.budget)\n            self.social_coeff = 1.5 - 0.5 * (1 - evaluations / self.budget)\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11040 with standard deviation 0.03559.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09942477129688587, 0.07210317929262877, 0.07480412679740911, 0.15215185792380204, 0.16757081489555703, 0.1570349444710596, 0.09741298331061132, 0.09165003976882025, 0.08148855297316282]}}
{"id": "473f71ee-fb6e-40e4-8f39-5d8653c76417", "fitness": 0.12239804324312731, "name": "EnhancedMetaheuristicOptimizer", "description": "Add dynamic adjustment to the cognitive coefficient for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            \n            self.cognitive_coeff = 1.5 * (1 - evaluations / self.budget) + 0.5 * (evaluations / self.budget)  # Dynamic cognitive coefficient\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12240 with standard deviation 0.03098.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10323165280425961, 0.15720819204902015, 0.0808267513360843, 0.14364294394941068, 0.16782877169377108, 0.15300892702156932, 0.10829503703557841, 0.09824287299479506, 0.08929724030365715]}}
{"id": "7766f50a-b3a1-47cd-847d-6f74ecc404fc", "fitness": 0.11461600385269384, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce dynamic cognitive and social coefficients for adaptive exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            self.cognitive_coeff = 2.0 - progress  # Dynamic cognitive coefficient\n            self.social_coeff = 1.0 + progress  # Dynamic social coefficient\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - progress)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11462 with standard deviation 0.03185.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10068062966967983, 0.07522554562139627, 0.07963329144542897, 0.1536934610802969, 0.16877643996431013, 0.14809570692117058, 0.09778029786124498, 0.09813636896448041, 0.10952229314623663]}}
{"id": "edff20f2-80cf-4f1a-877a-fa90e34ab6e4", "fitness": 0.11793717501814394, "name": "RefinedMetaheuristicOptimizer", "description": "Enhance convergence by integrating adaptive population size reduction and dynamic parameter tuning.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.initial_learning_factor = 1.0\n        self.final_learning_factor = 0.3\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.99\n        self.min_population_size = 5\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress_ratio) + self.final_learning_factor\n            self.inertia_weight *= 0.98  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - progress_ratio)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5 and evaluations % 10 == 0:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11794 with standard deviation 0.03317.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09597833219853757, 0.1430215084853218, 0.06803028110186171, 0.15131289861224095, 0.16763096331047223, 0.15049364120365938, 0.09527190286255283, 0.10108316338639345, 0.0886118840022555]}}
{"id": "a2e8bdbb-3513-461b-9827-67ae8a0260ca", "fitness": 0.11640483058770815, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive mutation and elitism to enhance exploration and exploitation balance in the optimization process.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        elitism_factor = 0.1  # Fraction of top performers maintained\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            indices = np.argsort(personal_best_scores)\n            elite_count = int(elitism_factor * population_size)\n            elites = positions[indices[:elite_count]]\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                if np.random.rand() < self.mutation_rate:\n                    mutations = np.random.randn(self.dim) * 0.1 * search_space\n                    velocities[i] += mutations\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n            if population_size < self.initial_population_size:\n                positions[:elite_count] = elites[:elite_count]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11640 with standard deviation 0.03129.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10097455513089915, 0.08827179604754976, 0.124455620043045, 0.14695192930803047, 0.16872619339305528, 0.15375203476285382, 0.09306370353710058, 0.09626330593852983, 0.07518433712830941]}}
{"id": "8e57c96c-47eb-4bac-97d6-7271b24da097", "fitness": 0.0956337253085451, "name": "EnhancedMetaheuristicOptimizerV2", "description": "Incorporate adaptive velocity scaling and dynamic inertia adjustment to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_scaling_factor = 1.0\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic inertia adjustment\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * self.adaptive_scaling_factor\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    self.adaptive_scaling_factor = 1.5  # Increase scaling when improving\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Acceptance based on Metropolis criterion\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Gradually reduce population size and temperature\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n            if evaluations % 100 == 0:\n                self.adaptive_scaling_factor = 1.0  # Reset scaling factor periodically\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedMetaheuristicOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09563 with standard deviation 0.04542.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.04904638570143316, 0.07390673302929085, 0.035794710735143065, 0.1553633759205939, 0.16610614381970956, 0.1471044202078765, 0.08705505023045768, 0.07940004781166177, 0.06692666032073935]}}
