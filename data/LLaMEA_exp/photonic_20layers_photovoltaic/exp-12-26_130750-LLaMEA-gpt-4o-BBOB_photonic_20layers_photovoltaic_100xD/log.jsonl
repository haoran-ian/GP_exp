{"id": "2780ad82-a029-412a-b08f-ff7c0bf26c83", "fitness": 0.07945553742703423, "name": "HybridPSO_ADM", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Mutation integrates swarm intelligence with adaptive mutation strategies for diverse exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_ADM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_ADM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07946 with standard deviation 0.05722.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.014672766880426735, 0.014781433464161386, 0.015372616279626161, 0.06658424406397423, 0.08736492261253914, 0.06124081556169281, 0.13631575205239244, 0.17371239412000372, 0.14505489180849152]}}
{"id": "b2294b2e-58a8-4013-ab03-b550ac9852e6", "fitness": 0.07877302939122265, "name": "EnhancedHybridPSO", "description": "Enhanced Hybrid PSO with Dynamic Inertia and Adaptive Mutation introduces momentum variability and adaptive learning to improve convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n\n        evaluations = 0\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    w * self.velocities[i] +\n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07877 with standard deviation 0.04732.", "error": "", "parent_ids": ["2780ad82-a029-412a-b08f-ff7c0bf26c83"], "operator": null, "metadata": {"aucs": [0.01948821181647553, 0.027278225513254428, 0.03211153471115358, 0.06711478327500642, 0.0689084357033437, 0.07233031199669782, 0.13402007777449942, 0.14110865325970368, 0.14659703047086925]}}
{"id": "d15ababd-f402-478e-839b-9d683ca54d9a", "fitness": 0.07593774734371002, "name": "EnhancedHybridPSO_AVM", "description": "Enhanced Hybrid PSO with Adaptive Velocity and Mutation dynamically adjusts velocities and mutation strategies based on convergence dynamics for improved solution accuracy and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_AVM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.7  # increased inertia weight for more exploration\n        self.c1 = 1.2  # reduced cognitive coefficient\n        self.c2 = 1.7  # increased social coefficient for better convergence\n        self.initial_mutation_rate = 0.2\n        self.final_mutation_rate = 0.05\n        self.mutation_rate = self.initial_mutation_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                # Adaptive inertia weight to focus on exploration initially and exploitation later\n                self.w = 0.9 - (0.5 * (evaluations / self.budget))\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation rate, decreasing over time to stabilize convergence\n            self.mutation_rate = (self.initial_mutation_rate - self.final_mutation_rate) * ((self.budget - evaluations) / self.budget) + self.final_mutation_rate\n\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSO_AVM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07594 with standard deviation 0.05466.", "error": "", "parent_ids": ["2780ad82-a029-412a-b08f-ff7c0bf26c83"], "operator": null, "metadata": {"aucs": [0.013176552494024829, 0.015718650904148257, 0.016599647387243954, 0.07016604184354625, 0.06336141384180805, 0.061660235709320776, 0.14825224005668736, 0.14942533056465523, 0.1450796132919555]}}
{"id": "5179b8ab-a2fb-456b-8c57-acebf0d1111d", "fitness": 0.0731366952826652, "name": "EnhancedHybridPSO_ADM", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Mutation incorporates dynamic population sizing and learning rates, improving convergence by balancing exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_ADM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.max_population_size = self.initial_population_size * 2\n        self.velocities = np.random.rand(self.initial_population_size, dim) * 0.1\n        self.positions = np.random.rand(self.initial_population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.initial_population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_max, self.w_min = 0.9, 0.4  # inertia weights\n        self.c1_start, self.c1_end = 2.5, 0.5  # cognitive coefficients\n        self.c2_start, self.c2_end = 0.5, 2.5  # social coefficients\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            population_size = int(self.initial_population_size + (self.max_population_size - self.initial_population_size) * (evaluations / self.budget))\n            if len(self.positions) < population_size:\n                new_positions = lb + (ub - lb) * np.random.rand(population_size - len(self.positions), self.dim)\n                new_velocities = np.random.rand(population_size - len(self.velocities), self.dim) * 0.1\n                self.positions = np.vstack((self.positions, new_positions))\n                self.velocities = np.vstack((self.velocities, new_velocities))\n                self.personal_best_positions = np.vstack((self.personal_best_positions, new_positions))\n                self.personal_best_values = np.append(self.personal_best_values, np.full(population_size - len(self.personal_best_values), np.inf))\n            \n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            c1 = self.c1_start - (self.c1_start - self.c1_end) * (evaluations / self.budget)\n            c2 = self.c2_start + (self.c2_end - self.c2_start) * (evaluations / self.budget)\n            \n            for i in range(population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(population_size):\n                self.velocities[i] = (\n                    w * self.velocities[i] + \n                    c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_ADM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07314 with standard deviation 0.05133.", "error": "", "parent_ids": ["2780ad82-a029-412a-b08f-ff7c0bf26c83"], "operator": null, "metadata": {"aucs": [0.02074866570334566, 0.016529873994788558, 0.01902233002407716, 0.061308160286151714, 0.05510518260060315, 0.059865583737771844, 0.1423613986132619, 0.14418880133729717, 0.13910026124668962]}}
{"id": "67f2171d-d99e-4e2f-b106-516ca9036fe1", "fitness": 0.07717094249894349, "name": "HybridPSO_ADM", "description": "Enhanced Hybrid PSO with Dynamic Inertia Weight and Adaptive Mutation Rate improves exploration and exploitation by adapting inertia and mutation based on progress.", "code": "import numpy as np\n\nclass HybridPSO_ADM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # Dynamic inertia starts higher\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.mutation_rate = 0.2  # Start with higher mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Decrease inertia weight dynamically\n            self.w = 0.9 - (0.4 * evaluations / self.budget)\n            \n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n                        \n            # Update mutation rate dynamically\n            self.mutation_rate = 0.2 * (1 - evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_ADM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07717 with standard deviation 0.05224.", "error": "", "parent_ids": ["2780ad82-a029-412a-b08f-ff7c0bf26c83"], "operator": null, "metadata": {"aucs": [0.013467465222831265, 0.015628567389129544, 0.028365047658317377, 0.07299255623710277, 0.06384963139183686, 0.06484121107021779, 0.13685070395965826, 0.14534905750170268, 0.1531942420596949]}}
{"id": "9136ea6d-25ce-41d2-8844-ddb02c511ba7", "fitness": 0.08165065347061638, "name": "HybridPSO_ADM", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Mutation by dynamically adjusting inertia weight for better convergence.", "code": "import numpy as np\n\nclass HybridPSO_ADM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            self.w = 0.9 - 0.8 * (evaluations / self.budget)  # Dynamically update inertia weight\n\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_ADM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08165 with standard deviation 0.05214.", "error": "", "parent_ids": ["2780ad82-a029-412a-b08f-ff7c0bf26c83"], "operator": null, "metadata": {"aucs": [0.033392623852541936, 0.02127516508447047, 0.015158527193177895, 0.0677248921974346, 0.08850226576305686, 0.06348595196070062, 0.15711659092073316, 0.145132522919862, 0.1430673413435699]}}
{"id": "2a623cd4-aa6a-4f26-b765-15b03a37a998", "fitness": -Infinity, "name": "ImprovedHybridPSO_ADM", "description": "Enhanced Hybrid PSO with Adaptive Differential Mutation and Dynamic Niching for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_ADM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_rate = 0.1\n        self.niche_radius = 0.1 * np.linalg.norm(np.array([func.bounds.ub - func.bounds.lb]), axis=1) / np.sqrt(dim)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            self.w = 0.9 - 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Dynamic niching strategy\n            for i in range(self.population_size):\n                for j in range(i + 1, self.population_size):\n                    if np.linalg.norm(self.positions[i] - self.positions[j]) < self.niche_radius:\n                        if self.personal_best_values[i] < self.personal_best_values[j]:\n                            self.personal_best_positions[j] = self.personal_best_positions[i]\n                            self.personal_best_values[j] = self.personal_best_values[i]\n                        else:\n                            self.personal_best_positions[i] = self.personal_best_positions[j]\n                            self.personal_best_values[i] = self.personal_best_values[j]\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 6, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["9136ea6d-25ce-41d2-8844-ddb02c511ba7"], "operator": null, "metadata": {}}
{"id": "da82b06b-127f-44ad-904b-a143f5f938d8", "fitness": 0.08453320465893972, "name": "HybridPSO_ADM_LS", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Mutation and Local Search (HybridPSO_ADM_LS) incorporating a local search strategy to exploit promising regions for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_ADM_LS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update inertia weight\n            self.w = 0.9 - 0.8 * (evaluations / self.budget)\n\n            # Apply differential mutation\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb)\n                local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_search_value = func(local_search_position)\n                evaluations += 1\n                if local_search_value < self.global_best_value:\n                    self.global_best_value = local_search_value\n                    self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_ADM_LS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08453 with standard deviation 0.05388.", "error": "", "parent_ids": ["9136ea6d-25ce-41d2-8844-ddb02c511ba7"], "operator": null, "metadata": {"aucs": [0.02080010789382236, 0.021082008716304945, 0.04759965366303931, 0.07064445961679278, 0.062095822062949724, 0.06832633565462443, 0.15224355665925415, 0.16329951057484748, 0.15470738708882237]}}
{"id": "60d5eb7b-24b8-42a2-800d-d09c654603d6", "fitness": 0.08147441356459531, "name": "APSO_EDM_DLS", "description": "Adaptive Particle Swarm Optimization with Enhanced Differential Mutation and Dynamic Local Search (APSO_EDM_DLS) utilizing a dynamic adaptive strategy for both exploration and exploitation, enhancing convergence performance.", "code": "import numpy as np\n\nclass APSO_EDM_DLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.mutation_rate = 0.15\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive inertia weight based on diversity\n            diversity = np.mean(np.std(self.positions, axis=0))\n            self.w = 0.9 - 0.5 * (diversity / (ub - lb).mean())\n\n            # Apply enhanced differential mutation\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.6 * (donor1 - donor2) + 0.4 * (self.global_best_position - target)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Dynamic local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb)\n                for _ in range(2):  # Perform two local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 8, "feedback": "The algorithm APSO_EDM_DLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08147 with standard deviation 0.04551.", "error": "", "parent_ids": ["da82b06b-127f-44ad-904b-a143f5f938d8"], "operator": null, "metadata": {"aucs": [0.02033028196042508, 0.030099938451106145, 0.0628068250710313, 0.05493099127044976, 0.07336765268996204, 0.0673115942907968, 0.1343198227630361, 0.13916780647771898, 0.15093480910683155]}}
{"id": "8ea30249-0305-40ae-ae87-901abf091560", "fitness": 0.09411165989780425, "name": "HybridPSO_ALR_SLS", "description": "Enhanced Hybrid PSO with Adaptive Learning Rates and Stochastic Local Search to improve convergence robustness by dynamically adjusting learning rates and introducing stochasticity in local exploration.", "code": "import numpy as np\n\nclass HybridPSO_ALR_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # inertia weight\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply differential mutation\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb)\n                for _ in range(3):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSO_ALR_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09411 with standard deviation 0.04245.", "error": "", "parent_ids": ["da82b06b-127f-44ad-904b-a143f5f938d8"], "operator": null, "metadata": {"aucs": [0.10597931730286003, 0.030613635214979285, 0.06912626525571641, 0.05810344023198455, 0.07170104177828629, 0.06731766978186315, 0.14143121025345218, 0.15866439835803958, 0.14406796090305674]}}
{"id": "b54bb262-869f-4afb-be0a-edeefa00951e", "fitness": 0.09353296817144356, "name": "HybridPSO_QuantumALR_ISLS", "description": "Introducing an Adaptive Hybrid PSO with Quantum-Inspired Mutation and Improved Stochastic Local Search for enhanced exploration and exploitation in dynamic landscapes.", "code": "import numpy as np\n\nclass HybridPSO_QuantumALR_ISLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # inertia weight\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply Quantum-Inspired Mutation\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                phi = np.random.uniform(0, 1, self.dim)\n                mutant = phi * target + (1 - phi) * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved Stochastic Local Search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb)\n                for _ in range(5):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSO_QuantumALR_ISLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09353 with standard deviation 0.03710.", "error": "", "parent_ids": ["8ea30249-0305-40ae-ae87-901abf091560"], "operator": null, "metadata": {"aucs": [0.06168910634940905, 0.040238972066950485, 0.07387307484358208, 0.07485296684514664, 0.0889324161014271, 0.07366785838504453, 0.13534442372837108, 0.14690239562243046, 0.1462954996006306]}}
{"id": "2a0a25b5-8b41-4419-bca5-4a60e9f417f4", "fitness": 0.07845920449287688, "name": "HybridPSO_ALR_SLS", "description": "Enhanced Hybrid PSO with Improved Exploration via Adaptive Mutation Rate and Local Search Frequency, optimizing exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_ALR_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # inertia weight\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply differential mutation with adaptive rate\n            self.mutation_rate = 0.1 + 0.4 * (1 - evaluations / self.budget)  # adaptive mutation rate\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best with adjusted frequency\n            if evaluations < self.budget and evaluations % 20 == 0:  # adjust frequency of local search\n                local_radius = 0.1 * (ub - lb)\n                for _ in range(3):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSO_ALR_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07846 with standard deviation 0.05706.", "error": "", "parent_ids": ["8ea30249-0305-40ae-ae87-901abf091560"], "operator": null, "metadata": {"aucs": [0.02332443689073227, 0.018107461613771525, 0.019699352540077375, 0.07021156181515575, 0.05200681677088992, 0.05603090650809073, 0.16155347123693564, 0.15376551231372004, 0.15143332074651872]}}
{"id": "60daeadf-7d92-4fd2-a8f6-0116800c81ca", "fitness": 0.08021614321941595, "name": "AdaptiveMultiSwarmPSO", "description": "Adaptive Multi-Swarm PSO with Dynamic Learning Rates and Focused Local Search to enhance exploration and exploitation by dynamically managing multiple swarms and refining local searches around promising solutions.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = np.clip(3, 1, dim // 2)  # number of swarms\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_velocities = [np.random.rand(self.population_size, dim) * 0.1 for _ in range(self.num_swarms)]\n        self.swarm_positions = [np.random.rand(self.population_size, dim) for _ in range(self.num_swarms)]\n        self.swarm_best_positions = [np.copy(p) for p in self.swarm_positions]\n        self.swarm_best_values = [np.full(self.population_size, np.inf) for _ in range(self.num_swarms)]\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        for positions in self.swarm_positions:\n            positions *= (ub - lb)\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for s in range(self.num_swarms):\n                for i in range(self.population_size):\n                    value = func(self.swarm_positions[s][i])\n                    evaluations += 1\n                    if value < self.swarm_best_values[s][i]:\n                        self.swarm_best_values[s][i] = value\n                        self.swarm_best_positions[s][i] = self.swarm_positions[s][i]\n                    if value < self.global_best_value:\n                        self.global_best_value = value\n                        self.global_best_position = self.swarm_positions[s][i]\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n            for s in range(self.num_swarms):\n                r1, r2 = np.random.rand(2)\n                for i in range(self.population_size):\n                    self.swarm_velocities[s][i] = (\n                        self.inertia_weight * self.swarm_velocities[s][i] +\n                        self.cognitive_coeff * r1 * (self.swarm_best_positions[s][i] - self.swarm_positions[s][i]) +\n                        self.social_coeff * r2 * (self.global_best_position - self.swarm_positions[s][i])\n                    )\n                    self.swarm_positions[s][i] += self.swarm_velocities[s][i]\n                    self.swarm_positions[s][i] = np.clip(self.swarm_positions[s][i], lb, ub)\n\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            self.cognitive_coeff = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)\n            self.social_coeff = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)\n            \n            if np.random.rand() < self.mutation_rate:\n                for s in range(self.num_swarms):\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    target, donor1, donor2 = self.swarm_positions[s][idxs]\n                    mutant = target + 0.8 * (donor1 - donor2)\n                    mutant = np.clip(mutant, lb, ub)\n                    \n                    if evaluations < self.budget:\n                        mutant_value = func(mutant)\n                        evaluations += 1\n                        if mutant_value < self.swarm_best_values[s][idxs[0]]:\n                            self.swarm_best_values[s][idxs[0]] = mutant_value\n                            self.swarm_best_positions[s][idxs[0]] = mutant\n\n            local_radius = 0.1 * (ub - lb)\n            for _ in range(3):\n                local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_search_value = func(local_search_position)\n                evaluations += 1\n                if local_search_value < self.global_best_value:\n                    self.global_best_value = local_search_value\n                    self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08022 with standard deviation 0.04770.", "error": "", "parent_ids": ["8ea30249-0305-40ae-ae87-901abf091560"], "operator": null, "metadata": {"aucs": [0.06735136508492934, 0.016432346777419116, 0.02694923994067633, 0.06370748986250807, 0.05817101527334856, 0.057781115617490664, 0.14353324240824594, 0.14446294825515082, 0.14355652575497468]}}
{"id": "53a3dc10-97ff-4d9c-b16b-4e1880a14df0", "fitness": 0.09321439155760629, "name": "HybridPSO_ALR_SLS", "description": "Enhanced Hybrid PSO with Adaptive Learning Rates and Stochastic Local Search, now incorporating adaptive mutation rate based on search progress for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_ALR_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # inertia weight\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply adaptive differential mutation\n            self.mutation_rate = 0.1 + 0.4 * (evaluations / self.budget)  # adaptive mutation rate\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb)\n                for _ in range(3):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSO_ALR_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09321 with standard deviation 0.03962.", "error": "", "parent_ids": ["8ea30249-0305-40ae-ae87-901abf091560"], "operator": null, "metadata": {"aucs": [0.08606725973930018, 0.03425945067688663, 0.06889938696356979, 0.06730763981076326, 0.07293004860693231, 0.07095666719864757, 0.14807156274966538, 0.14790706567830192, 0.14253044259438952]}}
{"id": "d62ab207-f55f-4145-8abc-e1b9665dec8d", "fitness": 0.09211524694897849, "name": "HybridPSO_ALR_SLS_Enhanced", "description": "Introduce adaptive mutation rate based on diversity to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_ALR_SLS_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # inertia weight\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply differential mutation with adaptive rate\n            diversity = np.mean(np.std(self.positions, axis=0))\n            self.mutation_rate = 0.1 + 0.9 * (1 - diversity / (ub - lb).max())\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb)\n                for _ in range(3):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSO_ALR_SLS_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09212 with standard deviation 0.04099.", "error": "", "parent_ids": ["8ea30249-0305-40ae-ae87-901abf091560"], "operator": null, "metadata": {"aucs": [0.09539322042901333, 0.04069183465875281, 0.06166410170877912, 0.07033271672993369, 0.057276183751814425, 0.06415053895965972, 0.1468959566329191, 0.15611064760738957, 0.1365220220625446]}}
{"id": "292c9d11-f24d-4f1f-b9d0-90535a517991", "fitness": 0.09430520927354563, "name": "HybridPSO_ALR_SLS", "description": "Improved Hybrid PSO with Adaptive Learning Rates and Stochastic Local Search by optimizing inertia weight update for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSO_ALR_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.6 + 0.3 * (1 - evaluations / self.budget)  # improved inertia weight formula\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply differential mutation\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb)\n                for _ in range(3):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 15, "feedback": "The algorithm HybridPSO_ALR_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09431 with standard deviation 0.04241.", "error": "", "parent_ids": ["8ea30249-0305-40ae-ae87-901abf091560"], "operator": null, "metadata": {"aucs": [0.12374959486770709, 0.02977147556391746, 0.05761794506588569, 0.060923150372548585, 0.07243746964700848, 0.07040927947208064, 0.13881833854437375, 0.14880290755336156, 0.14621672237502747]}}
{"id": "ca4f29ad-dd0a-4ffd-9fb5-929b111d8684", "fitness": 0.09529163317058352, "name": "HybridPSO_ALR_SLS", "description": "Enhanced Hybrid PSO with Adaptive Exploration and Adaptive Mutation Rate for improved exploitation and exploration balance. ", "code": "import numpy as np\n\nclass HybridPSO_ALR_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.6 + 0.3 * (1 - evaluations / self.budget)  # improved inertia weight formula\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply differential mutation\n            self.mutation_rate = 0.1 + 0.4 * (evaluations / self.budget)  # Adaptive mutation rate\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb) * (1 - evaluations / self.budget)  # Adaptive exploration range\n                for _ in range(3):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 16, "feedback": "The algorithm HybridPSO_ALR_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09529 with standard deviation 0.03996.", "error": "", "parent_ids": ["292c9d11-f24d-4f1f-b9d0-90535a517991"], "operator": null, "metadata": {"aucs": [0.11943361908946193, 0.033659069088953664, 0.06771227707773897, 0.06292155102181818, 0.06652393574537874, 0.07663825368793353, 0.14375280367390975, 0.1458837097505863, 0.14109947939947065]}}
{"id": "1784e230-1256-4d1d-a6d5-baea9264348c", "fitness": 0.08811135086629222, "name": "EnhancedHybridPSO_ALR_SLS", "description": "Enhanced Hybrid PSO with Adaptive Exploration, Adaptive Mutation Rate, and Local Search with Dynamic Neighborhood Size for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_ALR_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.6 + 0.3 * (1 - evaluations / self.budget)  # improved inertia weight formula\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply differential mutation\n            self.mutation_rate = 0.1 + 0.4 * (evaluations / self.budget)  # Adaptive mutation rate\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best with dynamic neighborhood size\n            dynamic_neigh_size = 3 + int(5 * np.sqrt(1 - evaluations / self.budget))\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb) * (1 - evaluations / self.budget)  # Adaptive exploration range\n                for _ in range(dynamic_neigh_size):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSO_ALR_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08811 with standard deviation 0.04479.", "error": "", "parent_ids": ["ca4f29ad-dd0a-4ffd-9fb5-929b111d8684"], "operator": null, "metadata": {"aucs": [0.024537482133533683, 0.043953888598162516, 0.07775525997594745, 0.07034269134212046, 0.061896903099641576, 0.07135630643058821, 0.14471520012294803, 0.14797524216810376, 0.15046918392558428]}}
{"id": "abc38cc3-30a0-4ced-8855-9d9182c4cf41", "fitness": 0.0953740232120146, "name": "HybridPSO_ALR_SLS", "description": "Improved Hybrid PSO with Adaptive Weighted Mutation Strategy for Enhanced Convergence.", "code": "import numpy as np\n\nclass HybridPSO_ALR_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamically update coefficients based on performance\n            self.w = 0.6 + 0.3 * (1 - evaluations / self.budget)  # improved inertia weight formula\n            self.c1 = 1.5 + (1.5 - 0.5) * (evaluations / self.budget)  # cognitive coefficient\n            self.c2 = 0.5 + (2.0 - 0.5) * (1 - evaluations / self.budget)  # social coefficient\n\n            # Apply differential mutation with adaptive weight\n            self.mutation_rate = 0.1 + 0.4 * (evaluations / self.budget)  # Adaptive mutation rate\n            weight = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive weighting factor\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Stochastic local search around the global best\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb) * (1 - evaluations / self.budget)  # Adaptive exploration range\n                for _ in range(3):  # perform multiple local searches\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSO_ALR_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09537 with standard deviation 0.03970.", "error": "", "parent_ids": ["ca4f29ad-dd0a-4ffd-9fb5-929b111d8684"], "operator": null, "metadata": {"aucs": [0.1194720269423104, 0.033485888748834736, 0.06876147293867896, 0.06374988981118623, 0.06652393574537874, 0.07668190943127495, 0.14270835639135648, 0.14588324949964027, 0.14109947939947065]}}
{"id": "9ea34772-d17c-4826-a6a2-50d5d4063ab5", "fitness": 0.09399988994141696, "name": "EnhancedHybridPSO", "description": "Enhanced Adaptive PSO with Layered Differential Mutation and Contextual Local Search for Improved Convergence Stability and Performance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 - self.c1\n\n            self.mutation_rate = 0.05 + 0.45 * (evaluations / self.budget)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                weight = 0.8 + 0.2 * (1 - evaluations / self.budget)\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - evaluations / self.budget)\n                for _ in range(5):  # increased local search frequency\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.04566.", "error": "", "parent_ids": ["abc38cc3-30a0-4ced-8855-9d9182c4cf41"], "operator": null, "metadata": {"aucs": [0.026183825189403542, 0.04554835823000003, 0.07856953359844077, 0.07416886102022979, 0.076880960529773, 0.08445415128785438, 0.1434634193675871, 0.16421157517852214, 0.15251832507094187]}}
{"id": "9872c82e-45b0-4b1e-a2a6-f8c83604aa53", "fitness": 0.096875786164876, "name": "EnhancedHybridPSO_SALM", "description": "Enhanced Hybrid PSO with Self-Adaptive Learning and Dynamic Mutation Strategy for Superior Convergence and Exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_SALM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4  # initial and final inertia weights\n        self.c1_init, self.c1_final = 2.5, 0.5  # initial and final cognitive coefficients\n        self.c2_init, self.c2_final = 0.5, 2.5  # initial and final social coefficients\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy\n            self.mutation_rate = 0.2 + 0.3 * eval_ratio\n            weight = 0.3 + 0.7 * (1 - eval_ratio)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search with refinement\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSO_SALM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09688 with standard deviation 0.03861.", "error": "", "parent_ids": ["abc38cc3-30a0-4ced-8855-9d9182c4cf41"], "operator": null, "metadata": {"aucs": [0.062025372351693364, 0.04565135877917359, 0.0746469871333334, 0.08826002421685741, 0.0879884059857613, 0.0673148071619909, 0.1464503167447625, 0.14861617106764202, 0.15092863204266949]}}
{"id": "98a75a17-c357-49a1-aa07-5e60578298be", "fitness": 0.09158573100441533, "name": "EnhancedHybridPSO_SALM", "description": "Enhanced Hybrid PSO with Improved Mutation and Exploitation Strategies for Better Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_SALM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4  # initial and final inertia weights\n        self.c1_init, self.c1_final = 2.5, 0.5  # initial and final cognitive coefficients\n        self.c2_init, self.c2_final = 0.5, 2.5  # initial and final social coefficients\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy\n            self.mutation_rate = 0.3 + 0.3 * eval_ratio  # Increased base mutation rate\n            weight = 0.5 + 0.5 * (1 - eval_ratio)  # Increased weight factor\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search with refinement\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSO_SALM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09159 with standard deviation 0.04125.", "error": "", "parent_ids": ["9872c82e-45b0-4b1e-a2a6-f8c83604aa53"], "operator": null, "metadata": {"aucs": [0.053341872851956684, 0.038988657498121415, 0.07549086255335369, 0.06846848402896188, 0.06993080339631963, 0.07455200879859503, 0.15327608449681296, 0.14470178013796875, 0.145521025277648]}}
{"id": "3bdacdbc-d617-487d-8d04-c76268b03c96", "fitness": 0.1048044754326201, "name": "EnhancedHybridPSO_ANTQID", "description": "Enhanced Hybrid PSO with Adaptive Neighborhood Topology and Quadratic Inertia Decay for Accelerated Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_ANTQID:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4  # initial and final inertia weights\n        self.c1_init, self.c1_final = 2.5, 0.5  # initial and final cognitive coefficients\n        self.c2_init, self.c2_final = 0.5, 2.5  # initial and final social coefficients\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        neighborhood_size = max(2, self.population_size // 10)\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Determine neighborhood bests\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy\n            self.mutation_rate = 0.2 + 0.3 * eval_ratio\n            weight = 0.3 + 0.7 * (1 - eval_ratio)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search with refinement\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridPSO_ANTQID got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10480 with standard deviation 0.03034.", "error": "", "parent_ids": ["9872c82e-45b0-4b1e-a2a6-f8c83604aa53"], "operator": null, "metadata": {"aucs": [0.06647091027737306, 0.07105243098764913, 0.12314348477447434, 0.09373070938820138, 0.07422723911902351, 0.09092443243999426, 0.14443708271003175, 0.14644502241859925, 0.13280896677823417]}}
{"id": "4f183ce4-cbaa-4336-8265-979df314ceca", "fitness": 0.07270066553116061, "name": "EnhancedHybridPSO_LAM", "description": "Enhanced PSO with Layered Adaptive Mechanisms, including dynamic subpopulation migrations and elite perturbations for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_LAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_rate = 0.1\n        self.subpop_size = self.population_size // 2\n        self.elite_perturbation_prob = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            subpop_indices = np.random.choice(self.population_size, self.subpop_size, replace=False)\n            subpop_positions = self.positions[subpop_indices]\n            subpop_velocities = self.velocities[subpop_indices]\n\n            for i in range(self.subpop_size):\n                value = func(subpop_positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[subpop_indices[i]]:\n                    self.personal_best_values[subpop_indices[i]] = value\n                    self.personal_best_positions[subpop_indices[i]] = subpop_positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = subpop_positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            for i in range(self.subpop_size):\n                neighborhood_indices = np.random.choice(self.subpop_size, max(2, self.subpop_size // 5), replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[subpop_indices[idx]] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[subpop_indices[idx]]\n                        self.neighborhood_best_positions[subpop_indices[i]] = self.personal_best_positions[subpop_indices[idx]]\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.subpop_size):\n                r1, r2 = np.random.rand(2)\n                subpop_velocities[i] = (\n                    self.w * subpop_velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[subpop_indices[i]] - subpop_positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[subpop_indices[i]] - subpop_positions[i])\n                )\n                subpop_positions[i] += subpop_velocities[i]\n                subpop_positions[i] = np.clip(subpop_positions[i], lb, ub)\n\n            self.positions[subpop_indices] = subpop_positions\n            self.velocities[subpop_indices] = subpop_velocities\n\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                weight = 0.3 + 0.7 * (1 - eval_ratio)\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                if np.random.rand() < self.elite_perturbation_prob:\n                    elite_indices = np.argsort(self.personal_best_values)[:2]\n                    elite_position = self.personal_best_positions[elite_indices[0]]\n                    perturbation = np.random.normal(0, 0.01 * (ub - lb), self.dim)\n                    perturbed_position = elite_position + perturbation\n                    perturbed_position = np.clip(perturbed_position, lb, ub)\n                    perturbed_value = func(perturbed_position)\n                    evaluations += 1\n                    if perturbed_value < self.global_best_value:\n                        self.global_best_value = perturbed_value\n                        self.global_best_position = perturbed_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSO_LAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07270 with standard deviation 0.04815.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.01966007075927856, 0.02781587378339767, 0.022308666337525485, 0.056030414233043, 0.06481565446503113, 0.05074091840197004, 0.14055615466786187, 0.13818138248123701, 0.13419685465110076]}}
{"id": "885849d2-284e-496d-b22d-bc1a22f728a1", "fitness": 0.0945297702239281, "name": "EnhancedHybridPSO_ANTQID", "description": "Enhanced Hybrid PSO with Improved Exploration via Dynamic Mutation and Local Search Refinement.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_ANTQID:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4  # initial and final inertia weights\n        self.c1_init, self.c1_final = 2.5, 0.5  # initial and final cognitive coefficients\n        self.c2_init, self.c2_final = 0.5, 2.5  # initial and final social coefficients\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        neighborhood_size = max(2, self.population_size // 10)\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Determine neighborhood bests\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic mutation strategy\n            self.mutation_rate = 0.15 + 0.25 * eval_ratio  # Line changed\n            weight = 0.4 + 0.6 * (1 - eval_ratio)  # Line changed\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Enhanced local search with refined radius adjustment\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb) * (1 - eval_ratio)  # Line changed\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedHybridPSO_ANTQID got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09453 with standard deviation 0.03772.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.04958364413207805, 0.06882660826974318, 0.1188104691991334, 0.05823323357992771, 0.056182945892626845, 0.0769291568672208, 0.1445019555836401, 0.14118008805902726, 0.13651983043195548]}}
{"id": "2908e930-9dfa-49ba-983e-151618ada0ea", "fitness": 0.09614249608601144, "name": "EnhancedHybridPSO_REFINE", "description": "Refined Enhanced Hybrid PSO with Dynamic Topology Adjustment and Adaptive Mutation Rate for Optimized Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_REFINE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        dynamic_neighborhood_size = lambda evals: max(2, self.population_size // (1 + evals // (self.budget // 5)))\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n                if evaluations >= self.budget:\n                    break\n\n            neighborhood_size = dynamic_neighborhood_size(evaluations)\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            self.mutation_rate = 0.2 + 0.3 * eval_ratio * (1 - eval_ratio)\n            weight = 0.3 + 0.7 * (1 - eval_ratio)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSO_REFINE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09614 with standard deviation 0.03578.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.06489893471120234, 0.074275312676928, 0.0768264957117698, 0.07151727470816394, 0.056041621939232567, 0.08521043846109244, 0.14797071113473304, 0.1398312139665996, 0.14871046146438127]}}
{"id": "4a26313f-1b9c-4b75-bc30-5ced1ba9de5e", "fitness": 0.0856299683055947, "name": "IntensifiedAdaptiveHybridPSO", "description": "Intensified Adaptive Hybrid PSO with Dynamic Neighborhood and Exponential Inertia Decay for Enhanced Global Search.", "code": "import numpy as np\n\nclass IntensifiedAdaptiveHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic neighborhood strategy\n            for i in range(self.population_size):\n                neighborhood_size = max(2, int(self.population_size * (1 - evaluations / self.budget)))\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Exponential decay for inertia weight and linear scaling for coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-5 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * (1 - eval_ratio)\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * eval_ratio\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy with increasing probability\n            self.mutation_rate = 0.1 + 0.4 * (evaluations / self.budget)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                weight = 0.3 + 0.7 * (1 - eval_ratio)\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Intensified local search with dynamic radius\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 26, "feedback": "The algorithm IntensifiedAdaptiveHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08563 with standard deviation 0.04193.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.02500757940942544, 0.04313949070173739, 0.06863164999879878, 0.06271933713823674, 0.07747157582812503, 0.07041622420177507, 0.14022408107989026, 0.14050967710112583, 0.14255009929123774]}}
{"id": "79e54a7c-c371-4691-bbaa-0994b75b5d28", "fitness": 0.09222946810691024, "name": "AdvancedAdaptivePSO_DNEEM", "description": "Advanced Adaptive PSO with Dynamic Neighborhoods and Enhanced Mutation for Superior Convergence.", "code": "import numpy as np\n\nclass AdvancedAdaptivePSO_DNEEM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 60))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic neighborhood bests based on distance\n            for i in range(self.population_size):\n                distances = np.linalg.norm(self.positions - self.positions[i], axis=1)\n                neighborhood_indices = np.argsort(distances)[:max(3, self.population_size // 5)]\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Enhanced mutation strategy with perturbation\n            self.mutation_rate = 0.3 * eval_ratio + 0.2\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                weight = np.random.uniform(0.5, 0.9)\n                mutant = target + weight * (donor1 - donor2)\n                perturbation = np.random.normal(0, 0.01, size=self.dim)\n                mutant += perturbation\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Enhanced local search\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 27, "feedback": "The algorithm AdvancedAdaptivePSO_DNEEM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09223 with standard deviation 0.04089.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.025731452728521176, 0.0434396502444242, 0.07374319020950659, 0.07639159098763715, 0.09904997471490351, 0.08467149080044545, 0.14349357785976324, 0.1391010635480845, 0.14444322186890635]}}
{"id": "76d874c3-c78a-44a7-b916-71ee6449c1ec", "fitness": 0.09650528738735371, "name": "ImprovedHybridPSO_AMDN", "description": "Improved Enhanced Hybrid PSO with Adaptive Mutation Rate and Dynamic Neighborhood Topology for Exploitation-Exploration Balance.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_AMDN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.8, 0.3\n        self.c1_init, self.c1_final = 2.0, 0.3\n        self.c2_init, self.c2_final = 0.3, 2.0\n        self.mutation_rate_base = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic neighborhood size based on evaluations\n            neighborhood_size = max(2, self.population_size // (1 + int(np.log1p(evaluations))))\n            \n            # Determine neighborhood bests\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy\n            self.mutation_rate = self.mutation_rate_base * (1 + eval_ratio)\n            weight = 0.2 + 0.5 * (1 - eval_ratio)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search with exploration refinement\n            if evaluations < self.budget:\n                local_radius = 0.1 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 28, "feedback": "The algorithm ImprovedHybridPSO_AMDN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09651 with standard deviation 0.03637.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.05366192647051249, 0.06364459044723636, 0.08888816296412028, 0.08420278121249936, 0.06567800401727897, 0.07458665791163854, 0.14653452964778724, 0.14809695931214295, 0.14325397450296729]}}
{"id": "49b2f772-b6c5-460a-a52e-ac4130d2a004", "fitness": 0.10377420475094583, "name": "QuantumAdaptivePSO_GAR", "description": "Quantum-Inspired Adaptive PSO with Gradient-Assisted Refinement for Enhanced Exploitation and Exploration Balance.", "code": "import numpy as np\n\nclass QuantumAdaptivePSO_GAR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        neighborhood_size = max(2, self.population_size // 10)\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            self.mutation_rate = 0.2 + 0.3 * eval_ratio\n            weight = 0.3 + 0.7 * (1 - eval_ratio)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                quantum_mutation = target + np.random.normal(0, 0.1, self.dim)\n                mutant = quantum_mutation + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 29, "feedback": "The algorithm QuantumAdaptivePSO_GAR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10377 with standard deviation 0.03292.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.06369455600079832, 0.07498954312365547, 0.12801887503508735, 0.09546285062642812, 0.07547724975036774, 0.06808790865572811, 0.138748170900601, 0.14635031892036854, 0.14313836974547778]}}
{"id": "37c72673-c4cf-4a09-b077-14a595e115fa", "fitness": 0.07864178752513445, "name": "AdaptiveQuantumPSO_DAS", "description": "Adaptive Quantum-Inspired PSO with Dynamic Attraction-Switching for Enhanced Exploration and Exploitation Balancing.", "code": "import numpy as np\n\nclass AdaptiveQuantumPSO_DAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4  # initial and final inertia weights\n        self.c1_init, self.c1_final = 2.5, 0.5  # initial and final cognitive coefficients\n        self.c2_init, self.c2_final = 0.5, 2.5  # initial and final social coefficients\n        self.mutation_rate = 0.1\n        self.attraction_switch = 0.5  # dynamic attraction-switching parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n\n        evaluations = 0\n        neighborhood_size = max(2, self.population_size // 10)\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Determine neighborhood bests\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions with dynamic attraction switching\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                local_best_position = self.personal_best_positions[i] if np.random.rand() < self.attraction_switch else self.neighborhood_best_positions[i]\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (local_best_position - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy\n            self.mutation_rate = 0.2 + 0.3 * eval_ratio\n            weight = 0.3 + 0.7 * (1 - eval_ratio)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Quantum-inspired exploration with dynamic radius\n            quantum_radius = 0.1 * (ub - lb) * (1 - eval_ratio)\n            for _ in range(3):\n                quantum_position = np.clip(\n                    self.global_best_position + quantum_radius * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)),\n                    lb, ub\n                )\n                quantum_value = func(quantum_position)\n                evaluations += 1\n                if quantum_value < self.global_best_value:\n                    self.global_best_value = quantum_value\n                    self.global_best_position = quantum_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveQuantumPSO_DAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07864 with standard deviation 0.04604.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.04975248367530272, 0.024031225530929068, 0.038525671696085784, 0.05765891702830528, 0.05004207367995639, 0.0614469741731023, 0.14394658431398377, 0.14328787379675068, 0.13908428383179416]}}
{"id": "cbbe3295-f27e-44cc-a915-a1888cafd5b4", "fitness": 0.1048044754326201, "name": "EnhancedHybridPSO_ANTQID", "description": "Enhanced Hybrid PSO with Adaptive Neighborhood Topology and Quadratic Inertia Decay for Accelerated Convergence and Optimized Neighborhood Size.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_ANTQID:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4  # initial and final inertia weights\n        self.c1_init, self.c1_final = 2.5, 0.5  # initial and final cognitive coefficients\n        self.c2_init, self.c2_final = 0.5, 2.5  # initial and final social coefficients\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        neighborhood_size = max(2, int(0.1 * self.population_size))  # Change made here\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Determine neighborhood bests\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy\n            self.mutation_rate = 0.2 + 0.3 * eval_ratio\n            weight = 0.3 + 0.7 * (1 - eval_ratio)\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search with refinement\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridPSO_ANTQID got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10480 with standard deviation 0.03034.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.06647091027737306, 0.07105243098764913, 0.12314348477447434, 0.09373070938820138, 0.07422723911902351, 0.09092443243999426, 0.14443708271003175, 0.14644502241859925, 0.13280896677823417]}}
{"id": "57f2914b-7d48-4976-b2a9-c7a444a261af", "fitness": 0.10127221180472154, "name": "DynamicQuantumPSO_DE", "description": "Dynamic Quantum-inspired Adaptive PSO with Differential Evolution Refinement for Optimal Convergence and Exploration Balance.", "code": "import numpy as np\n\nclass DynamicQuantumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_best_positions = np.copy(self.positions)\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        \n        evaluations = 0\n        neighborhood_size = max(2, self.population_size // 10)\n        \n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Quantum-behavior inspired by neighborhood best\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_value = np.inf\n                for idx in neighborhood_indices:\n                    if self.personal_best_values[idx] < neighborhood_best_value:\n                        neighborhood_best_value = self.personal_best_values[idx]\n                        self.neighborhood_best_positions[i] = self.personal_best_positions[idx]\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] +\n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                    self.c2 * r2 * (self.neighborhood_best_positions[i] - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy with DE refinement\n            self.mutation_rate = 0.2 + 0.3 * eval_ratio\n            weight = 0.5 + 0.3 * (1 - eval_ratio)\n            for _ in range(3):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + weight * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Quantum-inspired local search refinement\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    theta = np.random.uniform(0, 2 * np.pi, self.dim)\n                    local_search_position = self.global_best_position + local_radius * np.cos(theta)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 32, "feedback": "The algorithm DynamicQuantumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10127 with standard deviation 0.03323.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.10659165866272335, 0.06542428045848037, 0.09791394275520393, 0.0971180179488852, 0.07106917672572932, 0.049093042709862256, 0.13334824407590995, 0.1493174066197488, 0.14157413628595072]}}
{"id": "1d071776-abce-4be7-9a28-3a55e1ecef9d", "fitness": 0.1092499017647554, "name": "AdaptiveMultiSwarmPSO", "description": "Adaptive Multi-Swarm PSO with Dynamic Neighborhood and Differential Mutation for Enhanced Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10925 with standard deviation 0.03234.", "error": "", "parent_ids": ["3bdacdbc-d617-487d-8d04-c76268b03c96"], "operator": null, "metadata": {"aucs": [0.10847112219005028, 0.11057104903132275, 0.13138898421599643, 0.08066838063419024, 0.056136751161142695, 0.06787187540124928, 0.15402930173601226, 0.1338787367125408, 0.14023291480029376]}}
{"id": "d25d7582-52f6-4502-94c4-a851a7dd273b", "fitness": 0.10806578059196334, "name": "AdaptiveMultiSwarmPSO", "description": "Enhanced Adaptive Multi-Swarm PSO with Adaptive Mutation Rate for Improved Convergence and Robustness.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_rate_init, self.mutation_rate_final = 0.3, 0.1  # Initialize adaptive mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n            self.mutation_rate = self.mutation_rate_final + (self.mutation_rate_init - self.mutation_rate_final) * eval_ratio  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < self.mutation_rate:  # Adjusted mutation condition\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10807 with standard deviation 0.03482.", "error": "", "parent_ids": ["1d071776-abce-4be7-9a28-3a55e1ecef9d"], "operator": null, "metadata": {"aucs": [0.10587625277419799, 0.11287103435080581, 0.13281264674106652, 0.06784369290122061, 0.06759730106951767, 0.05347705408989578, 0.15402930173601226, 0.13769886975527434, 0.1403858719096791]}}
{"id": "9820635b-7606-466c-9c51-c235f6af5dce", "fitness": 0.07250783367569416, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhanced Adaptive Multi-Swarm PSO with Variable Swarm Dynamics and Elite Selection for Balanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = np.random.randint(2, 5)  # Variable swarm count for diversity\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**3)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.25:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.6 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Elite selection for global best improvement\n            if evaluations < self.budget:\n                elite_count = 5\n                elite_indices = np.argsort(self.personal_best_values)[:elite_count]\n                elite_positions = self.personal_best_positions[elite_indices]\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for elite_pos in elite_positions:\n                    local_search_position = elite_pos + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07251 with standard deviation 0.05081.", "error": "", "parent_ids": ["1d071776-abce-4be7-9a28-3a55e1ecef9d"], "operator": null, "metadata": {"aucs": [0.016368743681815734, 0.015078131880682855, 0.013619402020045634, 0.06567284633441095, 0.058403177918407434, 0.0681458192717539, 0.13498502191102613, 0.1397274682837546, 0.1405698917793502]}}
{"id": "41c6e61a-50ee-48c2-b39e-2a8e50842cfa", "fitness": 0.06932528031263585, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhanced Adaptive Multi-Swarm PSO with Hierarchical Clustering for Targeted Exploitation and Adaptive Differential Mutation for Improved Global Convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with adaptive differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                F = 0.5 + 0.5 * np.random.rand() * eval_ratio  # Adaptive mutation factor\n                mutant = target + F * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Hierarchical clustering-based local exploitation\n            if evaluations < self.budget:\n                cluster_labels = KMeans(n_clusters=self.swarm_count).fit_predict(self.positions)\n                for cluster_id in range(self.swarm_count):\n                    cluster_members = self.positions[cluster_labels == cluster_id]\n                    cluster_best_idx = np.argmin([func(pos) for pos in cluster_members])\n                    cluster_best_pos = cluster_members[cluster_best_idx]\n                    \n                    local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                    local_search_position = cluster_best_pos + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06933 with standard deviation 0.05199.", "error": "", "parent_ids": ["1d071776-abce-4be7-9a28-3a55e1ecef9d"], "operator": null, "metadata": {"aucs": [0.011909219248454561, 0.014958558239426267, 0.012459880519565147, 0.05910164237362281, 0.052071362494745754, 0.06078936606228924, 0.1540105327256952, 0.1300579479848626, 0.12856901316506109]}}
{"id": "332ab7d8-53bd-47ad-8125-1ffac67a7501", "fitness": -Infinity, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhanced Multi-Swarm PSO with Adaptive Velocity Clamping and Gradient-Based Local Enhancement for Improved Performance on BBOB Functions.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.max_velocity = 0.2 * (func.bounds.ub - func.bounds.lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions with clamping\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = np.clip(\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i]),\n                    -self.max_velocity, self.max_velocity\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Gradient-based local enhancement\n            if evaluations < self.budget:\n                grad_step_size = 0.01 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    gradient_estimate = np.random.normal(size=self.dim)\n                    local_search_position = self.global_best_position - grad_step_size * gradient_estimate\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 37, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["1d071776-abce-4be7-9a28-3a55e1ecef9d"], "operator": null, "metadata": {}}
{"id": "52d0e352-2ec7-46e1-88a9-9111fc2e3cee", "fitness": 0.11381202437081722, "name": "AdaptiveMultiSwarmPSO", "description": "Introducing an exponential decay factor to the inertia weight for faster convergence in Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)  # Changed line\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11381 with standard deviation 0.02877.", "error": "", "parent_ids": ["1d071776-abce-4be7-9a28-3a55e1ecef9d"], "operator": null, "metadata": {"aucs": [0.1045923643514628, 0.11342121279406259, 0.13139203482769368, 0.07463853487641736, 0.06938202027102658, 0.0935402239065325, 0.15131040256235706, 0.14658944729087808, 0.1394419784569242]}}
{"id": "fe38e20d-b64d-4a9a-a682-cacbacf29ee8", "fitness": 0.0706978172322816, "name": "RefinedAdaptiveMultiSwarmPSO", "description": "Introduce a self-adaptive learning strategy for control parameters and enhance local search with Lvy flight for diversification in Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass RefinedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def levy_flight(self, size, alpha=1.5):\n        u = np.random.normal(0, 1, size) * (1.0 / np.power(np.random.normal(0, 1, size), 1 / alpha))\n        return u\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation and enhanced local search\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search with Lvy flight around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    levy_step = self.levy_flight(self.dim) * local_radius\n                    local_search_position = self.global_best_position + levy_step\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 39, "feedback": "The algorithm RefinedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07070 with standard deviation 0.05614.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.013765821441615644, 0.01513434180842077, 0.011347521083897472, 0.05613589417749465, 0.054827547591163706, 0.0456551312849538, 0.15620182181662556, 0.1361085303681, 0.14710374551826289]}}
{"id": "ab728b2a-d72c-496a-9791-c43df5317440", "fitness": 0.11091416624939682, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introducing a diversity mechanism with self-adaptive learning rates for enhanced exploration in Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Introduce diversity mechanism\n            if evaluations < self.budget:\n                diversity = np.std(self.positions, axis=0).mean()\n                if diversity < self.diversity_threshold:\n                    for i in range(self.population_size):\n                        if np.random.rand() < 0.1:\n                            perturbation = np.random.randn(self.dim) * 0.1 * (ub - lb)\n                            self.positions[i] = np.clip(self.positions[i] + perturbation, lb, ub)\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11091 with standard deviation 0.03379.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.10927633315684293, 0.10517096118447877, 0.11846145928631646, 0.07660219953029002, 0.0673847036879226, 0.06564888689572668, 0.15130349571606794, 0.14861895565716, 0.15576050112976592]}}
{"id": "0bbf2f1b-ed7e-41c6-ad43-07490b6d46a8", "fitness": 0.11092770519960794, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introducing a two-phase search strategy combining adaptive inertia weight adjustment with a late-stage genetic search for enhanced convergence in Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.genetic_phase_threshold = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Genetic search phase\n            if eval_ratio > self.genetic_phase_threshold:\n                for j in range(int(self.population_size / 2)):\n                    parent1, parent2 = self.positions[np.random.choice(self.population_size, 2, replace=False)]\n                    crossover_point = np.random.randint(1, self.dim)\n                    child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                    if np.random.rand() < 0.1:\n                        mutation_vector = np.random.normal(0, 0.1, self.dim)\n                        child += mutation_vector\n                    child = np.clip(child, lb, ub)\n                    if evaluations < self.budget:\n                        child_value = func(child)\n                        evaluations += 1\n                        if child_value < self.global_best_value:\n                            self.global_best_value = child_value\n                            self.global_best_position = child\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11093 with standard deviation 0.03354.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.10868548190458827, 0.10469689292048001, 0.11783807329714369, 0.07659036164237942, 0.06920669763315956, 0.06564888689572668, 0.15130349571606794, 0.14861895565716, 0.15576050112976592]}}
{"id": "f605eeb2-1fff-427a-936e-fadcf1072ea9", "fitness": 0.10655064459248692, "name": "AdaptiveMultiSwarmPSO", "description": "Enhanced Adaptive Multi-Swarm PSO by dynamically adjusting the global best position update rate based on the evaluation ratio for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = (1 - eval_ratio) * local_search_position + eval_ratio * self.global_best_position  # Changed line\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10655 with standard deviation 0.03502.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.07648532369113592, 0.09970347738911722, 0.12586293625025935, 0.06914742712722377, 0.06801084908822264, 0.07196992063137675, 0.15131040256235706, 0.15702348613576544, 0.1394419784569242]}}
{"id": "899499c8-cc34-41b7-afae-4288353d080e", "fitness": 0.10567753375157092, "name": "AdaptiveMultiSwarmPSO", "description": "Implementing a self-adaptive neighborhood strategy and time-varying differential mutation rate in Adaptive Multi-Swarm PSO for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighborhood_size = max(1, int(self.swarm_size * (1 - eval_ratio)))\n                neighbor_idx = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with time-varying differential mutation\n            if np.random.rand() < (0.3 + 0.2 * eval_ratio):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor = 0.8 * (1 - eval_ratio)\n                mutant = target + mutation_factor * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10568 with standard deviation 0.02893.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.11526734280542594, 0.11462775467901831, 0.08159814674764021, 0.07344474072580298, 0.07628765507101565, 0.07136898743995312, 0.1527297837077748, 0.13428570398987028, 0.13148768859763704]}}
{"id": "7b797265-407a-4a94-95df-ef44f9a3c4d3", "fitness": 0.11124038960872171, "name": "AdaptiveMultiSwarmPSO", "description": "Introducing a non-linear decay factor to the inertia weight for balanced exploration and exploitation in Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-4 * eval_ratio)  # Changed line\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 44, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11124 with standard deviation 0.03242.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.10454066924781502, 0.10420240895241106, 0.1313950428788948, 0.0892626886598501, 0.06831438672846712, 0.0602362736258657, 0.14872935604500348, 0.14311944283169753, 0.15136323750849057]}}
{"id": "1caf3f95-bb1f-4737-9100-d32d33623b40", "fitness": 0.11145978175565165, "name": "AdaptiveMultiSwarmPSO", "description": "Introducing diverse mutation strategies and adaptive velocity clamping to enhance exploration and convergence in Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.vel_clamp_ratio_init, self.vel_clamp_ratio_final = 0.5, 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n            vel_clamp = self.vel_clamp_ratio_final + (self.vel_clamp_ratio_init - self.vel_clamp_ratio_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.velocities[i] = np.clip(self.velocities[i], -vel_clamp * (ub - lb), vel_clamp * (ub - lb))\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                if np.random.rand() < 0.5:\n                    mutant = target + 0.8 * (donor1 - donor2)\n                else:\n                    mutant = donor1 + 0.8 * (donor2 - donor1)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 45, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11146 with standard deviation 0.03182.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.11108979874302427, 0.10230745992884349, 0.12445548922798277, 0.07090109644498588, 0.08512238158861019, 0.06306803981848819, 0.15131040256235706, 0.1460294243965502, 0.14885394309002287]}}
{"id": "7d988a2c-28a4-46e7-92de-2ece0b63ea0d", "fitness": 0.07338122713945525, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhance Adaptive Multi-Swarm PSO by introducing adaptive learning rates and fitness diversity mechanism for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        # Dynamic learning rate based on global best improvement\n        improvement_threshold = 1e-5\n        last_global_best_value = self.global_best_value\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients with fitness diversity\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Fitness diversity mechanism\n            fitness_variance = np.var(self.personal_best_values)\n            diversity_factor = np.tanh(1.0 / (1.0 + fitness_variance))\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3 * diversity_factor:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if self.global_best_value < last_global_best_value - improvement_threshold:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n                last_global_best_value = self.global_best_value\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07338 with standard deviation 0.05642.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.011730269450607955, 0.016846995666244702, 0.01403924074858387, 0.06167254755781815, 0.05346434050748028, 0.05788109901900729, 0.1666869657791089, 0.13524574205657391, 0.14286384346967218]}}
{"id": "761e0f67-18a9-429c-aa7e-99035434906b", "fitness": 0.11093311053599075, "name": "ImprovedAdaptiveMultiSwarmPSO", "description": "Introducing adaptive learning rates based on swarm performance to enhance convergence in Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass ImprovedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Swarm performance-based adaptive learning rates\n            swarm_best_values = [np.min(self.personal_best_values[i:i + self.swarm_size]) for i in range(0, self.population_size, self.swarm_size)]\n            best_swarm_idx = np.argmin(swarm_best_values)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * (1 - swarm_best_values[best_swarm_idx] / self.global_best_value)\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (swarm_best_values[best_swarm_idx] / self.global_best_value)\n            \n            # Self-adaptive inertia weight\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 47, "feedback": "The algorithm ImprovedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11093 with standard deviation 0.03414.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.10481317388002265, 0.09233646378578686, 0.13319228665929062, 0.07831563829764032, 0.07141642357552602, 0.07015284957151402, 0.1734576615617086, 0.14018919810808328, 0.1345242993843444]}}
{"id": "3d0ebb7a-2c0b-4f25-bc08-8e9e4b9d2dd2", "fitness": 0.10317771347620981, "name": "AdaptiveMultiSwarmPSO", "description": "Introducing turbulent neighborhood exploration and adaptive learning factors in Adaptive Multi-Swarm PSO for enhanced diversity and convergence.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Self-adaptive inertia weight and coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.rand(3)  # Added r3 for turbulence\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i]) +\n                    0.2 * r3 * (self.global_best_position - self.positions[i])  # Added turbulence term\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Dynamic neighborhood with differential mutation\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + 0.8 * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            # Improved local search around global best\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.03623.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.1106533125962127, 0.10505367002533395, 0.07297462596323878, 0.05543640380411008, 0.06710687067427146, 0.07116041958553043, 0.14606465335073127, 0.15085318445903373, 0.14929628082742596]}}
{"id": "2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b", "fitness": 0.11382208748590308, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Incorporating adaptive differential mutation strategy and enhanced velocity update mechanism for increased diversity and convergence in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11382 with standard deviation 0.02878.", "error": "", "parent_ids": ["52d0e352-2ec7-46e1-88a9-9111fc2e3cee"], "operator": null, "metadata": {"aucs": [0.1045923643514628, 0.11342121279406259, 0.13139203482769368, 0.07463853487641736, 0.06938202027102658, 0.0935402239065325, 0.15131040256235706, 0.14668001532665087, 0.1394419784569242]}}
{"id": "56371045-817b-4d01-940b-14568bc0ff1d", "fitness": 0.10685979555175856, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce dynamic population resizing and adaptive inertial weight in the EnhancedAdaptiveMultiSwarmPSO for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)  # More aggressive decay\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] +\n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.4:  # Increased mutation chance\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.2 * np.cos(np.pi * eval_ratio)  # Different mutation adaptation\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.07 * (ub - lb) * (1 - eval_ratio)  # Slightly larger local search radius\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n            # Dynamic population resizing based on progress\n            if evaluations < self.budget and eval_ratio > 0.5:\n                self.population_size = max(10, int(self.population_size * (1 - 0.1 * eval_ratio)))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10686 with standard deviation 0.03349.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.11561215250390733, 0.10715467408329071, 0.10668450334588642, 0.0692599951452243, 0.057980673292829854, 0.06749230741666545, 0.1499187864711643, 0.13753504885092016, 0.1501000188559385]}}
{"id": "b4129b9f-2066-4959-be75-d3c05305e659", "fitness": 0.10073020367878317, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introducing a dynamic swarm size adjustment strategy and enhanced perturbation mechanism to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n            self.swarm_size = int(np.clip(self.population_size * (1 - eval_ratio), 10, self.population_size))  # Dynamic swarm size\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10073 with standard deviation 0.03860.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10103943139680405, 0.11215547677287585, 0.05135107794598326, 0.06816669975190615, 0.047988450504583335, 0.08232820499412319, 0.1465734945396603, 0.1491239617778255, 0.14784503542528693]}}
{"id": "587d121c-b0ba-4bcf-9eb6-376a86a77f68", "fitness": 0.08464714808739453, "name": "EnhancedMultiSwarmPSOWithLevy", "description": "Introduce a local exploration phase with Lvy flight and adaptive swarm coherence to enhance search space exploration and convergence in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedMultiSwarmPSOWithLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim) * (1.0 / L) ** 0.5\n        v = np.random.normal(0, 1, self.dim)\n        return u / np.abs(v) ** (1.0 / L)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    levy_step = self.levy_flight(1.5) * (1 - eval_ratio)\n                    local_search_position = self.global_best_position + levy_step\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedMultiSwarmPSOWithLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08465 with standard deviation 0.04404.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.06417413444645381, 0.054493722331627414, 0.04407277744894389, 0.056351610315348966, 0.05471233161647682, 0.04953605889725088, 0.15572252361286343, 0.13595003980296683, 0.14681113431461867]}}
{"id": "8bf2fedf-937e-45ac-89df-eb2595d813bb", "fitness": 0.10137498572022197, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce dynamic neighborhood size improvement for enhanced convergence in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                dynamic_swarm_size = self.swarm_size + int(np.ceil(eval_ratio * 5))\n                neighbor_idx = i // dynamic_swarm_size * dynamic_swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + dynamic_swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10137 with standard deviation 0.03201.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10713131525272357, 0.0773453732786803, 0.0782450747302178, 0.07715754491031579, 0.09038818138756866, 0.05446368513873201, 0.14929676622579757, 0.14169491930466638, 0.13665201125329562]}}
{"id": "aa021001-fbbc-46be-96a4-1411fa519932", "fitness": 0.10465158625360828, "name": "EnhancedAdaptiveMultiSwarmPSOv2", "description": "Introduce dynamic swarm topology adaptation and adaptive exploration-exploitation balancing to enhance diversity and convergence in a Multi-Swarm PSO framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSOv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n        self.dynamic_swarm_topology = True\n        self.adaptive_explore_exploit = True\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate fitness and update personal and global bests\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n                if evaluations >= self.budget:\n                    break\n\n            # Update inertia weight and acceleration coefficients\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            # Dynamic swarm topology adjustment\n            if self.dynamic_swarm_topology:\n                swarm_size = max(1, int(self.population_size * (0.5 + 0.5 * np.cos(np.pi * eval_ratio))))\n                for i in range(self.population_size):\n                    r1, r2 = np.random.rand(2)\n                    neighbors = np.random.choice(self.population_size, swarm_size, replace=False)\n                    neighborhood_best_pos = self.personal_best_positions[neighbors].min(axis=0)\n                    self.velocities[i] = (\n                        self.w * self.velocities[i] + \n                        self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                        self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                    )\n                    self.positions[i] += self.velocities[i]\n                    self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Adaptive mutation strategy\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                if self.adaptive_explore_exploit:\n                    mutation_factor_adaptive = 0.5 + 0.4 * np.sin(np.pi * eval_ratio)\n                else:\n                    mutation_factor_adaptive = self.mutation_factor\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSOv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10465 with standard deviation 0.02995.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.09154678502037927, 0.10632009191368608, 0.10857387373089533, 0.05996129505039749, 0.09229587751839163, 0.061682232428367345, 0.14488478246040837, 0.13919529944922782, 0.13740403871072115]}}
{"id": "33379f5d-2be4-4664-8021-53caa1531543", "fitness": 0.10503812330346653, "name": "DynamicSubgroupingAdaptivePSO", "description": "Introduce dynamic subgrouping and adaptive learning rates to enhance convergence and exploration in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass DynamicSubgroupingAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * (1 - eval_ratio)\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * eval_ratio\n\n            # Dynamic subgrouping\n            dynamic_swarm_assignments = np.random.permutation(self.population_size)\n            for i in range(self.population_size):\n                swarm_id = dynamic_swarm_assignments[i] // self.swarm_size\n                r1, r2 = np.random.rand(2)\n                subgroup_start = swarm_id * self.swarm_size\n                subgroup_positions = self.personal_best_positions[subgroup_start:subgroup_start + self.swarm_size]\n                subgroup_best_pos = subgroup_positions[np.argmin(self.personal_best_values[subgroup_start:subgroup_start + self.swarm_size])]\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (subgroup_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 55, "feedback": "The algorithm DynamicSubgroupingAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10504 with standard deviation 0.03709.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.08374616923018852, 0.1589949061204461, 0.07138393348269845, 0.07475590910743724, 0.06250147545614948, 0.07013256942175217, 0.1416313023731437, 0.14015500815830806, 0.14204183638107504]}}
{"id": "104a50cf-c6dc-4613-9c6a-30f5ad6dd1fc", "fitness": 0.1120359593339005, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "EnhancedAdaptiveMultiSwarmPSO with adaptive inertia weight based on cosine function for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 + np.cos(np.pi * eval_ratio)) / 2  # Adjusted line\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11204 with standard deviation 0.03141.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10835069238041872, 0.1126011809834172, 0.13138899552802996, 0.07798872753018449, 0.06537857402402036, 0.07318762435956538, 0.1540243014605962, 0.14263043679705323, 0.14277310094181894]}}
{"id": "bcf131e8-a0c2-4a98-8384-0e975e35e8ed", "fitness": 0.09980789313078743, "name": "DynamicNeighborhoodMultiSwarmPSO", "description": "Introduce dynamic swarm size adjustment and adaptive neighborhood-based learning to enhance convergence and exploration in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass DynamicNeighborhoodMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Adjust swarm size dynamically based on evaluation progress\n            if evaluations > 0 and evaluations % (self.budget // 10) == 0:\n                self.swarm_size = max(2, self.swarm_size - 1)\n\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighborhood_indices = np.random.choice(self.population_size, self.swarm_size, replace=False)\n                neighborhood_best_pos = self.personal_best_positions[neighborhood_indices].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 57, "feedback": "The algorithm DynamicNeighborhoodMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09981 with standard deviation 0.03639.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.11357026109989654, 0.11062698713953534, 0.04169862747315489, 0.06178419764942766, 0.0902750069351621, 0.058665607833392475, 0.14201558133786163, 0.14309918462826277, 0.13653558408039346]}}
{"id": "b673b8d8-e0a2-442d-97a7-e8e97ca57b9e", "fitness": 0.1113211021460817, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduced dynamic neighborhood size adjustment and enhanced mutation strategy for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio) + 0.1 * np.cos(2 * np.pi * eval_ratio)  # Change 1\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio) * (1 + 0.2 * np.sin(np.pi * eval_ratio))  # Change 2\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11132 with standard deviation 0.02977.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.1028720863674647, 0.11377741127512919, 0.13005460103625055, 0.07262677919977722, 0.06761634370098835, 0.0825291962291933, 0.1513114547575345, 0.14170883159346837, 0.1393932151549292]}}
{"id": "da1dba2a-3ab9-4037-906c-28130c615cae", "fitness": 0.10677541770527951, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Integrating chaotic map for enhanced exploration and convergence control in Enhanced Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n        self.chaotic_sequence = self._generate_chaotic_sequence(self.budget)\n\n    def _generate_chaotic_sequence(self, length):\n        x = 0.7  # Initial value for logistic map\n        seq = []\n        for _ in range(length):\n            x = 4 * x * (1 - x)\n            seq.append(x)\n        return np.array(seq)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] +\n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i] * self.chaotic_sequence[evaluations % self.budget]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10678 with standard deviation 0.03778.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.09601317861296466, 0.10585250334678542, 0.12708587451529263, 0.06512983678159201, 0.054380058314553725, 0.062150919072263, 0.15039392991998757, 0.1396879168216142, 0.16028454196246245]}}
{"id": "31893bad-50a6-4cf5-8821-ecfc9123d70a", "fitness": 0.1106367698747209, "name": "EnhancedDynamicSwarmPSO", "description": "Introducing dynamic swarm reshaping and adaptive crossover to further enhance convergence and exploration in the metaheuristic strategy.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    if np.random.rand() < self.crossover_prob:\n                        mask = np.random.rand(self.dim) < 0.5\n                        mutant[mask] = target[mask]\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedDynamicSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11064 with standard deviation 0.03404.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10427961239453065, 0.0914175411360304, 0.14060536997873074, 0.06992973734653496, 0.06791610569068507, 0.07599092530937224, 0.15131040256235706, 0.13952229343065548, 0.15475894102359156]}}
{"id": "b9fc3b13-71f2-49e1-a060-ab5d14d0a5cf", "fitness": 0.079765509268305, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduced stochastic weight adjustment and dynamic neighborhood selection to accelerate convergence and enhance exploration in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-0.5 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighborhood_size = np.random.randint(1, self.swarm_size)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_slice = slice(neighbor_idx, neighbor_idx + neighborhood_size)\n                neighborhood_best_pos = self.personal_best_positions[neighborhood_slice].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07977 with standard deviation 0.04423.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.05153427223792617, 0.04516150992682533, 0.016309558427569426, 0.05068679877664328, 0.060129929611195454, 0.07883770554768132, 0.14321424856354115, 0.13543566412026598, 0.13657989620309696]}}
{"id": "d09e9079-4755-407a-876a-f53c1f277313", "fitness": 0.10457400570345571, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introducing a dynamic neighborhood topology and adaptive inertial weight to enhance exploration-exploitation balance in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_indices = np.random.choice(self.population_size, self.swarm_size, replace=False)\n                neighborhood_best_pos = self.personal_best_positions[neighbor_indices].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10457 with standard deviation 0.03176.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.11587885641364915, 0.11221646780714756, 0.07822472647446255, 0.06967207869728997, 0.07393887063371085, 0.06389071628071519, 0.1399045093655178, 0.1376336771672909, 0.14980614849131735]}}
{"id": "acffa3cc-0d8f-4cb5-a0df-fe8007176115", "fitness": 0.10405455288183735, "name": "EnhancedAdaptiveMultiSwarmPSO2", "description": "EnhancedAdaptiveMultiSwarmPSO2 employs a dynamic hierarchical topology and multi-velocity update mechanism to boost exploration and exploitation balance in multi-swarm optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.rand(3)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i]) +\n                    r3 * (self.global_best_position - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10405 with standard deviation 0.03264.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10517367835282165, 0.11451103742381985, 0.1175146059840867, 0.06618864939321678, 0.06316410173687781, 0.05368892404351411, 0.1345248804071828, 0.1436700738526704, 0.138055024742346]}}
{"id": "d6a42766-eb39-4917-9d2c-676175b83e2f", "fitness": 0.09610500249599366, "name": "RefinedAdaptiveMultiSwarmPSO", "description": "Introducing a novel dynamic hyper-parameter adjustment and cooperative mutation approach to enhance the adaptability and convergence of EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass RefinedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio**2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * (1 - eval_ratio**2)\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * eval_ratio**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 64, "feedback": "The algorithm RefinedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09611 with standard deviation 0.03284.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.08162560099175298, 0.09622312470852823, 0.07543127459974008, 0.06546758600395686, 0.06958620554198669, 0.05637958532122256, 0.14016827736043314, 0.13506236271610872, 0.14500100522021364]}}
{"id": "1fffe45f-1bf8-4beb-81dc-293550c762fc", "fitness": 0.11004388636887445, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhanced Dynamic Neighborhood Adjustment and Adaptive Mutation Frequency for Improved Convergence", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.5 - 0.4 * eval_ratio:  # Adaptive mutation frequency\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11004 with standard deviation 0.02745.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.11236021278901154, 0.10402296957969015, 0.12136727228495336, 0.07750129896849067, 0.08190293443928998, 0.06921618980532629, 0.15131040256235706, 0.1347108527960249, 0.13800284409472607]}}
{"id": "aaff17ac-67eb-4475-a2a3-de7b6769242f", "fitness": 0.11377044291747367, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introducing dynamic population size adjustment based on performance feedback for improved exploration and exploitation balance in Enhanced Adaptive Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.population_size = self.base_population_size\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n        stagnation_counter = 0\n        adjustment_frequency = int(self.budget * 0.1)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n            if evaluations % adjustment_frequency == 0:\n                if stagnation_counter > adjustment_frequency * 0.5:\n                    self.population_size = min(self.population_size + 1, 2 * self.base_population_size)\n                    stagnation_counter = 0\n                elif stagnation_counter < adjustment_frequency * 0.3:\n                    self.population_size = max(self.population_size - 1, self.base_population_size // 2)\n                self.swarm_size = self.population_size // self.swarm_count\n                self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n                self.positions = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.personal_best_positions = np.copy(self.positions)\n                self.personal_best_values = np.full(self.population_size, np.inf)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11377 with standard deviation 0.02791.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.1045923643514628, 0.1097165419213304, 0.12787380121482805, 0.07463853487641736, 0.07384754477009825, 0.09466430886625787, 0.15131040256235706, 0.14737053477392392, 0.13991995292058734]}}
{"id": "5e018862-82cb-4b5a-82c8-c3fab8ff4731", "fitness": 0.1126051830371104, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introducing a dynamic adaptive mutation factor and a local search strategy based on function landscape analysis to enhance diversity and convergence in multi-swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                landscape_gradient = np.abs(func(self.global_best_position) - func(self.positions[i]))\n                mutation_factor_adaptive = 0.5 + 0.5 * landscape_gradient / (np.abs(self.global_best_value - self.personal_best_values[i]) + 1e-9)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11261 with standard deviation 0.02908.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10220838868061877, 0.11143246511767257, 0.12866402585595416, 0.073767248866619, 0.06804728256715975, 0.09248771501840491, 0.15131040256235706, 0.14652598272944362, 0.13900313593576363]}}
{"id": "8c8b7c2f-9a94-4f4a-86ff-5e7039ec516a", "fitness": 0.09496409077174044, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Fine-tune the neighborhood's best position update to boost convergence in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size][np.argmin(self.personal_best_values[neighbor_idx:neighbor_idx + self.swarm_size])]\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09496 with standard deviation 0.04265.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.06499727141872014, 0.06999317040665065, 0.058460001882932766, 0.05017933182523193, 0.07256801147406533, 0.07672577094822497, 0.15843498200380102, 0.14121830558002446, 0.16209997140601262]}}
{"id": "3668c1ab-44bb-484c-a355-351a0b056c86", "fitness": 0.10793535367110929, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhance swarm diversity and convergence by introducing a non-uniform mutation strategy and dynamic swarm radius adjustment.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_non_uniform = 0.5 + (0.4 * eval_ratio)\n                mutant = target + mutation_factor_non_uniform * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1.2 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10794 with standard deviation 0.03247.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.101882904785491, 0.11013884624708703, 0.13017571843239506, 0.07569235204452829, 0.057106343141915206, 0.06816657201800103, 0.15130318868788772, 0.13738767397863516, 0.13956458370404312]}}
{"id": "fbbed17f-a6db-45fd-9a3d-566fb2cce1a3", "fitness": 0.10965904249854568, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhanced mutation adaptation and more aggressive local search strategies to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.4:  # Changed probability for mutation\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * np.sin(np.pi * eval_ratio)  # Adjusted adaptation\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.08 * (ub - lb) * (1 - eval_ratio)  # Increased local search radius\n                for _ in range(5):  # More aggressive local search\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10966 with standard deviation 0.03698.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10682615617660352, 0.12107477243956921, 0.13128648863880965, 0.06008214541906165, 0.0586918177651492, 0.06383874247500532, 0.15133115290698362, 0.14271219517304767, 0.1510879114926812]}}
{"id": "9defff07-d58e-48eb-b5cc-392fcf2aeb4d", "fitness": 0.09482152659783084, "name": "RefinedAdaptiveMultiSwarmPSO", "description": "Introducing dynamic swarm fusion and adaptive inertia weight to further enhance diversity and convergence in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass RefinedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 12, 60))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.7, 0.3\n        self.c1_init, self.c1_final = 1.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 1.5\n        self.mutation_factor = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio ** 2)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.4:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * np.cos(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget and np.random.rand() < 0.5:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n            if evaluations < self.budget and np.random.rand() < 0.05 + 0.5 * eval_ratio:\n                fusion_center = np.mean(self.positions[:self.swarm_size], axis=0)\n                for i in range(self.swarm_size):\n                    self.positions[i] = fusion_center + np.random.uniform(-0.1, 0.1, self.dim)\n                    self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 71, "feedback": "The algorithm RefinedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09482 with standard deviation 0.03649.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.06256279297709866, 0.07604582170272634, 0.06705115438440612, 0.08017616944380856, 0.053636737346265284, 0.08036236185808321, 0.13160456968404488, 0.14657108903571925, 0.15538304294832528]}}
{"id": "b3806495-6b86-4cc4-95ca-e370a5db2e0b", "fitness": 0.1108209941277071, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce an adaptive inertia weight ceiling to further refine velocity updates for dynamic balance of exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = min(self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio), 0.8) \n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11082 with standard deviation 0.03115.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10303564657511666, 0.1006218031960604, 0.13037330388571078, 0.08096042959938499, 0.07202428139890737, 0.06886076946869657, 0.14611932401907513, 0.15337636740193894, 0.14201702160447305]}}
{"id": "567a847c-036b-4771-b3b7-dd63090e5648", "fitness": 0.10382545873390306, "name": "EnhancedChaosMultiSwarmPSO", "description": "Introducing a dynamic chaos-driven exploration strategy and adaptive multi-objective mutation to enhance exploration and convergence in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedChaosMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n        self.chaos_map = np.random.rand(self.population_size, dim)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                chaos_factor = 0.5 + 0.5 * np.sin(np.pi * self.chaos_map[idxs[0]])\n                mutant = target + chaos_factor * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n            self.chaos_map = (self.chaos_map * 3.9 * (1 - self.chaos_map)) % 1\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedChaosMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10383 with standard deviation 0.03485.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.09104335518748441, 0.09896061530346512, 0.1157721443860833, 0.056539033248878434, 0.07400785030478141, 0.059920587215299026, 0.1574817159945241, 0.1402821559932218, 0.1404216709713899]}}
{"id": "aa8adcf7-ebec-48f9-b312-1507f7915df2", "fitness": 0.10310433616110476, "name": "EnhancedHybridLevyMultiSwarmPSO", "description": "Introducing hybrid exploration-exploitation dynamics by integrating adaptive inertia weight with Lvy flight-based mutation in Multi-Swarm PSO for enhanced convergence towards global optima.", "code": "import numpy as np\n\nclass EnhancedHybridLevyMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        def levy_flight(Lambda):\n            sigma1 = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) /\n                      (np.math.gamma((1 + Lambda) / 2) * Lambda * 2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n            u = np.random.normal(0, sigma1, self.dim)\n            v = np.random.normal(0, 1, self.dim)\n            step = u / abs(v) ** (1 / Lambda)\n            return step\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + levy_flight(1.5) * local_radius\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedHybridLevyMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10310 with standard deviation 0.03381.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.09244146883349214, 0.08366747774134398, 0.09776848846823893, 0.07071519839272855, 0.05880612543218933, 0.07976011120833792, 0.15572252361286343, 0.14214866906197587, 0.14690896269877263]}}
{"id": "a91592c4-87d1-4365-ba14-c62db411bc41", "fitness": 0.10967979381001212, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhanced strategy using adaptive mutation frequency to balance exploration and exploitation in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < (0.3 + 0.2 * (1 - eval_ratio)):  # Adjusted adaptive mutation frequency\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10968 with standard deviation 0.02899.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10444444711385636, 0.10856961824217404, 0.10562666051426861, 0.07052275467838576, 0.08307893979651182, 0.07573907475153896, 0.1515433223992897, 0.13915344108012317, 0.14843988571396072]}}
{"id": "b47ab5aa-bff1-4660-a1ed-a646b50aa06e", "fitness": 0.09327594727575118, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "A slight adjustment in the velocity update mechanism to fine-tune the balance between exploration and exploitation in the EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (self.global_best_position - self.positions[i])  # Changed neighborhood_best_pos to global_best_position\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutant = target + self.mutation_factor * (donor1 - donor2)\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09328 with standard deviation 0.03957.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.057426387686443814, 0.04272826230821436, 0.07292790792798576, 0.07561075404062978, 0.07481376417473129, 0.07388934145423864, 0.14740591543607517, 0.15136899709837004, 0.14331219535507178]}}
{"id": "ea046fa0-f557-423d-ac0f-80f26e69b60b", "fitness": 0.10425016877298371, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Integrate a dynamic adaptive learning factor and enhanced swarm communication to improve convergence speed and solution quality in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                adaptive_learning_factor = 1 + 0.5 * np.cos(np.pi * eval_ratio)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    adaptive_learning_factor * self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10425 with standard deviation 0.03235.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10490334007786462, 0.10548724104135376, 0.10821240237002017, 0.07002066639952675, 0.05794652583017168, 0.06366769444930365, 0.1435931764824896, 0.14451172415716618, 0.13990874814895693]}}
{"id": "84138ca2-c834-487b-b553-5e788d968520", "fitness": -Infinity, "name": "RefinedAdaptiveMultiSwarmPSO", "description": "Introduce a dynamic neighborhood size and adaptive mutation scaling for increased exploration and convergence in Multi-Swarm PSO.", "code": "import numpy as np\n\nclass RefinedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n            neighborhood_size = int(self.swarm_size * (1 + 0.5 * np.sin(np.pi * eval_ratio)))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                swarm_start = (i // self.swarm_size) * self.swarm_size\n                neighborhood_idx = np.random.choice(range(swarm_start, swarm_start + self.swarm_size), neighborhood_size, replace=False)\n                neighborhood_best_pos = self.personal_best_positions[neighborhood_idx].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.5 + 0.3 * np.cos(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio * np.cos(np.pi * eval_ratio))\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 78, "feedback": "An exception occurred: IndexError('index 11 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 11 is out of bounds for axis 0 with size 10')", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {}}
{"id": "f6170bb0-4810-4424-8420-68bdfe8ea12d", "fitness": 0.11428986320419046, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce a minor adaptive component in mutation factor to enhance convergence speed while preserving diversity in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                # Slightly adjust the mutation factor adaptively\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11429 with standard deviation 0.02866.", "error": "", "parent_ids": ["2afc5efa-97ae-4b62-a0bc-dd6c3bd56c5b"], "operator": null, "metadata": {"aucs": [0.10880234581604942, 0.11342121279406259, 0.13139203482769368, 0.07463853487641736, 0.06938202027102658, 0.0935402239065325, 0.15131040256235706, 0.14668001532665087, 0.1394419784569242]}}
{"id": "1f339f5b-5126-4807-a767-cd53861a4d9a", "fitness": 0.11412092080831544, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhance EnhancedAdaptiveMultiSwarmPSO by introducing a dynamic neighborhood size for improved local exploration.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                dynamic_swarm_size = int(self.swarm_size * (1 + 0.5 * np.sin(np.pi * eval_ratio)))\n                neighbor_idx = i // dynamic_swarm_size * dynamic_swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + dynamic_swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11412 with standard deviation 0.03030.", "error": "", "parent_ids": ["f6170bb0-4810-4424-8420-68bdfe8ea12d"], "operator": null, "metadata": {"aucs": [0.1045923643514628, 0.11342121279406259, 0.13139203482769368, 0.07463853487641736, 0.06538694419278779, 0.0935402239065325, 0.15437230470258134, 0.14658944729087808, 0.14315522033242278]}}
{"id": "e1903050-55f5-4bdc-82ac-5c963e4cc950", "fitness": 0.09695694294229117, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhance convergence and diversity by integrating orthogonal learning and adaptive neighborhood search into EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def orthogonal_learning(self, personal_pos, global_pos):\n        # Implement orthogonal learning to encourage diversity\n        learning_pos = np.random.rand(self.dim) * (personal_pos - global_pos)\n        return np.clip(global_pos + learning_pos, 0, 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-2 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                # Slightly adjust the mutation factor adaptively\n                mutation_factor_adaptive = 0.5 + 0.3 * np.sin(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.05 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(3):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n            # Adaptive neighborhood search\n            if np.random.rand() < 0.5:\n                for i in range(self.population_size):\n                    orthogonal_pos = self.orthogonal_learning(self.personal_best_positions[i], self.global_best_position)\n                    orthogonal_pos = lb + (ub - lb) * orthogonal_pos\n                    orthogonal_value = func(orthogonal_pos)\n                    evaluations += 1\n                    if orthogonal_value < self.personal_best_values[i]:\n                        self.personal_best_values[i] = orthogonal_value\n                        self.personal_best_positions[i] = orthogonal_pos\n                    if orthogonal_value < self.global_best_value:\n                        self.global_best_value = orthogonal_value\n                        self.global_best_position = orthogonal_pos\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09696 with standard deviation 0.03501.", "error": "", "parent_ids": ["f6170bb0-4810-4424-8420-68bdfe8ea12d"], "operator": null, "metadata": {"aucs": [0.09045665538925152, 0.09778427767691955, 0.07085011810160347, 0.06612126750694547, 0.06483482769296334, 0.053677776462845106, 0.1511494596998979, 0.13795359819256614, 0.13978450575762802]}}
{"id": "8167a4ce-c9ef-4eb4-9243-d3a7394a5be2", "fitness": 0.11723549543471395, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce dynamic local search and adaptive inertia weighting to enhance convergence and solution quality in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.2 * np.cos(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11724 with standard deviation 0.02567.", "error": "", "parent_ids": ["f6170bb0-4810-4424-8420-68bdfe8ea12d"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.07063628580095971, 0.0867896889174502, 0.1509376693312232, 0.1403230341100007, 0.14158805107229666]}}
{"id": "cdaa71c4-280a-4548-930c-b4182cbabb11", "fitness": 0.11723549543471395, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce a slight increase in the mutation factor for more exploration in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.85  # Increased from 0.8 to 0.85\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.2 * np.cos(np.pi * eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11724 with standard deviation 0.02567.", "error": "", "parent_ids": ["8167a4ce-c9ef-4eb4-9243-d3a7394a5be2"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.07063628580095971, 0.0867896889174502, 0.1509376693312232, 0.1403230341100007, 0.14158805107229666]}}
{"id": "7d32f0ef-ad13-4d31-8100-e7b60f23ff74", "fitness": 0.12026877091150744, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce time-varying mutation factor to improve exploration and exploitation balance in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)  # Changed 0.2 to 0.4 to increase adaptation\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12027 with standard deviation 0.02297.", "error": "", "parent_ids": ["8167a4ce-c9ef-4eb4-9243-d3a7394a5be2"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.0909195430655334, 0.0867896889174502, 0.15019427082552406, 0.14078182685794205, 0.14888887885662216]}}
{"id": "60b8fc1f-49a7-4b3c-8344-8cf650c77dd9", "fitness": 0.12026877091150744, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce an adaptive crossover rate in EnhancedAdaptiveMultiSwarmPSO to enhance diversification.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)  # Changed 0.2 to 0.4 to increase adaptation\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12027 with standard deviation 0.02297.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.0909195430655334, 0.0867896889174502, 0.15019427082552406, 0.14078182685794205, 0.14888887885662216]}}
{"id": "d77ac07c-8cdd-4417-bca6-86469bfdebc5", "fitness": 0.12021959422656349, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Refine time-varying mutation strategy to increase diversity in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.7 + 0.3 * (1 - eval_ratio)  # Changed 0.6 to 0.7 to enhance mutation\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12022 with standard deviation 0.02294.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.09093476896038033, 0.0867896889174502, 0.15035836134396552, 0.14015992028015822, 0.14888887885662216]}}
{"id": "74dc4255-18d5-4bb0-b3e2-b4c885c1108f", "fitness": 0.10902243750752522, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Adjusted local search radius reduction rate to enhance convergence in local search phase.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)  # Changed 0.2 to 0.4 to increase adaptation\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.02 * (ub - lb) * (1 - eval_ratio)  # Changed from 0.03 to 0.02 to refine local search\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10902 with standard deviation 0.03168.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.09164434982978897, 0.10518036854409041, 0.12091327115626882, 0.07480608688342405, 0.09036069344411735, 0.05718102610691922, 0.15019863161810065, 0.14256885477210834, 0.1483486552129092]}}
{"id": "93a83970-82b5-47cc-99c2-82c68fc6b586", "fitness": 0.11154972012972197, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce dynamic neighborhood selection and adaptive local search intensity to improve convergence in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                # Dynamic neighborhood selection based on dimensionality\n                neighborhood_size = int(np.clip(self.swarm_size * (1 + eval_ratio), 1, self.swarm_size))\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + neighborhood_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                # Adaptive local search intensity\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                num_local_searches = int(np.clip(5 * (1 - eval_ratio), 1, 5))\n                for _ in range(num_local_searches):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11155 with standard deviation 0.02594.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.11097279842222596, 0.10170625805848965, 0.1194807915195929, 0.07557026288363022, 0.08403642849549253, 0.0831643016013861, 0.14987795694641914, 0.1400221424509298, 0.13911654078933144]}}
{"id": "6d3f2e02-cb20-4f7c-b8a2-2fc01c29275b", "fitness": 0.08054479815615932, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce dynamic neighborhood best selection and adaptive local search frequency to improve convergence in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighborhood_best_idx = np.argmin(self.personal_best_values[i//self.swarm_size*self.swarm_size:(i//self.swarm_size+1)*self.swarm_size])\n                neighborhood_best_pos = self.personal_best_positions[neighborhood_best_idx]\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            local_search_probability = 0.1 + 0.3 * (1 - eval_ratio)  # Increase local search probability as convergence nears\n            if np.random.rand() < local_search_probability and evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08054 with standard deviation 0.05379.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.021790260043190735, 0.020966057015233575, 0.026831079743921404, 0.04980918960552405, 0.06821933847186668, 0.08443224086800838, 0.15397933127335495, 0.1582111277679511, 0.14066455861638305]}}
{"id": "14c5af7c-04c9-42e6-924f-c2af380a4dcf", "fitness": 0.12021959422656349, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Increase mutation adaptation in EnhancedAdaptiveMultiSwarmPSO to improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.7 + 0.3 * (1 - eval_ratio)  # Changed 0.6 to 0.7\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12022 with standard deviation 0.02294.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.09093476896038033, 0.0867896889174502, 0.15035836134396552, 0.14015992028015822, 0.14888887885662216]}}
{"id": "fa88cecb-67de-44fa-b391-885225e7b94f", "fitness": 0.11836409070233439, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce more adaptive mutation factor by replacing constant value with evolving parameter in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * np.abs(np.sin(np.pi * eval_ratio))  # Changed linear adaptation to sinusoidal pattern\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11836 with standard deviation 0.02610.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.07303402267727688, 0.0867896889174502, 0.1509376693312232, 0.14078182685794205, 0.14888887885662216]}}
{"id": "1e7fc5ea-617b-48e0-a1d0-a5a25f375fa4", "fitness": 0.11366856514689033, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Refine EnhancedAdaptiveMultiSwarmPSO by introducing adaptive inertia weight and crossover strategy to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * (1 - eval_ratio)  # Adaptive inertia weight\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if np.random.rand() < self.crossover_rate:\n                    crossover_point = np.random.randint(0, self.dim)\n                    mutant[:crossover_point] = self.global_best_position[:crossover_point]\n\n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11367 with standard deviation 0.03106.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.108673794215696, 0.10961939012802546, 0.12326300774923993, 0.07765556446263822, 0.0719677718137286, 0.07948968224506592, 0.15283529236028248, 0.15995881385928623, 0.13955376948804998]}}
{"id": "9df01619-1c1c-46cd-b3f1-3fcb06754798", "fitness": 0.11326964903748582, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce dynamic learning rates and adaptive neighborhood size to enhance convergence in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                adaptive_swarm_size = max(1, int(self.swarm_size * (1 - eval_ratio)))  # Dynamic neighborhood size\n                neighbor_idx = i // adaptive_swarm_size * adaptive_swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + adaptive_swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)  # Adaptive mutation factor\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11327 with standard deviation 0.02463.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.09395136316516339, 0.08838705952938641, 0.12741790176801693, 0.10450121767039466, 0.08549462253686257, 0.08891585680088587, 0.1494713569928845, 0.14356116718123235, 0.13772629569254569]}}
{"id": "e445fb4c-0b22-456b-887e-5ff0eff494c5", "fitness": 0.11400443981830301, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce a mutation factor scaling based on the ratio of best global improvement to enhance exploitative adaptability in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                improvement_ratio = (self.global_best_value - np.min(self.personal_best_values)) / (np.abs(self.global_best_value) + 1e-9)  # New line added\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio) * improvement_ratio\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11400 with standard deviation 0.03036.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.04736318469042955, 0.0867896889174502, 0.1509376693312232, 0.14015992028015822, 0.1359447654649707]}}
{"id": "4cf85f95-11dd-47b5-a828-c4e6c9fd9ca4", "fitness": 0.12022862062777821, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce a dynamic swarm size to enhance adaptability in exploration and exploitation balance for EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n            \n            # Dynamic swarm size\n            self.swarm_size = max(2, int(self.population_size // self.swarm_count * (1 + 0.5 * eval_ratio)))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12023 with standard deviation 0.02293.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.0909195430655334, 0.0867896889174502, 0.15001872217748757, 0.14066490884993554, 0.1488199929591021]}}
{"id": "d41583e4-fdf9-455a-8e2d-a97b5d5f32e0", "fitness": 0.062196785214435266, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Enhance exploration in EnhancedAdaptiveMultiSwarmPSO by introducing a dynamic inertia weight based on swarm diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        def calculate_swarm_diversity():\n            centroid = np.mean(self.positions, axis=0)\n            diversity = np.mean(np.linalg.norm(self.positions - centroid, axis=1))\n            return diversity\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            swarm_diversity = calculate_swarm_diversity()\n            diversity_factor = (swarm_diversity - 0.1) / (0.5 - 0.1)  # Normalize to [0, 1]\n            self.w = (self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)) * diversity_factor\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06220 with standard deviation 0.05351.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.011499707401516623, 0.011723163892871313, 0.011425465121672751, 0.039415845656839865, 0.042149800196980114, 0.035284778907886394, 0.13112760356948616, 0.13640664572583083, 0.14073805645683335]}}
{"id": "9ff2284c-8e3c-4251-9734-95a30bb6ba2a", "fitness": 0.11713042809196911, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Introduce a dynamic adjustment to the mutation probability based on optimization progress to enhance the exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Change: Dynamic mutation probability based on optimization progress\n            mutation_probability = 0.3 * (1 - eval_ratio)\n            if np.random.rand() < mutation_probability:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11713 with standard deviation 0.02722.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.11372631946058231, 0.12024473176803652, 0.13124269701309288, 0.09397927618572488, 0.07430481107046227, 0.08017501624798995, 0.14985371075824339, 0.14015992028015822, 0.1504873700434316]}}
{"id": "161f19e4-804d-4207-a535-edafd631a4ae", "fitness": 0.10723789513348479, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Employ adaptive inertia weights and hybrid mutation strategies to improve diversity and convergence in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.7, 0.3\n        self.c1_init, self.c1_final = 2.0, 1.0\n        self.c2_init, self.c2_final = 1.0, 2.0\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.cos(np.pi * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.6 + 0.4 * (1 - eval_ratio)\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                perturbation = 0.1 * (ub - lb) * np.random.uniform(-1, 1, self.dim)\n                mutant = np.clip(mutant + perturbation, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10724 with standard deviation 0.03493.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.12040438804307041, 0.11140239261847007, 0.07823578773438344, 0.07361304682749625, 0.07058786817338636, 0.06236144631588003, 0.15378312489772394, 0.14133642896177312, 0.15341657262917952]}}
{"id": "aa0de4a2-6ff7-440b-b53e-6c334f789ece", "fitness": 0.12019241550616863, "name": "EnhancedAdaptiveMultiSwarmPSO", "description": "Adjusted the mutation factor's adaptation range to enhance exploration-exploitation trade-off in EnhancedAdaptiveMultiSwarmPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(np.clip(5 * np.log10(dim), 10, 50))\n        self.swarm_count = 3\n        self.swarm_size = self.population_size // self.swarm_count\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.positions = np.random.rand(self.population_size, dim)\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.w_init, self.w_final = 0.9, 0.4\n        self.c1_init, self.c1_final = 2.5, 0.5\n        self.c2_init, self.c2_final = 0.5, 2.5\n        self.mutation_factor = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = lb + (ub - lb) * self.positions\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.positions[i])\n                evaluations += 1\n\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            eval_ratio = evaluations / self.budget\n            self.w = self.w_final + (self.w_init - self.w_final) * np.exp(-3 * eval_ratio)\n            self.c1 = self.c1_final + (self.c1_init - self.c1_final) * eval_ratio\n            self.c2 = self.c2_final + (self.c2_init - self.c2_final) * (1 - eval_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                neighbor_idx = i // self.swarm_size * self.swarm_size\n                neighborhood_best_pos = self.personal_best_positions[neighbor_idx:neighbor_idx + self.swarm_size].min(axis=0)\n                self.velocities[i] = (\n                    self.w * self.velocities[i] + \n                    self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + \n                    self.c2 * r2 * (neighborhood_best_pos - self.positions[i])\n                )\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            if np.random.rand() < 0.3:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                target, donor1, donor2 = self.positions[idxs]\n                mutation_factor_adaptive = 0.5 + 0.5 * (1 - eval_ratio)  # Adjusted the adaptation range from 0.6-0.4 to 0.5-0.5\n                mutant = target + mutation_factor_adaptive * (donor1 - donor2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutant_value = func(mutant)\n                    evaluations += 1\n                    if mutant_value < self.personal_best_values[idxs[0]]:\n                        self.personal_best_values[idxs[0]] = mutant_value\n                        self.personal_best_positions[idxs[0]] = mutant\n\n            if evaluations < self.budget:\n                local_radius = 0.03 * (ub - lb) * (1 - eval_ratio)\n                for _ in range(5):\n                    local_search_position = self.global_best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n                    local_search_position = np.clip(local_search_position, lb, ub)\n                    local_search_value = func(local_search_position)\n                    evaluations += 1\n                    if local_search_value < self.global_best_value:\n                        self.global_best_value = local_search_value\n                        self.global_best_position = local_search_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12019 with standard deviation 0.02285.", "error": "", "parent_ids": ["7d32f0ef-ad13-4d31-8100-e7b60f23ff74"], "operator": null, "metadata": {"aucs": [0.10892400652506373, 0.11610513413258661, 0.135503480679932, 0.10431210834291271, 0.09101534013229629, 0.0867896889174502, 0.15019427082552406, 0.14078182685794205, 0.14810588314180995]}}
