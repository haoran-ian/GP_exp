{"id": "c061f81b-2836-4298-9573-df51fd63dc2f", "fitness": -Infinity, "name": "HybridDEMASO", "description": "Hybrid Differential and Evolutionary Multi-Agent Swarm Optimization combines differential evolution with swarm intelligence and local search to effectively navigate complex search spaces.", "code": "import numpy as np\n\nclass HybridDEMASO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.best_agent = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_agent = self.population[np.argmin([func(ind) for ind in self.population])]\n    \n    def differential_evolution(self, target_idx, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        return trial\n\n    def local_search(self, agent, bounds):\n        noise = np.random.normal(0, 0.1, self.dim)\n        new_agent = np.clip(agent + noise, bounds.lb, bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for idx in range(self.population_size):\n                trial = self.differential_evolution(idx, bounds)\n                if func(trial) < func(self.population[idx]):\n                    self.population[idx] = trial\n                    evaluations += 1\n                    if func(trial) < func(self.best_agent):\n                        self.best_agent = trial\n\n                # Local search step\n                if evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], bounds)\n                    if func(candidate) < func(self.population[idx]):\n                        self.population[idx] = candidate\n                        evaluations += 1\n                        if func(candidate) < func(self.best_agent):\n                            self.best_agent = candidate\n\n        return self.best_agent", "configspace": "", "generation": 0, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 101, in evaluateBBOB\n    algorithm(problem)\n  File \"<string>\", line 38, in __call__\n  File \"<string>\", line 16, in initialize_population\n  File \"<string>\", line 16, in <listcomp>\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 101, in evaluateBBOB\n    algorithm(problem)\n  File \"<string>\", line 38, in __call__\n  File \"<string>\", line 16, in initialize_population\n  File \"<string>\", line 16, in <listcomp>\nNameError: name 'func' is not defined\n", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "adbd53f4-d306-4a6b-b78c-7e3bbdc4ddbb", "fitness": 0.06765299608421567, "name": "AdaptiveMultiAgentSwarmOptimization", "description": "Adaptive Multi-Agent Evolutionary Swarm Optimization (AMESO) refines HybridDEMASO by introducing adaptive parameter control and diversified swarm intelligence to enhance exploration and exploitation. ", "code": "import numpy as np\n\nclass AdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = [func(ind) for ind in self.population]\n        self.best_agent = self.population[np.argmin(fitness)]\n\n    def adaptive_parameters(self):\n        # Adjust parameters based on the progress\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = np.random.uniform(0.7, 1.0)\n\n    def differential_evolution(self, target_idx, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        return trial\n\n    def local_search(self, agent, func):\n        noise = np.random.normal(0, 0.1, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            for idx in range(self.population_size):\n                # Differential Evolution step\n                trial = self.differential_evolution(idx, func)\n                if func(trial) < func(self.population[idx]):\n                    self.population[idx] = trial\n                    self.evaluations += 1\n                    if func(trial) < func(self.best_agent):\n                        self.best_agent = trial\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    if func(candidate) < func(self.population[idx]):\n                        self.population[idx] = candidate\n                        self.evaluations += 1\n                        if func(candidate) < func(self.best_agent):\n                            self.best_agent = candidate\n\n        return self.best_agent", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06765 with standard deviation 0.05259.", "error": "", "parent_ids": ["c061f81b-2836-4298-9573-df51fd63dc2f"], "operator": null, "metadata": {"aucs": [0.012472529991146342, 0.012755811933312988, 0.012528711630641287, 0.05341679500836749, 0.049966756430305126, 0.05324739501667897, 0.12797374446918486, 0.14357934216258927, 0.14293587811571473]}}
{"id": "1c6224f5-337e-4732-af44-38f3e328f52d", "fitness": 0.07025223633977229, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Enhanced Adaptive Multi-Agent Evolutionary Swarm Optimization (EAMESO) introduces dynamic population resizing and stochastic parameter adaptation to balance exploration and exploitation based on convergence progress.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = [func(ind) for ind in self.population]\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.random.normal(0.5, 0.2)\n        self.CR = np.random.normal(0.9, 0.05)\n\n    def dynamic_population_resizing(self):\n        # Decrease population size if improvement stagnates\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, self.population_size - 5)\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n    def differential_evolution(self, target_idx, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        return trial\n\n    def local_search(self, agent, func):\n        noise = np.random.normal(0, 0.1, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing()\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                trial = self.differential_evolution(idx, func)\n                if func(trial) < func(self.population[idx]):\n                    self.population[idx] = trial\n                    self.evaluations += 1\n                    if func(trial) < func(self.best_agent):\n                        self.best_agent = trial\n                        self.last_improvement_evaluation = self.evaluations\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    if func(candidate) < func(self.population[idx]):\n                        self.population[idx] = candidate\n                        self.evaluations += 1\n                        if func(candidate) < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07025 with standard deviation 0.05671.", "error": "", "parent_ids": ["adbd53f4-d306-4a6b-b78c-7e3bbdc4ddbb"], "operator": null, "metadata": {"aucs": [0.012613372456626526, 0.011005022566781375, 0.014528125880768572, 0.04918014192047926, 0.05740050148004805, 0.04643876775581146, 0.14116260249774515, 0.156812328076944, 0.1431292644227462]}}
{"id": "435c6d0a-d07a-451d-8035-06d5fc59a6ca", "fitness": 0.06881296816751432, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Introduced multi-agent memory and adaptive local search improvements to optimize exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.memory = []  # Memory to store past best solutions\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = [func(ind) for ind in self.population]\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.memory.append(self.best_agent)  # Store initial best in memory\n        self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.random.normal(0.5, 0.2)\n        self.CR = np.random.normal(0.9, 0.05)\n\n    def dynamic_population_resizing(self):\n        # Decrease population size if improvement stagnates\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, self.population_size - 5)\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n    def differential_evolution(self, target_idx, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        return trial\n\n    def local_search(self, agent, func):\n        # Enhanced local search with memory influence\n        memory_influence = np.mean(self.memory, axis=0) if self.memory else np.zeros(self.dim)\n        noise = np.random.normal(0, 0.1, self.dim)\n        new_agent = np.clip(agent + noise + memory_influence, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing()\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                trial = self.differential_evolution(idx, func)\n                if func(trial) < func(self.population[idx]):\n                    self.population[idx] = trial\n                    self.evaluations += 1\n                    if func(trial) < func(self.best_agent):\n                        self.best_agent = trial\n                        self.last_improvement_evaluation = self.evaluations\n                        self.memory.append(self.best_agent)  # Update memory with new best\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    if func(candidate) < func(self.population[idx]):\n                        self.population[idx] = candidate\n                        self.evaluations += 1\n                        if func(candidate) < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n                            self.memory.append(self.best_agent)  # Update memory with new best\n\n        return self.best_agent", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06881 with standard deviation 0.05066.", "error": "", "parent_ids": ["1c6224f5-337e-4732-af44-38f3e328f52d"], "operator": null, "metadata": {"aucs": [0.01643870312974527, 0.019983075480525025, 0.01752382002050923, 0.0465888939602459, 0.05073490691721927, 0.054705937697545726, 0.13316166226721116, 0.13724383591891265, 0.14293587811571473]}}
{"id": "76ecbf26-d975-424d-b4e7-271c6cd934c6", "fitness": 0.07031048726041489, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Enhanced Adaptive Multi-Agent Evolutionary Swarm Optimization (EAMESO) now incorporates adaptive local search noise scaling to refine exploitation strategies based on convergence progress.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = [func(ind) for ind in self.population]\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.random.normal(0.5, 0.2)\n        self.CR = np.random.normal(0.9, 0.05)\n\n    def dynamic_population_resizing(self):\n        # Decrease population size if improvement stagnates\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, self.population_size - 5)\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n    def differential_evolution(self, target_idx, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        return trial\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.05, 0.1 * (1 - (self.evaluations / self.budget)))  # Adaptive noise scaling\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing()\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                trial = self.differential_evolution(idx, func)\n                if func(trial) < func(self.population[idx]):\n                    self.population[idx] = trial\n                    self.evaluations += 1\n                    if func(trial) < func(self.best_agent):\n                        self.best_agent = trial\n                        self.last_improvement_evaluation = self.evaluations\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    if func(candidate) < func(self.population[idx]):\n                        self.population[idx] = candidate\n                        self.evaluations += 1\n                        if func(candidate) < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07031 with standard deviation 0.05604.", "error": "", "parent_ids": ["1c6224f5-337e-4732-af44-38f3e328f52d"], "operator": null, "metadata": {"aucs": [0.012583778444076321, 0.010994023917171636, 0.014497301478190394, 0.05289499916208795, 0.05623563976547774, 0.04781784401780109, 0.13959717530389315, 0.15523774513932098, 0.14293587811571473]}}
{"id": "e548042d-e69a-4a7e-96bc-4b4659cf7dc7", "fitness": 0.07281823430530544, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "The algorithm incorporates a novel hierarchical adaptive strategies framework where both individual-level differential evolution and population-level dynamic adjustments are guided by an entropy-based convergence measure to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05  # Boost exploration\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  # Adaptive noise scaling\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07282 with standard deviation 0.05058.", "error": "", "parent_ids": ["76ecbf26-d975-424d-b4e7-271c6cd934c6"], "operator": null, "metadata": {"aucs": [0.0259220583977936, 0.020922604398098676, 0.01729636345853014, 0.0540682576072381, 0.05244149083289884, 0.060747843732211315, 0.14255322343778376, 0.1352532289577384, 0.14615903792545615]}}
{"id": "9b7e1c5c-0cef-49ba-89cd-16dc531c9e93", "fitness": 0.07074876420021514, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Incorporate a randomized local search mechanism to enhance exploitation by occasionally performing aggressive exploration steps.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05  # Boost exploration\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        if np.random.rand() < 0.1:  # Aggressive exploration with a small probability\n            noise_scale = max(0.05, 0.5 * (1 - (self.evaluations / self.budget)))  # Adjusted noise scaling\n        else:\n            noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget))) \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07075 with standard deviation 0.05161.", "error": "", "parent_ids": ["e548042d-e69a-4a7e-96bc-4b4659cf7dc7"], "operator": null, "metadata": {"aucs": [0.014345036680635692, 0.012481785684890334, 0.020076557352059154, 0.05621779338324784, 0.05498893484089451, 0.060383065779880174, 0.13072560663215482, 0.14228176403112802, 0.14523833341704573]}}
{"id": "db0ee85c-935f-497f-bb30-a98ef75e5d2c", "fitness": 0.07037336804642316, "name": "SynergisticAdaptiveSwarmOptimization", "description": "Introduce a layered synergy of adaptive differential evolution and particle swarm optimization, leveraging dynamic learning rates and mutation strategies to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass SynergisticAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.7  # Inertia weight\n        self.population = None\n        self.velocity = None\n        self.best_agent = None\n        self.personal_best = None\n        self.personal_best_fitness = None\n        self.evaluations = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.personal_best = np.copy(self.population)\n        self.personal_best_fitness = np.copy(fitness)\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.95\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def differential_evolution_step(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n\n    def particle_swarm_optimization_step(self, idx, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocity[idx] = (self.w * self.velocity[idx] + \n                              self.c1 * r1 * (self.personal_best[idx] - self.population[idx]) +\n                              self.c2 * r2 * (self.best_agent - self.population[idx]))\n        self.population[idx] = np.clip(self.population[idx] + self.velocity[idx], func.bounds.lb, func.bounds.ub)\n\n        current_fitness = func(self.population[idx])\n        if current_fitness < self.personal_best_fitness[idx]:\n            self.personal_best[idx] = self.population[idx]\n            self.personal_best_fitness[idx] = current_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.entropy_based_adaptation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                self.differential_evolution_step(idx, func, fitness)\n                self.evaluations += 1\n\n                if self.evaluations < self.budget:\n                    self.particle_swarm_optimization_step(idx, func)\n                    self.evaluations += 1\n\n        return self.best_agent", "configspace": "", "generation": 7, "feedback": "The algorithm SynergisticAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07037 with standard deviation 0.05036.", "error": "", "parent_ids": ["e548042d-e69a-4a7e-96bc-4b4659cf7dc7"], "operator": null, "metadata": {"aucs": [0.02080494421819601, 0.015171783702853991, 0.03248927733705309, 0.04911375474815338, 0.04593436620620306, 0.050751180408775465, 0.13773907186871004, 0.13712266865901734, 0.14423326526884606]}}
{"id": "24590ca6-1f4f-4bb2-9881-08c704b3e668", "fitness": 0.07365011639269818, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "The adjustment rate for the differential weight F is modified for better convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03  # Adjusted exploration boost\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  # Adaptive noise scaling\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07365 with standard deviation 0.05177.", "error": "", "parent_ids": ["e548042d-e69a-4a7e-96bc-4b4659cf7dc7"], "operator": null, "metadata": {"aucs": [0.036282217558073815, 0.018071070986996007, 0.01728512624155354, 0.05190203451059483, 0.050876031953891454, 0.05489009567427683, 0.1499010958921576, 0.14070749660102477, 0.14293587811571473]}}
{"id": "a4cbe33c-4829-40f8-96af-116f6f5c18d7", "fitness": 0.07365011639269818, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Introduced a subtle enhancement in adaptive parameter tuning to improve convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03  # Adjusted exploration boost\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  # Adaptive noise scaling\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07365 with standard deviation 0.05177.", "error": "", "parent_ids": ["24590ca6-1f4f-4bb2-9881-08c704b3e668"], "operator": null, "metadata": {"aucs": [0.036282217558073815, 0.018071070986996007, 0.01728512624155354, 0.05190203451059483, 0.050876031953891454, 0.05489009567427683, 0.1499010958921576, 0.14070749660102477, 0.14293587811571473]}}
{"id": "9ec78d0e-50a5-4b3c-94a1-610963394a41", "fitness": 0.07281823430530544, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Improved convergence by adjusting the differential weight F reduction factor.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03  # Adjusted exploration boost\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.95  # Adjusted F reduction factor\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  # Adaptive noise scaling\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07282 with standard deviation 0.05058.", "error": "", "parent_ids": ["24590ca6-1f4f-4bb2-9881-08c704b3e668"], "operator": null, "metadata": {"aucs": [0.0259220583977936, 0.020922604398098676, 0.01729636345853014, 0.0540682576072381, 0.05244149083289884, 0.060747843732211315, 0.14255322343778376, 0.1352532289577384, 0.14615903792545615]}}
{"id": "d0006747-6f95-46bc-973b-7b1138f4ee4f", "fitness": 0.07232374347049048, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Introduced adaptive noise scaling in the local search to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03  # Adjusted exploration boost\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        # Added adaptive noise scaling based on evaluations\n        noise_scale = max(0.01, 0.2 * (1 - (self.evaluations / self.budget)))  # Adjusted noise scale\n        noise = np.random.normal(0, noise_scale, self.dim)  # Introduced more exploration\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07232 with standard deviation 0.05046.", "error": "", "parent_ids": ["24590ca6-1f4f-4bb2-9881-08c704b3e668"], "operator": null, "metadata": {"aucs": [0.021678378156330003, 0.019179826830682867, 0.02044885463572832, 0.0525492764572818, 0.05813730444269627, 0.05720425915854965, 0.14316580549220448, 0.1356141079452261, 0.14293587811571473]}}
{"id": "ba8efb3e-5e36-4ac9-8ceb-f17e137e6300", "fitness": 0.07365011639269818, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "Enhanced local search mechanism by tuning the noise scale to improve convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03  # Adjusted exploration boost\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.005, 0.1 * (1 - (self.evaluations / self.budget)))  # Adjusted noise scaling\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveMultiAgentSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07365 with standard deviation 0.05177.", "error": "", "parent_ids": ["24590ca6-1f4f-4bb2-9881-08c704b3e668"], "operator": null, "metadata": {"aucs": [0.036282217558073815, 0.018071070986996007, 0.01728512624155354, 0.05190203451059483, 0.050876031953891454, 0.05489009567427683, 0.1499010958921576, 0.14070749660102477, 0.14293587811571473]}}
{"id": "bc60ce2c-4258-41f0-9956-59c57bd26c3f", "fitness": -Infinity, "name": "EnhancedAdaptiveMultiAgentSwarmOptimization", "description": "The adjustment rate for the differential weight F is modified for better convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  # Threshold to trigger dynamic changes\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  # Threshold for entropy-based adjustments\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        # Calculate fitness entropy\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))  # Avoid log(0)\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03  # Adjusted exploration boost\n            self.CR *= 0.95  # Enhance refinement\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def adaptive_parameters(self):\n        # Stochastic adaptation of parameters\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n        self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n    def dynamic_population_resizing(self, fitness):\n        # Adjust population size based on performance\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5  # Increase threshold to avoid frequent resizing\n\n        # Entropy-based adaptation\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  # Adaptive noise scaling\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Differential Evolution step\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                # Local search step\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 9, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["24590ca6-1f4f-4bb2-9881-08c704b3e668"], "operator": "\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.0% of the code, which means if the code has 100 lines, you can only change 0.9708737864077669 lines, and the rest of the lines should remain unchanged. This input code has 103 lines, so you can only change 1 lines, the rest 102 lines should remain unchanged. This changing rate 1.0% is the mandatory requirement, you cannot change more or less than this rate.\n    ", "metadata": {"aucs": [0.036282217558073815, 0.018071070986996007, 0.01728512624155354, 0.05190203451059483, 0.050876031953891454, 0.05489009567427683, 0.1499010958921576, 0.14070749660102477, 0.14293587811571473]}}
{"id": "1d151b01-bbe9-4924-a145-d1f209ab87ac", "fitness": 0.07468091732134688, "name": "AdvancedSelfAdaptiveSwarmOptimization", "description": "Introducing a novel self-adaptive multi-strategy approach by integrating covariance matrix adaptation and local search to improve convergence and robustness.", "code": "import numpy as np\n\nclass AdvancedSelfAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9  \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  # Initialize covariance matrix\n        self.mean_vector = np.zeros(dim)  # Initialize mean vector\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 14, "feedback": "The algorithm AdvancedSelfAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07468 with standard deviation 0.05017.", "error": "", "parent_ids": ["24590ca6-1f4f-4bb2-9881-08c704b3e668"], "operator": null, "metadata": {"aucs": [0.019974686360599958, 0.026121860906440753, 0.018372676593594206, 0.0679479273582888, 0.05279654787767163, 0.062499696755478173, 0.1346486004359425, 0.14297118078792992, 0.14679507881617593]}}
{"id": "82972c21-543e-4935-91bb-992d7b60eb99", "fitness": 0.07097661344580333, "name": "AdvancedSelfAdaptiveSwarmOptimization", "description": "Enhance the covariance-guided search by dynamically updating the mean vector based on the best agent to improve convergence towards promising regions.", "code": "import numpy as np\n\nclass AdvancedSelfAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9  \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  # Initialize covariance matrix\n        self.mean_vector = np.zeros(dim)  # Initialize mean vector\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        # Updated line: Dynamically update the mean vector based on the best agent\n        self.mean_vector = self.best_agent\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 15, "feedback": "The algorithm AdvancedSelfAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07098 with standard deviation 0.05304.", "error": "", "parent_ids": ["1d151b01-bbe9-4924-a145-d1f209ab87ac"], "operator": null, "metadata": {"aucs": [0.020109804679113608, 0.014060093417760489, 0.014677015644009583, 0.05224340446211717, 0.054048555795051745, 0.05569720835093328, 0.13805363234684764, 0.14295454372573158, 0.14694526259066487]}}
{"id": "a73bbb4e-42b9-4094-a643-9288e7badcff", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveSwarmOptimization", "description": "Enhanced Self-Adaptive Swarm Optimization with Elite Memetic Search to balance exploration and exploitation through a multi-faceted adaptive strategy using elite memory and adaptive mutation.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9  \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n        self.elite_memory = []\n        self.elite_fraction = 0.1  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n        self.update_elite_memory(fitness)\n\n    def update_elite_memory(self, fitness):\n        elite_size = int(self.elite_fraction * self.population_size)\n        sorted_indices = np.argsort(fitness)\n        self.elite_memory = self.population[sorted_indices[:elite_size]]\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))  \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def elite_memetic_search(self, agent, func):\n        if self.elite_memory:\n            elite_agent = self.elite_memory[np.random.randint(len(self.elite_memory))]\n            mutation_vector = np.random.normal(0, 0.1, self.dim)\n            new_agent = np.clip(agent + 0.5 * (elite_agent - agent) + mutation_vector, func.bounds.lb, func.bounds.ub)\n            return new_agent\n        return agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.elite_memetic_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 16, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["1d151b01-bbe9-4924-a145-d1f209ab87ac"], "operator": null, "metadata": {}}
{"id": "f985bf91-92f7-48aa-b4f7-61d267801b5a", "fitness": 0.08031131314666973, "name": "AdvancedSelfAdaptiveSwarmOptimization", "description": "Introducing a slight increase in the noise scale for local search to further explore the search space.", "code": "import numpy as np\n\nclass AdvancedSelfAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9  \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  # Initialize covariance matrix\n        self.mean_vector = np.zeros(dim)  # Initialize mean vector\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))  # Slightly increased noise scale\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 17, "feedback": "The algorithm AdvancedSelfAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08031 with standard deviation 0.04642.", "error": "", "parent_ids": ["1d151b01-bbe9-4924-a145-d1f209ab87ac"], "operator": null, "metadata": {"aucs": [0.07064824878850562, 0.026121860906440753, 0.018372676593594206, 0.0679479273582888, 0.05279654787767163, 0.062499696755478173, 0.1346486004359425, 0.14297118078792992, 0.14679507881617593]}}
{"id": "a884d22b-8c32-427b-9a3b-653b6d4372f6", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmOptimization", "description": "Integrate adaptive learning strategies and multi-agent collaboration to dynamically adjust exploration-exploitation balance and enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9  \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n        self.agent_learning_rate = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_learning(self, func, fitness):\n        learning_coeff = np.random.uniform(0, self.agent_learning_rate, self.population_size)\n        for i, agent in enumerate(self.population):\n            learning_vector = learning_coeff[i] * (self.best_agent - agent)\n            new_agent = np.clip(agent + learning_vector, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(new_agent)\n            if new_fitness < fitness[i]:\n                self.population[i] = new_agent\n                fitness[i] = new_fitness\n                if new_fitness < func(self.best_agent):\n                    self.best_agent = new_agent\n                    self.last_improvement_evaluation = self.evaluations\n\n    def multi_agent_collaboration(self, fitness):\n        if self.evaluations % (self.budget // 10) == 0:\n            perturb_agents = np.random.choice(self.population_size, size=(self.population_size // 5), replace=False)\n            for agent_idx in perturb_agents:\n                self.population[agent_idx] = self.best_agent + np.random.normal(0, 0.1, self.dim)\n                self.population[agent_idx] = np.clip(self.population[agent_idx], func.bounds.lb, func.bounds.ub)\n                fitness[agent_idx] = func(self.population[agent_idx])\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_learning(func, fitness)\n            self.multi_agent_collaboration(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 18, "feedback": "An exception occurred: IndexError('index 41 is out of bounds for axis 0 with size 41').", "error": "IndexError('index 41 is out of bounds for axis 0 with size 41')", "parent_ids": ["f985bf91-92f7-48aa-b4f7-61d267801b5a"], "operator": null, "metadata": {}}
{"id": "ee62942f-4d02-429d-9797-6a0d18c21709", "fitness": 0.13296596489395388, "name": "AdaptiveClusteredSwarmOptimization", "description": "Leverage adaptive k-means clustering to dynamically focus exploration and exploitation in particle swarms.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget))) \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13297 with standard deviation 0.16633.", "error": "", "parent_ids": ["f985bf91-92f7-48aa-b4f7-61d267801b5a"], "operator": null, "metadata": {"aucs": [0.019565693120702554, 0.02598864384675026, 0.01820685092971086, 0.5795749734006581, 0.05428364419235654, 0.06024049641713203, 0.141018683140526, 0.14582580257938615, 0.15198889641836244]}}
{"id": "e43cf762-08e1-439f-adfe-f6d02f062950", "fitness": 0.07576134523270438, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance exploration-exploitation balance by dynamically adjusting mutation rates and integrating elitism during cluster adaptation.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget))) \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n                # Integrate elitism by retaining the best cluster center\n                if new_fitness < func(cluster_center):\n                    self.population[kmeans.labels_ == cluster_idx][np.random.randint(len(cluster_points))] = cluster_center\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 20, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07576 with standard deviation 0.04836.", "error": "", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {"aucs": [0.029188238430143842, 0.021401794914239547, 0.03652443954300999, 0.0609687654975396, 0.052322936742355663, 0.055574600607721014, 0.13601241521165008, 0.14692303803196494, 0.14293587811571473]}}
{"id": "234af40b-25bb-4d5f-97fa-6648af86bf5b", "fitness": 0.07440711405344148, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance adaptive clustering with fitness diversity measurement to improve convergence by maintaining exploration variance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        \n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_fitness = fitness[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            fitness_variance = np.var(cluster_fitness)\n            if len(cluster_points) > 0 and fitness_variance > 0.01:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07441 with standard deviation 0.05286.", "error": "", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {"aucs": [0.019565693120702554, 0.02598864384675026, 0.01820685092971086, 0.05254531583604649, 0.05428364419235654, 0.06024049641713203, 0.141018683140526, 0.14582580257938615, 0.15198889641836244]}}
{"id": "61e5d97b-9465-4c50-b139-03594182f25e", "fitness": 0.07254962179116914, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance swarm adaptability with entropy-driven hyperparameter tuning and cluster-based exploration balancing exploitation for improved optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.95\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07255 with standard deviation 0.05076.", "error": "", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {"aucs": [0.022285592531843257, 0.019570647210192083, 0.024721823487362404, 0.05575652646773066, 0.05229043844769565, 0.05265572561525966, 0.13618565503177604, 0.14618560633653677, 0.14329458099212578]}}
{"id": "9f8a50e3-56b9-4a4c-9641-a6506e17d6fb", "fitness": 0.07254962179116914, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance particle swarm optimization using dynamic clustering and adaptive entropy-guided exploration and exploitation balancing.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.15 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.95\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget))) \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07255 with standard deviation 0.05076.", "error": "", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {"aucs": [0.022285592531843257, 0.019570647210192083, 0.024721823487362404, 0.05575652646773066, 0.05229043844769565, 0.05265572561525966, 0.13618565503177604, 0.14618560633653677, 0.14329458099212578]}}
{"id": "a127a712-c3e4-4566-a146-fd3197edb257", "fitness": 0.0759996765330791, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance mutation factor adaptation for improved convergence in clustered swarms.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.8  # Enhanced mutation factor for better exploration\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget))) \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07600 with standard deviation 0.05367.", "error": "", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {"aucs": [0.016264634505739006, 0.017279173785963442, 0.03470900175200908, 0.05735754172644969, 0.052629086961894056, 0.05893846820700621, 0.14390674048465213, 0.15485352104606454, 0.14805892032793377]}}
{"id": "0b08e8ec-2b67-4a5b-b4f2-fddd1ba3d8ef", "fitness": 0.07440711405344148, "name": "AdaptiveClusteredSwarmOptimization", "description": "Refine the probability scaling factor for entropy-based adaptation to enhance exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        prob = np.clip(prob, 1e-10, None)  # Change to ensure valid probabilities\n        entropy = -np.sum(prob * np.log(prob))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget))) \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07441 with standard deviation 0.05286.", "error": "", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {"aucs": [0.019565693120702554, 0.02598864384675026, 0.01820685092971086, 0.05254531583604649, 0.05428364419235654, 0.06024049641713203, 0.141018683140526, 0.14582580257938615, 0.15198889641836244]}}
{"id": "fe06b6b4-6dd0-40ec-8353-4f5c0146d143", "fitness": -Infinity, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance adaptive clustering with selective local search to improve exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  \n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)  \n        self.mean_vector = np.zeros(dim)  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget))) \n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n                # Enhance exploration by triggering local search on selected clusters\n                if np.random.rand() < 0.3: \n                    candidate = self.local_search(new_point, func)\n                    candidate_fitness = func(candidate)\n                    self.evaluations += 1\n                    if candidate_fitness < new_fitness:\n                        new_fitness = candidate_fitness\n                        self.population[kmeans.labels_ == cluster_idx][min_idx] = candidate\n                        fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.covariance_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 26, "feedback": "An exception occurred: IndexError('index 11 is out of bounds for axis 0 with size 3').", "error": "IndexError('index 11 is out of bounds for axis 0 with size 3')", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {}}
{"id": "f9e7bcef-4c66-4d24-b503-f870cda666c1", "fitness": 0.14869996812432085, "name": "AdaptiveClusteredSwarmOptimization", "description": "Integrate adaptive Gaussian perturbations and elite preservation strategy to enhance diversity and robustness in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14870 with standard deviation 0.20608.", "error": "", "parent_ids": ["ee62942f-4d02-429d-9797-6a0d18c21709"], "operator": null, "metadata": {"aucs": [0.7164515375165249, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "818c6dca-a225-418f-a1e6-d47f0549026e", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance population diversity by introducing environment-driven adaptation in elite preservation strategy.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        self.mean_vector = np.mean(self.population[elite_indices], axis=0)  # Updated line\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 28, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "038a21fa-f6c5-4f6a-ba58-944ecb489c9a", "fitness": -Infinity, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance search efficiency by incorporating dynamic learning rates and memory-based elite retention to improve Adaptive Clustered Swarm Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.dynamic_learning_rate = 0.01  # New dynamic learning rate\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_memory = []  # Memory to keep track of elite agents\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def update_dynamic_learning_rate(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.dynamic_learning_rate *= 1.05\n        else:\n            self.dynamic_learning_rate *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.update_dynamic_learning_rate(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = self.dynamic_learning_rate  # Use dynamic learning rate\n        mutant = np.clip(a + F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < 0.9  # Fixed crossover rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(0.2 * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        elite_agents = self.population[elite_indices]\n        self.elite_memory = elite_agents if not self.elite_memory else np.vstack((self.elite_memory, elite_agents))\n        return self.elite_memory\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 29, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {}}
{"id": "8203d167-e51c-4771-b55d-ad56a76acaaf", "fitness": 0.08400345867708968, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance swarm optimization by combining adaptive Gaussian sampling, multi-layer clustering, and dynamic elite strategy to balance exploration and exploitation effectively.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            if len(cluster_points) > 0:\n                cluster_fitness = fitness[kmeans.labels_ == cluster_idx]\n                best_idx = np.argmin(cluster_fitness)\n                worst_idx = np.argmax(cluster_fitness)\n\n                # Mix best and worst for new exploratory point\n                new_point = 0.6 * cluster_points[best_idx] + 0.4 * cluster_points[worst_idx]\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < cluster_fitness[worst_idx]:\n                    self.population[kmeans.labels_ == cluster_idx][worst_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][worst_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma / 2, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08400 with standard deviation 0.05149.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.14074582794835344, 0.016933588292372237, 0.01954593820373407, 0.05094813924058195, 0.05426915425055223, 0.055747330144921725, 0.1348365929325267, 0.13857179064504022, 0.14443276643572456]}}
{"id": "def62459-d654-4774-b205-697556f07d2d", "fitness": 0.07153033406978876, "name": "QuantumClusteredSwarmOptimization", "description": "Enhance swarm-based optimization by incorporating quantum-inspired position updates and a decentralized information exchange mechanism to improve global exploration and local exploitation.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass QuantumClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n        self.quantum_probability = 0.1\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def quantum_position_update(self, agent, func):\n        new_agent = np.copy(agent)\n        for i in range(self.dim):\n            if np.random.rand() < self.quantum_probability:\n                new_agent[i] = self.best_agent[i] + norm.rvs(0, np.abs(self.best_agent[i] - agent[i]))\n        new_agent = np.clip(new_agent, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.quantum_position_update(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 31, "feedback": "The algorithm QuantumClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07153 with standard deviation 0.05117.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.018179504847336325, 0.016734462860533816, 0.022089500137468576, 0.047405717802771696, 0.058427075344599455, 0.05896110192574944, 0.1375184514646629, 0.13995588580050655, 0.14450130644447]}}
{"id": "34994b20-9e82-4b5e-bb82-37cd895a5dfd", "fitness": 0.07496528177081503, "name": "AdaptiveClusteredSwarmOptimization", "description": "Introduce an elite exploration mechanism and tune hyperparameters for improved convergence in AdaptiveClusteredSwarmOptimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.6  # Adjusted from 0.5\n        self.CR = 0.85  # Adjusted from 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n    \n    def elite_exploration(self, elite_population, func):  # New elite exploration\n        for elite in elite_population:\n            candidate = self.covariance_guided_search(elite, func)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(self.best_agent):\n                self.best_agent = candidate\n                self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            self.elite_exploration(elite_population, func)  # Added elite exploration\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07497 with standard deviation 0.05366.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.018023623044975512, 0.013513027882695705, 0.02607370549650434, 0.05479586180842322, 0.055671371656516255, 0.06560181286214484, 0.15288131105161296, 0.1412306972664087, 0.1468961248680538]}}
{"id": "519a22ae-38bc-451f-be6c-934f2dc545f3", "fitness": 0.07358455212727594, "name": "AdaptiveClusteredSwarmOptimization", "description": "Incorporate dynamic mutation scaling based on fitness variance to improve exploration and convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        fitness_variance = np.var(fitness)  # New line\n        mutant = np.clip(a + self.F * fitness_variance * (b - c), lb, ub)  # Modified line\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07358 with standard deviation 0.05278.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.013546619062062448, 0.013616048885920717, 0.03442694028994786, 0.05375028634087742, 0.05670732508132781, 0.05522301516511241, 0.1464427507862366, 0.14110284149481778, 0.14744514203918047]}}
{"id": "d6aa12d1-7100-46b8-8485-b06fffbe93c2", "fitness": 0.07241381939648142, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance Adaptive Clustered Swarm Optimization with multi-scale neighborhood search and elite reinforcement for improved exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def multi_scale_search(self, agent, func):\n        scales = [0.1, 0.05, 0.01]\n        new_agent = agent.copy()\n        for scale in scales:\n            noise = np.random.normal(0, scale, self.dim)\n            candidate = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n            if func(candidate) < func(new_agent):\n                new_agent = candidate\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            if len(cluster_points) > 0:\n                cluster_center = np.mean(cluster_points, axis=0)\n                new_point = np.clip(cluster_center, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.multi_scale_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07241 with standard deviation 0.05874.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.01300007531879599, 0.01613644189673491, 0.01369631993861642, 0.04815610198394171, 0.05738725284406332, 0.049077147162576606, 0.13916489249299657, 0.14030372905965094, 0.1748024138709563]}}
{"id": "6f324203-2f23-4ac4-bd3c-f1ea376105b5", "fitness": 0.07858595128707829, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance clustering-based swarm optimization by integrating dynamic learning rates and mutation strategies for improved exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.85, 1.0\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1  \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2 \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def dynamic_learning_rate(self, improvement):\n        if improvement > 0:\n            self.F = np.random.uniform(self.F_min, self.F_max)\n            self.CR = np.random.uniform(self.CR_min, self.CR_max)\n        else:\n            self.F, self.CR = self.F_min, self.CR_min\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            improvement = np.mean(fitness) - np.min(fitness)\n            self.dynamic_learning_rate(improvement)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n        return self.best_agent", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07859 with standard deviation 0.04447.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.037405557124216005, 0.041366465449635514, 0.03476883775955808, 0.054085821261376954, 0.05520778880029564, 0.06362090124830377, 0.13860047631906303, 0.13928183550554085, 0.14293587811571473]}}
{"id": "8681acee-1b07-4da5-8338-8593807fefa8", "fitness": 0.07464454213103267, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance swarm optimization convergence by introducing dynamic crossover rates and memory-based mutation to balance exploration and exploitation effectively.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n        self.memory_size = 5\n        self.memory = []\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def dynamic_crossover(self):\n        self.CR = max(0.5, 1 - (self.evaluations / self.budget))\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n            self.update_memory(trial)\n\n    def update_memory(self, agent):\n        self.memory.append(agent)\n        if len(self.memory) > self.memory_size:\n            self.memory.pop(0)\n\n    def memory_based_mutation(self, agent, func):\n        if len(self.memory) < self.memory_size:\n            return agent\n        mem_agent = self.memory[np.random.randint(0, len(self.memory))]\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(mem_agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            self.dynamic_crossover()\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.memory_based_mutation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07464 with standard deviation 0.04853.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.034507288163348804, 0.02864687721528092, 0.03862050602004785, 0.046567875496073885, 0.048745753875427345, 0.047132871442390534, 0.13502102382401338, 0.14158947831857427, 0.150969204824137]}}
{"id": "d75a7d57-8b2f-47e7-b030-770f51f95cff", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Slightly increase the elite_fraction to preserve more high-quality solutions, enhancing convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.25  # Fraction of elite members to preserve (Changed from 0.2 to 0.25)\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "6289fb56-2797-4201-b7da-eb85770894db", "fitness": 0.0752925479354916, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance diversity and exploration by integrating chaotic maps for parameter adaptation in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def chaotic_map(self, k):\n        return 4 * k * (1 - k)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n        k = np.random.rand()\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            k = self.chaotic_map(k)  # Update using chaotic map\n            self.F = 0.4 + 0.3 * k  # Chaotic update of F\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07529 with standard deviation 0.05285.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.0253824857226016, 0.01740260830703999, 0.01878453119757173, 0.05961966281986397, 0.05152255390771754, 0.06592765052744798, 0.1523396520172816, 0.14061346301553512, 0.14604032390436483]}}
{"id": "bc2bc2e7-961c-4681-948e-148415dbc315", "fitness": 0.07124525725215408, "name": "EnhancedClusteredSwarmOptimization", "description": "Introduce self-adaptive mutation scaling and dynamic elite cluster formation to improve the exploration-exploitation balance in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def dynamic_mutation_scaling(self, fitness):\n        best_fitness = np.min(fitness)\n        avg_fitness = np.mean(fitness)\n        scaling_factor = 1 + 0.5 * (avg_fitness - best_fitness) / (np.std(fitness) + 1e-10)\n        self.F = 0.5 * scaling_factor\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        elite_population = self.elite_preservation(fitness)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            if len(cluster_points) > 0:\n                cluster_center = np.mean(cluster_points, axis=0)\n                for elite in elite_population:\n                    new_point = 0.5 * (cluster_center + elite)\n                    new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                    new_fitness = func(new_point)\n                    self.evaluations += 1\n                    if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                        min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                        self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                        fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                        if new_fitness < func(self.best_agent):\n                            self.best_agent = new_point\n                            self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_mutation_scaling(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n\n        return self.best_agent", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07125 with standard deviation 0.05155.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019510322500193245, 0.024353999146858207, 0.016749693843665647, 0.05510467051195467, 0.05090894924788525, 0.04936933484760364, 0.14296735726763132, 0.13930710978788008, 0.14293587811571473]}}
{"id": "56ba8f73-6789-4a83-8321-58bd55a49d6a", "fitness": 0.07538122123157043, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance exploration by dynamically adjusting the number of clusters based on population diversity.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        population_diversity = np.std(self.population, axis=0).mean()\n        n_clusters = max(2, int(self.population_size * 0.1 / (population_diversity + 1e-10)))  # Changed line\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07538 with standard deviation 0.05235.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.023796943752349642, 0.02701179094486983, 0.01591050705623398, 0.06175779729700426, 0.054416782062934876, 0.0563149049422611, 0.14551901380445698, 0.1477048341138283, 0.1459984171101949]}}
{"id": "729ca2d0-90ff-408f-9dd5-9a4e82bf5173", "fitness": 0.07198541333530323, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance adaptive clustered swarm optimization by introducing entropy-controlled covariance adaptation and elite perturbation to improve convergence speed and solution quality.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_controlled_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.covariance_matrix *= 1.1\n        else:\n            self.covariance_matrix *= 0.9\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_controlled_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def elite_perturbation(self, elite, func):\n        for agent in elite:\n            perturb = np.random.normal(0, 0.001, self.dim)\n            new_agent = np.clip(agent + perturb, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(new_agent)\n            self.evaluations += 1\n            if new_fitness < func(self.best_agent):\n                self.best_agent = new_agent\n                self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            self.elite_perturbation(elite_population, func)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07199 with standard deviation 0.05216.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.015076264788086435, 0.020528490712143355, 0.016549083132298414, 0.05591887243586169, 0.06042807159177699, 0.053342690318979535, 0.13589470591822228, 0.14203060465959083, 0.14809993646076947]}}
{"id": "b724749f-ce0a-4317-bd92-3274bb3105fb", "fitness": 0.07413253671285047, "name": "AdaptiveClusteredSwarmOptimization", "description": "Refined AdaptiveClusteredSwarmOptimization integrates slight F and CR adjustment for enhanced convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.55  # Changed from 0.5 to 0.55\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2 \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07413 with standard deviation 0.05260.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.02099600063467255, 0.01511557327400892, 0.020774867165743727, 0.06141659468538252, 0.05710483677101175, 0.05764579278485005, 0.13806645071663004, 0.15068085800163955, 0.14539185638171515]}}
{"id": "d1c64587-ce5c-4455-b3a3-45af8435cf4b", "fitness": 0.07867249450515494, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance clustered swarm optimization by incorporating a memory-based elite recombination mechanism and dynamically adjusting exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.history = []\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.evaluations += self.population_size\n        self.history.append(self.best_agent)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n\n    def local_search(self, agent, func):\n        noise_scale = 0.1 * (1 - (self.evaluations / self.budget))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n\n    def elite_preservation_and_recombination(self, func, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        elites = self.population[elite_indices]\n        \n        new_agents = []\n        for i in range(elite_count):\n            for j in range(i + 1, elite_count):\n                recombined = 0.5 * (elites[i] + elites[j])\n                recombined = np.clip(recombined, func.bounds.lb, func.bounds.ub)\n                new_agents.append(recombined)\n        \n        new_agents = np.array(new_agents)\n        for agent in new_agents:\n            agent_fitness = func(agent)\n            self.evaluations += 1\n            if agent_fitness < np.max(fitness):\n                replace_idx = np.argmax(fitness)\n                self.population[replace_idx] = agent\n                fitness[replace_idx] = agent_fitness\n                if agent_fitness < func(self.best_agent):\n                    self.best_agent = agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_clustering(func, fitness)\n            self.elite_preservation_and_recombination(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n\n        return self.best_agent", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07867 with standard deviation 0.04808.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.0341485112921176, 0.0275747726084572, 0.03985199322967359, 0.06265876872640097, 0.05298711397581379, 0.056039771917510195, 0.1455149322434065, 0.13744546123293544, 0.15183112532007914]}}
{"id": "c0f5a82b-7a73-40a0-a519-60cbb1842db1", "fitness": 0.0752409827431045, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance adaptive Gaussian perturbations with progressive sigma scaling for refined exploration.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        progress_factor = (1 - (self.evaluations / self.budget))\n        sigma = np.std(self.population, axis=0) * progress_factor\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 44, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07524 with standard deviation 0.05013.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.030204598466270327, 0.018153840617878503, 0.019746239869665505, 0.06208038093473911, 0.056726556210089485, 0.06303785688007035, 0.1441794473938035, 0.1364455538557724, 0.1465943704596514]}}
{"id": "6a4bd8d5-05c5-40ea-a24d-eeef4bbce95e", "fitness": 0.07270199675387184, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance the strategy by employing adaptive mutation strategies and introducing focal targeted exploration to improve convergence robustness and efficiency.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.92\n        else:\n            self.F *= 0.95\n            self.CR *= 1.08\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.07\n        else:\n            self.covariance_matrix *= 0.93\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.3))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func, scale_factor=0.1):\n        noise_scale = max(0.02, scale_factor * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def targeted_exploration(self, index, func, fitness):\n        elite_population = self.elite_preservation(fitness)\n        agent = self.population[index]\n        distances = np.linalg.norm(elite_population - agent, axis=1)\n        closest_elite = elite_population[np.argmin(distances)]\n        direction = np.clip(closest_elite - agent, func.bounds.lb, func.bounds.ub)\n        step_size = 0.3 * np.linalg.norm(direction)\n        new_agent = np.clip(agent + (step_size * direction), func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func, scale_factor=0.15)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.targeted_exploration(idx, func, fitness)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07270 with standard deviation 0.05282.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.026909991036688563, 0.016156651258599997, 0.01785737970546919, 0.05253429976427704, 0.057591013626970056, 0.04902256618508605, 0.14910473483463915, 0.13989759437050997, 0.14524374000260665]}}
{"id": "d6ac5b17-3b1c-4307-805b-caade0ec4151", "fitness": 0.07095763320679534, "name": "EnhancedClusteredSwarmOptimization", "description": "Introduce a dynamic elite enhancement strategy and adaptive mutation scaling to improve convergence in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n        self.elite_enhancement_factor = 1.1\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0) * self.elite_enhancement_factor\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def elite_enhancement(self, func, elite_population, fitness):\n        enhanced_elite = []\n        for elite in elite_population:\n            new_agent = self.adaptive_gaussian_perturbation(elite, func)\n            new_fitness = func(new_agent)\n            self.evaluations += 1\n            if new_fitness < func(self.best_agent):\n                self.best_agent = new_agent\n                self.last_improvement_evaluation = self.evaluations\n            enhanced_elite.append(new_agent)\n        return np.array(enhanced_elite)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.entropy_based_adaptation(fitness)\n            elite_population = self.elite_preservation(fitness)\n            enhanced_elite = self.elite_enhancement(func, elite_population, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07096 with standard deviation 0.05115.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.028305391376739264, 0.02337972575286007, 0.01481991077043443, 0.05231473302555956, 0.047725773988188, 0.04809672115609309, 0.13555473737641366, 0.14438625603382094, 0.14403544938104906]}}
{"id": "d4c300e3-3c3c-419f-96ce-5949d4d40122", "fitness": 0.07755731189342771, "name": "EnhancedClusteredSwarmOptimization", "description": "Implement dynamic feedback-driven covariance matrix adaptation to enhance exploration and convergence in clustered adaptive swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.elite_fraction = 0.2\n        self.cov_matrices = [np.identity(dim) for _ in range(self.population_size)]\n        self.mean_vectors = [np.zeros(dim) for _ in range(self.population_size)]\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def adaptive_covariance_matrix_adaptation(self, idx, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.cov_matrices[idx] *= 1.05\n        else:\n            self.cov_matrices[idx] *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def cluster_covariance_guided_search(self, cluster_idx, cluster_points, func, fitness):\n        cluster_center = np.mean(cluster_points, axis=0)\n        agent = cluster_points[np.random.randint(len(cluster_points))]\n        z = np.random.multivariate_normal(self.mean_vectors[cluster_idx], self.cov_matrices[cluster_idx])\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        new_fitness = func(new_agent)\n        self.evaluations += 1\n        if new_fitness < np.min(fitness[cluster_idx]):\n            fitness[cluster_idx] = new_fitness\n            self.population[cluster_idx] = new_agent\n            if new_fitness < func(self.best_agent):\n                self.best_agent = new_agent\n                self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        clusters = [self.population[kmeans.labels_ == i] for i in range(n_clusters)]\n        for i, cluster_points in enumerate(clusters):\n            if len(cluster_points) > 0:\n                self.cluster_covariance_guided_search(i, cluster_points, func, fitness)\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.adaptive_covariance_matrix_adaptation(idx, fitness)\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n        return self.best_agent", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07756 with standard deviation 0.04955.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.03269323233592725, 0.02821428635847445, 0.02267770515012124, 0.06454161610864939, 0.05381486008711367, 0.061582470822277635, 0.15146060659480975, 0.1400951514677613, 0.14293587811571473]}}
{"id": "d1493417-a663-47b8-b5c9-83f378ab5ddf", "fitness": 0.07416249107867978, "name": "RefinedClusteredSwarmOptimization", "description": "Incorporate adaptive mutation scaling and fitness-weighted migration to improve convergence speed and solution quality in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass RefinedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.min_population_size = 10\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.mutation_scale = 1.0\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.entropy_threshold = 0.1\n        self.elite_fraction = 0.2\n        self.covariance_matrix = np.identity(dim)\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.evaluations += self.population_size\n\n    def adapt_mutation_scale(self, fitness):\n        fitness_diff = np.max(fitness) - np.min(fitness)\n        self.mutation_scale = max(0.1, 1.0 * (fitness_diff / max(1e-9, np.sum(fitness))))\n\n    def fitness_weighted_migration(self, func, fitness):\n        weights = 1.0 / (1.0 + fitness - np.min(fitness))\n        weighted_population = self.population * weights[:, np.newaxis]\n        new_population = np.random.permutation(weighted_population)\n        \n        for idx in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            candidate = new_population[idx]\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < fitness[idx]:\n                self.population[idx] = candidate\n                fitness[idx] = candidate_fitness\n                if candidate_fitness < func(self.best_agent):\n                    self.best_agent = candidate\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.mutation_scale * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR_base\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                cluster_center = np.mean(cluster_points, axis=0)\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adapt_mutation_scale(fitness)\n            self.fitness_weighted_migration(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n            self.adaptive_clustering(func, fitness)\n            self.elite_preservation(fitness)\n\n        return self.best_agent", "configspace": "", "generation": 48, "feedback": "The algorithm RefinedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07416 with standard deviation 0.05379.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.017077119805953944, 0.02216016860150849, 0.014394954952145489, 0.06147116806110642, 0.05488564001401253, 0.058619760144443145, 0.15523115000630872, 0.14068658000692458, 0.14293587811571473]}}
{"id": "2bbcff38-4adf-4837-8734-e6c4433a8e9b", "fitness": 0.07268122044362368, "name": "DualPopulationAdaptiveSwarmOptimization", "description": "Enhance diversity and convergence speed by introducing a dual population strategy with adaptive perturbation and clustering for improved exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass DualPopulationAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.main_population_size = 50\n        self.secondary_population_size = int(0.5 * self.main_population_size)\n        self.F = 0.5\n        self.CR = 0.9\n        self.main_population = None\n        self.secondary_population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.entropy_threshold = 0.1\n        self.elite_fraction = 0.2\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n\n    def initialize_populations(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.main_population = np.random.uniform(lb, ub, (self.main_population_size, self.dim))\n        self.secondary_population = np.random.uniform(lb, ub, (self.secondary_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.main_population])\n        self.best_agent = self.main_population[np.argmin(fitness)]\n        self.evaluations += self.main_population_size + self.secondary_population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def differential_evolution(self, target_idx, func, population, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(len(population)) if i != target_idx]\n        a, b, c = population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n\n    def cluster_and_relocate(self, func, population, fitness):\n        n_clusters = max(2, len(population) // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.main_population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_populations(func)\n        main_fitness = np.array([func(ind) for ind in self.main_population])\n        secondary_fitness = np.array([func(ind) for ind in self.secondary_population])\n\n        while self.evaluations < self.budget:\n            self.entropy_based_adaptation(main_fitness)\n            self.covariance_matrix_adaptation(main_fitness)\n            self.cluster_and_relocate(func, self.main_population, main_fitness)\n\n            for idx in range(self.main_population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, self.main_population, main_fitness)\n                self.evaluations += 1\n\n            if self.evaluations < self.budget:\n                for idx in range(self.secondary_population_size):\n                    if self.evaluations >= self.budget:\n                        break\n                    candidate = self.adaptive_gaussian_perturbation(self.secondary_population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < secondary_fitness[idx]:\n                        self.secondary_population[idx] = candidate\n                        secondary_fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n\n        return self.best_agent", "configspace": "", "generation": 49, "feedback": "The algorithm DualPopulationAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07268 with standard deviation 0.05291.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.01835168767049511, 0.014969405165770278, 0.027674069291644954, 0.05288836685267273, 0.054025112507137596, 0.05192567296119399, 0.13684771123399664, 0.15311981584221068, 0.14432914246749118]}}
{"id": "1abf4f76-6d17-4a28-9f76-0fb93f081f1d", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance adaptive clustered swarm optimization by introducing dynamic covariance scaling and refined elite preservation to improve convergence efficiency.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.3  # Increased elite fraction for better preservation\n        self.dynamic_covariance_scale = 1.1  # New parameter for dynamic scaling\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= self.dynamic_covariance_scale  # Dynamic scaling\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "15923f39-4599-44bf-8119-c77700c4b452", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Improves exploitation by enhancing covariance-guided search and optimizing elite retention strategy.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim) * 0.5  # Adjusted for enhanced exploitation\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.3  # Increased elite fraction for better retention\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 51, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "507d701a-6463-469d-92b7-341b72e93380", "fitness": 0.07141760674123583, "name": "AdaptiveClusteredSwarmOptimization", "description": "Introduce adaptive mutation scaling based on fitness variability to enhance exploration in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        # Adjusted mutation scaling\n        fitness_range = np.ptp(fitness) + 1e-10\n        scaled_F = self.F + 0.2 * (fitness[target_idx] - np.min(fitness)) / fitness_range\n        mutant = np.clip(a + scaled_F * (b - c), lb, ub)\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07142 with standard deviation 0.05116.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019476572025252548, 0.01626900011576371, 0.024541663011938386, 0.05244255376726281, 0.04962300359846106, 0.05768157880370384, 0.13773271189933867, 0.13548218086723707, 0.14950919658216444]}}
{"id": "adf3bebb-aa8e-4a6f-8baf-e423897a1229", "fitness": 0.07514785545284589, "name": "EnhancedClusteredSwarmOptimization", "description": "Introduce adaptive mutation scaling and cluster-based local exploitation to enhance exploration-exploitation balance in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n        self.mutation_adaptation_rate = 0.1\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def adaptive_mutation_scaling(self, fitness):\n        improvement = np.min(fitness)\n        if improvement < np.mean(fitness):\n            self.F *= (1 + self.mutation_adaptation_rate)\n        else:\n            self.F *= (1 - self.mutation_adaptation_rate)\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                for _ in range(3):\n                    noise = np.random.normal(0, 0.1, self.dim)\n                    new_point = np.clip(cluster_center + noise, func.bounds.lb, func.bounds.ub)\n                    new_fitness = func(new_point)\n                    self.evaluations += 1\n                    if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                        min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                        self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                        fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                        if new_fitness < func(self.best_agent):\n                            self.best_agent = new_point\n                            self.last_improvement_evaluation = self.evaluations\n                            break\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_mutation_scaling(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n        return self.best_agent", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07515 with standard deviation 0.04741.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.046117760356405246, 0.023557951164452695, 0.017184398376979937, 0.05944330984060797, 0.06327947113956867, 0.04932882240572545, 0.13590567754668137, 0.13857743012947688, 0.14293587811571473]}}
{"id": "000e479d-e89d-4ab2-a26f-1256db319748", "fitness": 0.07487468808003128, "name": "AdaptiveClusteredSwarmOptimization", "description": "Integrate dynamic mutation scaling and enhanced elite reinforcement to improve search efficiency and convergence in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n        self.dynamic_mutation_factor = 0.05  # New attribute: mutation factor for dynamic scaling\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        self.F = self.dynamic_mutation_factor * np.random.rand()  # Change: Dynamic mutation scaling\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        elites = self.population[elite_indices]\n        self.mean_vector = np.mean(elites, axis=0)  # Change: Enhance elite reinforcement by updating mean vector\n        return elites\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 54, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07487 with standard deviation 0.05077.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.015710533108224123, 0.014847942197991126, 0.020617909568214743, 0.06762609357375471, 0.05882446209043135, 0.07546872862591802, 0.1392793490816654, 0.13845245751240198, 0.14304471696168009]}}
{"id": "85a6113c-f81e-4f12-8543-9c5f8d604886", "fitness": 0.06952765047662185, "name": "EnhancedAdaptiveClusteredSwarmOptimization", "description": "Enhance AdaptiveClusteredSwarmOptimization by introducing a multi-scale exploration strategy and enhanced elite preservation for improved convergence and exploration.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n        self.exploration_scales = [0.05, 0.1, 0.2]\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def multi_scale_exploration(self, agent, func):\n        best_candidate = agent\n        best_fitness = func(agent)\n        for scale in self.exploration_scales:\n            noise = np.random.normal(0, scale, self.dim)\n            candidate = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < best_fitness:\n                best_candidate, best_fitness = candidate, candidate_fitness\n        return best_candidate\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.multi_scale_exploration(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06953 with standard deviation 0.05247.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.013230363152690994, 0.012203736172160529, 0.014562556237003865, 0.05308253868569024, 0.05604790649850633, 0.05819916041607853, 0.14101370194927687, 0.1344730130624745, 0.14293587811571473]}}
{"id": "2c8b8f0f-1da7-4d0b-888e-0425ae3cb345", "fitness": 0.07315915710609446, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance mutation step by increasing diversity through dynamic scaling of F in differential evolution.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        dynamic_F = self.F * (1 + 0.1 * np.random.rand())  # Dynamic scaling of F\n        mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 56, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07316 with standard deviation 0.05648.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.016936929718477933, 0.015509379179603155, 0.017559907423367216, 0.048083145652100145, 0.05820255329922841, 0.05276593271743635, 0.14380949566874102, 0.16262919218018113, 0.14293587811571473]}}
{"id": "a8c28b6b-5d77-4ad6-b9b3-7895cbef067e", "fitness": 0.07382300660383846, "name": "AdaptiveClusteredSwarmOptimization", "description": "Implement a multi-modal stimulating strategy and hybridize with a gradient-based local search to enhance exploitation in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def gradient_based_local_search(self, agent, func):\n        step_size = 0.1 * (1 - (self.evaluations / self.budget))\n        grad_approx = np.random.normal(0, step_size, self.dim)\n        new_agent = np.clip(agent - grad_approx, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                new_point = self.multi_modal_stimulation(cluster_center, cluster_points, func)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def multi_modal_stimulation(self, cluster_center, cluster_points, func):\n        random_point = cluster_points[np.random.randint(len(cluster_points))]\n        direction = np.random.uniform(-1, 1, self.dim)\n        new_point = cluster_center + direction * np.linalg.norm(cluster_center - random_point)\n        return np.clip(new_point, func.bounds.lb, func.bounds.ub)\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.gradient_based_local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07382 with standard deviation 0.05223.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.015169057408895847, 0.018662280449468382, 0.01684514195991993, 0.06051660486741994, 0.07026820310336479, 0.05492251753754929, 0.13687339811422328, 0.1453873931607952, 0.1457624628329095]}}
{"id": "55a2423d-d6cf-4482-a600-c25f97660bfc", "fitness": 0.06959299711835146, "name": "DynamicSwarmOptimization", "description": "Introduce dynamic learning rate and adaptive elite replacement in clustered swarm optimization to balance exploration and exploitation effectively.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass DynamicSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.learning_rate = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.dynamic_covariance = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_adapted_learning_rate(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.learning_rate *= 1.05\n        else:\n            self.learning_rate *= 0.95\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.dynamic_covariance *= 1.05\n        else:\n            self.dynamic_covariance *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_adapted_learning_rate(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.learning_rate * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.dynamic_covariance)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            if len(cluster_points) > 0:\n                best_point = cluster_points[np.argmin(fitness[kmeans.labels_ == cluster_idx])]\n                new_point = self.covariance_guided_search(best_point, func)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation_replacement(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        new_elite_indices = np.random.choice(np.arange(self.population_size), elite_count, replace=False)\n        self.population[elite_indices] = self.population[new_elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            self.elite_preservation_replacement(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 58, "feedback": "The algorithm DynamicSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06959 with standard deviation 0.05297.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.013577813378130021, 0.013820660561821074, 0.015013035395671892, 0.055729472129794955, 0.05473098311553415, 0.050778763951868866, 0.13910809304057536, 0.14064227437605203, 0.14293587811571473]}}
{"id": "c98cdc59-b8a0-40f5-8eb4-23bfbdd5f0b7", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance convergence by adjusting the covariance matrix adaptation scaling factor.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2 \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.03  # Changed from 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 59, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "1ee4dc27-b068-423f-979d-52c78d7c1aef", "fitness": 0.07559320668231609, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance swarm dynamics by incorporating adaptive inertia weight adjustment and step size decay for improved convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n        self.inertia_weight = 0.9  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0) * self.inertia_weight\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                self.inertia_weight *= 0.99  \n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 60, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07559 with standard deviation 0.04950.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.02312839127543298, 0.021527273415142156, 0.0286118405460023, 0.05645265943782518, 0.05945744351585269, 0.06407419572699391, 0.13743019080137342, 0.14464209871961287, 0.14501476670260927]}}
{"id": "3c6e278e-8a6a-4c33-ab69-8c3a28193181", "fitness": 0.0752013184043907, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance the existing adaptive clustered swarm optimization by integrating a novel entropy-based adaptive learning rate mechanism and a self-adaptive mutation strategy for improved convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.learning_rate = 0.1\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_learning_rate(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        self.learning_rate = min(1.0, max(0.01, self.learning_rate * (1 + 0.1 * (entropy - self.entropy_threshold))))\n\n    def self_adaptive_mutation(self, agent, func):\n        sigma = self.learning_rate * np.std(self.population, axis=0)\n        mutation = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + mutation, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.entropy_based_learning_rate(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.self_adaptive_mutation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.04993.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.027880466600153975, 0.02929635650478868, 0.02474572335940839, 0.05424486951779506, 0.052582908933829886, 0.05712571522322041, 0.13209909459929203, 0.15196984669585156, 0.14686688420517635]}}
{"id": "0b3f57ac-874f-4bd0-8869-472e93f0fe25", "fitness": 0.0722109502957526, "name": "EnhancedAdaptiveClusteredSwarmOptimization", "description": "Integrate swarm intelligence with adaptive covariance matrix dynamics and entropy-driven mutations to enhance exploitation while maintaining exploration balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n        self.mutation_factor = 0.1\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n            self.mutation_factor *= 1.05\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n            self.mutation_factor *= 0.95\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0) * self.mutation_factor\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07221 with standard deviation 0.05127.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.01801241444735413, 0.019105287750428412, 0.01765868572462359, 0.05654451054698051, 0.05451715533221835, 0.06098863016558287, 0.1367502139522493, 0.1419661677901436, 0.1443554869521927]}}
{"id": "69782d51-518f-4f29-b38f-921f90477e6b", "fitness": 0.07556341730958233, "name": "EnhancedAdaptiveClusteredSwarmOptimization", "description": "Improve convergence by integrating differential evolution with a novel entropy-guided dynamic clustering and adaptive mutation strategy.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass EnhancedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.2 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.95\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        adjustment_factor = 1.05 if improvement > 0 else 0.95\n        self.covariance_matrix *= adjustment_factor\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.1\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_mutation(self, elite_members, func):\n        for agent in elite_members:\n            sigma = np.std(self.population, axis=0) / 2\n            g_noise = np.random.normal(0, sigma, self.dim)\n            new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(new_agent)\n            if new_fitness < func(agent):\n                agent[:] = new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            self.adaptive_mutation(elite_population, func)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n        return self.best_agent", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07556 with standard deviation 0.04967.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.025688614324986703, 0.029063402018349782, 0.025309643374014756, 0.05272467555741056, 0.05450399480436452, 0.06210835234749745, 0.14656813167266336, 0.1407997422748325, 0.14330419941212125]}}
{"id": "003c158a-0be8-4f29-b486-0d1fb248298b", "fitness": 0.07346205804006463, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance clustered swarm optimization with adaptive momentum and diversity tracking to better balance exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n        self.momentum = np.zeros((self.population_size, self.dim))\n        self.momentum_factor = 0.9\n    \n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def momentum_perturbation(self, idx, func):\n        current_agent = self.population[idx]\n        self.momentum[idx] = self.momentum_factor * self.momentum[idx] + np.random.normal(0, 0.1, self.dim)\n        new_agent = np.clip(current_agent + self.momentum[idx], func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.momentum_perturbation(idx, func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07346 with standard deviation 0.04982.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.026590676847495498, 0.01776241897099995, 0.022135185843587646, 0.05694281022326353, 0.05614001094130838, 0.05910527054387571, 0.13898501676628083, 0.14056125410805542, 0.14293587811571473]}}
{"id": "65982ce5-cfca-4f9f-affb-9f4c829dcfb2", "fitness": 0.07187597469647478, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance evolutionary diversity and convergence by introducing a dynamic elite perturbation mechanism.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def dynamic_elite_perturbation(self, elite_population, func):\n        for elite in elite_population:\n            perturbed_elite = self.adaptive_gaussian_perturbation(elite, func)\n            perturbed_fitness = func(perturbed_elite)\n            if perturbed_fitness < func(self.best_agent):\n                self.best_agent = perturbed_elite\n                self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            self.dynamic_elite_perturbation(elite_population, func)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07188 with standard deviation 0.05103.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.016004987133444337, 0.017290058125615904, 0.025271990971548863, 0.052754644960997465, 0.05542350307456223, 0.05733480274013869, 0.13968800211508614, 0.14017990503116462, 0.14293587811571473]}}
{"id": "1bc1d93c-5922-431d-a721-67d1f0efdb51", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance exploitation by introducing strategy to select better trial vectors in differential evolution based on fitness improvement threshold.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx] and (fitness[target_idx] - trial_fitness) > 1e-8:  # Improved line\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 66, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "869dc521-e849-42bb-8701-18ed810970b9", "fitness": 0.07126213362271278, "name": "EnhancedClusteredSwarmOptimization", "description": "Introduce inertia-weighted velocity adaptation and chaotic local search to enhance global exploration and local exploitation in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.inertia_weight = 0.7\n        self.population = None\n        self.velocities = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def inertia_weighted_velocity_update(self):\n        self.velocities *= self.inertia_weight\n        self.velocities += np.random.uniform(-0.1, 0.1, self.velocities.shape)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def chaotic_local_search(self, agent, func):\n        logistic_map = np.random.rand()\n        logistic_map = 4 * logistic_map * (1 - logistic_map)\n        noise = logistic_map * np.random.normal(0, 0.1, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.inertia_weighted_velocity_update()\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.chaotic_local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07126 with standard deviation 0.05058.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.016198001798754746, 0.014852873756994178, 0.024656228813309644, 0.05392788178403185, 0.05757287732830618, 0.05617004782552981, 0.13633037310337048, 0.1387150400784033, 0.14293587811571473]}}
{"id": "2bdae612-42df-43d0-aaa6-e3220de82bc7", "fitness": 0.07373245607869794, "name": "AdaptiveClusteredSwarmOptimization", "description": "Integrate adaptive Gaussian perturbations and elite preservation strategy to enhance diversity and robustness in clustered swarm optimization, with refined noise scale for local search.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = 0.05  # Refined noise scale\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07373 with standard deviation 0.05222.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.02297682987946803, 0.019353511008615376, 0.023256321237518196, 0.05384217381610401, 0.05060359644933643, 0.059288004071121114, 0.1360720656429627, 0.15526372448744086, 0.14293587811571473]}}
{"id": "44c4fa95-50c7-43dd-a080-8486877fb634", "fitness": 0.07432404233111839, "name": "RefinedClusteredSwarmOptimization", "description": "Incorporate adaptive inertia weights and Lvy flight perturbations to augment diversity and convergence speed in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import levy\n\nclass RefinedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def levy_flight_perturbation(self, agent, func):\n        levy_step = levy.rvs(size=self.dim)\n        new_agent = np.clip(agent + levy_step * self.inertia_weight, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def update_inertia_weight(self):\n        self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * 0.99)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.levy_flight_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n            self.update_inertia_weight()\n\n        return self.best_agent", "configspace": "", "generation": 69, "feedback": "The algorithm RefinedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07432 with standard deviation 0.05320.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.018090854882860996, 0.016879528520329257, 0.0230466194665625, 0.05742995641559878, 0.04938069321446237, 0.06634857266169503, 0.15049519290336488, 0.14366505541105068, 0.14357990750414096]}}
{"id": "b729bf4f-7921-4f66-8a66-9697bb0b0b70", "fitness": -Infinity, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance the exploitation phase using Lvy flights and dynamic elite adjustment to improve convergence speed and exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.15  # Adjusted elite fraction\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def levy_flight(self, agent, func):  # New method for Lvy flights\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v)**(1 / beta)\n        new_agent = np.clip(agent + step, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.levy_flight(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 70, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {}}
{"id": "48f07a1e-1d74-42f3-a63c-77d5e1430b8a", "fitness": 0.07819533905410908, "name": "QuantumAdaptiveClusteredSwarmOptimization", "description": "Incorporate adaptive learning rates and quantum-inspired searches to enhance exploration and exploitation in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass QuantumAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        learning_rate = 0.1 * np.exp(-entropy)\n        if entropy < self.entropy_threshold:\n            self.F += learning_rate * (1.0 - self.F)\n            self.CR *= (1.0 - learning_rate)\n        else:\n            self.F *= (1.0 - learning_rate)\n            self.CR += learning_rate * (1.0 - self.CR)\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def quantum_inspired_search(self, agent, func):\n        prob_amplitude = np.random.normal(0, 1, self.dim)\n        quantum_gain = 0.5 * np.linalg.norm(agent - self.best_agent)\n        new_agent = np.clip(agent + quantum_gain * prob_amplitude, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.quantum_inspired_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 71, "feedback": "The algorithm QuantumAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07820 with standard deviation 0.05014.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.07568005909648623, 0.019952564633056058, 0.018667624845638775, 0.05077372434531768, 0.04493294694302863, 0.05871466373215162, 0.14038610398184825, 0.1504635467228036, 0.14418681718665083]}}
{"id": "1d7beacc-fb35-4148-a5a7-93c45481b69a", "fitness": 0.07147010512649264, "name": "AdaptiveClusteredSwarmOptimization", "description": "Augment adaptive clustered swarm optimization with self-adaptive parameter tuning and dynamic subspace search to enhance exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.elite_fraction = 0.2\n        self.dynamic_F_CR()\n\n    def dynamic_F_CR(self):\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = np.random.uniform(0.8, 1.0)\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F = min(0.9, self.F * 1.03)\n            self.CR = max(0.7, self.CR * 0.95)\n        else:\n            self.F = max(0.4, self.F * 0.97)\n            self.CR = min(1.0, self.CR * 1.05)\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def subspace_search(self, agent, func):\n        sub_dim = np.random.randint(1, self.dim + 1)\n        indices = np.random.choice(self.dim, sub_dim, replace=False)\n        noise = np.random.normal(0, 0.1, sub_dim)\n        new_agent = np.array(agent)\n        new_agent[indices] = np.clip(agent[indices] + noise, func.bounds.lb[indices], func.bounds.ub[indices])\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.subspace_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 72, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07147 with standard deviation 0.05397.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.015801691773646875, 0.01485381742195857, 0.01591850125583394, 0.054155207600183, 0.05503038522596149, 0.054792528580185684, 0.14347437327276635, 0.1516553701128146, 0.13754907089508328]}}
{"id": "8233e29a-9828-420d-b42a-b4bc1a702cc3", "fitness": 0.07848725629124988, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance adaptive clustered swarm optimization by introducing dynamic weight adjustment and multi-modal exploitation to improve search efficiency and convergence stability.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.F = 0.5\n        self.CR = 0.9\n        self.elite_fraction = 0.2\n        self.last_improvement_evaluation = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.entropy_threshold = 0.1\n        self.dynamic_weights = np.ones(self.population_size)\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def dynamic_weight_adjustment(self, fitness):\n        best_fitness = np.min(fitness)\n        self.dynamic_weights = 1.0 / (1 + np.exp(fitness - best_fitness))\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def exploit_clusters(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            if len(cluster_points) > 0:\n                centroid = np.mean(cluster_points, axis=0)\n                noise = np.random.normal(0, 0.1, size=self.dim)\n                candidate = np.clip(centroid + noise, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                self.evaluations += 1\n                if candidate_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = candidate\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = candidate_fitness\n                    if candidate_fitness < func(self.best_agent):\n                        self.best_agent = candidate\n                        self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_weight_adjustment(fitness)\n            elite_indices = np.argsort(fitness)[:int(self.elite_fraction * self.population_size)]\n            elite_population = self.population[elite_indices]\n\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                if idx in elite_indices:\n                    continue\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n            self.exploit_clusters(func, fitness)\n\n        return self.best_agent", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07849 with standard deviation 0.04425.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.04275612549649588, 0.03413742735322689, 0.05123048820439702, 0.048471505504077195, 0.05024325598835655, 0.05820751266027535, 0.1403501817761741, 0.13805293152253117, 0.14293587811571473]}}
{"id": "aa144e18-895c-456a-ac6a-f57b5a3f4278", "fitness": 0.07330225557412436, "name": "RefinedClusteredSwarmOptimization", "description": "Augment clustered swarm optimization with adaptive learning rates and dynamic exploration-exploitation balancing for improved convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass RefinedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.elite_fraction = 0.2\n        self.learning_rate = 0.1  # Adaptive learning rate\n    \n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def adaptive_learning_rate(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.learning_rate *= 1.1\n        else:\n            self.learning_rate *= 0.9\n\n    def dynamic_exploration_exploitation(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.F *= 1.1\n            self.CR *= 0.9\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n            self.last_improvement_evaluation = self.evaluations\n        else:\n            self.F *= 0.9\n            self.CR *= 1.1\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        noise_scale = self.learning_rate\n        g_noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_exploration_exploitation(fitness)\n            self.adaptive_learning_rate(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 74, "feedback": "The algorithm RefinedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07330 with standard deviation 0.05078.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.021853224688588635, 0.015806780241518492, 0.026077331313319574, 0.057880668419516224, 0.05720540305922517, 0.054889809442286164, 0.1434648982810912, 0.13777616104882928, 0.1447660236727445]}}
{"id": "1b03d032-75a5-43ee-8565-6d3c1c030827", "fitness": 0.07521713842692755, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance the robustness of the clustered swarm optimization by integrating a self-adaptive learning rate mechanism and hybridizing local search with global exploration techniques.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n        self.learning_rate = 0.1\n        self.learning_rate_decay = 0.99\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, self.learning_rate * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def global_exploration(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        new_agent = np.random.uniform(lb, ub, self.dim)\n        return new_agent\n\n    def hybrid_search(self, agent, func):\n        if np.random.rand() < 0.5:\n            return self.local_search(agent, func)\n        else:\n            return self.global_exploration(func)\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.hybrid_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n            self.learning_rate *= self.learning_rate_decay\n\n        return self.best_agent", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07522 with standard deviation 0.05431.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.024757295196774165, 0.018859580457208036, 0.018551990789714923, 0.05573767575074706, 0.05298869831993758, 0.05950258704095368, 0.13743485541195044, 0.15041250309591114, 0.15870905977915095]}}
{"id": "b37a0530-ea88-46dd-bec3-9c7e071b4535", "fitness": 0.07322818068116467, "name": "HybridClusteredSwarmOptimization", "description": "Introduce a hybrid strategy using stochastic tunneling and adaptive inertia weight in clustered swarm optimization for enhanced exploration and convergence control.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass HybridClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n        self.tunnel_beta = 0.1\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial = self.stochastic_tunneling(trial, func)\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_point = self.stochastic_tunneling(new_point, func)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def stochastic_tunneling(self, agent, func):\n        current_fitness = func(agent)\n        tunneling_factor = np.exp(-self.tunnel_beta * current_fitness)\n        tunneled_agent = agent + tunneling_factor * np.random.uniform(-1, 1, self.dim)\n        return np.clip(tunneled_agent, func.bounds.lb, func.bounds.ub)\n\n    def update_inertia_weight(self):\n        self.inertia_weight *= self.inertia_decay\n        self.inertia_weight = max(0.4, self.inertia_weight)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.update_inertia_weight()\n\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 76, "feedback": "The algorithm HybridClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07323 with standard deviation 0.05072.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.016530778697317672, 0.02406671874548527, 0.018864182908487015, 0.05725883044951696, 0.0599049132962044, 0.05890230320279566, 0.1358151460923791, 0.13955971482285667, 0.14815103791543927]}}
{"id": "7286224a-b482-4073-8b10-10143a6b91a8", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance adaptability by dynamically adjusting the elite_fraction to improve convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        # Dynamically adjust elite fraction based on entropy\n        entropy = -np.sum((fitness / np.sum(fitness)) * np.log(fitness / np.sum(fitness) + 1e-10))\n        self.elite_fraction = min(0.5, max(0.1, 0.2 * (1 - entropy)))  # Adjust elite fraction\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "d4dbc437-df17-45e1-bd93-8f1f979bedd5", "fitness": 0.07554784010825616, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance adaptive clustered swarm optimization by incorporating Lvy flight perturbation for improved exploration and convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def levy_flight(self, L=1.5):\n        u = np.random.normal(0, 1, self.dim) * (1.0 / (np.abs(np.random.normal(0, 1, self.dim))**(1/L)))\n        return u\n\n    def levy_guided_search(self, agent, func):\n        step = self.levy_flight() * (func.bounds.ub - func.bounds.lb) * 0.1\n        new_agent = np.clip(agent + step, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.levy_guided_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07555 with standard deviation 0.05235.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.01997932442300343, 0.02390295471639836, 0.027179207771032332, 0.055299936986273335, 0.05341440743936865, 0.05901927020006115, 0.14336508578198015, 0.15349253921353123, 0.14427783444265674]}}
{"id": "f36b5e6c-2323-4ec2-80bb-06dfaa3106c3", "fitness": 0.07547912664927256, "name": "RefinedAdaptiveClusteredSwarmOptimization", "description": "Utilize adaptive population strategies with entropy-based clustering and mutation to enhance exploration and convergence in swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass RefinedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 100  # Increased initial population size\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.05 * self.budget  # Decreased threshold for faster adaptation\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.05  # Adjusted for more sensitive adaptation\n        self.elite_fraction = 0.1  # Reduced elite fraction for diversity\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.93\n        else:\n            self.F *= 0.95\n            self.CR *= 1.07\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.3))\n            self.stagnation_threshold *= 1.2\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.01, 0.05 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(3, self.population_size // 15)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 79, "feedback": "The algorithm RefinedAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07548 with standard deviation 0.05538.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.017266203954095394, 0.018285212526757078, 0.01585620219026862, 0.054462363051534735, 0.057931192401611376, 0.06974516195069214, 0.13192215338564672, 0.14807702578464232, 0.16576662459820468]}}
{"id": "1ce39e52-5cea-414e-9581-8a9417869b29", "fitness": 0.07004590823882895, "name": "EnhancedClusteredSwarmOptimization", "description": "Enhance dynamic population control and adaptive learning with targeted reinforcement of elite strategies to improve convergence in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.95\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.3))\n            self.stagnation_threshold *= 1.4\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def targeted_elite_reinforcement(self, elite_population, func):\n        for agent in elite_population:\n            reinforced_agent = self.adaptive_gaussian_perturbation(agent, func)\n            reinforced_fitness = func(reinforced_agent)\n            self.evaluations += 1\n            if reinforced_fitness < func(self.best_agent):\n                self.best_agent = reinforced_agent\n                self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            self.targeted_elite_reinforcement(elite_population, func)\n\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07005 with standard deviation 0.05159.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.01577796378653562, 0.01573071904219847, 0.021421736218072973, 0.05529932966953155, 0.04750912619206904, 0.05471555166589259, 0.13373503489270644, 0.1419417178766722, 0.14428199480578163]}}
{"id": "a50ced98-503b-46ee-a8c0-77628396cd39", "fitness": 0.07395605614492373, "name": "AdaptiveClusteredSwarmOptimization", "description": "Integrate dynamic mutation scaling and enhanced elite preservation to improve convergence in adaptive clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        dynamic_F = max(0.2, self.F * (1 - self.evaluations / self.budget))  # Dynamic mutation scaling\n        mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        if self.evaluations < self.budget * 0.5:  # Enhanced elite preservation\n            elite_count = int(1.5 * elite_count)\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07396 with standard deviation 0.04801.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.025310291817757458, 0.02066085999315681, 0.029749640424902468, 0.05548170436015942, 0.054116568263328335, 0.0635612119617347, 0.13353794615778702, 0.13708652600776905, 0.14609975631771832]}}
{"id": "b8f6da82-8a67-43ab-8eba-0907e0705987", "fitness": 0.07294550993949495, "name": "EnhancedClusteredSwarmOptimization", "description": "Introduce multiscale adaptive perturbations and dynamic elite cluster reformation to enhance convergence and exploration in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n        self.multiscale_factor = 0.5\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def multiscale_local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def dynamic_elite_reformation(self, elite_population, func):\n        for elite_agent in elite_population:\n            if self.evaluations >= self.budget:\n                break\n            candidate = self.adaptive_gaussian_perturbation(elite_agent, func)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < func(self.best_agent):\n                self.best_agent = candidate\n                self.last_improvement_evaluation = self.evaluations\n            self.evaluations += 1\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            self.dynamic_elite_reformation(elite_population, func)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.multiscale_local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07295 with standard deviation 0.05139.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.015999563489217272, 0.017277331307204102, 0.024641924005960103, 0.055407108134876926, 0.05722818394039875, 0.05991072552888044, 0.1356480557187133, 0.14586147867468902, 0.14453521865551466]}}
{"id": "c071003f-d791-4131-9097-f2b896c3508e", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Integrate adaptive Gaussian perturbations and elite preservation strategy to enhance diversity and robustness in clustered swarm optimization with refined mutation factor control.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.F = max(0.1, min(1.0, self.F))  # Ensure F stays within bounds\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 83, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "03981de9-21aa-4d42-a3f0-ba16a5818450", "fitness": 0.0729460980288657, "name": "EnhancedAdaptiveClusteredSwarmOptimization", "description": "Utilize dynamic multi-strategy blending and adaptive clustering to enhance exploration-exploitation balance in swarm-based optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.last_improvement_evaluation = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.entropy_threshold = 0.1\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        adjust_factor = 1.03 if entropy < self.entropy_threshold else 0.97\n        self.F *= adjust_factor\n        self.CR /= adjust_factor\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07295 with standard deviation 0.05267.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.022725268788243325, 0.015108721512528733, 0.016913398409640346, 0.05617807059574553, 0.05220547069360637, 0.06183569015041401, 0.13875878882547243, 0.14628178038361606, 0.14650769290052446]}}
{"id": "54529d6b-43a9-40b1-b349-aad6580dfb0e", "fitness": 0.07460475716559747, "name": "AdaptiveClusteredSwarmOptimizationV2", "description": "Incorporate adaptive clustering and dynamic parameter tuning to balance exploration and exploitation in swarm-based optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteredSwarmOptimizationV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n            self.CR *= 0.95\n    \n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 8)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                new_point = np.clip(cluster_center, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveClusteredSwarmOptimizationV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07460 with standard deviation 0.05325.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.02230898079561916, 0.017830711078658523, 0.02580938147744427, 0.051459017720582145, 0.06039679236900497, 0.0519515933900071, 0.13961246099898406, 0.15440854967952367, 0.14766532698055335]}}
{"id": "e7408b19-be29-4799-94d6-88e20627f88d", "fitness": 0.07128363869780524, "name": "AdaptiveClusteredSwarmOptimization", "description": "Incorporate enhanced covariance scaling for improved exploration in the clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.1  # Adjusted scaling factor for exploration\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07128 with standard deviation 0.05008.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052887416699134104, 0.05206650767476506, 0.059918376521527095, 0.1332709963489681, 0.14080016295301412, 0.14293587811571473]}}
{"id": "66007537-47da-473f-b1b8-92a82b421c54", "fitness": 0.07154482079618728, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhance dynamic population resizing and elite preservation to improve diversity and efficiency in optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.3))  # Adjusted from 1.2 to 1.3\n            self.stagnation_threshold *= 1.4  # Adjusted from 1.5 to 1.4\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 87, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07154 with standard deviation 0.05035.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.019704572677884613, 0.01947133367623821, 0.020497503613001178, 0.052055588952450105, 0.05145503507748339, 0.062043354860482736, 0.1332709963489681, 0.14153435802067915, 0.14387064393849802]}}
{"id": "078fa33c-e91c-4a60-b61f-7ae8099a60ed", "fitness": 0.07779980979197756, "name": "EnhancedAdaptiveClusteredSwarmOptimization", "description": "Enhance adaptive clustered swarm optimization by incorporating a dynamic elite selection mechanism and a novel diversity-preserving hybrid crossover strategy for improved exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def hybrid_crossover(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n        # Hybrid Crossover Strategy\n        cross_points = np.random.rand(self.dim) < self.CR\n        uniform_cross_points = np.random.rand(self.dim) < 0.5\n        cross_points = np.logical_or(cross_points, uniform_cross_points)\n\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def dynamic_elite_selection(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        sorted_indices = np.argsort(fitness)[:elite_count]\n        return self.population[sorted_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.dynamic_elite_selection(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.hybrid_crossover(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07780 with standard deviation 0.05347.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.01596300520633942, 0.03652966061328333, 0.020571095584598686, 0.05477251725262544, 0.05874308768415326, 0.06392062850223224, 0.14158670677635177, 0.16265255333810646, 0.14545903317010744]}}
{"id": "1a3fa18e-0b39-40be-afd8-70059c42a435", "fitness": 0.07434306375699384, "name": "EnhancedClusteredSwarmOptimization", "description": "Integrate adaptive Gaussian perturbations with hybrid clustering and evolutionary dynamics to improve exploration-exploitation balance in swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.9\n        else:\n            self.F *= 0.95\n            self.CR *= 1.1\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.1\n        else:\n            self.covariance_matrix *= 0.9\n\n    def hybrid_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 5)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            if len(cluster_points) > 0:\n                cluster_fitness = fitness[kmeans.labels_ == cluster_idx]\n                best_idx = np.argmin(cluster_fitness)\n                cluster_center = cluster_points[best_idx]\n                perturbation = np.clip(np.random.normal(0, 1, self.dim), func.bounds.lb, func.bounds.ub)\n                new_point = np.clip(cluster_center + perturbation, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < cluster_fitness[best_idx]:\n                    self.population[kmeans.labels_ == cluster_idx][best_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][best_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.entropy_based_adaptation(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.hybrid_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n        return self.best_agent", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07434 with standard deviation 0.04999.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.025243286496004935, 0.024533392504565654, 0.029534569263804267, 0.05056188634787728, 0.055219862884577364, 0.054308797607071746, 0.13941267208836394, 0.14529165555514056, 0.14498145106553884]}}
{"id": "4e2558b2-e9da-475e-b06d-96b7d89b91f6", "fitness": 0.07233063609293452, "name": "EnhancedClusteredSwarmOptimization", "description": "Introduce a multi-faceted elitism strategy and employ entropy-controlled mutation to enhance the exploration-exploitation balance in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.15\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.95\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def entropy_controlled_mutation(self, agent, func):\n        sigma = 0.1  # Standard deviation for mutation\n        mutation_prob = np.random.rand(self.dim) < self.CR\n        mutation_noise = np.random.normal(0, sigma, self.dim) * mutation_prob\n        new_agent = np.clip(agent + mutation_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.entropy_controlled_mutation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07233 with standard deviation 0.05318.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.014635680719874089, 0.015619927112499266, 0.020064350202230408, 0.05597680524826765, 0.05506276772706875, 0.05776549958998978, 0.14219088465971874, 0.14334484732350117, 0.1463149622532609]}}
{"id": "6ebcf0ab-41cc-477b-977d-7db0a6d4a998", "fitness": 0.07209949116464395, "name": "AdaptiveClusteredSwarmOptimization", "description": "Introduce inertia weighting factor for enhanced balance between exploration and exploitation in Differential Evolution.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n        self.inertia_weight = 0.7  # Additional line\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.inertia_weight * self.F * (b - c), lb, ub)  # Modified line\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 91, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07210 with standard deviation 0.04912.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.030944522626522364, 0.01781241965807301, 0.022958569516901783, 0.05559126152852689, 0.05401662686485209, 0.049716386872934226, 0.13665502800577234, 0.13826472729249817, 0.14293587811571473]}}
{"id": "6c7e85f7-b889-49e4-bf4f-0db0e88c73f0", "fitness": 0.0780281526405609, "name": "MultiPhaseAdaptiveSwarmOptimization", "description": "Implement a multi-phase evolutionary strategy combining adaptive clustering and covariance matrix adaptation to improve exploration and exploitation in swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass MultiPhaseAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.evaluations = 0\n        self.population = None\n        self.best_agent = None\n        self.elite_fraction = 0.2\n        self.cov_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.phase_switch_threshold = budget * 0.5\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.evaluations += self.population_size\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_clustering(self, func, fitness):\n        if self.evaluations < self.phase_switch_threshold:\n            n_clusters = max(2, self.population_size // 10)\n            kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n            for cluster_idx in range(n_clusters):\n                cluster_points = self.population[kmeans.labels_ == cluster_idx]\n                if len(cluster_points) > 0:\n                    cluster_center = np.mean(cluster_points, axis=0)\n                    random_point = cluster_points[np.random.randint(len(cluster_points))]\n                    new_point = 0.5 * (cluster_center + random_point)\n                    new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                    new_fitness = func(new_point)\n                    self.evaluations += 1\n                    if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                        min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                        self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                        fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                        if new_fitness < func(self.best_agent):\n                            self.best_agent = new_point\n\n    def covariance_guided_search(self, func):\n        if self.evaluations >= self.phase_switch_threshold:\n            for idx in range(self.population_size):\n                z = np.random.multivariate_normal(self.mean_vector, self.cov_matrix)\n                candidate = np.clip(self.population[idx] + z, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                self.evaluations += 1\n                if candidate_fitness < func(self.best_agent):\n                    self.best_agent = candidate\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n        while self.evaluations < self.budget:\n            self.adaptive_clustering(func, fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n            self.covariance_guided_search(func)\n        return self.best_agent", "configspace": "", "generation": 92, "feedback": "The algorithm MultiPhaseAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07803 with standard deviation 0.05049.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.030660488652995976, 0.035770590730650476, 0.02892388000325319, 0.052417575672395356, 0.05372502623650899, 0.05712571522322041, 0.15886027378895085, 0.14183394534135807, 0.14293587811571473]}}
{"id": "18c9caaf-750d-4011-855a-59ea82237e1e", "fitness": 0.07371700223595347, "name": "EnhancedClusteredSwarmOptimization", "description": "Hybridize adaptive Gaussian perturbations with stochastic ranking and covariance matrix adaptation to enhance search efficiency and convergence in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.evaluations += self.population_size\n\n    def stochastic_ranking(self, fitness, threshold=0.45):\n        n = len(fitness)\n        order = np.arange(n)\n        for _ in range(n):\n            for i in range(n - 1):\n                prob = np.random.rand()\n                if prob < threshold:\n                    if fitness[order[i]] > fitness[order[i + 1]]:\n                        order[i], order[i + 1] = order[i + 1], order[i]\n                else:\n                    if np.random.rand() > np.random.rand():\n                        order[i], order[i + 1] = order[i + 1], order[i]\n        return order\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            order = self.stochastic_ranking(fitness)\n            for idx in order:\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n\n        return self.best_agent", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07372 with standard deviation 0.05347.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.016606548024612033, 0.021862648324214473, 0.026281262355893786, 0.04994378201048888, 0.052347725168298, 0.05530318041378146, 0.1463315668412165, 0.15184042886936133, 0.14293587811571473]}}
{"id": "2946a0c0-7152-46b9-9f1e-e1a8e83d2484", "fitness": 0.06974264889815021, "name": "EnhancedClusteredSwarmOptimization", "description": "Introduce multi-scale neighborhood search and adaptive mutation control to enhance exploration and convergence in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def multi_scale_search(self, agent, func):\n        scales = [0.02, 0.05, 0.1]\n        best_candidate = agent\n        best_fitness = func(agent)\n        for scale in scales:\n            noise = np.random.normal(0, scale, self.dim)\n            candidate = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < best_fitness:\n                best_candidate = candidate\n                best_fitness = candidate_fitness\n        return best_candidate\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.multi_scale_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06974 with standard deviation 0.05205.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.01337879177846113, 0.012964709420575149, 0.016454186945615623, 0.04615693122527087, 0.058474926964390495, 0.06352259395558235, 0.13215297846866103, 0.1415670484880952, 0.14301167283670002]}}
{"id": "82c9ddd5-0ef3-4ad2-8705-d1c711963757", "fitness": 0.07607446994112665, "name": "QuantumClusteredSwarmOptimization", "description": "Incorporate adaptive quantum-inspired search with entropy-controlled perturbation to enhance diversity and convergence in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass QuantumClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.entropy_threshold = 0.1\n        self.quantum_factor = 0.1 \n        self.elite_fraction = 0.2 \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.quantum_factor *= 1.05\n        else:\n            self.quantum_factor *= 0.95\n\n    def quantum_inspired_search(self, agent, func):\n        z = np.random.normal(0, self.quantum_factor, self.dim)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            random_point = cluster_points[np.random.randint(len(cluster_points))]\n            new_point = 0.5 * (cluster_center + random_point)\n            new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(new_point)\n            self.evaluations += 1\n            if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                if new_fitness < func(self.best_agent):\n                    self.best_agent = new_point\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.entropy_based_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                candidate = self.quantum_inspired_search(self.population[idx], func)\n                candidate_fitness = func(candidate)\n                if candidate_fitness < fitness[idx]:\n                    self.population[idx] = candidate\n                    fitness[idx] = candidate_fitness\n                    self.evaluations += 1\n                    if candidate_fitness < func(self.best_agent):\n                        self.best_agent = candidate\n\n        return self.best_agent", "configspace": "", "generation": 95, "feedback": "The algorithm QuantumClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07607 with standard deviation 0.05778.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.013863703514623293, 0.013312619142762938, 0.012831152360193498, 0.050637689417406206, 0.05819033562959686, 0.08018208230431212, 0.15476064686306823, 0.1505015041620299, 0.15039049607614685]}}
{"id": "eb69b348-da62-4ab5-900d-ad5ca444cc2b", "fitness": -Infinity, "name": "EnhancedAdaptiveClusteredSwarmOptimization", "description": "Enhance AdaptiveClusteredSwarmOptimization by incorporating Lvy flight perturbations and time-varying learning rates to improve exploration and convergence rates.  ", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget\n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1\n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)\n        self.elite_fraction = 0.2\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def levy_flight_perturbation(self, step_size, dim):\n        beta = 1.5  # typically this value is between 1 and 2\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v)**(1 / beta)\n        return step_size * step\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    step_size = 0.1 * (1 - (self.evaluations / self.budget))\n                    candidate = self.levy_flight_perturbation(step_size, self.dim)\n                    candidate = np.clip(self.population[idx] + candidate, func.bounds.lb, func.bounds.ub)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 96, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {}}
{"id": "c62f75a3-0943-4f6d-972c-6b7f26bb5815", "fitness": 0.07916219223978253, "name": "RefinedClusteredSwarmOptimization", "description": "Introduce dynamic elite fraction adjustment and enhanced local search to boost convergence efficiency in clustered swarm optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass RefinedClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  \n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def dynamic_elite_adjustment(self, fitness):\n        diversity = np.std(fitness)\n        if diversity < self.entropy_threshold:\n            self.elite_fraction = min(0.5, self.elite_fraction * 1.1)\n        else:\n            self.elite_fraction = max(0.1, self.elite_fraction * 0.9)\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        self.covariance_matrix *= (1.05 if improvement > 0 else 0.95)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def enhanced_local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_elite_adjustment(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.enhanced_local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 97, "feedback": "The algorithm RefinedClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07916 with standard deviation 0.04944.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.07280063449611218, 0.016286994009672706, 0.01717112908249885, 0.059284681719926735, 0.04826488460403633, 0.06651493043072243, 0.14042629438820398, 0.1475618152393552, 0.14414836618751437]}}
{"id": "862fce92-424d-4ebe-a393-f281294eb718", "fitness": 0.07474086918248261, "name": "EnhancedAdaptiveClusteredSwarmOptimization", "description": "Introduce entropy-guided adaptive mutation and dynamic elite clustering in a swarm-based optimization for enhanced exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.05\n            self.CR *= 0.95\n        else:\n            self.F *= 0.95\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07474 with standard deviation 0.05078.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.02872869718641058, 0.021250451588699315, 0.017004302477519717, 0.05818497436584169, 0.05962629584180035, 0.05808217283545969, 0.13880068252463618, 0.1460534130215121, 0.14493683280046388]}}
{"id": "d8596807-6582-4198-a24d-1092e84b1065", "fitness": 0.07366445351028794, "name": "AdaptiveClusteredSwarmOptimization", "description": "Enhanced local search by incorporating covariance-guided exploration for improved convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\n\nclass AdaptiveClusteredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.F = 0.5\n        self.CR = 0.9 \n        self.population = None\n        self.best_agent = None\n        self.evaluations = 0\n        self.stagnation_threshold = 0.1 * self.budget  \n        self.last_improvement_evaluation = 0\n        self.entropy_threshold = 0.1 \n        self.covariance_matrix = np.identity(dim)\n        self.mean_vector = np.zeros(dim)  \n        self.elite_fraction = 0.2  # Fraction of elite members to preserve\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in self.population])\n        self.best_agent = self.population[np.argmin(fitness)]\n        self.last_improvement_evaluation = self.evaluations\n        self.evaluations += self.population_size\n\n    def entropy_based_adaptation(self, fitness):\n        prob = fitness / np.sum(fitness)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        if entropy < self.entropy_threshold:\n            self.F *= 1.03\n            self.CR *= 0.95\n        else:\n            self.F *= 0.97\n            self.CR *= 1.05\n\n    def covariance_matrix_adaptation(self, fitness):\n        improvement = np.mean(fitness) - np.min(fitness)\n        if improvement > 0:\n            self.covariance_matrix *= 1.05\n        else:\n            self.covariance_matrix *= 0.95\n\n    def dynamic_population_resizing(self, fitness):\n        if self.evaluations - self.last_improvement_evaluation > self.stagnation_threshold:\n            self.population_size = max(10, int(self.population_size / 1.2))\n            self.stagnation_threshold *= 1.5\n        self.entropy_based_adaptation(fitness)\n\n    def differential_evolution(self, target_idx, func, fitness):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        trial_fitness = func(trial)\n        if trial_fitness < fitness[target_idx]:\n            self.population[target_idx] = trial\n            fitness[target_idx] = trial_fitness\n            if trial_fitness < func(self.best_agent):\n                self.best_agent = trial\n                self.last_improvement_evaluation = self.evaluations\n\n    def local_search(self, agent, func):\n        noise_scale = max(0.02, 0.1 * (1 - (self.evaluations / self.budget)))\n        noise = np.random.normal(0, noise_scale, self.dim)\n        new_agent = np.clip(agent + noise, func.bounds.lb, func.bounds.ub)\n        # Change 1: Enhanced local search by covariance-guided exploration\n        if np.random.rand() < 0.5:\n            new_agent = self.covariance_guided_search(new_agent, func)\n        return new_agent\n\n    def covariance_guided_search(self, agent, func):\n        z = np.random.multivariate_normal(self.mean_vector, self.covariance_matrix)\n        new_agent = np.clip(agent + z, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def adaptive_clustering(self, func, fitness):\n        n_clusters = max(2, self.population_size // 10)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n        for cluster_idx in range(n_clusters):\n            cluster_points = self.population[kmeans.labels_ == cluster_idx]\n            cluster_center = np.mean(cluster_points, axis=0)\n            if len(cluster_points) > 0:\n                random_point = cluster_points[np.random.randint(len(cluster_points))]\n                new_point = 0.5 * (cluster_center + random_point)\n                new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_point)\n                self.evaluations += 1\n                if new_fitness < np.min(fitness[kmeans.labels_ == cluster_idx]):\n                    min_idx = np.argmin(fitness[kmeans.labels_ == cluster_idx])\n                    self.population[kmeans.labels_ == cluster_idx][min_idx] = new_point\n                    fitness[kmeans.labels_ == cluster_idx][min_idx] = new_fitness\n                    if new_fitness < func(self.best_agent):\n                        self.best_agent = new_point\n                        self.last_improvement_evaluation = self.evaluations\n\n    def elite_preservation(self, fitness):\n        elite_count = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_count]\n        return self.population[elite_indices]\n\n    def adaptive_gaussian_perturbation(self, agent, func):\n        sigma = np.std(self.population, axis=0)\n        g_noise = np.random.normal(0, sigma, self.dim)\n        new_agent = np.clip(agent + g_noise, func.bounds.lb, func.bounds.ub)\n        return new_agent\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        fitness = np.array([func(ind) for ind in self.population])\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_resizing(fitness)\n            self.covariance_matrix_adaptation(fitness)\n            self.adaptive_clustering(func, fitness)\n            elite_population = self.elite_preservation(fitness)\n            for idx in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                self.differential_evolution(idx, func, fitness)\n                self.evaluations += 1\n                if self.evaluations < self.budget:\n                    candidate = self.local_search(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n                if self.evaluations < self.budget:\n                    candidate = self.adaptive_gaussian_perturbation(self.population[idx], func)\n                    candidate_fitness = func(candidate)\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        self.evaluations += 1\n                        if candidate_fitness < func(self.best_agent):\n                            self.best_agent = candidate\n                            self.last_improvement_evaluation = self.evaluations\n\n        return self.best_agent", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveClusteredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07366 with standard deviation 0.05232.", "error": "", "parent_ids": ["f9e7bcef-4c66-4d24-b503-f870cda666c1"], "operator": null, "metadata": {"aucs": [0.017700746347014906, 0.02031127344085193, 0.02195395513094156, 0.052796643176345026, 0.05765830486024759, 0.059034031705896384, 0.14115315471728518, 0.14826723996000135, 0.14410473225400755]}}
