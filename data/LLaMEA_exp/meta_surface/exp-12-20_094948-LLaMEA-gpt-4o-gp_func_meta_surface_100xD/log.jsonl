{"id": "2b62ad14-fb87-4854-8417-9b4dbd1a550f", "fitness": 0.06247367395988257, "name": "HybridPSO_DE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution to explore and exploit the search space efficiently.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Set population size\n        self.w = 0.5       # Inertia weight for PSO\n        self.c1 = 1.5      # Cognitive parameter for PSO\n        self.c2 = 1.5      # Social parameter for PSO\n        self.F = 0.8       # Mutation factor for DE\n        self.CR = 0.9      # Crossover rate for DE\n        \n    def __call__(self, func):\n        # Initialize swarm\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                # Select three random indices different from i\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Mutation operation\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                \n                # Crossover operation\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension crosses over\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                \n                # Evaluate new candidate\n                trial_score = func(trial)\n                eval_count += 1\n                \n                # Selection operation\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    \n                    # Update global best\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            \n            # Break if evaluation budget is exceeded\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0624756454474773, 0.062464673109858926, 0.062480703582511454, 0.06247564539492734, 0.06246467305755543, 0.062480703530063075, 0.0624756452395383, 0.06246467290219937, 0.06248070337481193]}}
{"id": "7882915e-a4e0-414b-a57c-3254212fe5c1", "fitness": 0.06247401126375063, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with self-adaptive parameters balancing exploration and exploitation to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight\n            self.w = 0.9 - 0.5 * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["2b62ad14-fb87-4854-8417-9b4dbd1a550f"], "operator": null, "metadata": {"aucs": [0.0624740160460191, 0.06246652671708175, 0.06248149128834002, 0.06247401599366109, 0.062466526664509914, 0.062481491235846565, 0.06247401583831824, 0.062466526509356246, 0.06248149108062273]}}
{"id": "ac8c36bf-82d7-45ee-a351-8a2786e97be9", "fitness": 0.06247260761100212, "name": "EnhancedHybridPSO_DE", "description": "Improved adaptive velocity weight adjustment based on swarm convergence rate in PSO to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight\n            self.w = 0.9 - 0.5 * (diversity / (diversity + self.epsilon)) * (1 - eval_count / self.budget)  # Modified line\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7882915e-a4e0-414b-a57c-3254212fe5c1"], "operator": null, "metadata": {"aucs": [0.06247488139627966, 0.0624597401850111, 0.06248320151180331, 0.06247488134373025, 0.06245974013269329, 0.062483201459492155, 0.06247488118856159, 0.062459739977380746, 0.06248320130406704]}}
{"id": "7b3d8abe-6c1b-408d-951c-68ebdd3c33ce", "fitness": 0.06247461410079323, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive DE mutation strategy for improved exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight\n            self.w = 0.9 - 0.5 * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Updated line to make DE mutation strategy adaptive\n                self.F = np.random.uniform(0.5, 1.0)  # Randomly adjust F in a range\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7882915e-a4e0-414b-a57c-3254212fe5c1"], "operator": null, "metadata": {"aucs": [0.06247631934116904, 0.062464732599981865, 0.06248279062145856, 0.0624763192886435, 0.06246473254743856, 0.06248279056898598, 0.06247631913345986, 0.062464732392289335, 0.06248279041371241]}}
{"id": "2f957173-7811-42d2-9be9-93504fe78b2d", "fitness": 0.0624757467478224, "name": "EnhancedHybridPSO_DE", "description": "Introducing a diversity-aware adaptive control parameter mechanism to improve exploration and exploitation balance in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7b3d8abe-6c1b-408d-951c-68ebdd3c33ce"], "operator": null, "metadata": {"aucs": [0.062475315224478134, 0.06247073492470856, 0.062481190354300775, 0.062475315172122126, 0.06247073487240817, 0.062481190301994505, 0.06247531501678649, 0.062470734717008036, 0.06248119014659481]}}
{"id": "913276ae-417d-42d1-83f5-b6eeaafbfdb4", "fitness": 0.0624757467478224, "name": "EnhancedHybridPSO_DE", "description": "Introducing a dynamic crossover rate adaptation based on diversity to further enhance exploration-exploitation balance in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                # Adapt crossover rate based on diversity\n                adaptive_CR = 0.4 + 0.5 * (diversity / (diversity + self.epsilon))\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.062475315224478134, 0.06247073492470856, 0.062481190354300775, 0.062475315172122126, 0.06247073487240817, 0.062481190301994505, 0.06247531501678649, 0.062470734717008036, 0.06248119014659481]}}
{"id": "867478f4-36c5-4be3-a733-c4be7faedbaf", "fitness": 0.06247329383373527, "name": "EnhancedHybridPSO_DE", "description": "Integrating a self-adaptive mutation strategy and dynamic neighborhood topology to improve convergence speed and robustness in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        self.neighborhood_size = 5  # Dynamic neighborhood size\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = np.clip(swarm[i] + velocities[i], lower_bound, upper_bound)\n            \n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                F_adaptive = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                a, b, c = np.random.choice(neighbors, 3, replace=False)\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00000.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.062473829429143146, 0.06246981366143456, 0.06247623867084495, 0.06247382937666168, 0.06246981360910464, 0.06247623861831619, 0.06247382922144218, 0.06246981345375269, 0.06247623846291739]}}
{"id": "5198e14c-8ef7-4693-8775-1360a8571f12", "fitness": 0.06247356093674102, "name": "EnhancedHybridPSO_DE", "description": "Integrating a convergence acceleration mechanism using a learning rate modulated by diversity to enhance the optimization process in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n        self.lr_max = 0.5    # Maximum learning rate\n        self.lr_min = 0.1    # Minimum learning rate\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # Adapt learning rate based on diversity\n            self.lr = self.lr_min + (self.lr_max - self.lr_min) * (diversity / (diversity + self.epsilon))\n\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + self.lr * velocities, lower_bound, upper_bound)\n\n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n\n        return global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.062472248539963804, 0.06246728521100964, 0.062481149319374985, 0.062472248487610904, 0.06246728515849398, 0.06248114926690829, 0.062472248332284486, 0.062467285003362516, 0.06248114911166058]}}
{"id": "8b7c9eed-d4c5-4358-8f65-3d8b7493f8b3", "fitness": 0.062474852908461984, "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive crossover rate based on diversity to further balance exploration and exploitation in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                # Adaptive CR based on diversity\n                adaptive_CR = self.CR - (self.CR * diversity)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.06247425706151688, 0.062466728780642744, 0.06248357314337494, 0.06247425700924292, 0.062466728728325815, 0.06248357309079877, 0.06247425685384267, 0.06246672857299862, 0.06248357293541451]}}
{"id": "40ab96f9-66f6-40e4-89e0-f2ea12584db0", "fitness": 0.0624757467478224, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with a dynamic population size adjustment based on convergence trends to improve balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n        self.dynamic_pop_size_factor = 0.2  # Factor indicating how much to adjust the population size\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            \n            # Calculate improvement rate\n            improvement = np.mean(personal_best_scores) - np.min(personal_best_scores)\n            # Adjust population size based on improvement rate\n            if improvement < self.epsilon:\n                self.pop_size = min(self.pop_size + int(self.dynamic_pop_size_factor * self.pop_size), self.budget - eval_count)\n                new_swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size - len(swarm), self.dim))\n                new_velocities = np.random.uniform(-1, 1, (self.pop_size - len(velocities), self.dim))\n                swarm = np.vstack((swarm, new_swarm))\n                velocities = np.vstack((velocities, new_velocities))\n                personal_best_positions = np.vstack((personal_best_positions, new_swarm))\n                personal_best_scores = np.append(personal_best_scores, [func(ind) for ind in new_swarm])\n                eval_count += len(new_swarm)\n\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n\n        return global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.062475315224478134, 0.06247073492470856, 0.062481190354300775, 0.062475315172122126, 0.06247073487240817, 0.062481190301994505, 0.06247531501678649, 0.062470734717008036, 0.06248119014659481]}}
{"id": "bc2cde5a-7ad3-4c16-b6ca-4c55df46859d", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Introducing a dynamic population resizing strategy along with diversity-based parameter adaptation to improve convergence in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20\n        self.min_pop_size = 10\n        self.max_pop_size = 40\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        swarm = np.random.uniform(lower_bound, upper_bound, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adaptive population size based on budget usage\n            pop_size = self.min_pop_size + int((self.max_pop_size - self.min_pop_size) * (eval_count / self.budget))\n            swarm = np.resize(swarm, (pop_size, self.dim))\n            velocities = np.resize(velocities, (pop_size, self.dim))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            \n            # PSO Update\n            r1, r2 = np.random.rand(pop_size, self.dim), np.random.rand(pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(pop_size):\n                indices = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 10, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,45) (10,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,45) (10,45) ')", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {}}
{"id": "401d4843-efd9-4b2e-877d-452a497ef4a1", "fitness": 0.062472026154502695, "name": "EnhancedHybridPSO_DE", "description": "Introducing a dynamic crossover probability mechanism to enhance convergence in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_max = 0.9\n        self.CR_min = 0.1\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                # Adaptive CR based on diversity\n                self.CR = self.CR_max - (self.CR_max - self.CR_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.06247084858364116, 0.06246311085426126, 0.062482119285796056, 0.062470848531143375, 0.06246311080195621, 0.06248211923328062, 0.06247084837597994, 0.06246311064659249, 0.062482119077873155]}}
{"id": "25419f63-9c55-449d-a1a1-09d9df2bb88f", "fitness": 0.062474726981514954, "name": "EnhancedHybridPSO_DE", "description": "Enhanced the DE mutation strategy by introducing an adaptive crossover rate mechanism based on population diversity for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8  # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                self.CR = 0.5 + 0.4 * (1 - diversity / (diversity + self.epsilon))  # Adaptive crossover rate\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best_position):\n                        global_best_position = trial\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00000.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.06247551808977714, 0.062471075440284296, 0.062477587674551804, 0.062475518037474864, 0.06247107538795249, 0.06247758762204769, 0.06247551788208472, 0.06247107523260864, 0.062477587466852946]}}
{"id": "0fa44f94-4569-488d-a383-04249c5e060c", "fitness": 0.06247619322264751, "name": "EnhancedHybridPSO_DE_Improved", "description": "Enhance the balance between exploration and exploitation by integrating a feedback mechanism to dynamically adjust parameters based on recent improvements in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        # Initialize feedback mechanism\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        # Record improvement\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        # Limit feedback window size\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Feedback mechanism: Increase exploration if no improvements\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["2f957173-7811-42d2-9be9-93504fe78b2d"], "operator": null, "metadata": {"aucs": [0.06247552187395211, 0.06247134414461997, 0.06248171390941404, 0.062475521821596325, 0.06247134409231914, 0.062481713857066246, 0.062475521666260136, 0.06247134393694431, 0.06248171370165534]}}
{"id": "e4e1eb18-4804-4491-a1a9-30efaa84d552", "fitness": 0.062475426839108034, "name": "EnhancedHybridPSO_DE_AdaptiveChaos", "description": "Introduce adaptive population resizing and chaos theory to enhance exploration and convergence speed in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_AdaptiveChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20\n        self.pop_size = self.initial_pop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = 0.7  # Initial chaos factor for chaotic behavior\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            \n            # PSO Update with chaos\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities + self.chaos_factor * np.random.uniform(-1, 1, (self.pop_size, self.dim)), lower_bound, upper_bound)\n\n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.pop_size = min(self.pop_size + 1, 2 * self.initial_pop_size)  # Adaptive population resizing\n                swarm = np.vstack((swarm, np.random.uniform(lower_bound, upper_bound, (1, self.dim))))\n                velocities = np.vstack((velocities, np.random.uniform(-1, 1, (1, self.dim))))\n                personal_best_positions = np.vstack((personal_best_positions, swarm[-1]))\n                personal_best_scores = np.append(personal_best_scores, func(swarm[-1]))\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n\n        return global_best_position", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSO_DE_AdaptiveChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0fa44f94-4569-488d-a383-04249c5e060c"], "operator": null, "metadata": {"aucs": [0.0624752828250853, 0.0624682680624602, 0.06248272988982717, 0.06247528277275505, 0.062468268010127614, 0.06248272983745584, 0.06247528261742097, 0.06246826785478132, 0.06248272968205881]}}
{"id": "5bc94a4a-b207-4a7f-b5ec-8c33982ef4b1", "fitness": 0.062476218776303855, "name": "EnhancedHybridPSO_DE_Improved", "description": "Introduce a dynamic crossover rate adjustment based on recent improvements to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        # Initialize feedback mechanism\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                # Dynamic CR adjustment\n                if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                    self.CR = np.clip(self.CR + 0.05, 0.6, 0.95)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        # Record improvement\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        # Limit feedback window size\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Feedback mechanism: Increase exploration if no improvements\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0fa44f94-4569-488d-a383-04249c5e060c"], "operator": null, "metadata": {"aucs": [0.06247552187395211, 0.06247134414461997, 0.06248179057042191, 0.062475521821596325, 0.06247134409231914, 0.06248179051790537, 0.062475521666260136, 0.06247134393694431, 0.062481790362715395]}}
{"id": "6d5d08ea-6f5a-4a85-a6d5-efec9a4501ad", "fitness": 0.06247439755447129, "name": "EnhancedHybridPSO_DE_Improved_Refined", "description": "Introduce adaptive mutation strategies and bell-curve crossover for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        # Initialize feedback mechanism\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                \n                # New adaptive mutation strategy\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                \n                # Bell-curve crossover instead of uniform\n                crossover = np.random.normal(0.5, 0.1, self.dim) < self.CR\n\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00000.", "error": "", "parent_ids": ["5bc94a4a-b207-4a7f-b5ec-8c33982ef4b1"], "operator": null, "metadata": {"aucs": [0.06247490594077054, 0.06246978057446295, 0.062478506408215284, 0.062474905888449284, 0.0624697805221015, 0.06247850635585561, 0.062474905733108876, 0.06246978036677142, 0.0624785062005061]}}
{"id": "0d4d60e4-a083-4295-a141-243556bfe25e", "fitness": 0.0624763324347987, "name": "EnhancedHybridPSO_DE_Improved", "description": "Fine-tune the balance of exploration and exploitation in the DE crossover strategy for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        # Initialize feedback mechanism\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                # Dynamic CR adjustment with a slight decrease to balance exploration\n                self.CR = np.clip(self.CR + 0.02, 0.6, 0.95)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        # Record improvement\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        # Limit feedback window size\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Feedback mechanism: Increase exploration if no improvements\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["5bc94a4a-b207-4a7f-b5ec-8c33982ef4b1"], "operator": null, "metadata": {"aucs": [0.06247341223400349, 0.062472106361343926, 0.062483478969228234, 0.062473412181436094, 0.06247210630883149, 0.06248347891686312, 0.062473412026319286, 0.062472106153675155, 0.06248347876148752]}}
{"id": "4b87284c-d534-492e-a167-cecc883e9cef", "fitness": 0.062476100130928844, "name": "EnhancedHybridPSO_DE_Improved", "description": "Introduce a stochastic learning factor adaptation to dynamically balance exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        # Initialize feedback mechanism\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        # Introduce stochastic learning factors\n        self.min_learning_factor = 0.5\n        self.max_learning_factor = 2.0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # Stochastic learning factor adaptation\n            self.c1 = np.random.uniform(self.min_learning_factor, self.max_learning_factor)\n            self.c2 = np.random.uniform(self.min_learning_factor, self.max_learning_factor)\n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive F based on diversity\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                # Dynamic CR adjustment with a slight decrease to balance exploration\n                self.CR = np.clip(self.CR + 0.02, 0.6, 0.95)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        # Record improvement\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        # Limit feedback window size\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Feedback mechanism: Increase exploration if no improvements\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.min_learning_factor = np.clip(self.min_learning_factor + 0.1, 0.5, 2.0)\n                self.max_learning_factor = np.clip(self.max_learning_factor - 0.1, 0.5, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0d4d60e4-a083-4295-a141-243556bfe25e"], "operator": null, "metadata": {"aucs": [0.06247480559417995, 0.06247023498442994, 0.062483260074264524, 0.06247480554184848, 0.062470234932073154, 0.06248326002175819, 0.06247480538650663, 0.062470234776745626, 0.06248325986655312]}}
{"id": "a0414468-cb4c-4f9d-bba0-b9318e0e6668", "fitness": 0.062476331982856195, "name": "EnhancedHybridPSO_DE_FeedbackLearning", "description": "Enhance the dynamic parameter adaptation by introducing a feedback-driven learning rate to improve convergence efficiency in varying problem landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_FeedbackLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        self.learning_rate = 0.1\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = self.F_max - (self.F_max - self.F_min) * (diversity / (diversity + self.epsilon))\n                self.CR = np.clip(self.CR + 0.02, 0.6, 0.95)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + self.learning_rate, 0, 2.0)\n                self.c2 = np.clip(self.c2 - self.learning_rate, 0, 2.0)\n                self.recent_improvements = []\n            else:\n                self.learning_rate = max(0.05, self.learning_rate - 0.01)\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSO_DE_FeedbackLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0d4d60e4-a083-4295-a141-243556bfe25e"], "operator": null, "metadata": {"aucs": [0.06247341223400349, 0.06247210255467328, 0.06248348142008253, 0.062473412181436094, 0.06247210250217761, 0.062483481367696325, 0.062473412026319286, 0.06247210234700129, 0.06248348121231584]}}
{"id": "86d3f22e-2974-4311-99c6-b29f440f6d17", "fitness": 0.06248324433623742, "name": "EnhancedHybridPSO_DE_Improved", "description": "Integrate a self-adaptive strategy for parameter tuning and introduce chaotic maps for enhanced diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        # Initialize feedback mechanism\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        # Chaotic map initialization\n        self.chaos_factor = np.random.rand()\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            # Adapt inertia weight based on diversity\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            # Chaotic map update\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            # Self-adaptive strategy for F and CR\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min) \n            self.CR = 0.6 + 0.35 * self.chaos_factor  # Dynamic CR adjustment\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        # Record improvement\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        # Limit feedback window size\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Feedback mechanism: Increase exploration if no improvements\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0d4d60e4-a083-4295-a141-243556bfe25e"], "operator": null, "metadata": {"aucs": [0.06248593981379902, 0.062474675932668755, 0.0624891175224519, 0.06248593976148631, 0.062474675880087815, 0.06248911747010344, 0.06248593960609938, 0.0624746757247342, 0.062489117314705966]}}
{"id": "f012b32b-6a93-4f67-9168-80d84d69ae6c", "fitness": 0.06248325391130622, "name": "EnhancedHybridPSO_DE_Improved", "description": "Introduce Lvy flight for global search and adaptive mutation rate for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        # Lvy flight parameters\n        self.levy_beta = 1.5\n        \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) / \n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = 0.6 + 0.35 * self.chaos_factor\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["86d3f22e-2974-4311-99c6-b29f440f6d17"], "operator": null, "metadata": {"aucs": [0.062486300510370074, 0.06247431034681261, 0.06248915113698261, 0.06248630045783932, 0.06247431029445116, 0.06248915108449449, 0.06248630030263158, 0.062474310139099765, 0.062489150929074366]}}
{"id": "8667d62f-ec58-453a-8c83-47a8ccaf63d5", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE_Improved_V2", "description": "Integrate dynamic swarm size adjustment and adaptive chaos factor to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20\n        self.pop_size = self.initial_pop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.chaos_step = 0.001\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) / \n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = 0.6 + 0.35 * self.chaos_factor\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n            \n            # Dynamic swarm size adjustment\n            if eval_count < self.budget // 2:\n                self.swarm_size_adjustment()\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position\n\n    def swarm_size_adjustment(self):\n        self.chaos_factor += self.chaos_step\n        self.pop_size = max(10, int(self.initial_pop_size * (1 + self.chaos_factor)))\n        if self.pop_size > self.budget:\n            self.pop_size = self.budget", "configspace": "", "generation": 22, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (39,45) (20,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (39,45) (20,45) ')", "parent_ids": ["f012b32b-6a93-4f67-9168-80d84d69ae6c"], "operator": null, "metadata": {}}
{"id": "0162ad56-4fc2-4047-b67f-46630597a785", "fitness": 0.0624835181882722, "name": "EnhancedHybridPSO_DE_Improved", "description": "Introduce a local search phase using Nelder-Mead simplex after DE step to refine solutions and enhance convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) / \n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = 0.6 + 0.35 * self.chaos_factor\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Local search phase\n            if np.random.rand() < 0.1:\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["f012b32b-6a93-4f67-9168-80d84d69ae6c"], "operator": null, "metadata": {"aucs": [0.062485964672947425, 0.06247544837125374, 0.06248914178071063, 0.062485964620608625, 0.062475448318896176, 0.0624891417283604, 0.06248596446520893, 0.0624754481634997, 0.062489141572964146]}}
{"id": "248ef7c0-11f2-4b59-8381-877109a6c74e", "fitness": 0.062483812122978946, "name": "DynamicHybridPSO_DE", "description": "Introduce dynamic parameter adaptation and adaptive local search based on population diversity and convergence trends to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 24, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0162ad56-4fc2-4047-b67f-46630597a785"], "operator": null, "metadata": {"aucs": [0.06248469107121912, 0.062477567638459575, 0.062489177919310857, 0.06248469101889009, 0.062477567586099125, 0.06248917786698116, 0.06248469086351238, 0.06247756743074484, 0.06248917771159335]}}
{"id": "64ea6a65-7266-42f7-b1ba-4b46d9392f41", "fitness": -Infinity, "name": "DynamicHybridPSO_DE", "description": "Enhance convergence by integrating stochastic local sampling and dynamic scaling of exploration-exploitation balance based on swarm entropy.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def entropy(self, positions):\n        \"\"\"Calculate swarm entropy to gauge diversity.\"\"\"\n        probs, _ = np.histogramdd(positions, bins=10)\n        probs = probs / np.sum(probs)\n        return -np.sum(probs * np.where(probs > 0, np.log(probs), 0))\n\n    def stochastic_sampling(self, func, position, num_samples=5):\n        \"\"\"Perform stochastic local sampling around a position.\"\"\"\n        samples = position + np.random.normal(0, 0.1, (num_samples, self.dim))\n        samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n        scores = np.array([func(sample) for sample in samples])\n        return samples[np.argmin(scores)], np.min(scores)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = self.entropy(swarm)\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.4:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local and stochastic sampling phase\n            if np.random.rand() < 0.2 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.stochastic_sampling(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 25, "feedback": "An exception occurred: ValueError('maximum supported dimension for an ndarray is 32, found 45').", "error": "ValueError('maximum supported dimension for an ndarray is 32, found 45')", "parent_ids": ["248ef7c0-11f2-4b59-8381-877109a6c74e"], "operator": null, "metadata": {}}
{"id": "b7b1392f-3676-4c84-bb51-1ab0787a84bb", "fitness": 0.062483812122978946, "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive inertia weight adjustment, chaos-enhanced exploration, and self-adaptive crossover rates to improve global search capability and convergence efficiency.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["248ef7c0-11f2-4b59-8381-877109a6c74e"], "operator": null, "metadata": {"aucs": [0.06248469107121912, 0.062477567638459575, 0.062489177919310857, 0.06248469101889009, 0.062477567586099125, 0.06248917786698116, 0.06248469086351238, 0.06247756743074484, 0.06248917771159335]}}
{"id": "8316bba2-ec87-4ff6-8992-42bfe242c989", "fitness": 0.062483812122978946, "name": "DynamicHybridPSO_DE", "description": "Incorporate adaptive learning rates and reinforcement-based parameter adjustment to enhance the exploration-exploitation dynamics, convergence reliability, and overall efficiency.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.learning_rate_adapt = 0.1  # New learning rate adaptation factor\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation with learning rate\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase with learning rate\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + self.learning_rate_adapt, 0, 2.0)\n                self.c2 = np.clip(self.c2 - self.learning_rate_adapt, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 27, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["248ef7c0-11f2-4b59-8381-877109a6c74e"], "operator": null, "metadata": {"aucs": [0.06248469107121912, 0.062477567638459575, 0.062489177919310857, 0.06248469101889009, 0.062477567586099125, 0.06248917786698116, 0.06248469086351238, 0.06247756743074484, 0.06248917771159335]}}
{"id": "f1b1ac52-d18d-4bb3-a81d-ecbb8959e297", "fitness": -Infinity, "name": "RefinedDynamicHybridPSO_DE", "description": "Improve exploitation by integrating cooperative local learning and enhanced mutation strategies, while maintaining adaptive diversity control for exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def cooperative_local_learning(self, func, swarm):\n        for i in range(self.pop_size):\n            neighbors = [swarm[j] for j in range(self.pop_size) if j != i]\n            neighbor_mean = np.mean(neighbors, axis=0)\n            if np.random.rand() < 0.2:\n                refined_position, refined_score = self.local_search(func, neighbor_mean)\n                if refined_score < func(swarm[i]):\n                    swarm[i] = refined_position\n\n    def enhanced_mutation(self, swarm, indices, a, b, c):\n        target = swarm[a]\n        mutant = swarm[b] + self.F * (swarm[c] - target)\n        return np.clip(mutant, func.bounds.lb, func.bounds.ub)\n    \n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.enhanced_mutation(swarm, indices, a, b, c)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            self.cooperative_local_learning(func, swarm)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 28, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["248ef7c0-11f2-4b59-8381-877109a6c74e"], "operator": null, "metadata": {}}
{"id": "fefb4dae-ee70-4734-8e2a-ea43023a1959", "fitness": 0.062483222861974705, "name": "DynamicHybridPSO_DE", "description": "Introduce momentary diversity-based velocity randomization to enhance exploration when convergence stalls.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm)) + np.random.randn(*velocities.shape) * 0.01 * diversity\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 29, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["248ef7c0-11f2-4b59-8381-877109a6c74e"], "operator": null, "metadata": {"aucs": [0.062486521514188764, 0.0624740088645388, 0.06248913846727555, 0.06248652146185707, 0.062474008812196224, 0.062489138414917766, 0.06248652130644483, 0.062474008656820956, 0.062489138259532395]}}
{"id": "9293119f-efdb-448c-aa02-23e610e2d24d", "fitness": 0.06248428218095629, "name": "DynamicHybridPSO_DE", "description": "Introduce a small modification to the crossover condition to improve exploration of the search space.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.05  # Modified line for crossover condition\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 30, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["248ef7c0-11f2-4b59-8381-877109a6c74e"], "operator": null, "metadata": {"aucs": [0.06248625478536085, 0.06247747687516392, 0.062489115142404184, 0.06248625473300162, 0.062477476822845324, 0.062489115090068936, 0.062486254577624245, 0.06247747666744663, 0.06248911493469089]}}
{"id": "05c5c104-1db7-4930-9367-d30ae6a55862", "fitness": 0.062114005764475094, "name": "EnhancedDynamicHybridPSO_DE", "description": "Introduce adaptive control of exploration and exploitation using a feedback loop to dynamically adjust parameters for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Adaptive parameter control based on feedback\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * ((eval_count / self.budget) + 0.1 * np.mean(self.recent_improvements))\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * ((eval_count / self.budget) - 0.1 * np.mean(self.recent_improvements))\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06211 with standard deviation 0.00023.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.06226584275793434, 0.061795816980682705, 0.0622803578141945, 0.06226584270553315, 0.06179581692875802, 0.06228035776177887, 0.06226584255018419, 0.061795816774822265, 0.06228035760638784]}}
{"id": "905b25c7-15d0-458a-8d79-9e59eb26a10e", "fitness": 0.0624842544410266, "name": "DynamicHybridPSO_DE", "description": "Adjust the global exploration strategy by refining the Lvy flight probability to enhance global search capability.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.2:  # Reduced probability for Lvy flight\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.05  # Modified line for crossover condition\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 32, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.06248576195061428, 0.062477886490171386, 0.062489115142404184, 0.06248576189827004, 0.06247788643766583, 0.062489115090068936, 0.062485761742869905, 0.06247788628248396, 0.06248911493469089]}}
{"id": "c4ecb99f-3a3f-4121-8803-fb5c92c5e64b", "fitness": 0.062483812122978946, "name": "DynamicHybridPSO_DE", "description": "Improve exploration and exploitation balance using adaptive operator probabilities and chaotic maps for parameter tuning.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.local_search_probability = 0.1\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n    \n    def chaotic_map(self):\n        return (4 * self.chaos_factor) * (1.0 - self.chaos_factor)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = self.chaotic_map()\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < self.local_search_probability * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 33, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.06248469107121912, 0.062477567638459575, 0.062489177919310857, 0.06248469101889009, 0.062477567586099125, 0.06248917786698116, 0.06248469086351238, 0.06247756743074484, 0.06248917771159335]}}
{"id": "740a00fd-ef40-43de-bf8c-e78502ae72ef", "fitness": 0.06248355953306563, "name": "EnhancedDynamicHybridPSO_DE", "description": "Incorporate self-adaptive differential mutation strategy and enhanced crossover probability to boost exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.2 * self.chaos_factor  # Enhanced crossover probability\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # Self-adaptive DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_adaptive = self.F_min + np.random.rand() * (self.F_max - self.F_min)\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.062486223758222215, 0.06247530648615385, 0.062489148614949586, 0.06248622370578594, 0.06247530643379573, 0.06248914856258614, 0.06248622355048061, 0.06247530627840814, 0.06248914840720843]}}
{"id": "b1c8ce36-add6-44f5-8651-02922bb0a46f", "fitness": 0.06248416646244093, "name": "DynamicHybridPSO_DE", "description": "Adjusted crossover condition to further enhance exploration capacity in DE.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified line for crossover condition\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 35, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.06248586557636615, 0.06247745615180733, 0.06248917791936304, 0.06248586552384228, 0.06247745609944766, 0.06248917786700092, 0.0624858653684397, 0.062477455944081384, 0.06248917771161988]}}
{"id": "8ae38943-fe8f-4c49-bcc4-833a2185f977", "fitness": 0.062483796732117715, "name": "EnhancedDynamicHybridPSO_DE", "description": "Integrate adaptive neighborhood search and chaotic mutation for enhanced convergence and exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.neighborhood_size = 5  # New parameter for neighborhood search\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def adaptive_neighborhood_search(self, func, swarm, scores):\n        for i in range(self.pop_size):\n            neighbors_idx = np.argsort(scores)[:self.neighborhood_size]\n            for idx in neighbors_idx:\n                trial = swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (swarm[i] - swarm[idx])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                trial_score = func(trial)\n                if trial_score < scores[i]:\n                    swarm[i] = trial\n                    scores[i] = trial_score\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.05\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            self.adaptive_neighborhood_search(func, swarm, personal_best_scores)  # New adaptive neighborhood search\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.062486202253395406, 0.06247600520465957, 0.06248918299841921, 0.06248620220099843, 0.062476005152319325, 0.06248918294605188, 0.06248620204563993, 0.06247600499694417, 0.06248918279063154]}}
{"id": "03de1b3f-dcfb-4872-9943-d48e8bf1a0c7", "fitness": 0.062483992320283725, "name": "EnhancedDynamicHybridPSO_DE", "description": "Enhanced chaos and adaptive learning for improved exploration and convergence efficiency.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.adaptive_learning_rate = 0.1  # New adaptive learning parameter\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor * self.adaptive_learning_rate)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Introduce Lvy flight for random global exploration\n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified line for stronger crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.15 * (1 - diversity):  # Increased probability for local search\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.15, 0, 2.0)  # Increased adjustment strength\n                self.c2 = np.clip(self.c2 - 0.15, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.06248609690964324, 0.062476743888167374, 0.0624891364231458, 0.062486096857310214, 0.062476743835814585, 0.06248913637069908, 0.062486096701935834, 0.06247674368044098, 0.062489136215396424]}}
{"id": "f330d6d6-51e4-4269-8ae8-160c16b7ceb8", "fitness": 0.062466384576849894, "name": "EnhancedHybridPSO_DE", "description": "Enhance exploration and exploitation balance in hybrid PSO-DE using adaptive inertia weight and chaotic DE mutation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            if np.random.rand() < 0.3:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00003.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.062485548986372375, 0.062424431991029095, 0.062489173013118515, 0.06248554893405467, 0.062424431938752245, 0.0624891729607866, 0.062485548778645206, 0.062424431783519196, 0.06248917280537114]}}
{"id": "fede50fa-6eb7-4cf6-a1ea-73366a4f8e72", "fitness": 0.062484324238186395, "name": "DynamicHybridPSO_DE", "description": "Implement a self-adaptive chaotic map for parameter tuning and enhance Lvy flight utilization for improved global exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Enhanced Lvy flight for improved exploration\n            if np.random.rand() < 0.5:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 39, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["9293119f-efdb-448c-aa02-23e610e2d24d"], "operator": null, "metadata": {"aucs": [0.06248628440535564, 0.062477529701628676, 0.06248915886767237, 0.062486284353003074, 0.06247752964926778, 0.062489158815305146, 0.06248628419760538, 0.06247752949391083, 0.062489158659928656]}}
{"id": "3a28c0e1-368b-49fd-af67-80f7cd29b49d", "fitness": 0.06248380271913502, "name": "EnhancedHybridPSO_DE", "description": "Enhance the synergy between PSO and DE using an adaptive inertia weight strategy and stochastic local re-optimization to ensure robust convergence across diverse landscapes.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.local_reopt_prob = 0.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='BFGS')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Enhanced Lvy flight for improved exploration\n            if np.random.rand() < 0.5:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Stochastic local re-optimization phase\n            if np.random.rand() < self.local_reopt_prob:\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.062485135424064864, 0.06247709909153476, 0.06248917390185471, 0.06248513537182754, 0.06247709903917387, 0.06248917384948516, 0.06248513521640453, 0.06247709888375097, 0.06248917369411877]}}
{"id": "71370f68-2047-461c-885d-bfc160f07276", "fitness": 0.062484324238186395, "name": "AdvancedDynamicHybridPSO_DE", "description": "Introduce adaptive swarm restructuring based on entropy measure and integrate a progressive mutation strategy for enhanced convergence and diversity.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdvancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.entropy_threshold = 0.7\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def calculate_entropy(self, swarm):\n        normalized_swarm = (swarm - np.min(swarm, axis=0)) / (np.max(swarm, axis=0) - np.min(swarm, axis=0) + self.epsilon)\n        entropy = -np.sum(normalized_swarm * np.log2(normalized_swarm + self.epsilon), axis=0)\n        return np.mean(entropy)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Enhanced Lvy flight for improved exploration\n            if np.random.rand() < 0.5:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n\n            # Swarm restructuring based on entropy\n            if self.calculate_entropy(swarm) < self.entropy_threshold:\n                swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n\n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 41, "feedback": "The algorithm AdvancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.06248628440535564, 0.062477529701628676, 0.06248915886767237, 0.062486284353003074, 0.06247752964926778, 0.062489158815305146, 0.06248628419760538, 0.06247752949391083, 0.062489158659928656]}}
{"id": "fe3462f9-ab2e-43cd-a7a7-9bf2c14e9800", "fitness": 0.06248231600394505, "name": "DynamicHybridPSO_DE", "description": "Integrate adaptive mutation scaling and population clustering to refine exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom sklearn.cluster import KMeans\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.mutation_factor = 0.8  # New\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            if np.random.rand() < 0.5:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.mutation_factor * self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)  # Change\n                crossover = np.random.rand(self.dim) < self.CR + 0.1\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n            \n            # Clustering for adaptive exploration/exploitation\n            if eval_count % (self.pop_size * 2) == 0:  # Change\n                n_clusters = max(2, self.pop_size // 5)\n                kmeans = KMeans(n_clusters=n_clusters).fit(swarm)  # Change\n                for i in range(n_clusters):  # Change\n                    cluster_indices = np.where(kmeans.labels_ == i)[0]\n                    if len(cluster_indices) > 1:  # Change\n                        cluster_points = swarm[cluster_indices]\n                        cluster_center = np.mean(cluster_points, axis=0)\n                        swarm[cluster_indices] = cluster_center + np.random.normal(0, 0.1, cluster_points.shape)  # Change\n        \n        return global_best_position", "configspace": "", "generation": 42, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.06248651147170459, 0.0624712793875013, 0.062489157412706886, 0.06248651141932737, 0.062471279335056806, 0.06248915736036942, 0.062486511263951106, 0.06247127917992168, 0.062489157204966284]}}
{"id": "1f68f46a-a948-40ee-8ad2-004cce3c758d", "fitness": 0.062484324238186395, "name": "DynamicHybridPSO_DE", "description": "Implement a self-adaptive chaotic map for parameter tuning and enhance Lvy flight utilization for improved global exploration, with adaptive population size adjustment based on recent improvements.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Enhanced Lvy flight for improved exploration\n            if np.random.rand() < 0.5:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n                self.pop_size = max(10, self.pop_size - 1)  # Decrease population size if improvements are minimal\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 43, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.06248628440535564, 0.062477529701628676, 0.06248915886767237, 0.062486284353003074, 0.06247752964926778, 0.062489158815305146, 0.06248628419760538, 0.06247752949391083, 0.062489158659928656]}}
{"id": "5ac5a6a6-4cf6-4248-acd9-74214ff158ee", "fitness": 0.06248269000280579, "name": "EnhancedDynamicHybridPSO_DE", "description": "Integrate a self-adaptive chaos-enhanced differential evolution and local search strategy with multi-population cooperative coevolution for enhanced exploration and exploitation balancing in black-box optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.sub_pop_num = 5\n        self.sub_pop_size = self.pop_size // self.sub_pop_num\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        sub_populations = [np.random.uniform(lower_bound, upper_bound, (self.sub_pop_size, self.dim)) for _ in range(self.sub_pop_num)]\n        velocities = [np.random.uniform(-1, 1, (self.sub_pop_size, self.dim)) for _ in range(self.sub_pop_num)]\n        personal_best_positions = [np.copy(pop) for pop in sub_populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in sub_populations]\n        global_best_position = min(personal_best_positions, key=lambda pop: np.min([func(ind) for ind in pop]))\n        global_best_score = func(global_best_position[np.argmin([func(ind) for ind in global_best_position])])\n        \n        eval_count = sum(len(pop) for pop in sub_populations)\n\n        while eval_count < self.budget:\n            for sub_pop_idx in range(self.sub_pop_num):\n                swarm = sub_populations[sub_pop_idx]\n                pbest_pos = personal_best_positions[sub_pop_idx]\n                pbest_scores = personal_best_scores[sub_pop_idx]\n                vel = velocities[sub_pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.1 * self.chaos_factor\n\n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.sub_pop_size, self.dim), np.random.rand(self.sub_pop_size, self.dim)\n                vel = (self.w * vel +\n                       self.c1 * r1 * (pbest_pos - swarm) +\n                       self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + vel, lower_bound, upper_bound)\n\n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.sub_pop_size, self.dim))\n\n                for i in range(self.sub_pop_size):\n                    indices = [idx for idx in range(self.sub_pop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR + 0.1\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_scores[i]:\n                        pbest_pos[i] = trial\n                        pbest_scores[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.sub_pop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_scores[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_scores[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n                if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                    self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                    self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                    self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.062485662828388744, 0.062473243575166815, 0.06248916386494496, 0.06248566277603618, 0.0624732435228349, 0.06248916381258596, 0.06248566262065769, 0.06247324336746596, 0.06248916365717094]}}
{"id": "fa9ef5be-6f2d-477e-9548-e9af2e263d29", "fitness": 0.06248260861914306, "name": "EnhancedDynamicMultiPopPSO_DE", "description": "Introduce a multi-population approach with dynamic regrouping and chaos-enhanced Lvy flights to enhance exploration and exploitation balance for black-box optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicMultiPopPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.num_subpops = 2\n        self.subpop_size = self.pop_size // self.num_subpops\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update with multi-population approach\n            for subpop_idx in range(self.num_subpops):\n                start_idx = subpop_idx * self.subpop_size\n                end_idx = start_idx + self.subpop_size\n                subpop = swarm[start_idx:end_idx]\n                subpop_velocities = velocities[start_idx:end_idx]\n                personal_best_subpop = personal_best_positions[start_idx:end_idx]\n                personal_best_subpop_scores = personal_best_scores[start_idx:end_idx]\n                \n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                subpop_velocities = (self.w * subpop_velocities +\n                                     self.c1 * r1 * (personal_best_subpop - subpop) +\n                                     self.c2 * r2 * (global_best_position - subpop))\n                subpop = np.clip(subpop + subpop_velocities, lower_bound, upper_bound)\n                \n                # Enhanced Lvy flight for improved exploration\n                if np.random.rand() < 0.5:\n                    subpop += self.levy_flight((self.subpop_size, self.dim))\n                \n                # DE Update\n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(subpop[a] + self.F * (subpop[b] - subpop[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified crossover\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, subpop[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < personal_best_subpop_scores[i]:\n                        personal_best_subpop[i] = trial\n                        personal_best_subpop_scores[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                swarm[start_idx:end_idx] = subpop\n                velocities[start_idx:end_idx] = subpop_velocities\n                personal_best_positions[start_idx:end_idx] = personal_best_subpop\n                personal_best_scores[start_idx:end_idx] = personal_best_subpop_scores\n                \n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            # Regroup populations if necessary\n            if eval_count % (self.pop_size * 5) == 0:\n                swarm = np.random.permutation(swarm)\n                velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedDynamicMultiPopPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.06248597127098099, 0.06247266092035453, 0.06248919392621666, 0.06248597121858013, 0.06247266086800418, 0.06248919387385321, 0.06248597106318121, 0.0624726607126429, 0.06248919371847372]}}
{"id": "ed305f90-98c4-4131-bea1-7c648feb171a", "fitness": 0.062484324238186395, "name": "EnhancedDynamicHybridPSO_DE", "description": "Enhance the balance between exploration and exploitation by integrating an adaptive learning rate influenced by population diversity and convergence speed.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lower_bound, upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n            self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n            self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n            self.CR = self.CR_base + 0.1 * self.chaos_factor\n            \n            # Dynamic parameter adaptation\n            self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lower_bound, upper_bound)\n            \n            # Enhanced Lvy flight for improved exploration\n            if np.random.rand() < 0.5:\n                swarm += self.levy_flight((self.pop_size, self.dim))\n            \n            # DE Update\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR + 0.1  # Modified crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, swarm[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        self.recent_improvements.append(global_best_score - trial_score)\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        if len(self.recent_improvements) > self.feedback_window:\n                            self.recent_improvements.pop(0)\n\n            # Adaptive local search phase\n            if np.random.rand() < 0.1 * (1 - diversity):\n                for i in range(self.pop_size):\n                    refined_position, refined_score = self.local_search(func, swarm[i])\n                    eval_count += refined_position.size\n                    if refined_score < personal_best_scores[i]:\n                        personal_best_positions[i] = refined_position\n                        personal_best_scores[i] = refined_score\n                        if refined_score < global_best_score:\n                            global_best_position = refined_position\n                            global_best_score = refined_score\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.06248628440535564, 0.062477529701628676, 0.06248915886767237, 0.062486284353003074, 0.06247752964926778, 0.062489158815305146, 0.06248628419760538, 0.06247752949391083, 0.062489158659928656]}}
{"id": "0848ff9a-a81a-4fd0-862a-3688470814dd", "fitness": 0.062484395430083675, "name": "EnhancedCooperativeMultiPop", "description": "Introduce a multi-population strategy with cooperative co-evolution and adaptive learning to enhance diversity and improve convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCooperativeMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Nelder-Mead')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.1 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n                \n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR + 0.1\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedCooperativeMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fede50fa-6eb7-4cf6-a1ea-73366a4f8e72"], "operator": null, "metadata": {"aucs": [0.062486027530144095, 0.06247800228854128, 0.0624891567316439, 0.06248602747778387, 0.06247800223621747, 0.06248915667927879, 0.06248602732240738, 0.06247800208084564, 0.06248915652389064]}}
{"id": "4c65149b-d825-49fb-824f-3cf280f0c8ee", "fitness": 0.0624845820621206, "name": "RefinedEnhancedCooperativeMultiPop", "description": "Introduce a multi-population strategy with adaptive chaos-enhanced cooperative co-evolution, dynamic parameter tuning, and hybrid search refinement to improve exploration and convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedEnhancedCooperativeMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.1 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n                \n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR + 0.1\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 48, "feedback": "The algorithm RefinedEnhancedCooperativeMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0848ff9a-a81a-4fd0-862a-3688470814dd"], "operator": null, "metadata": {"aucs": [0.062486467162891524, 0.06247809286949835, 0.06248918641406598, 0.06248646711052308, 0.062478092817133235, 0.06248918636169498, 0.0624864669551638, 0.0624780926617845, 0.06248918620632993]}}
{"id": "f133308f-6f91-4bef-837a-1e9b6515d285", "fitness": 0.0624845820621206, "name": "RefinedEnhancedCooperativeMultiPop", "description": "Implement a multi-population strategy with chaotic Levy flight and adaptive parameter tuning, incorporating dynamic subpopulation cooperation and a memory-based feedback mechanism to enhance convergence and exploration capabilities.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedEnhancedCooperativeMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.1 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n                \n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR + 0.1\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 49, "feedback": "The algorithm RefinedEnhancedCooperativeMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["4c65149b-d825-49fb-824f-3cf280f0c8ee"], "operator": null, "metadata": {"aucs": [0.062486467162891524, 0.06247809286949835, 0.06248918641406598, 0.06248646711052308, 0.062478092817133235, 0.06248918636169498, 0.0624864669551638, 0.0624780926617845, 0.06248918620632993]}}
{"id": "4fadb450-2029-43c2-9427-0bd477ac193a", "fitness": 0.0624838651495835, "name": "QuantumChaosCooperativeMultiPop", "description": "Introduce a novel adaptive multi-population strategy with chaos-enhanced exploratory dynamics, incorporating quantum-inspired crossover and dynamic parameter self-adjustment for superior convergence and robustness.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass QuantumChaosCooperativeMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.quantum_radius = 0.1\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def quantum_crossover(self, swarm, global_best_position):\n        return swarm + self.quantum_radius * np.random.normal(0, 1, swarm.shape) * (global_best_position - swarm)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.1 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n                \n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                swarm = self.quantum_crossover(swarm, global_best_position)\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR + 0.1\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 50, "feedback": "The algorithm QuantumChaosCooperativeMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4c65149b-d825-49fb-824f-3cf280f0c8ee"], "operator": null, "metadata": {"aucs": [0.06248628635685394, 0.06247611355746807, 0.06248919579451917, 0.06248628630448527, 0.06247611350510485, 0.062489195742148174, 0.06248628614912677, 0.06247611334976222, 0.06248919558678301]}}
{"id": "f8e65dbe-cb83-45c0-8e6a-cf2c73890833", "fitness": 0.062480888236504724, "name": "ImprovedMemoryAdaptiveExploitation", "description": "Improve convergence and exploration by incorporating a memory mechanism for learned parameters and adaptive exploitation strategies.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass ImprovedMemoryAdaptiveExploitation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.param_memory = []\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n        self.param_memory = [(self.w_max, self.c1_max, self.c2_min)] * self.num_subpops\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w, self.c1, self.c2 = self.param_memory[pop_idx]\n                self.w = max(self.w_min, self.w * (1 - diversity))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.1 * self.chaos_factor\n                \n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR + 0.1\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n                if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                    self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                    self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                    self.recent_improvements = []\n\n                self.param_memory[pop_idx] = (self.w, self.c1, self.c2)\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 51, "feedback": "The algorithm ImprovedMemoryAdaptiveExploitation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4c65149b-d825-49fb-824f-3cf280f0c8ee"], "operator": null, "metadata": {"aucs": [0.06248646715275186, 0.06246701156253398, 0.06248918625430355, 0.062486467100383414, 0.06246701151018008, 0.06248918620193278, 0.06248646694502413, 0.0624670113548651, 0.06248918604656761]}}
{"id": "368243f2-7616-4e9a-b1a8-dfd7972b2176", "fitness": 0.06248439834946332, "name": "QuantumEnhancedCooperativeMultiPop", "description": "Enhance the multi-population strategy by integrating a quantum-inspired mutation operator and adaptive parameter control based on entropy and fitness diversity for improved exploration and convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass QuantumEnhancedCooperativeMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.0\n        self.c1_min = 1.2\n        self.c2_max = 2.0\n        self.c2_min = 1.2\n        self.F_max = 1.0\n        self.F_min = 0.5\n        self.CR_base = 0.9\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.005\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def quantum_mutation(self, position, lower_bound, upper_bound):\n        q_bit = np.random.rand(self.dim)\n        mutant = position + (upper_bound - lower_bound) * (q_bit - 0.5)\n        return np.clip(mutant, lower_bound, upper_bound)\n\n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                entropy = -np.sum(pbest_score * np.log(pbest_score + self.epsilon))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.1 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (entropy / (entropy + self.epsilon))\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n                \n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    if np.random.rand() < 0.1:\n                        trial = self.quantum_mutation(swarm[i], lower_bound, upper_bound)\n                    else:\n                        indices = [idx for idx in range(self.subpop_size) if idx != i]\n                        a, b, c = np.random.choice(indices, 3, replace=False)\n                        mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                        crossover = np.random.rand(self.dim) < self.CR + 0.1\n                        if not np.any(crossover):\n                            crossover[np.random.randint(0, self.dim)] = True\n                        trial = np.where(crossover, mutant, swarm[i])\n                    \n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.0)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.0)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 52, "feedback": "The algorithm QuantumEnhancedCooperativeMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["4c65149b-d825-49fb-824f-3cf280f0c8ee"], "operator": null, "metadata": {"aucs": [0.062486383747791474, 0.062477622495458074, 0.062489189065233486, 0.06248638369542303, 0.062477622443093406, 0.06248918901286282, 0.06248638354006386, 0.062477622287746115, 0.06248918885749766]}}
{"id": "caf37b2e-6dd3-4010-968e-d53445b8d74c", "fitness": 0.06248462442344235, "name": "AdaptiveHistoricalMultiPop", "description": "Improve exploration by integrating adaptive mutation and crossover strategies with historical feedback for dynamic diversity management in cooperative multi-population optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 53, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["4c65149b-d825-49fb-824f-3cf280f0c8ee"], "operator": null, "metadata": {"aucs": [0.06248646717241457, 0.06247822569848194, 0.0624891806595248, 0.0624864671200458, 0.062478225646116714, 0.06248918060715414, 0.06248646696468674, 0.062478225490767536, 0.06248918045178897]}}
{"id": "2747a125-9bd6-49e2-9d48-7ddc2ea7ad6f", "fitness": 0.06248462442344235, "name": "AdaptiveHistoricalMultiPop", "description": "Enhance exploration by integrating adaptive mutation and crossover strategies with historical feedback for dynamic diversity management in cooperative multi-population optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5) \n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 54, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.06248646717241457, 0.06247822569848194, 0.0624891806595248, 0.0624864671200458, 0.062478225646116714, 0.06248918060715414, 0.06248646696468674, 0.062478225490767536, 0.06248918045178897]}}
{"id": "09705a43-88a1-4910-9f58-c2e57d622786", "fitness": 0.06248462442344235, "name": "EnhancedAdaptiveMultiPop", "description": "Enhance adaptive exploration by integrating a dynamic learning rate adjustment mechanism driven by real-time convergence analysis and adaptive swarm intelligence for improved global search efficiency.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.learning_rate = 0.05\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    \n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + self.learning_rate, self.c1_min, self.c1_max)\n                self.c2 = np.clip(self.c2 - self.learning_rate, self.c2_min, self.c2_max)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.06248646717241457, 0.06247822569848194, 0.0624891806595248, 0.0624864671200458, 0.062478225646116714, 0.06248918060715414, 0.06248646696468674, 0.062478225490767536, 0.06248918045178897]}}
{"id": "ca9819e5-d17b-4014-aaf3-ca8208c1d76f", "fitness": 0.062484391769174974, "name": "EnhancedAdaptiveHistoricalMultiPop", "description": "Enhance adaptive historical multi-population optimization by introducing a self-adaptive learning module that dynamically updates mutation and crossover probabilities based on individual performance variance to accelerate convergence and improve diversity.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.mutation_prob = 0.5\n        self.crossover_prob = 0.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < self.mutation_prob:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.crossover_prob\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Adjust mutation and crossover probabilities based on variance\n            score_variance = np.var(personal_best_scores)\n            self.mutation_prob = 0.5 + 0.5 * np.tanh(score_variance)\n            self.crossover_prob = 0.5 - 0.5 * np.tanh(score_variance)\n            \n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.062486463853991925, 0.06247753275747003, 0.06248917895615602, 0.06248646380162326, 0.062477532705105365, 0.06248917890378536, 0.0624864636462642, 0.06247753254975841, 0.06248917874842019]}}
{"id": "8af04f46-3a5f-4383-b4c7-300749868902", "fitness": 0.06248462442344235, "name": "ImprovedAdaptiveHistoricalMultiPop", "description": "Enhance exploration and exploitation by dynamically adjusting mutation, crossover rates, and incorporating elite reinitialization based on convergence stagnation and diversity metrics in a cooperative multi-population framework.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass ImprovedAdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.elite_reinit_threshold = 0.05\n        \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            global_diversity = np.mean([np.mean(np.std(pop, axis=0)) for pop in populations])\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if global_diversity < self.elite_reinit_threshold:\n                for pop_idx in range(self.num_subpops):\n                    populations[pop_idx] = np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim))\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 57, "feedback": "The algorithm ImprovedAdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.06248646717241457, 0.06247822569848194, 0.0624891806595248, 0.0624864671200458, 0.062478225646116714, 0.06248918060715414, 0.06248646696468674, 0.062478225490767536, 0.06248918045178897]}}
{"id": "43f3af97-7135-40a1-bf29-2a140560d285", "fitness": 0.06248335325891907, "name": "AdaptiveHistoricalMultiPop", "description": "Enhance exploration by adjusting mutation strategy with a dynamic scaling factor influenced by ongoing improvements in multi-population optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (1 + np.random.randn() * 0.1) * (swarm[b] - swarm[c]), lower_bound, upper_bound)  # Adjusted line\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 58, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.062474334285832045, 0.06248919868820124, 0.062486527010443105, 0.062474334233470596, 0.06248919863583047, 0.06248652685508371, 0.0624743340781333, 0.0624891984804653]}}
{"id": "c5ff3078-a2a2-4d51-a5ac-f147f28fddcd", "fitness": 0.06248444118972804, "name": "EnhancedAdaptiveMultiPop", "description": "Enhance exploration and exploitation by incorporating adaptive chaos-based control and focused local search for robust convergence in multi-population optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='L-BFGS-B')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.06248593772636157, 0.06247821644418461, 0.0624891696587232, 0.062485937674088055, 0.06247821639181372, 0.06248916960635409, 0.0624859375188197, 0.06247821623621608, 0.062489169450991366]}}
{"id": "5fe5aee0-0838-4d85-87c4-905a1b386b71", "fitness": 0.06248439748239636, "name": "HybridChaosMetaheuristic", "description": "Enhance exploration and convergence by utilizing a hybrid strategy of Differential Evolution and Particle Swarm Optimization with adaptive parameter tuning and chaos-based dynamic adjustments.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridChaosMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.1 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.epsilon:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 60, "feedback": "The algorithm HybridChaosMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.06248639786919452, 0.06247759688247789, 0.0624891979556097, 0.062486397816825856, 0.062477596830113225, 0.062489197903239146, 0.06248639766146702, 0.062477596674766045, 0.06248919774787387]}}
{"id": "fac4a422-7561-4d8b-bc1f-bc643a981f7c", "fitness": 0.06248464939963697, "name": "AdaptiveHistoricalMultiPop", "description": "Enhance convergence efficiency by increasing the frequency of local search application to individual solutions for improved refinement.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["caf37b2e-6dd3-4010-968e-d53445b8d74c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247822902568256, 0.06248919237051087, 0.062486527010443105, 0.06247822897331734, 0.0624891923181401, 0.06248652685508371, 0.06247822881796816, 0.06248919216277504]}}
{"id": "50e0df87-7203-4695-a12b-14313c946a15", "fitness": 0.0624846354064063, "name": "AdaptiveHistoricalMultiPop", "description": "Incorporate adaptive mutation factor scaling to balance exploration and exploitation dynamically based on recent improvements.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min) * (1 - (len(self.recent_improvements) / self.feedback_window))\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247818449326914, 0.06248919492323224, 0.062486527010443105, 0.062478184440903806, 0.062489194870861575, 0.06248652685508371, 0.06247818428555485, 0.06248919471549641]}}
{"id": "acaf90a3-2ea5-4b64-94fa-fda5b5e7987c", "fitness": 0.06248013383751261, "name": "AdaptiveHistoricalMultiPop", "description": "Prioritize dynamic velocity adjustment for better search adaptability.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + 1.1 * velocity, lower_bound, upper_bound) # Changed line\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 63, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248649306710241, 0.06246471726613201, 0.062489191439374814, 0.062486493014733746, 0.06246471721378055, 0.06248919138700415, 0.062486492859374465, 0.06246471705847234, 0.062489191231638985]}}
{"id": "98f4d5c1-2da2-47d7-8dfb-be3c83e838b9", "fitness": 0.06248326211548457, "name": "AdaptiveHistoricalMultiPop", "description": "Improve convergence by adjusting the chaos_factor's influence on F and CR to better explore the solution space.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min) * 0.5  # Adjusted influence\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 64, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247406716192505, 0.06248919238180439, 0.062486527010443105, 0.062474067109563824, 0.062489192329433396, 0.06248652685508371, 0.0624740669542273, 0.06248919217406845]}}
{"id": "606bb9a7-6748-413d-a162-56d5df5c363e", "fitness": 0.062484100695463916, "name": "AdaptiveHistoricalMultiPop", "description": "Slight increase in subpop_size to enhance search diversity and solution quality.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 6  # Increased from 5 to 6\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248647409074104, 0.062476778016983925, 0.06248905023875828, 0.062486474038372375, 0.062476777964620034, 0.06248905018638795, 0.062486473883013094, 0.06247677780927552, 0.06248905003102301]}}
{"id": "71596767-5c76-45e7-aa88-57f4574b1b5e", "fitness": 0.06248464939963697, "name": "AdaptiveHistoricalMultiPop", "description": "Improve diversity management by dynamically adjusting the velocity decay factor based on convergence progress.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n\n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.w *= 0.95  # Adjust decay factor to improve diversity\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 66, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247822902568256, 0.06248919237051087, 0.062486527010443105, 0.06247822897331734, 0.0624891923181401, 0.06248652685508371, 0.06247822881796816, 0.06248919216277504]}}
{"id": "6c42bdf7-7dd7-4235-ad0c-efb3a93bab57", "fitness": 0.06248464939963697, "name": "AdaptiveDynamicMultiPop", "description": "Introduce dynamic subpopulation adaptation and chaos-induced diversification to enhance exploration and exploitation balance in black-box optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDynamicMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.num_subpops = max(1, self.num_subpops - 1)  # Dynamically adjust subpop count\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 67, "feedback": "The algorithm AdaptiveDynamicMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247822902568256, 0.06248919237051087, 0.062486527010443105, 0.06247822897331734, 0.0624891923181401, 0.06248652685508371, 0.06247822881796816, 0.06248919216277504]}}
{"id": "583a5033-9648-4951-b361-8c6be0487b18", "fitness": 0.06248459394312236, "name": "AdaptiveHistoricalMultiPop", "description": "Introduce a small perturbation to the global best position based on Gaussian noise to improve exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial + np.random.normal(0, 0.1, self.dim)  # Perturbation added here\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.062478059047168744, 0.06248919597948044, 0.062486527010443105, 0.06247805899480363, 0.062489195927109886, 0.06248652685508371, 0.06247805883945512, 0.06248919577174472]}}
{"id": "9de7be04-123e-4292-b9b7-196c76bf77c3", "fitness": 0.06248448359062243, "name": "AdaptiveHistoricalMultiPop", "description": "Enhance exploitation by integrating individual adaptive local search frequency based on recent improvement metrics.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity): \n                    for i in range(self.subpop_size):\n                        if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                            refined_position, refined_score = self.local_search(func, swarm[i])\n                            eval_count += refined_position.size\n                            if refined_score < pbest_score[i]:\n                                pbest_pos[i] = refined_position\n                                pbest_score[i] = refined_score\n                                if refined_score < global_best_score:\n                                    global_best_position = refined_position\n                                    global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.062486295184644436, 0.062478133670348046, 0.06248902217714847, 0.06248629513214954, 0.0624781336179826, 0.06248902212461549, 0.06248629497688818, 0.06247813346263342, 0.062489021969191705]}}
{"id": "45a0f23c-59ef-4ece-bc58-35edb58296e5", "fitness": 0.062484626041996415, "name": "AdaptiveHistoricalMultiPopDynamic", "description": "Introduce dynamic subpopulation restructuring with adaptive individual learning to enhance exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPopDynamic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        # Restructure based on performance\n        ranked_indices = np.argsort([score.min() for score in scores])\n        best_pop_idx = ranked_indices[0]\n        worst_pop_idx = ranked_indices[-1]\n        best_individual = populations[best_pop_idx][np.argmin(scores[best_pop_idx])]\n        populations[worst_pop_idx][np.argmax(scores[worst_pop_idx])] = best_individual\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            self.restructure_subpopulations(populations, personal_best_scores)\n            \n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 70, "feedback": "The algorithm AdaptiveHistoricalMultiPopDynamic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247815713276417, 0.06248919419050758, 0.062486527010443105, 0.06247815708039883, 0.062489194138136805, 0.06248652685508371, 0.06247815692504988, 0.06248919398277175]}}
{"id": "057c65e1-8515-4342-bc28-978a76a9a62a", "fitness": 0.06248464939963697, "name": "AdaptiveDynamicMutation", "description": "Introduce dynamic mutation strategies and adaptive parameter tuning to enhance solution diversity and convergence speed.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDynamicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveDynamicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247822902568256, 0.06248919237051087, 0.062486527010443105, 0.06247822897331734, 0.0624891923181401, 0.06248652685508371, 0.06247822881796816, 0.06248919216277504]}}
{"id": "95b7cc92-289f-4b90-af7a-8c09ab52565e", "fitness": 0.06248464939963697, "name": "AdaptiveHistoricalMultiPop", "description": "Improved exploration by tuning chaos factor to increase diversity.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHistoricalMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)  # Change made here\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 72, "feedback": "The algorithm AdaptiveHistoricalMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247822902568256, 0.06248919237051087, 0.062486527010443105, 0.06247822897331734, 0.0624891923181401, 0.06248652685508371, 0.06247822881796816, 0.06248919216277504]}}
{"id": "00eae134-2727-45ac-9e64-b5d4dd2dc7cc", "fitness": 0.06248276120218199, "name": "EnhancedAdaptiveMultiPop", "description": "Adaptive exploration-exploitation balance leverages dynamic feedback and multi-scale perturbations for enhanced convergence in diverse environments.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_base = 2.0\n        self.c2_base = 2.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_base + 0.5 * np.sin(2 * np.pi * eval_count / self.budget)\n                self.c2 = self.c2_base + 0.5 * np.cos(2 * np.pi * eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1_base = np.clip(self.c1_base + 0.1, 0, 2.5)\n                self.c2_base = np.clip(self.c2_base - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveMultiPop got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248654536532938, 0.06247255226123327, 0.06248918624006827, 0.06248654531296072, 0.0624725522088736, 0.06248918618769739, 0.062486545157601214, 0.06247255205354163, 0.062489186032332444]}}
{"id": "a7b29ac0-19b5-4d7f-8c0e-63cff8bd7275", "fitness": 0.062484649509504116, "name": "DynamicSubpopRestructure", "description": "Introduce a dynamic subpopulation restructuring mechanism to balance exploration and exploitation for enhanced convergence in diverse problem landscapes.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.2 * (1 - diversity):  # Increased local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 74, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["fac4a422-7561-4d8b-bc1f-bc643a981f7c"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247822924651414, 0.06248919247928053, 0.062486527010443105, 0.062478229194148915, 0.06248919242690987, 0.06248652685508371, 0.06247822903879974, 0.062489192271545146]}}
{"id": "0c2b571f-565c-45e3-adab-7f326ebef786", "fitness": 0.06248465038214853, "name": "DynamicSubpopRestructure", "description": "Enhance balancing of exploration and exploitation by refining subpopulation restructuring frequency based on convergence trends.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 75, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a7b29ac0-19b5-4d7f-8c0e-63cff8bd7275"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489191053463955, 0.062486527010443105, 0.062478233237898806, 0.0624891910010934, 0.06248652685508371, 0.062478233082549406, 0.06248919084572846]}}
{"id": "87284e2c-b663-471c-a555-a278e92e612b", "fitness": 0.062472957288287265, "name": "AdaptiveSuccessRateTuning", "description": "Combine adaptive subpopulation restructuring with intelligent parameter tuning based on success rates to dynamically balance exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveSuccessRateTuning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.success_threshold = 0.1\n        self.success_rate = 0.0\n        self.recent_successes = []\n        self.feedback_window = 5\n    \n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.power((np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2)) /\n                (np.math.gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2)), 1 / beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def update_success_rate(self, improvement):\n        self.recent_successes.append(improvement)\n        if len(self.recent_successes) > self.feedback_window:\n            self.recent_successes.pop(0)\n        self.success_rate = np.mean(self.recent_successes) if self.recent_successes else 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n                self.F = self.F_min + self.success_rate * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.success_rate\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    improvement = max(0, pbest_score[i] - trial_score)\n                    self.update_success_rate(improvement)\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            global_best_position = trial\n                            global_best_score = trial_score\n\n                if np.random.rand() < 0.3 * (1 - self.success_rate):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 76, "feedback": "The algorithm AdaptiveSuccessRateTuning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.0624747802957526, 0.062460576526638945, 0.06248351530251506, 0.06247478024339359, 0.06246057647429082, 0.0624835152501475, 0.0624747800880634, 0.06246057631899238, 0.06248351509479111]}}
{"id": "9a1967a1-61a7-42ca-bdd0-584ed4271b6e", "fitness": 0.06247649078204192, "name": "DynamicSubpopRestructure", "description": "Enhance the mutation strategy by refining the chaos factor to improve exploration while maintaining the existing structure.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n\n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = 0.9 * (4 * self.chaos_factor) * (1 - self.chaos_factor)  # Refined chaos factor\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 77, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00002.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06245374896102052, 0.06248919658234642, 0.062486527010443105, 0.06245374890868005, 0.062489196529975755, 0.06248652685508371, 0.06245374875340526, 0.06248919637461059]}}
{"id": "3ff58728-069d-441f-a053-85fa040f040b", "fitness": 0.06248465038214853, "name": "DynamicSubpopRestructure", "description": "Enhance exploration-exploitation balance by introducing an adaptive chaos factor resetting mechanism based on the diversity of subpopulations.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                if diversity < 0.1:  # Reset chaos factor if diversity is low\n                    self.chaos_factor = np.random.rand()\n                    \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 78, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489191053463955, 0.062486527010443105, 0.062478233237898806, 0.0624891910010934, 0.06248652685508371, 0.062478233082549406, 0.06248919084572846]}}
{"id": "3bc501bf-a300-4687-a187-33df61323457", "fitness": 0.06248465038214853, "name": "DynamicSubpopRestructure", "description": "Enhance adaptability by adjusting chaos factor based on recent improvements.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = min((4 * self.chaos_factor) * (1 - self.chaos_factor), 1.0)  # Adjusted line for improvement\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 79, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489191053463955, 0.062486527010443105, 0.062478233237898806, 0.0624891910010934, 0.06248652685508371, 0.062478233082549406, 0.06248919084572846]}}
{"id": "eb988915-99a0-4d1a-a634-e15c45c2989a", "fitness": 0.06248456592347028, "name": "DynamicSubpopRestructure", "description": "Optimize dynamic subpopulation restructuring by refining chaos factor adjustment for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = np.random.rand()  # Adjust chaos factor determination \n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 80, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.062486399607125764, 0.062478098516194236, 0.0624891999071846, 0.0624863995547571, 0.062478098463829124, 0.06248919985481416, 0.06248639939939815, 0.06247809830848039, 0.062489199699448994]}}
{"id": "1c9e09e9-7b96-4070-8ad9-8b2a3b8e2296", "fitness": 0.06248420869154504, "name": "AdaptiveMutationStrategy", "description": "Improve the balance of exploration and exploitation by introducing adaptive mutation strategies influenced by swarm diversity and recent improvements.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMutationStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n\n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n\n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n\n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                for i in range(self.subpop_size):\n                    adaptive_factor = diversity / (diversity + self.epsilon) + np.clip(self.improvement_threshold - np.mean(self.recent_improvements), 0, 1)\n                    if np.random.rand() < adaptive_factor:\n                        swarm[i] += self.levy_flight(self.dim)\n                    \n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n\n        return global_best_position", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveMutationStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248645603101577, 0.062476970884150385, 0.0624891994195611, 0.062486455978647215, 0.06247697083178638, 0.06248919936719033, 0.062486455823287934, 0.06247697067644109, 0.062489199211825164]}}
{"id": "07173922-f213-4d2b-b071-260f0f8cad08", "fitness": 0.06248465038214853, "name": "EnhancedAdaptiveMemory", "description": "Introduce adaptive memory strategy to further enhance exploration-exploitation balance by dynamically adjusting parameter values based on historical performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.memory = []\n        self.max_memory_size = 10\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def adapt_params(self):\n        if len(self.memory) > 1:\n            improvements = np.diff(self.memory)\n            avg_improvement = np.mean(improvements)\n            if avg_improvement < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n        self.memory.append(global_best_score)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            self.memory.append(global_best_score)\n                            if len(self.memory) > self.max_memory_size:\n                                self.memory.pop(0)\n                            self.adapt_params()\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489191053463955, 0.062486527010443105, 0.062478233237898806, 0.0624891910010934, 0.06248652685508371, 0.062478233082549406, 0.06248919084572846]}}
{"id": "d10670be-0e27-485c-af8a-c184a45c077d", "fitness": 0.06248465038214853, "name": "EnhancedDynamicSubpopRestructure", "description": "Integrate adaptive chaotic dynamics and feedback-driven parameter adjustment to enhance exploration-exploitation balance and convergence efficiency.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n\n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedDynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489191053463955, 0.062486527010443105, 0.062478233237898806, 0.0624891910010934, 0.06248652685508371, 0.062478233082549406, 0.06248919084572846]}}
{"id": "54ee6610-4901-467b-974d-c0db907032cb", "fitness": 0.06248168916949167, "name": "AdaptiveMutationAdjustment", "description": "Adaptively adjust mutation and crossover rates based on dynamic feedback from performance trends to enhance convergence in diverse search landscapes.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMutationAdjustment:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_base = 0.8\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                F = self.F_base + 0.5 * (self.chaos_factor - 0.5)\n                CR = self.CR_base + 0.3 * (self.chaos_factor - 0.5)\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 84, "feedback": "The algorithm AdaptiveMutationAdjustment got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06246934295870743, 0.0624891977470351, 0.062486527010443105, 0.0624693429063512, 0.06248919769466432, 0.06248652685508371, 0.06246934275102911, 0.06248919753929916]}}
{"id": "5d8cacfb-7cf2-4b80-b8ea-c32d30ab599b", "fitness": 0.062484477743231785, "name": "DynamicSubpopRestructure", "description": "Introduce adaptive inertia weight to improve the balance between exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_min + (self.w_max - self.w_min) * (1 - eval_count / self.budget)  # Changed line\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 85, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248636992491041, 0.06247786596740501, 0.06248919759747329, 0.06248636987254197, 0.06247786591504012, 0.06248919754510285, 0.0624863697171828, 0.062477865759692164, 0.06248919738973746]}}
{"id": "a48ed308-456d-42ee-a0c1-5d92df9186fc", "fitness": 0.062484477743231785, "name": "DynamicSubpopRestructure", "description": "Enhance dynamic parameter adjustment by introducing time-varying inertia weight to improve convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Adjusted line\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 86, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248636992491041, 0.06247786596740501, 0.06248919759747329, 0.06248636987254197, 0.06247786591504012, 0.06248919754510285, 0.0624863697171828, 0.062477865759692164, 0.06248919738973746]}}
{"id": "0504a465-ac0d-4fd4-9f35-e6b0547ece94", "fitness": 0.06248465038214853, "name": "DynamicSubpopRestructure", "description": "Enhance balancing of exploration and exploitation by refining subpopulation restructuring frequency based on convergence trends, with additional dynamic parameter tuning for improved performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 87, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489191053463955, 0.062486527010443105, 0.062478233237898806, 0.0624891910010934, 0.06248652685508371, 0.062478233082549406, 0.06248919084572846]}}
{"id": "0a46c431-0bd2-4a7d-aec7-63462ae293e9", "fitness": 0.062476796069247754, "name": "DynamicSubpopRestructure", "description": "Leverage chaos factor adaptation for improved exploration by dynamically adjusting the chaos factor based on recent improvements.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = 0.5  # Modified line\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n                \n                if np.random.rand() < 0.5:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 88, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.0624756235388898, 0.06247133066477506, 0.062483434264143045, 0.0624756234865298, 0.062471330612416054, 0.06248343421177538, 0.062475623331196606, 0.06247133045708486, 0.06248343405641921]}}
{"id": "e5199b69-455d-4f0a-acab-e3872ba89051", "fitness": 0.062484650940012085, "name": "DynamicSubpopRestructure", "description": "Integrate adaptive mutation scaling based on recent global best improvements to enhance convergence speed.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 89, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0c2b571f-565c-45e3-adab-7f326ebef786"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489192727054776, 0.062486527010443105, 0.062478233237898806, 0.06248919267468411, 0.06248652685508371, 0.062478233082549406, 0.06248919251931895]}}
{"id": "f3a0e4ac-d7f0-4380-920e-5e26e41d3700", "fitness": 0.062484650940012085, "name": "DynamicSubpopRestructure", "description": "Enhance convergence speed by incorporating differential evolution with chaotic dynamics and adaptive feedback into subpopulation restructuring.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity + self.c1 * r1 * (pbest_pos - swarm) + self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 90, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["e5199b69-455d-4f0a-acab-e3872ba89051"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823329026403, 0.062489192727054776, 0.062486527010443105, 0.062478233237898806, 0.06248919267468411, 0.06248652685508371, 0.062478233082549406, 0.06248919251931895]}}
{"id": "6b918f1b-ef3a-4a7b-9b1b-59dc298a9e97", "fitness": 0.06248459896005153, "name": "MemoryAdaptiveDynamicSubpopRestructure", "description": "Introduce memory-based adaptive mutation scaling and chaotic local search to enhance exploration-exploitation balance and improve convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass MemoryAdaptiveDynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.memory_scale = 1.0\n        self.no_improvement_counter = 0\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = np.random.rand()  # Introduce more unpredictability\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Memory-based adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.memory_scale * self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            self.no_improvement_counter = 0\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n                    else:\n                        self.no_improvement_counter += 1\n\n                if self.no_improvement_counter > 10:  # If no improvement over 10 attempts, perturb with local search\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n                    self.no_improvement_counter = 0\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n            \n            # Dynamically adjust memory scale for mutation\n            self.memory_scale = np.clip(self.memory_scale * (0.9 if np.mean(self.recent_improvements) < self.improvement_threshold else 1.1), 0.1, 2.0)\n        \n        return global_best_position", "configspace": "", "generation": 91, "feedback": "The algorithm MemoryAdaptiveDynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["e5199b69-455d-4f0a-acab-e3872ba89051"], "operator": null, "metadata": {"aucs": [0.062486502780870645, 0.06247809473290644, 0.06248919962647148, 0.0624865027285022, 0.06247809468054144, 0.06248919957410082, 0.0624865025731427, 0.062478094525192374, 0.06248919941873565]}}
{"id": "bc2c9aac-9ff2-4a24-8fd5-fd0ef68ecd9c", "fitness": 0.06248465008524589, "name": "AdaptiveFeedbackExplorer", "description": "Introduce adaptive feedback-driven exploration with a dynamic balance between exploitation and exploration phases based on improvement trends.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveFeedbackExplorer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n\n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n\n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n\n                avg_improvement = np.mean(self.recent_improvements) if self.recent_improvements else 0.0\n                adaptive_exploration = max(0.3, min(0.7, 1 - avg_improvement))\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                if np.random.rand() < adaptive_exploration:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n\n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n\n        return global_best_position", "configspace": "", "generation": 92, "feedback": "The algorithm AdaptiveFeedbackExplorer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["e5199b69-455d-4f0a-acab-e3872ba89051"], "operator": null, "metadata": {"aucs": [0.06248652706281188, 0.06247823239955608, 0.062489191053463955, 0.062486527010443105, 0.06247823234719074, 0.0624891910010934, 0.06248652685508371, 0.062478232191841676, 0.06248919084572846]}}
{"id": "667cb227-1af8-4c5f-a510-4636dc235fa6", "fitness": 0.06248324365594585, "name": "DynamicSubpopRestructure", "description": "Introduce adaptive crossover rate modified by recent global best improvements to enhance exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR * (1 - np.mean(self.recent_improvements)) if self.recent_improvements else self.CR  # Modified crossover\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 93, "feedback": "The algorithm DynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["e5199b69-455d-4f0a-acab-e3872ba89051"], "operator": null, "metadata": {"aucs": [0.06248645059326874, 0.06247407945333805, 0.062489201181317844, 0.062486450540900296, 0.062474079400977045, 0.06248920112894729, 0.062486450385541015, 0.06247407924564041, 0.062489200973581904]}}
{"id": "cbd5cf51-180b-452e-9c80-776420454684", "fitness": 0.062483559466344395, "name": "EnhancedDynamicSubpopRestructure", "description": "Introduce temporal learning rates and diversity adaptation to balance exploration-exploitation and enhance convergence reliability.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.temporal_lr = 0.1\n        self.diversity_adaptation_rate = 0.1\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon)) * (1 - self.temporal_lr)\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget) * self.temporal_lr\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget) * (1 - self.temporal_lr)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.3 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + self.diversity_adaptation_rate, 0, 2.5)\n                self.c2 = np.clip(self.c2 - self.diversity_adaptation_rate, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedDynamicSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["e5199b69-455d-4f0a-acab-e3872ba89051"], "operator": null, "metadata": {"aucs": [0.06248654794035613, 0.0624749366573083, 0.06248919406145759, 0.062486547887987354, 0.06247493660494652, 0.06248919400908681, 0.06248654773262796, 0.06247493644960722, 0.06248919385372165]}}
{"id": "3e9e8740-1783-453c-a10f-d533bb93ee08", "fitness": 0.06248466649628232, "name": "EnhancedSubpopRestructure", "description": "Introduce chaotic local search and adaptive inertia weights to amplify convergence effectiveness.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 0.5\n        self.c2_max = 2.5\n        self.c2_min = 0.5\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.4 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["e5199b69-455d-4f0a-acab-e3872ba89051"], "operator": null, "metadata": {"aucs": [0.06248655054588381, 0.06247825235756077, 0.06248919684549681, 0.06248655049351515, 0.062478252305195436, 0.062489196793126145, 0.062486550338155644, 0.06247825214984615, 0.06248919663776098]}}
{"id": "ec47679d-2547-4ad1-a41a-9940ab6b20e3", "fitness": 0.06248466649628232, "name": "EnhancedSubpopRestructure", "description": "Enhance adaptive parameters with feedback-driven dynamic scaling and diversity consideration for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 0.5\n        self.c2_max = 2.5\n        self.c2_min = 0.5\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.4 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["3e9e8740-1783-453c-a10f-d533bb93ee08"], "operator": null, "metadata": {"aucs": [0.06248655054588381, 0.06247825235756077, 0.06248919684549681, 0.06248655049351515, 0.062478252305195436, 0.062489196793126145, 0.062486550338155644, 0.06247825214984615, 0.06248919663776098]}}
{"id": "6e46640a-3532-42c5-862c-10b585d60b17", "fitness": 0.0624834823202646, "name": "EnhancedSubpopRestructure", "description": "Introduce adaptive dimensional mutation and stochastic restarts to enhance global exploration and avoid local optima.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 0.5\n        self.c2_max = 2.5\n        self.c2_min = 0.5\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.restart_threshold = 0.05\n        self.restart_counter = 0\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def adaptive_mutation(self, swarm, diversity):\n        adaptive_dim = int(0.1 * self.dim * (1 + diversity))\n        indices = np.random.choice(self.dim, adaptive_dim, replace=False)\n        mutations = np.zeros_like(swarm)\n        mutations[:, indices] = self.levy_flight((self.subpop_size, adaptive_dim))\n        return mutations\n\n    def stochastic_restart(self, func, lower_bound, upper_bound):\n        if np.mean(self.recent_improvements) < self.restart_threshold:\n            self.restart_counter += 1\n            return np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)), True\n        return None, False\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive dimensional mutation\n                swarm += self.adaptive_mutation(swarm, diversity)\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.4 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            # Stochastic restarts\n            new_swarms, restarted = self.stochastic_restart(func, lower_bound, upper_bound)\n            if restarted:\n                populations[pop_idx] = new_swarms\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["3e9e8740-1783-453c-a10f-d533bb93ee08"], "operator": null, "metadata": {"aucs": [0.062486485562528005, 0.062474764852676445, 0.06248919680567777, 0.06248648551015945, 0.062474764800314775, 0.062489196753307, 0.06248648535480017, 0.06247476464497592, 0.06248919659794183]}}
{"id": "073cbe71-38a9-4b1c-a66b-2d7d41ef31a1", "fitness": 0.0624846657501332, "name": "EnhancedSubpopRestructure", "description": "Integrate dynamic subpopulation restructuring and multi-scale chaotic local search to enhance exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedSubpopRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 0.5\n        self.c2_max = 2.5\n        self.c2_min = 0.5\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.4 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations dynamically\n            if eval_count % (self.budget // 10) == 0:\n                populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + 0.1, 0, 2.5)\n                self.c2 = np.clip(self.c2 - 0.1, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedSubpopRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["3e9e8740-1783-453c-a10f-d533bb93ee08"], "operator": null, "metadata": {"aucs": [0.06248655054588381, 0.06247825235756077, 0.06248919460704949, 0.06248655049351515, 0.062478252305195436, 0.06248919455467872, 0.062486550338155644, 0.06247825214984615, 0.06248919439931366]}}
{"id": "07e220c6-2920-4342-90f4-9fb91d880f1d", "fitness": 0.06248466649628232, "name": "DynamicSubpopFeedback", "description": "Integrate dynamic subpopulation restructuring and enhanced feedback adaptation to improve solution diversity and convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSubpopFeedback:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.subpop_size = 5\n        self.num_subpops = self.pop_size // self.subpop_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 0.5\n        self.c2_max = 2.5\n        self.c2_min = 0.5\n        self.F_max = 1.5\n        self.F_min = 0.5\n        self.CR_base = 0.7\n        self.epsilon = 1e-8\n        self.improvement_threshold = 0.01\n        self.recent_improvements = []\n        self.feedback_window = 5\n        self.chaos_factor = np.random.rand()\n        self.levy_beta = 1.5\n        self.feedback_adaptation = 0.05\n    \n    def levy_flight(self, size):\n        sigma = (np.power((np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2)) /\n                (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * np.power(2, (self.levy_beta - 1) / 2)), 1 / self.levy_beta))\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.levy_beta)\n        return step\n    \n    def local_search(self, func, point):\n        result = minimize(func, point, method='Powell')\n        return result.x, result.fun\n\n    def restructure_subpopulations(self, populations, scores):\n        combined_pop = np.concatenate(populations)\n        combined_scores = np.concatenate(scores)\n        sorted_indices = np.argsort(combined_scores)\n        top_individuals = combined_pop[sorted_indices][:self.pop_size]\n        return np.array_split(top_individuals, self.num_subpops)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lower_bound, upper_bound, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        velocities = [np.random.uniform(-1, 1, (self.subpop_size, self.dim)) for _ in range(self.num_subpops)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best_position = personal_best_positions[0][np.argmin(personal_best_scores[0])]\n        global_best_score = func(global_best_position)\n        \n        eval_count = sum(len(scores) for scores in personal_best_scores)\n\n        while eval_count < self.budget:\n            for pop_idx in range(self.num_subpops):\n                swarm = populations[pop_idx]\n                velocity = velocities[pop_idx]\n                pbest_pos = personal_best_positions[pop_idx]\n                pbest_score = personal_best_scores[pop_idx]\n\n                diversity = np.mean(np.std(swarm, axis=0))\n                self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + self.epsilon))\n                self.chaos_factor = (4 * self.chaos_factor) * (1 - self.chaos_factor)\n                self.F = self.F_min + self.chaos_factor * (self.F_max - self.F_min)\n                self.CR = self.CR_base + 0.2 * self.chaos_factor\n                \n                self.c1 = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n                self.c2 = self.c2_min + (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n                r1, r2 = np.random.rand(self.subpop_size, self.dim), np.random.rand(self.subpop_size, self.dim)\n                velocity = (self.w * velocity +\n                            self.c1 * r1 * (pbest_pos - swarm) +\n                            self.c2 * r2 * (global_best_position - swarm))\n                swarm = np.clip(swarm + velocity, lower_bound, upper_bound)\n\n                # Adaptive mutation scaling\n                recent_improvement_factor = max(0.5, 1 - np.mean(self.recent_improvements)) if self.recent_improvements else 1.0\n                if np.random.rand() < 0.5 * recent_improvement_factor:\n                    swarm += self.levy_flight((self.subpop_size, self.dim))\n                \n                for i in range(self.subpop_size):\n                    indices = [idx for idx in range(self.subpop_size) if idx != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = np.clip(swarm[a] + self.F * (swarm[b] - swarm[c]), lower_bound, upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    if not np.any(crossover):\n                        crossover[np.random.randint(0, self.dim)] = True\n                    trial = np.where(crossover, mutant, swarm[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < pbest_score[i]:\n                        pbest_pos[i] = trial\n                        pbest_score[i] = trial_score\n                        if trial_score < global_best_score:\n                            self.recent_improvements.append(global_best_score - trial_score)\n                            global_best_position = trial\n                            global_best_score = trial_score\n                            if len(self.recent_improvements) > self.feedback_window:\n                                self.recent_improvements.pop(0)\n\n                if np.random.rand() < 0.4 * (1 - diversity):  # Adjusted local search frequency\n                    for i in range(self.subpop_size):\n                        refined_position, refined_score = self.local_search(func, swarm[i])\n                        eval_count += refined_position.size\n                        if refined_score < pbest_score[i]:\n                            pbest_pos[i] = refined_position\n                            pbest_score[i] = refined_score\n                            if refined_score < global_best_score:\n                                global_best_position = refined_position\n                                global_best_score = refined_score\n\n            # Restructuring subpopulations\n            populations = self.restructure_subpopulations(populations, personal_best_scores)\n\n            if len(self.recent_improvements) >= self.feedback_window and np.mean(self.recent_improvements) < self.improvement_threshold:\n                self.c1 = np.clip(self.c1 + self.feedback_adaptation, 0, 2.5)\n                self.c2 = np.clip(self.c2 - self.feedback_adaptation, 0, 2.5)\n                self.recent_improvements = []\n\n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position", "configspace": "", "generation": 99, "feedback": "The algorithm DynamicSubpopFeedback got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["3e9e8740-1783-453c-a10f-d533bb93ee08"], "operator": null, "metadata": {"aucs": [0.06248655054588381, 0.06247825235756077, 0.06248919684549681, 0.06248655049351515, 0.062478252305195436, 0.062489196793126145, 0.062486550338155644, 0.06247825214984615, 0.06248919663776098]}}
