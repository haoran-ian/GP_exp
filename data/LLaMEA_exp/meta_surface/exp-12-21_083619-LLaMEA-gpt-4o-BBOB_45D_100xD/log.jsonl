{"id": "9b404d62-c043-4a2e-aeda-88dc85c5adfb", "fitness": 0.05652980168999763, "name": "HybridDEPSO", "description": "A hybrid Differential Evolution and Particle Swarm Optimization (DE-PSO) algorithm that leverages the explorative power of DE and the exploitative nature of PSO to efficiently navigate complex search spaces.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.5  # DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 1.5  # PSO cognitive parameter\n        self.c2 = 1.5  # PSO social parameter\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n        return global_best, global_best_fitness", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05653 with standard deviation 0.05336.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12708871639448693, 0.1309569359372077, 0.12628123395435964, 0.03948580756380138, 0.038689026013754235, 0.04559982867970214, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "3f341699-d499-4366-b481-9c140dc543c3", "fitness": 0.059141093320310686, "name": "HybridDEPSO", "description": "An enhanced hybrid DE-PSO algorithm incorporating adaptive parameters and an elite preservation strategy to refine exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05914 with standard deviation 0.05356.", "error": "", "parent_ids": ["9b404d62-c043-4a2e-aeda-88dc85c5adfb"], "operator": null, "metadata": {"aucs": [0.1290004042435723, 0.13163237856131693, 0.12840138715048655, 0.04511095524741482, 0.05412648681939092, 0.04333156119394799, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "c2045df7-061d-4afd-97e2-f5a80c6b0ca3", "fitness": 0.0570619538164755, "name": "EnhancedHybridDEPSO", "description": "A hybrid DE-PSO algorithm with dynamic leader selection and diversity maintenance to improve exploration and adaptively balance the search intensities.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            # Diversity measure\n            if np.std(fitness) < self.diversity_threshold:\n                self.F = max(0.5, self.F * 0.9)  # Decrease DE mutation factor to increase exploration\n            \n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite dynamically\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05706 with standard deviation 0.05342.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.13160189181474513, 0.12600261003786695, 0.12798578813688388, 0.041781274520274914, 0.044645154330377856, 0.04087419884146404, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "eb150bce-97cc-47a8-869d-f0594e458e49", "fitness": 0.05588681105666493, "name": "HybridDEPSO", "description": "Enhanced hybrid DE-PSO algorithm with adaptive swarm sizes and inertia weight for improved convergence.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(30 + 20 * (dim / 10))  # Adaptive population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.9 - 0.2 * (self.budget / 10000)  # Adaptive inertia weight\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05589 with standard deviation 0.05364.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.12497185411130696, 0.13096041557474092, 0.1289488534177411, 0.03682124124436004, 0.04044792176246581, 0.04016434673270286, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "e0f0749a-9faa-4683-b7c1-e813a4de367f", "fitness": 0.05708134996439054, "name": "HybridDEPSO", "description": "Introducing a dynamic inertia weight strategy and an enhanced convergence check to improve the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.9  # Updated inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05708 with standard deviation 0.05482.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.1304257626537405, 0.13467753437904295, 0.1281213204583206, 0.03708067320502273, 0.04344507627527394, 0.03931511604144744, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "e265e616-17b4-41c1-8888-4e5f7f20eddd", "fitness": -Infinity, "name": "EnhancedHybridDEPSO", "description": "Introducing a novel adaptive inertia weight and dynamic population resizing strategy in the hybrid DE-PSO to enhance convergence speed and solution diversity.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.min_population_size = 10\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            # Adjust population size dynamically\n            population_size = int(self.initial_population_size * (1 - evaluations / self.budget)) + self.min_population_size\n            population = population[:population_size]\n            velocities = velocities[:population_size]\n            fitness = fitness[:population_size]\n            personal_best = personal_best[:population_size]\n            personal_best_fitness = personal_best_fitness[:population_size]\n\n            # Adaptive inertia weight\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            # Differential Evolution Phase\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 5, "feedback": "An exception occurred: IndexError('index 33 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 33 is out of bounds for axis 0 with size 30')", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {}}
{"id": "08fcc32a-c3ba-44c8-a1c1-11ab0d4dc33f", "fitness": 0.05891610463614613, "name": "HybridDEPSO", "description": "A refined hybrid DE-PSO algorithm that integrates an adaptive local search step based on the global best and elite solution for enhanced convergence.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Adaptive local search\n            if evaluations < self.budget - 2:\n                local_search = np.clip(global_best + 0.1 * np.random.randn(self.dim), lb, ub)\n                local_fitness = func(local_search)\n                evaluations += 1\n                if local_fitness < global_best_fitness:\n                    global_best = local_search\n                    global_best_fitness = local_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05892 with standard deviation 0.05395.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.1328324790314246, 0.13370034733361869, 0.12456420582143402, 0.048506460124966067, 0.04496995393692871, 0.045004828810276454, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "cbc0133f-e57e-4441-be8b-142850c9d6c1", "fitness": 0.0587367151088489, "name": "HybridDEPSO", "description": "A refined hybrid DE-PSO algorithm with adaptive parameter tuning and dynamic inertia for enhanced exploration and convergence balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.9  # Dynamic inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.5 + 0.25 * (evaluations / self.budget)  # Reduced adaptivity range\n\n        return elite, func(elite)", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.05607.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.1368925477883609, 0.13760710164311718, 0.12802299504792647, 0.03775930876515199, 0.04142652594835716, 0.04625529012005969, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "d41d4e10-ad77-45f4-997f-213113062230", "fitness": 0.05452870885796065, "name": "EnhancedHybridDEPSO", "description": "Adaptive Differential Evolution and Particle Swarm Optimization with Dynamic Search Space Reduction and Multi-Elite Strategy for Enhanced Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n        self.elite_count = 5\n        self.search_space_reduction_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = [global_best] * self.elite_count\n        \n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elites and adapt F\n            elite_candidates = np.append(population, elite, axis=0)\n            elite_candidates_fitness = np.array([func(ind) for ind in elite_candidates])\n            best_indices = np.argsort(elite_candidates_fitness)[:self.elite_count]\n            elite = elite_candidates[best_indices]\n            lb, ub = lb + (ub - lb) * (1 - self.search_space_reduction_rate), ub - (ub - lb) * (1 - self.search_space_reduction_rate)\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        best_elite_idx = np.argmin([func(e) for e in elite])\n        return elite[best_elite_idx], func(elite[best_elite_idx])", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05453 with standard deviation 0.05392.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.12280054824858788, 0.1278517515653831, 0.13263543675279965, 0.03362221815323352, 0.04360539776316985, 0.029576360571805127, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "cda6fe94-b81c-4959-b89f-a4086929461a", "fitness": 0.05759247685563486, "name": "EnhancedHybridDEPSO", "description": "A modified Hybrid DE-PSO algorithm introducing dynamic inertia weight adjustment and an enhanced elite preservation mechanism to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9  # Start with higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt parameters dynamically\n            if global_best_fitness < func(elite):\n                elite = global_best\n            \n            # Dynamic adjustment of inertia weight\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * 0.99)\n            # Dynamic adjustment of F based on elite's improvement\n            if evaluations / self.budget > 0.5:\n                self.F = 0.5 + 0.3 * ((evaluations - self.budget/2) / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05759 with standard deviation 0.05228.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.12333601798656169, 0.13002661794532844, 0.12631256275828895, 0.042434753353525645, 0.045090042228144944, 0.050465630762197344, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "fbc9f367-2679-43f3-b2ec-a83d346c2fc6", "fitness": 0.058830068405577446, "name": "RefinedHybridDEPSO", "description": "A refined hybrid DE-PSO algorithm that incorporates adaptive learning rates for DE/PSO phases and a dynamic elite adjustment for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n        self.elite_update_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            # Dynamically adjust the mutation factor F based on evaluations\n            F = self.initial_F * (1 - evaluations / self.budget)\n\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite with a dynamic adjustment\n            if global_best_fitness < func(elite):\n                elite = global_best\n            else:\n                elite = (1 - self.elite_update_rate) * elite + self.elite_update_rate * global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 10, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05883 with standard deviation 0.05495.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.129436157609772, 0.12930224505388788, 0.13748276655760994, 0.03965161002137674, 0.05208026469594873, 0.04085090504493505, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "edc71eb6-6fcd-4c72-95ec-a5512e55cb1b", "fitness": 0.059141093320310686, "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid DE-PSO that dynamically adjusts PSO parameters based on convergence speed and incorporates a diversity preservation mechanism to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt parameters\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n            diversity = np.mean(np.std(population, axis=0))\n            if diversity < self.diversity_threshold:\n                self.c1, self.c2 = 1.5, 1.5  # Increase exploration\n            else:\n                self.c1, self.c2 = 2.0, 2.0  # Standard values\n\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05914 with standard deviation 0.05356.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.1290004042435723, 0.13163237856131693, 0.12840138715048655, 0.04511095524741482, 0.05412648681939092, 0.04333156119394799, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "c4b889ef-8c71-431c-9a20-389de498428e", "fitness": 0.05731101890981977, "name": "HybridDEPSO", "description": "Enhanced hybrid DE-PSO with dynamic inertia weight and memory-based mutation to improve convergence.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + 0.1 * (elite - a), lb, ub)  # Memory-based mutation\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 12, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05731 with standard deviation 0.05420.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.12680458917217308, 0.13470644554366962, 0.12829362541658873, 0.04732389481683197, 0.04316705988238412, 0.03483688869006374, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "30f27561-ec25-4d06-be15-322b3c88472c", "fitness": 0.058714993436678, "name": "HybridDEPSO", "description": "An enhanced hybrid DE-PSO algorithm incorporating adaptive parameters, elite preservation, and a dynamic population scaling strategy to adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.min_population_size = 10  # Minimum population size for dynamic scaling\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Dynamic population scaling\n            if evaluations > self.budget // 2:\n                self.population_size = max(self.min_population_size, self.population_size // 2)\n                population = population[:self.population_size]\n                velocities = velocities[:self.population_size]\n                fitness = fitness[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_fitness = personal_best_fitness[:self.population_size]\n\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.5 + 0.3 * (evaluations / self.budget)\n\n        return elite, func(elite)", "configspace": "", "generation": 13, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05871 with standard deviation 0.05255.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.12555816187416158, 0.13176725095820063, 0.1252168684992424, 0.04682228678711742, 0.053777441631990275, 0.044626264512723, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "fdb38850-61c9-4da1-8aa1-2dbf5c436ccb", "fitness": 0.05939052922179586, "name": "HybridDEPSO", "description": "An enhanced hybrid DE-PSO algorithm with adaptive mutation factor and critical elite preservation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F (Enhanced elite preservation)\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.6 + 0.2 * (evaluations / self.budget)  # Slight modification here\n\n        return elite, func(elite)", "configspace": "", "generation": 14, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05939 with standard deviation 0.05418.", "error": "", "parent_ids": ["3f341699-d499-4366-b481-9c140dc543c3"], "operator": null, "metadata": {"aucs": [0.1256355796380042, 0.1324166373918949, 0.1346805695990949, 0.04240525466921219, 0.053520456234180114, 0.04518959879710971, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "68ad1e8c-d623-44ae-a129-743a8e1036dd", "fitness": 0.05854268516626631, "name": "HybridDEPSO", "description": "Adaptive DE-PSO with dynamic neighborhood topology and elite reinitialization to enhance global search capability and convergence speed.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n        self.elite_reinit_factor = 0.05  # Proportion of budget for elite reinitialization\n        self.reinit_threshold = 0.2  # Threshold for reinitialization based on improvement\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n        last_global_best_fitness = global_best_fitness\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase with Dynamic Neighborhood\n            for i in range(self.population_size):\n                neighbors_idx = np.random.choice(range(self.population_size), 5, replace=False)\n                a, b, c = population[neighbors_idx[:3]]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase with Elite Reinitialization\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.6 + 0.2 * (evaluations / self.budget)\n\n            # Reinitialize elite if improvement stalls\n            if (last_global_best_fitness - global_best_fitness) / last_global_best_fitness < self.reinit_threshold:\n                if evaluations + int(self.elite_reinit_factor * self.budget) <= self.budget:\n                    elite = np.random.uniform(lb, ub, self.dim)\n                    last_global_best_fitness = global_best_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 15, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05854 with standard deviation 0.05277.", "error": "", "parent_ids": ["fdb38850-61c9-4da1-8aa1-2dbf5c436ccb"], "operator": null, "metadata": {"aucs": [0.13117040506481936, 0.12392280981013715, 0.1287877007158834, 0.048497702362396033, 0.046972016697359065, 0.046866865179135075, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "7a594328-15ee-45fa-a75a-a4044a6f9eb0", "fitness": 0.058559219986825846, "name": "HybridDEPSO", "description": "Optimized Hybrid DE-PSO with dynamic adjustment of population size and CR for enhanced convergence.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)  # Dynamic population size based on dimension\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F (Enhanced elite preservation)\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.CR = 0.8 + 0.1 * (evaluations / self.budget)  # Slight modification here\n\n        return elite, func(elite)", "configspace": "", "generation": 16, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05856 with standard deviation 0.05285.", "error": "", "parent_ids": ["fdb38850-61c9-4da1-8aa1-2dbf5c436ccb"], "operator": null, "metadata": {"aucs": [0.12842506760685868, 0.12450892680578518, 0.13124263306202322, 0.052140426703763953, 0.047463970506528175, 0.0425852885298067, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "d75b1a35-f1c1-452a-bf87-739bcd579268", "fitness": 0.05697174759152879, "name": "HybridDEPSO", "description": "A refined HybridDEPSO algorithm with a dynamically adjusting inertia weight for improved convergence balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.F = 0.8  # Adaptive DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Differential Evolution Phase\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite and adapt F (Enhanced elite preservation)\n            if global_best_fitness < func(elite):\n                elite = global_best\n            self.F = 0.6 + 0.2 * (evaluations / self.budget)  # Slight modification here\n\n        return elite, func(elite)", "configspace": "", "generation": 17, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05697 with standard deviation 0.05386.", "error": "", "parent_ids": ["fdb38850-61c9-4da1-8aa1-2dbf5c436ccb"], "operator": null, "metadata": {"aucs": [0.13277555156566478, 0.12906648021006728, 0.12593108198119363, 0.03858823127363742, 0.0446347870987136, 0.04108292952781567, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "dbabb59b-44fb-41aa-beb1-35df5920d46f", "fitness": 0.060365144145956964, "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid DE-PSO algorithm with dynamic population adaptation and rotational diversity to improve convergence and prevent premature stagnation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30  # Initial population size\n        self.population_variability = 5  # Variability in population size\n        self.F = 0.8  # DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Adjust population size dynamically\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            # Differential Evolution Phase with rotational diversity\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                rotation_vector = np.random.uniform(-1, 1, self.dim)\n                mutant = np.clip(a + self.F * (b - c) + 0.1 * rotation_vector, lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06037 with standard deviation 0.05583.", "error": "", "parent_ids": ["fdb38850-61c9-4da1-8aa1-2dbf5c436ccb"], "operator": null, "metadata": {"aucs": [0.13710627945754084, 0.123708190546991, 0.1417842354715959, 0.05261282685416413, 0.048864925857399544, 0.03854317245925454, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "a9a1b444-208f-42c2-8bee-9c952b095ab0", "fitness": 0.05707604733981422, "name": "EnhancedHybridDEPSO", "description": "Adaptive Differential Evolution PSO (ADE-PSO) with adaptive mutation and crossover rates to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.F_min, self.F_max = 0.5, 1.0  # Range for adaptive DE mutation factor\n        self.CR_min, self.CR_max = 0.3, 0.9  # Range for adaptive DE crossover probability\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n\n    def adaptive_parameters(self, evaluations):\n        # Adaptive mutation and crossover rates based on progress\n        progress = evaluations / self.budget\n        F = self.F_min + (self.F_max - self.F_min) * (1 - progress)  # Decrease F over time\n        CR = self.CR_min + (self.CR_max - self.CR_min) * progress  # Increase CR over time\n        return F, CR\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            # Update adaptive parameters\n            F, CR = self.adaptive_parameters(evaluations)\n\n            # Differential Evolution Phase\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05708 with standard deviation 0.05325.", "error": "", "parent_ids": ["dbabb59b-44fb-41aa-beb1-35df5920d46f"], "operator": null, "metadata": {"aucs": [0.12306282351064102, 0.13076929960123218, 0.13063480218077816, 0.04655858107760169, 0.03984252147867384, 0.04214973154273438, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "0fa702db-a0e4-44aa-9f8d-7ee98f113143", "fitness": 0.059246948120360465, "name": "EnhancedHybridDEPSO", "description": "A hybrid DE-PSO algorithm with adaptive inertia weight, dynamic mutation, and enhanced elitism for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_base = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            # Update inertia weight\n            w = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            # Dynamic mutation factor\n            avg_fitness = np.mean(fitness)\n            F = self.F_base * (1 - (global_best_fitness / avg_fitness))\n\n            # Adjust population size dynamically\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            # Differential Evolution Phase\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Enhanced elitism strategy\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05925 with standard deviation 0.05473.", "error": "", "parent_ids": ["dbabb59b-44fb-41aa-beb1-35df5920d46f"], "operator": null, "metadata": {"aucs": [0.12709191196327196, 0.13722095456376437, 0.131432164714666, 0.042866087170901235, 0.05136191003849688, 0.042582837965477016, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "f213021e-1892-465d-8feb-d6a205253d55", "fitness": 0.06043045337224906, "name": "EnhancedHybridDEPSO", "description": "Introduced adaptive mutation scaling in the DE phase to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30  # Initial population size\n        self.population_variability = 5  # Variability in population size\n        self.F = 0.8  # DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.c1 = 2.0  # PSO cognitive parameter\n        self.c2 = 2.0  # PSO social parameter\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best  # Elite preservation\n\n        while evaluations < self.budget:\n            # Adjust population size dynamically\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            # Differential Evolution Phase with rotational diversity\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                rotation_vector = np.random.uniform(-1, 1, self.dim)\n                adaptive_F = self.F * (1 - (evaluations / self.budget))  # Adaptive mutation scaling\n                mutant = np.clip(a + adaptive_F * (b - c) + 0.1 * rotation_vector, lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            # Particle Swarm Optimization Phase\n            for i in range(population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Update elite\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06043 with standard deviation 0.05536.", "error": "", "parent_ids": ["dbabb59b-44fb-41aa-beb1-35df5920d46f"], "operator": null, "metadata": {"aucs": [0.125192332051004, 0.12480508330949402, 0.1489035090844607, 0.04075024181723019, 0.0513227936244991, 0.05223345379688682, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "6f5e7310-6a9b-4f66-a1cd-64a76ad1e7e4", "fitness": 0.06300785843115168, "name": "EnhancedHybridDEPSOCrowding", "description": "Introduced crowding distance mechanism in DE phase and velocity clamping in PSO phase to promote diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOCrowding:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n        self.velocity_clamp = np.array([1.0] * dim)  # Velocity clamping\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                adaptive_F = self.F * (1 - (evaluations / self.budget))\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = crowding_distance(population, fitness)\n            for i in range(population_size):\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (self.inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridDEPSOCrowding got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06301 with standard deviation 0.05386.", "error": "", "parent_ids": ["f213021e-1892-465d-8feb-d6a205253d55"], "operator": null, "metadata": {"aucs": [0.12706653581779448, 0.13705432906111426, 0.13074212871986812, 0.056646976556446016, 0.056638810119446936, 0.0582552789390286, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "4ab4f546-aff0-49c7-a99d-3369b5feb59a", "fitness": 0.06062946619749147, "name": "EnhancedHybridDEPSOAdaptive", "description": "Introduced adaptive inertia weighting in PSO phase and elitism strategy to maintain diversity and exploit best-found solutions.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                adaptive_F = self.F * (1 - (evaluations / self.budget))\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = crowding_distance(population, fitness)\n            inertia_weight = self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget))\n            for i in range(population_size):\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridDEPSOAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06063 with standard deviation 0.05151.", "error": "", "parent_ids": ["6f5e7310-6a9b-4f66-a1cd-64a76ad1e7e4"], "operator": null, "metadata": {"aucs": [0.12656588567209703, 0.12340689123805593, 0.1275574998164729, 0.04857424437148494, 0.06254551673765163, 0.056348491274994084, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "38d58269-61a8-4c38-abcf-dfb196517b68", "fitness": 0.06371610612912514, "name": "EnhancedHybridDEPSOAdaptiveElitism", "description": "Incorporate adaptive inertia weight in PSO phase and employ elitism-based local search to enhance exploration-exploitation balance and solution refinement.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                adaptive_F = self.F * (1 - (evaluations / self.budget))\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitism got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06372 with standard deviation 0.05390.", "error": "", "parent_ids": ["6f5e7310-6a9b-4f66-a1cd-64a76ad1e7e4"], "operator": null, "metadata": {"aucs": [0.13671325539224866, 0.12516558289672275, 0.13305438036781414, 0.052034546012595606, 0.06419684462814679, 0.06161367919793159, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "de7c542a-60ae-45fc-99cd-afebf1270f1c", "fitness": 0.05536741687505488, "name": "RefinedHybridDEPSOCrowding", "description": "Integrate adaptive differential evolution with dynamic velocity control and crowding distance to improve diversity and convergence in the population.", "code": "import numpy as np\n\nclass RefinedHybridDEPSOCrowding:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.elite_preservation_prob = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                adaptive_F = self.F * (1 - (evaluations / self.budget))\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(new_position)\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = new_position\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = new_position\n                            global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search with a small random chance\n            if np.random.rand() < self.elite_preservation_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(elite + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < global_best_fitness:\n                    elite = candidate\n                    global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 25, "feedback": "The algorithm RefinedHybridDEPSOCrowding got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05537 with standard deviation 0.05371.", "error": "", "parent_ids": ["38d58269-61a8-4c38-abcf-dfb196517b68"], "operator": null, "metadata": {"aucs": [0.12221838437681587, 0.12491072069928133, 0.1367045654619209, 0.03835818456184803, 0.03897702891947641, 0.03647120118948466, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "13767949-3766-4395-b407-9e69812ed716", "fitness": 0.05807245946985351, "name": "RefinedHybridDEPSO", "description": "Introduce dynamic leader selection and dual-phase local search to improve population diversity and solution convergence.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                adaptive_F = self.F * (1 - (evaluations / self.budget))\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                dynamic_leader = global_best if np.random.rand() > 0.5 else personal_best[i]\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (dynamic_leader - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Dual-phase local search\n            for phase in range(2):\n                perturbation = np.random.normal(0, 0.1 / (phase + 1), self.dim)\n                candidate = np.clip(elite + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < global_best_fitness:\n                    elite = candidate\n                    global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 26, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05807 with standard deviation 0.05290.", "error": "", "parent_ids": ["38d58269-61a8-4c38-abcf-dfb196517b68"], "operator": null, "metadata": {"aucs": [0.12211491280269093, 0.13241688915392935, 0.12916193253834962, 0.041279611521288784, 0.047430629733697494, 0.0495814928120587, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "fe97beac-1117-43ae-9e38-f40fc6ef601c", "fitness": -Infinity, "name": "EnhancedHybridDEPSOAdaptiveElitism", "description": "Introduce a dynamic updating mechanism for both the population size and crossover rate based on current progress to enhance adaptability.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F = 0.8\n        self.CR = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            population_size = max(20, int(self.population_initial_size * (1 + 0.5 * progress_ratio)))  # Changed line\n            self.CR = 0.9 - 0.5 * progress_ratio  # Changed line\n            if evaluations % (self.budget // 4) == 0:\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                adaptive_F = self.F * (1 - (evaluations / self.budget))\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 27, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_ids": ["38d58269-61a8-4c38-abcf-dfb196517b68"], "operator": null, "metadata": {}}
{"id": "c0f9c368-4955-46f8-a382-1e2c71430ab6", "fitness": 0.0702768887180409, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance to enhance exploration and convergence rates.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07028 with standard deviation 0.06544.", "error": "", "parent_ids": ["38d58269-61a8-4c38-abcf-dfb196517b68"], "operator": null, "metadata": {"aucs": [0.1985113683808507, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "e9f71076-76ff-4de3-8aae-663a81b18c86", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance and refined elitism perturbation to enhance exploration and convergence rates.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation scale\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "d54aed00-d3c9-4a1d-ba22-8ef6c77e4d94", "fitness": 0.06081113922439438, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly increase the initial F parameter to enhance the exploration capabilities early in the optimization process.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.85  # Increased from 0.8 to 0.85\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06081 with standard deviation 0.05288.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1307329519177145, 0.1252309488861837, 0.13087948840944763, 0.05157000756484009, 0.058092621465131944, 0.05012756810956487, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "6aa67c56-488a-4d93-bec8-e254d5553987", "fitness": 0.06220125600119307, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Fine-tune the crossover rate to enhance exploration by increasing its initial value.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.95  # Changed from 0.9 to 0.95\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06220 with standard deviation 0.05373.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12612428033699252, 0.13956269397319743, 0.12677892429496707, 0.06246030175695749, 0.04976469433680686, 0.05445374264514957, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "5754597a-29a6-4e67-98c0-ec325e2b67c0", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance to enhance exploration and convergence rates, with a refined elitism-based local search.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation for finer search\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "9e990bdd-3f38-472f-bbe2-75b564950125", "fitness": 0.06087243709280446, "name": "RefinedHybridDEPSO", "description": "Introduce adaptive learning rates and hybrid evolutionary operators to enhance diversity and convergence in a self-adaptive DE-PSO framework.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i] + self.learning_rate * np.random.randn(self.dim), lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 33, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06087 with standard deviation 0.05222.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1308199318463905, 0.12636894392177556, 0.12482210999914034, 0.06441650423574108, 0.04960560749201004, 0.05115216967351588, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "cd6dce19-90f2-4153-a175-ebe871d2d3f1", "fitness": 0.06523442008359193, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance to enhance exploration and convergence rates, now with improved velocity update scaling for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = 0.9 * (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))  # Changed line\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06523 with standard deviation 0.05367.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13038018384252947, 0.13212580930963502, 0.12994358666965677, 0.07735673367656026, 0.05155034037966044, 0.06508646020761866, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "22d76ae4-9e4d-4054-a0d4-4881044f25e2", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance to enhance exploration and convergence rates, and improve local search by reducing perturbation variance.  ", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.01, self.dim)  # Changed line\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "45586cfa-d8a8-4f50-8e63-63c808414c76", "fitness": 0.06341761140599216, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce adaptive population resizing and a multi-modal mutation strategy to enhance exploration and exploitation balance in optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 10\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    new_fitnesses = np.array([func(ind) for ind in new_individuals])\n                    fitness = np.concatenate((fitness, new_fitnesses))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, new_fitnesses))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            progress = evaluations / self.budget\n            F, CR = adaptive_parameters(progress)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                if np.random.rand() < 0.3:  # Introduce another mutation strategy\n                    mutant = np.clip(a + F * (global_best - c), lb, ub)\n                else:\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05293.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12979878033472492, 0.1307790666444002, 0.12859700925797324, 0.06322606114462559, 0.05923690848675767, 0.05845401011878104, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "357944d8-8235-40d5-b2b2-0c75874484c8", "fitness": 0.06632097816491997, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly enhance the exploration by adjusting the mutation strategy and refine elitism-based local search with adaptive perturbation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c) + F * (global_best - a), lb, ub)  # Enhanced exploration\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1 * (evaluations / self.budget), self.dim)  # Adaptive perturbation\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06632 with standard deviation 0.05439.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12957597754525818, 0.13868633487921, 0.13165636704371775, 0.0680491928130389, 0.06488534831414428, 0.06336891622224394, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "8ba82fab-df47-4604-b689-522619ce6a87", "fitness": 0.06063251322592812, "name": "RefinedHybridDEPSOAdaptiveElitism", "description": "Hybridization of differential evolution and particle swarm optimization with adaptive parameters and elitism to enhance convergence and robustness.", "code": "import numpy as np\n\nclass RefinedHybridDEPSOAdaptiveElitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1_initial = 2.0\n        self.c2_initial = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n\n                progress = evaluations / self.budget\n                F = self.F_initial * (1 - progress)\n                CR = self.CR_initial * progress\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = self.dynamic_crowding_distance(population, fitness)\n            inertia_weight = self.adaptive_inertia_weight(evaluations / self.budget)\n            for i in range(self.population_size):\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.adaptive_c1(evaluations / self.budget) * r1 * (personal_best[i] - population[i]) +\n                                     self.adaptive_c2(evaluations / self.budget) * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        return elite, func(elite)\n\n    def adaptive_inertia_weight(self, progress):\n        return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n    def adaptive_c1(self, progress):\n        return self.c1_initial * (1 - progress)\n\n    def adaptive_c2(self, progress):\n        return self.c2_initial * progress\n\n    def dynamic_crowding_distance(self, population, fitness):\n        distances = np.zeros(population.shape[0])\n        sorted_indices = np.argsort(fitness)\n        for i in range(self.dim):\n            sorted_pop = population[sorted_indices, i]\n            max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n            if max_val == min_val:\n                continue\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n            for j in range(1, len(population) - 1):\n                distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n        return distances", "configspace": "", "generation": 38, "feedback": "The algorithm RefinedHybridDEPSOAdaptiveElitism got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06063 with standard deviation 0.05411.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13116002295228812, 0.13235293697222483, 0.13066794959593897, 0.04727281283426499, 0.056573189736214946, 0.04699904027575452, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "31a894be-6a6d-4638-b8bd-1da6f0a22d8e", "fitness": 0.06265441259875482, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance to enhance exploration and convergence rates, and tweak the inertia weight schedule for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.85  # changed from 0.9 to 0.85\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06265 with standard deviation 0.05330.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12608502005089717, 0.13533050976727568, 0.12878387199929875, 0.06584797599491465, 0.057068132802901905, 0.05010753610683849, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "92ba9782-fe94-4f61-8926-5012c9067cb8", "fitness": 0.0615650304115454, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly increase the initial population size to enhance exploration at the start.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 32  # Changed from 30 to 32\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06157 with standard deviation 0.05187.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12864483737804322, 0.12747652312872249, 0.12504545158019031, 0.05917451215631586, 0.05677139769107409, 0.056305885102895914, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "45467722-941a-4f9c-9df5-ebbd4ce4d589", "fitness": 0.05597996942624042, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Integrate self-adaptive differential evolution with velocity update selection and elitism to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 1.5  # Modified\n        self.c2 = 2.5  # Modified\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    new_velocity = (inertia_weight * velocities[i] +  # Changed\n                                    self.c1 * r1 * (personal_best[i] - population[i]) +\n                                    self.c2 * r2 * (global_best - population[i]))\n                    if np.linalg.norm(new_velocity) < np.linalg.norm(velocities[i]):  # New\n                        velocities[i] = new_velocity  # New\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05598 with standard deviation 0.05354.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12990255980921162, 0.12762164088478634, 0.12707381273983165, 0.04173968916230397, 0.03819670678418108, 0.03861864878918242, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "bb540ad2-cafc-4a2c-ba04-f744e4d12189", "fitness": 0.060258183471803575, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Enhance velocity update by using a dynamic particle neighborhood structure for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                neighbors = np.random.choice(population_size, 5, replace=False)  # Dynamic neighborhood\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06026 with standard deviation 0.05284.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12708231687806104, 0.12680724399266807, 0.13234126251821943, 0.05389170435457846, 0.0524800832236475, 0.049054373612390956, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "913e3a3b-8b14-4e32-9e35-3d8cef13661c", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce a multi-modal restart mechanism based on stagnation detection to improve exploration and convergence in diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.stagnation_threshold = 50\n        self.restart_multiplier = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n        \n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        stagnation_count = 0\n        prev_best_fitness = global_best_fitness\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n            if abs(prev_best_fitness - global_best_fitness) < 1e-8:\n                stagnation_count += 1\n                if stagnation_count >= self.stagnation_threshold:\n                    restart_size = int(self.restart_multiplier * population_size)\n                    new_individuals = np.random.uniform(lb, ub, (restart_size, self.dim))\n                    population = np.concatenate((population[:population_size - restart_size], new_individuals))\n                    velocities = np.concatenate((velocities[:population_size - restart_size], np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness[:population_size - restart_size] = [func(ind) for ind in population[:population_size - restart_size]]\n                    fitness[population_size - restart_size:] = [func(ind) for ind in new_individuals]\n                    evaluations += restart_size\n                    stagnation_count = 0\n            else:\n                stagnation_count = 0\n\n            prev_best_fitness = global_best_fitness\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "d8020fb9-9a9e-47b8-a277-d720ba4a488f", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance to enhance exploration and convergence rates, with a minor change to improve exploration.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Changed from 0.1 to 0.05\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "2c37a278-e73c-4ec1-bc3e-46fd203a715d", "fitness": 0.06505169516010284, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly adjusted the inertia weight update strategy to improve convergence stability.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final) * 0.95\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06505 with standard deviation 0.05465.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13851318766292686, 0.1332860161751298, 0.1283190018543885, 0.05417997821001719, 0.05838734496736331, 0.07211306090443315, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "dd92ff40-3b7f-4d15-a23a-631fd807653c", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance, enhancing exploration and convergence rates by refining the elitism-based local search mechanism.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(8):  # Elitism-based local search (slightly refined)\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "fb12adca-ae48-425b-8ed1-a61aff0922dd", "fitness": 0.06286644936783287, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Integrate self-adaptive differential evolution with swarm intelligence and elite local search using hyperbolic tangent velocity modulation for enhanced diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.tanh(velocities[i]) * self.velocity_clamp\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06287 with standard deviation 0.05191.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1272794411328414, 0.13059361780308132, 0.1236301587413755, 0.06264332216634916, 0.056229149859921224, 0.06475568794026043, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "73a57590-5368-4401-b8c3-b1d49045ac88", "fitness": -Infinity, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Enhance search diversification by increasing the velocity clamp range to improve exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([2.0] * dim)  # Changed from 1.0 to 2.0\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 48, "feedback": "An exception occurred: TypeError(\"'float' object is not subscriptable\").", "error": "TypeError(\"'float' object is not subscriptable\")", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {}}
{"id": "6cd9fec3-ae99-49ca-9b02-691d95afd30a", "fitness": 0.06444075930300186, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Hybrid Adaptive Differential Evolution and Particle Swarm Optimization with Dynamic Exploration-Exploitation Balance for Enhanced Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp_factor = 0.1\n        self.elitism_local_search_steps = 10\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape) * (ub - lb) * self.velocity_clamp_factor\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress) + np.random.uniform(-0.1, 0.1)\n            CR = self.CR_initial * progress + np.random.uniform(-0.1, 0.1)\n            return np.clip(F, 0, 1), np.clip(CR, 0, 1)\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape) * (ub - lb) * self.velocity_clamp_factor))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb))\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(self.elitism_local_search_steps): \n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06444 with standard deviation 0.05523.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.14446941862561413, 0.13165387518525962, 0.1280570159336869, 0.058331613122829196, 0.05824136086661702, 0.05854688332634317, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "5ddfa25c-65ad-4501-b79c-424eaef9773a", "fitness": 0.057447116820764456, "name": "QuantumEnhancedHybridDEPSO", "description": "Integrate adaptive quantum-inspired mechanisms with enhanced elitism to improve exploration and exploitation balance in DEPSO.", "code": "import numpy as np\n\nclass QuantumEnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.quantum_radius = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                if np.random.rand() < 0.5:  # Quantum-inspired update\n                    quantum_jump = np.random.normal(0, self.quantum_radius, self.dim)\n                    trial = np.clip(personal_best[i] + quantum_jump, lb, ub)\n                    trial_fitness = func(trial)\n                    evaluations += 1\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                else:\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 50, "feedback": "The algorithm QuantumEnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05745 with standard deviation 0.05368.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12889834901500064, 0.12789429670346508, 0.13093010872000932, 0.04109895810190434, 0.04339371417864868, 0.044141958001185366, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "76a25fdf-b0d5-488c-8b51-5539cbcb2e8c", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce adaptive population resizing and multi-scale perturbation strategies to boost the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        # Multi-scale perturbation strategy\n        for _ in range(5):\n            for scale in [0.1, 0.05, 0.01]:\n                perturbation = np.random.normal(0, scale, self.dim)\n                candidate = np.clip(elite + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < global_best_fitness:\n                    elite = candidate\n                    global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "6b117d54-5ec0-4551-9617-c472999f38b1", "fitness": 0.05724633647492537, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce adaptive learning rate and diversity preservation mechanisms in a hybrid DE-PSO algorithm to enhance exploration-exploitation balance and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.learning_rate_initial = 0.01\n        self.learning_rate_final = 0.001\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            learning_rate = self.learning_rate_initial * (1 - progress) + self.learning_rate_final * progress\n            return F, CR, learning_rate\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        def calculate_diversity(pop):\n            mean = np.mean(pop, axis=0)\n            diversity = np.mean(np.sqrt(np.sum((pop - mean) ** 2, axis=1)))\n            return diversity\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR, learning_rate = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            diversity = calculate_diversity(population)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances) or diversity > self.diversity_threshold:\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + learning_rate * velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05725 with standard deviation 0.05461.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13347375641185355, 0.12942579614608196, 0.1296405956524035, 0.03996073679261203, 0.04217937711351505, 0.039870099491195576, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "0268723d-5893-4891-be3f-7385f1ac7f21", "fitness": 0.06341715046037572, "name": "StratifiedAdaptiveElitismV3", "description": "Introduce stratified adaptive elitism with a multi-layered exploration-exploitation balance for enhanced convergence in diverse landscapes.", "code": "import numpy as np\n\nclass StratifiedAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.elitism_layers = 3\n        self.elite_candidates = []\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n            # Stratified Elitism\n            self.elite_candidates.append((elite, global_best_fitness))\n            if len(self.elite_candidates) > self.elitism_layers:\n                self.elite_candidates.sort(key=lambda x: x[1])\n                self.elite_candidates = self.elite_candidates[:self.elitism_layers]\n\n        # Elitism-based local search\n        for elite_candidate in self.elite_candidates:\n            elite, _ = elite_candidate\n            for _ in range(5):  # Local search around each elite\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(elite + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < global_best_fitness:\n                    global_best = candidate\n                    global_best_fitness = candidate_fitness\n\n        return global_best, func(global_best)", "configspace": "", "generation": 53, "feedback": "The algorithm StratifiedAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "0c0848d2-c749-4e23-b7ee-3c4abd8918d8", "fitness": 0.056286223745835806, "name": "AdvancedHybridDEPSOMultiPhase", "description": "Introduce a multi-phase learning strategy integrating adaptive differential evolution and particle swarm optimization with a diversity preservation mechanism for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdvancedHybridDEPSOMultiPhase:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 50\n        self.population_variability = 10\n        self.F_initial = 0.7\n        self.CR_initial = 0.8\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.velocity_clamp = np.array([0.5] * dim)\n        self.phase_switch_threshold = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-0.5, 0.5, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, fitness[len(fitness)-len(new_individuals):]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                if progress < self.phase_switch_threshold:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                    F, CR = adaptive_parameters(progress)\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, population[i])\n\n                    trial_fitness = func(trial)\n                    evaluations += 1\n                    if trial_fitness < fitness[i]:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n                else:\n                    distances = dynamic_crowding_distance(population, fitness)\n                    inertia_weight = adaptive_inertia_weight(progress)\n                    if distances[i] < np.mean(distances):\n                        r1, r2 = np.random.rand(), np.random.rand()\n                        velocities[i] = (inertia_weight * velocities[i] +\n                                         self.c1 * r1 * (personal_best[i] - population[i]) +\n                                         self.c2 * r2 * (global_best - population[i]))\n                        velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                        population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                        new_fitness = func(population[i])\n                        evaluations += 1\n                        if new_fitness < fitness[i]:\n                            fitness[i] = new_fitness\n                            if new_fitness < personal_best_fitness[i]:\n                                personal_best[i] = population[i]\n                                personal_best_fitness[i] = new_fitness\n                                if new_fitness < global_best_fitness:\n                                    global_best = population[i]\n                                    global_best_fitness = new_fitness\n\n        elite = global_best\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.05, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 54, "feedback": "The algorithm AdvancedHybridDEPSOMultiPhase got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05629 with standard deviation 0.05238.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12608868266635065, 0.12571631642975956, 0.1268853378733168, 0.0415762619805794, 0.04495099775252953, 0.04069175034331962, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "fccd1805-9bd7-4090-a21f-cc9e9c633377", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Integrate a self-adaptive differential evolution with particle swarm optimization and a Gaussian perturbation on the elite to enhance diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search with Gaussian perturbation\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "1b9d283c-3e5f-40f7-a55c-5dd0ee0dd96b", "fitness": 0.06195049091221954, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Improve exploration by increasing the initial population size for EnhancedHybridDEPSOAdaptiveElitismV2.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 40  # Increased initial size from 30 to 40\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06195 with standard deviation 0.05310.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12630500865895677, 0.1330174248140258, 0.12894999817550024, 0.048078090022152575, 0.05469087085661639, 0.0658463590160574, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "74ebc181-61e2-4c67-a88f-8ae4b4646aae", "fitness": 0.05568966269386745, "name": "EnhancedHybridDEPSOAdaptiveStochasticRanking", "description": "Introduce a stochastic ranking mechanism with adaptive population sizing to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.stochastic_ranking_probability = 0.45\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def stochastic_ranking(pop, fit):\n            for i in range(len(pop) - 1):\n                for j in range(len(pop) - 1, i, -1):\n                    if (np.random.rand() < self.stochastic_ranking_probability and fit[j] < fit[j - 1]) or (fit[j] < fit[j - 1]):\n                        pop[j], pop[j - 1] = pop[j - 1], pop[j]\n                        fit[j], fit[j - 1] = fit[j - 1], fit[j]\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            stochastic_ranking(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05569 with standard deviation 0.05145.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12499110106254196, 0.12310446604151859, 0.1243801351510806, 0.04019473666742446, 0.04149601633775479, 0.046373842317819935, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "bcbbe85e-f60b-4e73-9145-6c0e687e01fb", "fitness": 0.06072036296746497, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Enhanced Hybrid DEPSO with Adaptive Differential Mutation and Localized Perturbation for Improved Exploration and Exploitation Balance", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress / 2)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            F, CR = adaptive_parameters(progress)\n\n            population_size = max(20, self.population_initial_size +\n                                  np.random.randint(-self.population_variability, self.population_variability))\n            if population_size > len(population):\n                new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                population = np.concatenate((population, new_individuals))\n                velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                new_fitness = np.array([func(ind) for ind in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                personal_best = np.concatenate((personal_best, new_individuals))\n                personal_best_fitness = np.concatenate((personal_best_fitness, new_fitness))\n                evaluations += len(new_individuals)\n            else:\n                population = population[:population_size]\n                velocities = velocities[:population_size]\n                fitness = fitness[:population_size]\n                personal_best = personal_best[:population_size]\n                personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search with adaptive perturbation\n            perturbation_scale = 0.1 * (1 - evaluations / self.budget)\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06072 with standard deviation 0.05250.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12608654500135164, 0.1271400842943592, 0.13072298241019187, 0.058034843179695206, 0.04573176392002598, 0.05810038123489414, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "064e971c-0e8b-4718-b4e7-216aba6ba87f", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance to enhance exploration and convergence rates, with improved elitism local search for final refinement.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation standard deviation\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "7673f555-0a86-415d-b873-c03b7c259832", "fitness": 0.06081113922439438, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly increase the initial differential weight `F_initial` to enhance exploration in early iterations.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.85  # Changed from 0.8 to 0.85\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06081 with standard deviation 0.05288.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1307329519177145, 0.1252309488861837, 0.13087948840944763, 0.05157000756484009, 0.058092621465131944, 0.05012756810956487, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "e966916b-b41e-4fea-86d5-43563689e5ff", "fitness": 0.06506887859054251, "name": "EnhancedHybridDEPSOAdaptiveMemory", "description": "Enhance hybrid DE-PSO with adaptive parameter tuning and memory-based mutation to improve convergence and robustness.  ", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.5\n        self.CR_initial = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.memory_size = 5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        memory = []\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = max(self.F_initial * (1 - progress), 0.1)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n\n                if len(memory) >= self.memory_size:\n                    d = memory[np.random.randint(self.memory_size)]\n                    mutant = np.clip(a + F * (b - c + d - global_best), lb, ub)\n                else:\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            if len(memory) >= self.memory_size:\n                                memory.pop(0)\n                            memory.append(global_best)\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n                                if len(memory) >= self.memory_size:\n                                    memory.pop(0)\n                                memory.append(global_best)\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06507 with standard deviation 0.05274.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1311761288001272, 0.12852530172828047, 0.12728368732845097, 0.06791940447970002, 0.056640028078235316, 0.073408690233422, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "ca54351d-3f96-4225-9a2e-5dd3421577d6", "fitness": 0.0633185425772228, "name": "EnhancedHybridDEPSOAdaptiveChaosV3", "description": "Integrate adaptive chaos theory with a self-adaptive differential evolution strategy to improve exploration and convergence rates.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveChaosV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        def chaotic_map(x):\n            # Using Logistic map as chaos generator\n            return 4.0 * x * (1.0 - x)\n\n        chaotic_sequence = np.random.rand(population_size)\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                chaotic_F = F * chaotic_sequence[i]\n                mutant = np.clip(a + chaotic_F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            # Update chaotic sequence\n            chaotic_sequence = chaotic_map(chaotic_sequence)\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveChaosV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06332 with standard deviation 0.05323.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12649810824210606, 0.1315281543650565, 0.13171538783356596, 0.048640700187809194, 0.06286504485350108, 0.06795282104629974, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "2cd17934-c981-4c77-b86a-f6aa3466dc2c", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Leverage adaptive differential evolution with dynamic crowding and elite reinforcement through local search to improve convergence accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(10):  # Enhanced elitism-based local search\n            perturbation_scale = np.exp(-evaluations / self.budget)\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "53f22b29-0005-4c86-8f2d-e065b5e9d7c4", "fitness": 0.06278857445018954, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Integrate self-adaptive differential evolution with a novel dynamic parameter tuning strategy and enhanced local search to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * np.cos(progress * np.pi / 2)  # Improved dynamic tuning using cosine\n            CR = self.CR_initial * np.sin(progress * np.pi / 2)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Enhanced local search\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced noise in local search\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06279 with standard deviation 0.05318.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13056326580734834, 0.12585214006558854, 0.13330857326936973, 0.05261676719340014, 0.05590531321811332, 0.06618444383121902, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "79570068-f77b-4062-b4ed-26ff7a870d00", "fitness": 0.06467046012772718, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Leverage a dynamic population resizing strategy with enhanced crossover and mutation control based on global fitness trends to boost convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress, global_improvement):\n            F = self.F_initial * (1 - progress) * (1 + global_improvement)\n            CR = self.CR_initial * (progress) * (1 + global_improvement)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        history_best_fitness = [global_best_fitness]\n        \n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            latest_global_best_fitness = global_best_fitness\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                global_improvement = (history_best_fitness[-1] - global_best_fitness) / history_best_fitness[-1] if history_best_fitness[-1] != 0 else 0\n                F, CR = adaptive_parameters(progress, global_improvement)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n            \n            history_best_fitness.append(global_best_fitness)\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06467 with standard deviation 0.05309.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12725479696817465, 0.1330337546352789, 0.13031355086269847, 0.06422021369869857, 0.06364436683611774, 0.06290079148190952, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "e2b0e515-f834-4dbe-96eb-a4a3e4098fa5", "fitness": 0.061412657133168014, "name": "EnhancedLvyDEPSO", "description": "Enhance global exploration by incorporating adaptive Lvy flight and local exploitation via mutation strategies to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedLvyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def levy_flight(Lambda):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) /\n                             (np.math.gamma((1 + Lambda) / 2) * Lambda *\n                             np.power(2, (Lambda - 1) / 2)), 1 / Lambda)\n            sigma2 = 1\n            u = np.random.normal(0, sigma1, size=self.dim)\n            v = np.random.normal(0, sigma2, size=self.dim)\n            step = u / np.power(np.abs(v), 1 / Lambda)\n            return step\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand() * (personal_best[i] - population[i]) +\n                                 self.c2 * np.random.rand() * (global_best - population[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            # Lvy flight step for exploration\n            if evaluations % (self.budget // 10) == 0:\n                levy_step = levy_flight(1.5)\n                for j in range(population_size):\n                    candidate = np.clip(population[j] + levy_step, lb, ub)\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    if candidate_fitness < fitness[j]:\n                        population[j] = candidate\n                        fitness[j] = candidate_fitness\n                        if candidate_fitness < personal_best_fitness[j]:\n                            personal_best[j] = candidate\n                            personal_best_fitness[j] = candidate_fitness\n                            if candidate_fitness < global_best_fitness:\n                                global_best = candidate\n                                global_best_fitness = candidate_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedLvyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06141 with standard deviation 0.05298.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12671262053708332, 0.13452709952243003, 0.12572510080220034, 0.04503402670725454, 0.057680070826105934, 0.06236832913677126, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "088848ef-a13b-42c2-b69d-8ae6886cfa8c", "fitness": 0.06318403122502575, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Refine the inertia weight adaptation for improved convergence and stability.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return (self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)) ** 2  # Change 1: refine calculation\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06318 with standard deviation 0.05311.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12756620932295315, 0.1290920231382997, 0.13222701733115805, 0.05216350654954027, 0.05591644141384844, 0.07102441660276537, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "f7db7ad8-3ccb-4c73-b499-94e29f94c1f6", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Enhance local search adaptability by modifying perturbation variance based on progress.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)  # Modified line\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "c988bd8b-fd2a-44dc-a1f7-5ae0592bead0", "fitness": 0.06383632378771269, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Adjust the initial inertia weight to potentially improve balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.95  # Adjusted from 0.9 to 0.95\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06384 with standard deviation 0.05303.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12827971334932264, 0.13335244534328028, 0.1247145358131676, 0.053084012396621305, 0.05417910063302345, 0.08025043988733216, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "257d4b0f-ee60-45f4-b1e3-6ca5ceebdb44", "fitness": 0.06442243255327645, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Adjust the mutation factor (F) to improve diversity and convergence.  ", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.9  # Changed from 0.8 to 0.9\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06442 with standard deviation 0.05255.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.133515723049487, 0.1276185295762935, 0.12497434234797722, 0.061819687924884015, 0.060770824193319806, 0.0704361192208598, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "21231b51-ef88-482c-bc33-281d96f14924", "fitness": 0.06483018706384179, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance and enhanced inertia weight adjustment for improved exploration and convergence rates.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget + 0.05)  # Slight modification here\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06483 with standard deviation 0.05236.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12746318320357575, 0.12390582651773874, 0.13239521312178026, 0.06583699763031559, 0.07576184861428048, 0.05744194782021861, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "8a43f69f-677d-48f6-9f26-594a7d598998", "fitness": 0.06400266806860357, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Enhance adaptive DE-PSO hybrid with non-uniform mutation and fitness diversity-driven exploration for robust convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def non_uniform_mutation(a, b, c, progress):\n            F, _ = adaptive_parameters(progress)\n            tau = 1.0 - progress  # non-uniformity factor\n            delta = np.random.uniform(0, 1, self.dim) * tau\n            return a + F * ((b - c) + delta * (ub - lb) * (np.random.rand(self.dim) - 0.5))\n\n        def fitness_diversity(pop, fit):\n            mean_fit = np.mean(fit)\n            return np.std([np.linalg.norm(fit[i] - mean_fit) for i in range(len(fit))])\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            diversity = fitness_diversity(population, fitness)\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = non_uniform_mutation(a, b, c, progress)\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = np.zeros(population.shape[0])\n            sorted_indices = np.argsort(fitness)\n            for i in range(self.dim):\n                sorted_pop = population[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(population) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances) * diversity:\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06400 with standard deviation 0.05408.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1284164925902691, 0.13226569664672594, 0.13597731552032588, 0.06622235854497593, 0.057494367309199435, 0.05498111533926908, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "a51d0f05-1074-4abe-a393-b7c87bb00602", "fitness": 0.06298737308270676, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Implement an adaptive learning rate and diversity preservation mechanism within the hybrid DE-PSO framework to balance exploration and exploitation, aiming to enhance performance on diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.learning_rate_initial = 0.1\n        self.learning_rate_final = 0.001\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * progress\n            return F, CR\n\n        def adaptive_learning_rate(progress):\n            return self.learning_rate_initial * (1 - progress) + self.learning_rate_final * progress\n\n        def diversity_preservation(pop, fit):\n            diversity_factor = np.var(pop, axis=0)\n            sorted_indices = np.argsort(fit)\n            if np.mean(diversity_factor) < 0.01:\n                pop[sorted_indices[-1]] = np.random.uniform(lb, ub, self.dim)\n                fit[sorted_indices[-1]] = func(pop[sorted_indices[-1]])\n            return pop, fit\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                learning_rate = adaptive_learning_rate(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            population, fitness = diversity_preservation(population, fitness)\n\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 learning_rate * (self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i])))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                new_fitness = func(population[i])\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best = population[i]\n                            global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06299 with standard deviation 0.05550.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1396230210779631, 0.12833155245511274, 0.13650164757364547, 0.04589112633523229, 0.05514319703492987, 0.060729146600810635, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "e458faa6-c3f7-454f-b975-4fc7279a2591", "fitness": 0.061743408690917226, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Enhance adaptive parameter control by incorporating a success-based adjustment mechanism to fine-tune exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.success_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n        successful_mutations = 0\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(success_rate):\n            F = self.F_initial * (1 - success_rate)\n            CR = self.CR_initial * success_rate\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                success_rate = successful_mutations / max(1, evaluations)\n                F, CR = adaptive_parameters(success_rate)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    successful_mutations += 1\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06174 with standard deviation 0.05451.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12214221506614642, 0.14644235185776822, 0.1272469847558424, 0.05722338993707332, 0.05424472754707699, 0.047724342387680974, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "9791f5b7-8022-4302-8662-226419ec826c", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance and modified elitism perturbation for improved local search.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # Changed from normal to uniform distribution\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "65e3b576-71db-41e6-8e6d-cedfb09e3503", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Adjust dynamic crowding by updating the crowding distance calculation for improved diversity control.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    distances[sorted_indices] += 1.0  # Change line\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "7eb655a5-1223-46a3-83c4-ee76154fec90", "fitness": 0.05786786760761477, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Enhance exploration and exploitation by incorporating particle diversity management and adaptive parameter tuning based on population state.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress, diversity):\n            F = self.F_initial * (1 - progress) * (1 + diversity)\n            CR = self.CR_initial * (progress) * (1 + diversity)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        def calculate_diversity(pop):\n            if len(pop) < 2:\n                return 0\n            centroid = np.mean(pop, axis=0)\n            diversity = np.mean(np.linalg.norm(pop - centroid, axis=1))\n            return diversity\n\n        while evaluations < self.budget:\n            diversity = calculate_diversity(population)\n            if diversity < self.diversity_threshold:\n                population = np.random.uniform(lb, ub, (population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, population.shape)\n                fitness = np.array([func(ind) for ind in population])\n                evaluations += population_size\n                personal_best = population.copy()\n                personal_best_fitness = fitness.copy()\n                global_best_idx = np.argmin(fitness)\n                global_best = population[global_best_idx]\n                global_best_fitness = fitness[global_best_idx]\n                elite = global_best\n                continue\n\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress, diversity)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05787 with standard deviation 0.05212.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12438281212386237, 0.12464093415323463, 0.13025740418970488, 0.04712798296727427, 0.04729739399570221, 0.04643761437208782, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "d603e19b-0f88-4712-96ac-0c726384fabe", "fitness": 0.06022500423028273, "name": "EnhancedAdaptiveMultiElitismDEPSO", "description": "Introduce adaptive population resizing and multi-elitism to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiElitismDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_variability = 10\n        self.F_initial = 0.7\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * progress\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.initial_population_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            num_elites = max(1, int(self.elite_fraction * population_size))\n            elite_indices = np.argsort(fitness)[:num_elites]\n            elites = population[elite_indices]\n\n            for elite in elites:\n                for _ in range(3):  # Elitism-based local search\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = np.clip(elite + perturbation, lb, ub)\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    if candidate_fitness < global_best_fitness:\n                        global_best = candidate\n                        global_best_fitness = candidate_fitness\n\n        return global_best, func(global_best)", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveMultiElitismDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06023 with standard deviation 0.05308.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1285156370923315, 0.1300233123233373, 0.12886390506123346, 0.05776275964731925, 0.05046131321837133, 0.045731444063285, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "03c0ad1d-a059-4df2-858c-8747931a6588", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Introduced elite perturbation with variance adjustment to improve local search effectiveness.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Decreased variance from 0.1 to 0.05\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "096cde10-153b-4a13-8387-89b27cbf1ea5", "fitness": 0.06700518917518776, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Refine the inertia weight update strategy to enhance convergence precision in the later stages of optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.2  # Changed from 0.4 to 0.2\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06701 with standard deviation 0.05492.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13264789358607054, 0.14153498530496, 0.12760014756078586, 0.05701315775383009, 0.06526782535299835, 0.07831602635137824, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "70d6a849-eae5-4f42-b8a8-d6b4da995d20", "fitness": 0.05459568244181036, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Integrate adaptive memory and elite perturbation with a refined dynamic diversity preservation to balance exploration-exploitation trade-offs and enhance solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.memory_size = 5  # new parameter for adaptive memory\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n        memory = [global_best]  # adaptive memory to store best solutions\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances / np.max(distances)  # normalize distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            memory.append(global_best)  # update memory\n                            if len(memory) > self.memory_size:\n                                memory.pop(0)\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            elite_memory = np.mean(memory, axis=0)  # use average of memory for elite perturbation\n            for _ in range(5):  # Elitism-based local search\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(elite_memory + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < global_best_fitness:\n                    elite = candidate\n                    global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05460 with standard deviation 0.05314.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12889868792110515, 0.12086730079424357, 0.13009326638165064, 0.03757421437554698, 0.03707472544476309, 0.03618628039231708, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "ae483760-660a-40a5-9bd2-218678f276a0", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Enhance hybrid Differential Evolution and Particle Swarm Optimization by integrating adaptive population sizing and fitness diversity mechanisms for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            diversity = np.std(fitness)\n            if evaluations % (self.budget // 4) == 0 or diversity < 1e-6:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    new_fitness = [func(ind) for ind in new_individuals]\n                    fitness = np.concatenate((fitness, new_fitness))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, new_fitness))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "7eb1bfdd-dfa9-416e-bfec-cfd4e4d497ab", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly adjusted the initial population variability to enhance diversity and exploration capability.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 6  # Adjusted from 5 to 6\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "937715c2-7aad-4cdb-919b-d9f5088396ae", "fitness": 0.06300258343790135, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Adaptive adjustment of crossover rate (CR) to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (1 - progress * 0.5)  # Changed this line to adjust CR\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06300 with standard deviation 0.05567.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13194593504825636, 0.1320112072021532, 0.14210105012399898, 0.05630530693529889, 0.049461237801773916, 0.05453184716296411, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "208ed651-b0e7-4008-9ab1-41a8f74be7cd", "fitness": 0.05841914272685552, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce adaptive population scaling and chaotic maps to enhance exploration-exploitation balance and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.chaotic_factor = 0.7\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def chaotic_map(x):\n            return 4 * x * (1 - x)\n\n        chaotic_value = np.random.rand()\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n\n            if evaluations % (self.budget // 4) == 0:\n                chaotic_value = chaotic_map(chaotic_value)\n                variability = int(self.population_variability * chaotic_value)\n                population_size = max(20, self.population_initial_size + variability)\n\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    new_fitness = np.array([func(ind) for ind in new_individuals])\n                    fitness = np.concatenate((fitness, new_fitness))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, new_fitness))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = fitness - np.min(fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(progress)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05842 with standard deviation 0.05263.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12882913766349202, 0.12742270355865404, 0.12669365822554324, 0.04708206916112112, 0.044328233690907104, 0.05074981557531544, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "3dc57a8b-5ca6-4d47-a987-823a547ef771", "fitness": 0.06445552475275589, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Incorporate a multi-strategy search mechanism and dynamic F and CR adjustments to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress) + 0.2 * np.sin(progress * np.pi)\n            CR = self.CR_initial * (progress) + 0.1 * np.cos(progress * np.pi)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06446 with standard deviation 0.05508.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12600679732487297, 0.13361241385941292, 0.14272393470969447, 0.04955196057758404, 0.061829580517170024, 0.06570836911940181, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "6ac5d3c7-2183-408c-b28c-9472fc1bb6a9", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Enhance local search by dynamically adjusting the perturbation scale for elitism-based local search.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation_scale = np.exp(-evaluations/self.budget)  # Dynamic adjustment\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "64021ef5-59d7-49c5-a1b9-189e0524203c", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce an adaptive population size and a reinforcement learning-inspired reward mechanism to guide the exploration-exploitation balance dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.max_population_size = 50\n        self.min_population_size = 20\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.evaluation_reward_threshold = 0.01  # Reward threshold for RL mechanism\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 10) == 0:\n                average_improvement = np.mean(np.abs(np.diff(fitness)))\n                if average_improvement < self.evaluation_reward_threshold:\n                    population_size = np.clip(population_size + self.population_variability, self.min_population_size, self.max_population_size)\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "f7399782-24ba-4835-b499-e304988744ce", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Enhance the integration of self-adaptive differential evolution and dynamic crowding distance with a novel variable population strategy and local search intensification.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 8\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.local_search_intensity = 10\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 3) == 0:\n                population_size = max(15, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(self.local_search_intensity):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "641fb4a1-838e-4881-bc18-620260ad3175", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly adjusted the calculation method for the dynamic crowding distance to improve exploration diversity.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val + 1e-9 - min_val)  # Changed line\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "900513bb-feb2-4a1d-9788-c03355cd8cd8", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Introduce a slight enhancement to the elitism-based local search by varying the perturbation scale adaptively.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "7ea98c66-7ecd-4483-a3e3-773c018b1ae7", "fitness": 0.06098267893076402, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Utilize a refined randomization in the mutation step to slightly increase diversity and exploration capability.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c + np.random.normal(0, 0.1, size=self.dim)), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06098 with standard deviation 0.05276.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13007364630985918, 0.12960597437542498, 0.12569832661322555, 0.047589093275403394, 0.06487485019054795, 0.05033555294574843, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "a98039e6-28ad-402e-9c10-24e8af984aef", "fitness": 0.058060079732931445, "name": "EnhancedAdaptiveDEPSOWithElitistSearchV3", "description": "Enhance the adaptive differential evolution by incorporating dynamic velocity clamping and elitist adaptive local search to improve convergence and solution refinement.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOWithElitistSearchV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.linspace(0.1, 1.0, budget)\n        \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp[evaluations], self.velocity_clamp[evaluations])\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(10):  # Enhanced elitism-based local search\n            perturbation = np.random.normal(0, 0.05, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveDEPSOWithElitistSearchV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05806 with standard deviation 0.05466.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13656895413659775, 0.125574525453496, 0.13163152831102398, 0.04218812487518453, 0.04497984983113934, 0.040931068322274666, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "1f2bd7e1-e01a-4a1a-8620-349cedc5a807", "fitness": 0.057376035415994155, "name": "ChaosEnhancedMultiSwarmDEPSO", "description": "Enhance exploration by incorporating a chaos-enhanced differential evolution strategy and dynamic multi-swarm cooperation for robust convergence.", "code": "import numpy as np\n\nclass ChaosEnhancedMultiSwarmDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n        self.num_swarms = 3\n        self.swarms = []\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n\n        def chaotic_map(x):\n            return 4 * x * (1 - x)\n\n        def initialize_swarm():\n            swarm = {\n                'population': np.random.uniform(lb, ub, (population_size, self.dim)),\n                'velocities': np.random.uniform(-1, 1, (population_size, self.dim)),\n                'fitness': np.full(population_size, np.inf),\n                'personal_best': None,\n                'personal_best_fitness': np.full(population_size, np.inf),\n                'global_best': None,\n                'global_best_fitness': np.inf\n            }\n            swarm['fitness'] = np.array([func(ind) for ind in swarm['population']])\n            global_best_idx = np.argmin(swarm['fitness'])\n            swarm['personal_best'] = swarm['population'].copy()\n            swarm['personal_best_fitness'] = swarm['fitness'].copy()\n            swarm['global_best'] = swarm['population'][global_best_idx]\n            swarm['global_best_fitness'] = swarm['fitness'][global_best_idx]\n            return swarm\n\n        for _ in range(self.num_swarms):\n            self.swarms.append(initialize_swarm())\n\n        evaluations = self.num_swarms * population_size\n        chaotic_param = 0.7\n\n        while evaluations < self.budget:\n            for swarm in self.swarms:\n                progress = evaluations / self.budget\n                F, CR = self.F_initial * (1 - progress), self.CR_initial * progress\n\n                for i in range(population_size):\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = swarm['population'][np.random.choice(indices, 3, replace=False)]\n\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm['population'][i])\n\n                    trial_fitness = func(trial)\n                    evaluations += 1\n                    if trial_fitness < swarm['fitness'][i]:\n                        swarm['population'][i] = trial\n                        swarm['fitness'][i] = trial_fitness\n                        if trial_fitness < swarm['personal_best_fitness'][i]:\n                            swarm['personal_best'][i] = trial\n                            swarm['personal_best_fitness'][i] = trial_fitness\n                            if trial_fitness < swarm['global_best_fitness']:\n                                swarm['global_best'] = trial\n                                swarm['global_best_fitness'] = trial_fitness\n\n                chaotic_param = chaotic_map(chaotic_param)\n                inertia_weight = self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n                for i in range(population_size):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    swarm['velocities'][i] = (inertia_weight * swarm['velocities'][i] +\n                                              self.c1 * r1 * (swarm['personal_best'][i] - swarm['population'][i]) * chaotic_param +\n                                              self.c2 * r2 * (swarm['global_best'] - swarm['population'][i]) * chaotic_param)\n                    swarm['velocities'][i] = np.clip(swarm['velocities'][i], -self.velocity_clamp, self.velocity_clamp)\n                    swarm['population'][i] = np.clip(swarm['population'][i] + swarm['velocities'][i], lb, ub)\n\n            # Multi-Swarm Cooperation\n            elite_candidates = [swarm['global_best'] for swarm in self.swarms]\n            elite_fitnesses = [swarm['global_best_fitness'] for swarm in self.swarms]\n            best_elite_idx = np.argmin(elite_fitnesses)\n            for swarm in self.swarms:\n                if swarm['global_best_fitness'] > elite_fitnesses[best_elite_idx]:\n                    swarm['global_best'] = elite_candidates[best_elite_idx]\n                    swarm['global_best_fitness'] = elite_fitnesses[best_elite_idx]\n\n        # Final selection of the best solution across all swarms\n        final_best_idx = np.argmin([swarm['global_best_fitness'] for swarm in self.swarms])\n        final_best = self.swarms[final_best_idx]['global_best']\n        return final_best, func(final_best)", "configspace": "", "generation": 94, "feedback": "The algorithm ChaosEnhancedMultiSwarmDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05738 with standard deviation 0.05320.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12506246988023528, 0.13224274110381906, 0.12682470793366307, 0.040055604302505654, 0.03890858435697797, 0.052623544500079666, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "c96e3021-8fdf-4aa1-91a0-f4bd4bbca8d8", "fitness": 0.0611759120247726, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Slightly adjust adaptive parameters to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (0.9 - progress)  # Slightly adjusted\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06118 with standard deviation 0.05216.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12908566007708866, 0.12541434248367134, 0.12825600897230827, 0.05677290608162322, 0.057936639392599965, 0.052450984548995216, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "bfd504b2-6ba1-4928-a7b6-9905072de1dc", "fitness": 0.05704380787481554, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce an adaptive learning rate for velocity updates and a diversity boost by dynamically injecting new individuals for enhanced global exploration and local exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        def adaptive_learning_rate(progress):\n            return 0.5 * (1 - progress)\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                learning_rate = adaptive_learning_rate(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]) +\n                                     learning_rate * (np.random.uniform(lb, ub, self.dim) - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05704 with standard deviation 0.05364.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.1325440769232904, 0.12917040509446176, 0.12500502390364754, 0.040371664268092244, 0.04180151514253161, 0.04383491887464963, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "5c5686fa-e3a9-45a3-853f-ae3062bcb5fd", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Integrate a self-adaptive differential evolution strategy with dynamic crowding distance and neighborhood-based local search to enhance exploration and convergence rates.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(10):  # Enhanced neighborhood-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "d7144450-51df-40a4-a602-486a0e1c7947", "fitness": 0.061412396681257676, "name": "EnhancedHybridDEPSOAdaptiveElitismV3", "description": "Introduce a dynamic adaptive mutation rate and selective elitism to improve diversity and convergence in the enhanced hybrid DE-PSO strategy.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - np.exp(-5 * progress))\n            CR = self.CR_initial * (1 - np.sqrt(progress))\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Selective elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        return elite, func(elite)", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06141 with standard deviation 0.05298.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.12849289667621444, 0.12869949483088672, 0.13082096340686356, 0.060273778125403576, 0.05219619633043093, 0.05156157409485318, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "92e714a5-ba14-494a-9c2c-0e5a734d6f68", "fitness": 0.06341715046037572, "name": "EnhancedHybridDEPSOAdaptiveElitismV2", "description": "Introduce a small random mutation to elite after local search for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptiveElitismV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_initial_size = 30\n        self.population_variability = 5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp = np.array([1.0] * dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = self.population_initial_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, population.shape)\n        \n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        global_best_fitness = fitness[global_best_idx]\n        elite = global_best\n\n        def adaptive_inertia_weight(progress):\n            return self.inertia_weight_initial - progress * (self.inertia_weight_initial - self.inertia_weight_final)\n\n        def adaptive_parameters(progress):\n            F = self.F_initial * (1 - progress)\n            CR = self.CR_initial * (progress)\n            return F, CR\n\n        def dynamic_crowding_distance(pop, fit):\n            distances = np.zeros(pop.shape[0])\n            sorted_indices = np.argsort(fit)\n            for i in range(self.dim):\n                sorted_pop = pop[sorted_indices, i]\n                max_val, min_val = np.max(sorted_pop), np.min(sorted_pop)\n                if max_val == min_val:\n                    continue\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, len(pop) - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1] - sorted_pop[j - 1]) / (max_val - min_val)\n            return distances\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:\n                population_size = max(20, self.population_initial_size + np.random.randint(-self.population_variability, self.population_variability))\n                if population_size > len(population):\n                    new_individuals = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                    population = np.concatenate((population, new_individuals))\n                    velocities = np.concatenate((velocities, np.random.uniform(-1, 1, new_individuals.shape)))\n                    fitness = np.concatenate((fitness, [func(ind) for ind in new_individuals]))\n                    personal_best = np.concatenate((personal_best, new_individuals))\n                    personal_best_fitness = np.concatenate((personal_best_fitness, [func(ind) for ind in new_individuals]))\n                    evaluations += len(new_individuals)\n                else:\n                    population = population[:population_size]\n                    velocities = velocities[:population_size]\n                    fitness = fitness[:population_size]\n                    personal_best = personal_best[:population_size]\n                    personal_best_fitness = personal_best_fitness[:population_size]\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                progress = evaluations / self.budget\n                F, CR = adaptive_parameters(progress)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            distances = dynamic_crowding_distance(population, fitness)\n            for i in range(population_size):\n                inertia_weight = adaptive_inertia_weight(evaluations / self.budget)\n                if distances[i] < np.mean(distances):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     self.c1 * r1 * (personal_best[i] - population[i]) +\n                                     self.c2 * r2 * (global_best - population[i]))\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                    new_fitness = func(population[i])\n                    evaluations += 1\n                    if new_fitness < fitness[i]:\n                        fitness[i] = new_fitness\n                        if new_fitness < personal_best_fitness[i]:\n                            personal_best[i] = population[i]\n                            personal_best_fitness[i] = new_fitness\n                            if new_fitness < global_best_fitness:\n                                global_best = population[i]\n                                global_best_fitness = new_fitness\n\n            if global_best_fitness < func(elite):\n                elite = global_best\n\n        for _ in range(5):  # Elitism-based local search\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(elite + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            evaluations += 1\n            if candidate_fitness < global_best_fitness:\n                elite = candidate\n                global_best_fitness = candidate_fitness\n\n        elite = np.clip(elite + np.random.normal(0, 0.01, self.dim), lb, ub)  # Mutation after local search\n\n        return elite, func(elite)", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedHybridDEPSOAdaptiveElitismV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06342 with standard deviation 0.05385.", "error": "", "parent_ids": ["c0f9c368-4955-46f8-a382-1e2c71430ab6"], "operator": null, "metadata": {"aucs": [0.13677372406186394, 0.12736831433058204, 0.13070243361963652, 0.06315797988923177, 0.05345301501079569, 0.05863222056460471, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
