{"role": "client", "time": "2025-12-20 10:59:53.279581", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n"}
{"role": "gpt-4o", "time": "2025-12-20 10:59:58.883332", "content": "# Description: A dynamic particle swarm optimization (PSO) variant that adaptively adjusts particles' cognitive and social components based on performance feedback to efficiently explore and exploit the search space.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of coefficients\n            if eval_count % (self.budget // 10) == 0:\n                success_rate = np.sum(self.personal_best_scores < self.global_best_score) / self.pop_size\n                if success_rate < 0.2:\n                    self.c1 *= 1.1\n                    self.c2 *= 0.9\n                elif success_rate > 0.8:\n                    self.c1 *= 0.9\n                    self.c2 *= 1.1\n                \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:00:08.971913", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptivePSO: A dynamic particle swarm optimization (PSO) variant that adaptively adjusts particles' cognitive and social components based on performance feedback to efficiently explore and exploit the search space. (Score: 0.062475774829794196)\n\nThe selected solution to update is:\nA dynamic particle swarm optimization (PSO) variant that adaptively adjusts particles' cognitive and social components based on performance feedback to efficiently explore and exploit the search space.\n\nWith code:\nimport numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of coefficients\n            if eval_count % (self.budget // 10) == 0:\n                success_rate = np.sum(self.personal_best_scores < self.global_best_score) / self.pop_size\n                if success_rate < 0.2:\n                    self.c1 *= 1.1\n                    self.c2 *= 0.9\n                elif success_rate > 0.8:\n                    self.c1 *= 0.9\n                    self.c2 *= 1.1\n                \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:00:13.703778", "content": "# Description: EnhancedPSO: An improved dynamic PSO algorithm with adaptive inertia weight and velocity clamping to balance exploration and exploitation more effectively.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n            \n            # Velocity clamping\n            vmax = 0.1 * (ub - lb)\n            self.velocities = np.clip(self.velocities, -vmax, vmax)\n            \n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:00:23.378340", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptivePSO: A dynamic particle swarm optimization (PSO) variant that adaptively adjusts particles' cognitive and social components based on performance feedback to efficiently explore and exploit the search space. (Score: 0.062475774829794196)\n\nThe selected solution to update is:\nA dynamic particle swarm optimization (PSO) variant that adaptively adjusts particles' cognitive and social components based on performance feedback to efficiently explore and exploit the search space.\n\nWith code:\nimport numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of coefficients\n            if eval_count % (self.budget // 10) == 0:\n                success_rate = np.sum(self.personal_best_scores < self.global_best_score) / self.pop_size\n                if success_rate < 0.2:\n                    self.c1 *= 1.1\n                    self.c2 *= 0.9\n                elif success_rate > 0.8:\n                    self.c1 *= 0.9\n                    self.c2 *= 1.1\n                \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:00:30.292702", "content": "# Description: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:00:39.560041", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptivePSO: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance. (Score: 0.06247687484462842)\n\nThe selected solution to update is:\nAn enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.4% of the code, which means if the code has 100 lines, you can only change 1.3888888888888888 lines, and the rest of the lines should remain unchanged. This input code has 72 lines, so you can only change 1 lines, the rest 71 lines should remain unchanged. This changing rate 1.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:00:44.055145", "content": "# Description: Enhanced PSO with dynamic social coefficient reducing over time for improved exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = (self.c2 * (1 - eval_count / self.budget)) * r2 * (self.global_best_position - self.positions)  # Adjusted line\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:00:54.308500", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptivePSO: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance. (Score: 0.06247687484462842)\n\nThe selected solution to update is:\nAn enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.4% of the code, which means if the code has 100 lines, you can only change 1.3888888888888888 lines, and the rest of the lines should remain unchanged. This input code has 72 lines, so you can only change 1 lines, the rest 71 lines should remain unchanged. This changing rate 1.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:00:59.161359", "content": "# Description: Introduce a random mutation strategy to enhance diversity when updating positions.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities + np.random.normal(0, 0.1 * (ub - lb), self.positions.shape)  # Added random mutation\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:01:09.044836", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptivePSO: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance. (Score: 0.06247687484462842)\n\nThe selected solution to update is:\nAn enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.4% of the code, which means if the code has 100 lines, you can only change 1.3888888888888888 lines, and the rest of the lines should remain unchanged. This input code has 72 lines, so you can only change 1 lines, the rest 71 lines should remain unchanged. This changing rate 1.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:01:13.771096", "content": "# Description: Enhanced PSO with adaptive velocity clamping for improved stability and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            # Adaptive velocity clamping\n            max_velocity = (ub - lb) * 0.1\n            self.velocities = np.clip(self.velocities, -max_velocity, max_velocity)\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:01:22.989119", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptivePSO: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance. (Score: 0.06247687484462842)\n\nThe selected solution to update is:\nAn enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.4% of the code, which means if the code has 100 lines, you can only change 1.3888888888888888 lines, and the rest of the lines should remain unchanged. This input code has 72 lines, so you can only change 1 lines, the rest 71 lines should remain unchanged. This changing rate 1.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:01:30.304551", "content": "# Description: Introduced a decay factor in the cognitive and social coefficients to enhance convergence by reducing emphasis on personal and global bests over time.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            decay_factor = 1 - (eval_count / self.budget)\n            cognitive_velocity = self.c1 * r1 * decay_factor * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * decay_factor * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```\n"}
{"role": "client", "time": "2025-12-20 11:01:39.923290", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptivePSO: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance. (Score: 0.06247687484462842)\n\nThe selected solution to update is:\nAn enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:01:45.560671", "content": "# Description: A dual-population PSO that alternates between original and opposition-based learning strategies, with dynamic inertia and velocity clamping for enhanced convergence and solution quality.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDualPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.v_max = 0.2 * (func.bounds.ub - func.bounds.lb)  # Max velocity\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        toggle_flag = True  # Toggle flag for dual population strategy\n        while eval_count < self.budget:\n            if toggle_flag:\n                population = self.positions\n            else:\n                # Opposition-based population\n                population = lb + ub - self.positions\n            \n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(population[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = population[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = population[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            \n            # Velocity clamping\n            self.velocities = np.clip(self.velocities, -self.v_max, self.v_max)\n            \n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Toggle flag to switch between original and opposition population\n            toggle_flag = not toggle_flag\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:01:45.568646", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptivePSO: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance. (Score: 0.06247687484462842)\n\nThe selected solution to update is:\nAn enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.8% of the code, which means if the code has 100 lines, you can only change 2.7777777777777777 lines, and the rest of the lines should remain unchanged. This input code has 72 lines, so you can only change 2 lines, the rest 70 lines should remain unchanged. This changing rate 2.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:01:51.397349", "content": "# Description: Enhanced PSO with additional local search using Levy flight to improve exploration.\n# Code:\n```python\nimport numpy as np\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Levy flight local search\n            if np.random.rand() < 0.1:  # 10% chance to perform Levy flight\n                levy_step = np.random.uniform(-1, 1, self.dim) * (np.random.normal(size=self.dim) / np.power(np.random.normal(size=self.dim), 1.5))\n                temp_position = self.positions + levy_step\n                temp_position = np.clip(temp_position, lb, ub)\n                temp_score = func(temp_position)\n                eval_count += 1\n                if temp_score < self.global_best_score:\n                    self.global_best_score = temp_score\n                    self.global_best_position = temp_position\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:01:51.462103", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptivePSO: An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance. (Score: 0.06247687484462842)\n\nThe selected solution to update is:\nAn enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:01:57.415743", "content": "# Description: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:02:08.809635", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:02:13.767525", "content": "# Description: Introducing a self-adaptive mechanism for dynamically adjusting cognitive and social coefficients, alongside enhanced neighborhood exploration through diversity-enriched local search strategies.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  \n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 2.0, 3.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            diversity = np.std(self.positions, axis=0).mean()\n            c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - diversity)\n            c2 = self.c2_min + (self.c2_max - self.c2_min) * diversity\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:02:25.114409", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.25 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 1 lines, the rest 79 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:02:29.906318", "content": "# Description: Fine-tuning the dynamic neighborhood size for better adaptability and convergence efficiency in the enhanced PSO framework.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(4, self.pop_size // 5)  # Adjusted dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:02:41.073083", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.25 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 1 lines, the rest 79 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:02:45.901410", "content": "# Description: Introduce a dynamic adaptive mechanism to adjust the social coefficient based on the current evaluation progress to balance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight and social coefficient\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            self.c2 = 1.5 + (2.5 - 1.5) * (eval_count / self.budget)  # Adaptive social coefficient\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:02:55.949925", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.25 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 1 lines, the rest 79 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:03:03.555166", "content": "# Description: Introduce a non-linear inertia weight decay for more balanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight using non-linear decay\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) ** 2\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:03:12.911304", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:03:19.220268", "content": "# Description: Introducing multi-swarm interaction with adaptive velocity clamping and quantum-behaved particles to enhance search diversity and convergence in the ImprovedAdaptivePSO framework.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.velocity_clamp = 0.1  # Adaptive velocity clamp\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.05:  # 5% chance for quantum-behaved exploration\n                quantum_positions = lb + np.random.rand(self.pop_size, self.dim) * (ub - lb) * 0.5\n                quantum_scores = np.array([func(pos) for pos in quantum_positions])\n                eval_count += len(quantum_positions)\n                improved_indices = quantum_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = quantum_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = quantum_positions[improved_indices]\n                if np.min(quantum_scores) < self.global_best_score:\n                    self.global_best_score = np.min(quantum_scores)\n                    self.global_best_position = quantum_positions[np.argmin(quantum_scores)]\n                \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            \n            # Adaptive velocity clamping\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:03:28.506609", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 15.0% of the code, which means if the code has 100 lines, you can only change 15.0 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 12 lines, the rest 68 lines should remain unchanged. This changing rate 15.0% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:03:34.315347", "content": "# Description: Incorporating multi-leader dynamics with variable neighborhood learning to enhance search diversity and convergence in PSO.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.multi_leaders = None  # New: Keep track of multiple leaders\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.multi_leaders = np.full((self.neighborhood_size, self.dim), float('inf'))  # New\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                score = func(self.positions[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    # Update multi-leaders\n                    if score < np.max(self.multi_leaders):\n                        worst_leader_idx = np.argmax(self.multi_leaders)\n                        self.multi_leaders[worst_leader_idx] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Variable neighborhood learning\n                neighborhood_indices = np.random.choice(self.pop_size, np.random.randint(1, self.neighborhood_size), replace=False)\n                best_neighbor = min(neighborhood_indices, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n\n            self.positions = np.clip(self.positions, lb, ub)\n\n        return np.min(self.multi_leaders), self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:03:34.323118", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 25.0% of the code, which means if the code has 100 lines, you can only change 25.0 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 20 lines, the rest 60 lines should remain unchanged. This changing rate 25.0% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:03:38.353157", "content": "# Description: Enhancing adaptive PSO with a chaotic local search mechanism and neighborhood mutation to improve exploration and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  \n        self.c1 = 1.5  \n        self.c2 = 2.5  \n        self.w_min = 0.4  \n        self.w_max = 0.9  \n        self.neighborhood_size = max(3, self.pop_size // 5)  \n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n                if np.random.rand() < 0.2:  # 20% chance to mutate neighborhood\n                    local_best_positions[i] = lb + np.random.rand(self.dim) * (ub - lb)\n\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:03:47.614566", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:03:51.720148", "content": "# Description: Incorporating a self-adaptive mutation strategy with a diversity preservation mechanism to enhance the exploratory capability and convergence of the improved PSO framework.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Self-adaptive mutation strategy\n            mutation_probability = 0.2 * (1 - eval_count / self.budget)\n            for i in range(self.pop_size):\n                if np.random.rand() < mutation_probability:\n                    mutation_vector = np.random.uniform(-1, 1, self.dim)\n                    self.positions[i] += mutation_vector * (ub - lb) * 0.1\n            \n            # Diversity preservation\n            if np.random.rand() < 0.1:\n                diversity_vector = np.mean(self.positions, axis=0)\n                self.positions += (diversity_vector - self.positions) * 0.1\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:04:01.119554", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:04:06.184354", "content": "# Description: Introducing local search diversification and velocity clamping to enhance convergence and exploitation in dynamic PSO.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.velocity_clamp = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Velocity clamping\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n\n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Local search diversification\n            if np.random.rand() < 0.1:\n                perturbations = np.random.normal(0, 0.1, self.positions.shape)\n                perturbed_positions = self.positions + perturbations\n                perturbed_positions = np.clip(perturbed_positions, lb, ub)\n                perturbed_scores = np.array([func(pos) for pos in perturbed_positions])\n                eval_count += len(perturbed_positions)\n                improved_indices = perturbed_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = perturbed_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = perturbed_positions[improved_indices]\n                if np.min(perturbed_scores) < self.global_best_score:\n                    self.global_best_score = np.min(perturbed_scores)\n                    self.global_best_position = perturbed_positions[np.argmin(perturbed_scores)]\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:04:15.763913", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:04:22.314866", "content": "# Description: Introducing a multi-swarm strategy with adaptive learning coefficients and random orthogonal exploration to simultaneously enhance global search diversity and convergence efficiency.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.num_swarms = 2  # Number of swarms\n        self.positions = [np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim)) for _ in range(self.num_swarms)]\n        self.velocities = [np.random.uniform(-1, 1, (self.pop_size, self.dim)) for _ in range(self.num_swarms)]\n        self.personal_best_positions = [np.copy(p) for p in self.positions]\n        self.personal_best_scores = [np.full(self.pop_size, float('inf')) for _ in range(self.num_swarms)]\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.c1_max, self.c1_min = 2.5, 1.5\n        self.c2_max, self.c2_min = 2.5, 1.5\n        self.w_min, self.w_max = 0.4, 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                for i in range(self.pop_size):\n                    if eval_count >= self.budget:\n                        break\n                    \n                    # Evaluate current position\n                    score = func(self.positions[swarm_idx][i])\n                    eval_count += 1\n                    \n                    # Update personal bests\n                    if score < self.personal_best_scores[swarm_idx][i]:\n                        self.personal_best_scores[swarm_idx][i] = score\n                        self.personal_best_positions[swarm_idx][i] = self.positions[swarm_idx][i]\n                    \n                    # Update global best\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best_position = self.positions[swarm_idx][i]\n                \n                # Adaptive adjustment of coefficients\n                progress = eval_count / self.budget\n                c1 = self.c1_max - (self.c1_max - self.c1_min) * progress\n                c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n                w = self.w_max - (self.w_max - self.w_min) * progress\n\n                # Random orthogonal exploration technique\n                if np.random.rand() < 0.2:  # 20% chance for orthogonal exploration\n                    ortho_positions = self.positions[swarm_idx] + np.random.rand(*self.positions[swarm_idx].shape) * (ub - lb) / 5\n                    ortho_scores = np.array([func(pos) for pos in ortho_positions])\n                    eval_count += len(ortho_positions)\n                    improved_indices = ortho_scores < self.personal_best_scores[swarm_idx]\n                    self.personal_best_scores[swarm_idx][improved_indices] = ortho_scores[improved_indices]\n                    self.personal_best_positions[swarm_idx][improved_indices] = ortho_positions[improved_indices]\n                    if np.min(ortho_scores) < self.global_best_score:\n                        self.global_best_score = np.min(ortho_scores)\n                        self.global_best_position = ortho_positions[np.argmin(ortho_scores)]\n                \n                # Update velocities and positions\n                r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n                r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[swarm_idx] - self.positions[swarm_idx])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[swarm_idx])\n                self.velocities[swarm_idx] = w * self.velocities[swarm_idx] + cognitive_velocity + social_velocity\n                self.positions[swarm_idx] += self.velocities[swarm_idx]\n                \n                # Clip to bounds\n                self.positions[swarm_idx] = np.clip(self.positions[swarm_idx], lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:04:22.320985", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework. (Score: 0.062476953383788794)\n\nThe selected solution to update is:\nIncorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.5% of the code, which means if the code has 100 lines, you can only change 2.5 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 2 lines, the rest 78 lines should remain unchanged. This changing rate 2.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:04:26.381044", "content": "# Description: Enhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:04:30.865331", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Enhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence. (Score: 0.062477181221836466)\n\nThe selected solution to update is:\nEnhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.25 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 1 lines, the rest 79 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:04:34.954211", "content": "# Description: Incorporate a stochastic weight adjustment to enhance exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) + np.random.uniform(-0.1, 0.1)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:04:38.418984", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Enhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence. (Score: 0.062477181221836466)\n\nThe selected solution to update is:\nEnhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.25 lines, and the rest of the lines should remain unchanged. This input code has 80 lines, so you can only change 1 lines, the rest 79 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:04:43.505175", "content": "# Description: Integrate a dynamic adjustment of cognitive and social coefficients during iterations for improved exploitation and exploration balance.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            self.c1 = 1.8 + 0.4 * (eval_count / self.budget)  # Dynamic adjustment of cognitive coefficient\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:04:46.964741", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptivePSO: Enhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence. (Score: 0.062477181221836466)\n\nThe selected solution to update is:\nEnhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:04:51.508420", "content": "# Description: Enhanced ImprovedAdaptivePSO with dynamic inertia weight adjustment, adaptive selection, and differential evolution-inspired mutation for improved exploration-exploitation balance.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:04:55.061333", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedImprovedAdaptivePSO: Enhanced ImprovedAdaptivePSO with dynamic inertia weight adjustment, adaptive selection, and differential evolution-inspired mutation for improved exploration-exploitation balance. (Score: 0.062477394760682065)\n\nThe selected solution to update is:\nEnhanced ImprovedAdaptivePSO with dynamic inertia weight adjustment, adaptive selection, and differential evolution-inspired mutation for improved exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:05:02.292054", "content": "# Description: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n# Code:\n```python\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:05:05.853155", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima. (Score: 0.0624775830456452)\n\nThe selected solution to update is:\nHybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:05:11.608999", "content": "# Description: Enhanced Hybrid PSO with Lvy Flights integrating adaptive mutation and dynamic neighborhood topology for superior exploration-exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_fraction = 0.25\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            sorted_indices = np.argsort(self.personal_best_scores)\n            top_indices = sorted_indices[:int(self.pop_size * self.neighborhood_fraction)]\n            local_best_positions = self.personal_best_positions[top_indices]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                if np.random.rand() < 0.15:\n                    f = 0.5 + np.random.rand() * 0.5\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                    mutant_positions = np.clip(mutant_positions, lb, ub)\n                    mutant_score = func(mutant_positions)\n                    eval_count += 1\n                    if mutant_score < self.personal_best_scores[indices[0]]:\n                        self.personal_best_scores[indices[0]] = mutant_score\n                        self.personal_best_positions[indices[0]] = mutant_positions\n                    if mutant_score < self.global_best_score:\n                        self.global_best_score = mutant_score\n                        self.global_best_position = mutant_positions\n\n                r1 = np.random.uniform(0, 1, (self.dim,))\n                r2 = np.random.uniform(0, 1, (self.dim,))\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (local_best_positions[i % len(local_best_positions)] - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n                self.positions[i] += self.velocities[i]\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:05:15.226047", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima. (Score: 0.0624775830456452)\n\nThe selected solution to update is:\nHybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:05:22.086173", "content": "# Description: Enhanced Hybrid Adaptive PSO with Lvy Flights and Dynamic Population to improve convergence by balancing exploration and exploitation with adaptive population size adjustments.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def dynamic_population_adjustment(self):\n        if np.random.rand() < 0.1:\n            self.pop_size = min(max(5, int(self.pop_size * (0.9 + 0.2 * np.random.rand()))), 2 * self.pop_size)\n            self.neighborhood_size = max(3, self.pop_size // 4)\n            self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n            self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n            self.personal_best_positions = np.copy(self.positions)\n            self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:05:25.790597", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima. (Score: 0.0624775830456452)\n\nThe selected solution to update is:\nHybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.0752688172043012 lines, and the rest of the lines should remain unchanged. This input code has 93 lines, so you can only change 1 lines, the rest 92 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:05:31.089549", "content": "# Description: Hybrid Adaptive PSO with Lvy Flights and adaptive mutation rate for enhanced exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15 + (0.25 * (1 - eval_count / self.budget)): # Changed line\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:05:34.674069", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima. (Score: 0.0624775830456452)\n\nThe selected solution to update is:\nHybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:05:41.023126", "content": "# Description: Enhanced Hybrid Adaptive PSO integrates dynamic parameter tuning and adaptive Lvy flight based on fitness improvements for superior exploration-exploitation synergy.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.leap_probability = 0.1\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            self.adaptive_leap_probability(eval_count)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < self.leap_probability:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\n    def adaptive_leap_probability(self, eval_count):\n        improvement_rate = (self.global_best_score - np.min(self.personal_best_scores)) / max(self.global_best_score, 1e-9)\n        self.leap_probability = 0.1 + 0.1 * (1 - improvement_rate) * (eval_count / self.budget)\n```"}
{"role": "client", "time": "2025-12-20 11:05:44.622584", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima. (Score: 0.0624775830456452)\n\nThe selected solution to update is:\nHybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.3% of the code, which means if the code has 100 lines, you can only change 4.301075268817205 lines, and the rest of the lines should remain unchanged. This input code has 93 lines, so you can only change 4 lines, the rest 89 lines should remain unchanged. This changing rate 4.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:05:49.537842", "content": "# Description: Optimized Hybrid Adaptive PSO with Lvy Flights by adjusting mutation strategy and employing adaptive neighborhood influence for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) # Line 1\n                \n            if np.random.rand() < 0.1: # Line 2\n                f = 0.6 + np.random.rand() * 0.4 # Line 3\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:05:53.110959", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima. (Score: 0.0624775830456452)\n\nThe selected solution to update is:\nHybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:05:59.273930", "content": "# Description: Enhanced Hybrid Adaptive PSO with Lvy Flights incorporating dynamic neighborhood and mutation probability for improved convergence and diversity.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.dynamic_mutation_prob = 0.1\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            dynamic_neighborhood_size = max(3, int((self.pop_size / 4) * (1 - eval_count / self.budget)))\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            mutation_prob = self.dynamic_mutation_prob + (1.0 - self.dynamic_mutation_prob) * (eval_count / self.budget)\n            \n            if np.random.rand() < mutation_prob:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:06:02.821113", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima. (Score: 0.0624775830456452)\n\nThe selected solution to update is:\nHybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.0752688172043012 lines, and the rest of the lines should remain unchanged. This input code has 93 lines, so you can only change 1 lines, the rest 92 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:06:08.798934", "content": "# Description: Implemented a different neighborhood size calculation to potentially improve local optima escape in Hybrid Adaptive PSO with Lvy Flights.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))  # Modified neighborhood size calculation\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:06:12.364318", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Implemented a different neighborhood size calculation to potentially improve local optima escape in Hybrid Adaptive PSO with Lvy Flights. (Score: 0.062477781145056074)\n\nThe selected solution to update is:\nImplemented a different neighborhood size calculation to potentially improve local optima escape in Hybrid Adaptive PSO with Lvy Flights.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))  # Modified neighborhood size calculation\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:06:18.662343", "content": "# Description: Introducing a dynamic neighborhood size adjustment strategy and adaptive mutation rate to improve global optima convergence in Hybrid Adaptive PSO with Lvy Flights.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSOLevyDynamic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                self.dynamic_neighborhood_size(eval_count)\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < self.adaptive_mutation_rate(eval_count):\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n    \n    def dynamic_neighborhood_size(self, eval_count):\n        progress = eval_count / self.budget\n        if progress < 0.5:\n            self.neighborhood_size = max(2, int(self.pop_size * (0.3 + 0.2 * progress)))\n        else:\n            self.neighborhood_size = max(2, int(self.pop_size * (0.5 - 0.2 * (progress - 0.5))))\n\n    def adaptive_mutation_rate(self, eval_count):\n        progress = eval_count / self.budget\n        return 0.15 * (1 - progress) + 0.05 * progress\n```"}
{"role": "client", "time": "2025-12-20 11:06:22.377048", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridAdaptivePSOLevy: Implemented a different neighborhood size calculation to potentially improve local optima escape in Hybrid Adaptive PSO with Lvy Flights. (Score: 0.062477781145056074)\n\nThe selected solution to update is:\nImplemented a different neighborhood size calculation to potentially improve local optima escape in Hybrid Adaptive PSO with Lvy Flights.\n\nWith code:\nimport numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))  # Modified neighborhood size calculation\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:06:27.713213", "content": "# Description: Combine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:06:31.283553", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Combine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces. (Score: 0.062477784172413564)\n\nThe selected solution to update is:\nCombine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:06:38.097733", "content": "# Description: Integrate Adaptive PSO, Lvy Flights, and a Dynamic Neighborhood Search with Random Walks to enhance diversification and intensification in solving complex optimization problems.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedDynamicNeighborhoodPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.dynamic_neighborhood = True\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def random_walk(self, position, bounds):\n        step_size = np.random.uniform(0, 1, self.dim)\n        direction = np.random.choice([-1, 1], self.dim)\n        new_position = position + direction * step_size\n        return np.clip(new_position, bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            if self.dynamic_neighborhood:\n                neighborhood_size = max(2, int(self.pop_size * (0.1 + 0.4 * (1 - eval_count / self.budget))))\n                local_best_positions = np.copy(self.personal_best_positions)\n                for i in range(self.pop_size):\n                    neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                    best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                    local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            else:\n                local_best_positions = np.copy(self.personal_best_positions)\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            if np.random.rand() < 0.05:\n                for i in range(self.pop_size):\n                    new_position = self.random_walk(self.positions[i], func.bounds)\n                    new_score = func(new_position)\n                    eval_count += 1\n                    if new_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = new_score\n                        self.personal_best_positions[i] = new_position\n                    if new_score < self.global_best_score:\n                        self.global_best_score = new_score\n                        self.global_best_position = new_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:06:41.715082", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Combine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces. (Score: 0.062477784172413564)\n\nThe selected solution to update is:\nCombine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 31.9% of the code, which means if the code has 100 lines, you can only change 31.914893617021278 lines, and the rest of the lines should remain unchanged. This input code has 94 lines, so you can only change 30 lines, the rest 64 lines should remain unchanged. This changing rate 31.9% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:06:47.003305", "content": "# Description: Integrate dynamic neighborhood adjustment and chaotic map initialization to enhance diversity and convergence in the search process.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = self.chaotic_map_init(func.bounds.lb, func.bounds.ub)\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_map_init(self, lb, ub):\n        x = np.random.rand(self.pop_size, self.dim)\n        return lb + (ub - lb) * np.sin(np.pi * x)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            neighborhood_size = int(self.pop_size * np.random.uniform(0.2, 0.6))\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```\n"}
{"role": "client", "time": "2025-12-20 11:06:47.005881", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Combine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces. (Score: 0.062477784172413564)\n\nThe selected solution to update is:\nCombine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.1% of the code, which means if the code has 100 lines, you can only change 2.127659574468085 lines, and the rest of the lines should remain unchanged. This input code has 94 lines, so you can only change 2 lines, the rest 92 lines should remain unchanged. This changing rate 2.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:06:58.265380", "content": "# Description: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:07:01.834599", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:07:07.098589", "content": "# Description: Introduced an adaptive inertia weight influenced by swarm diversity and dynamic neighborhood to boost global exploration and local exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_inertia(self, current_positions, global_best_position):\n        diversity = np.mean(np.linalg.norm(current_positions - global_best_position, axis=1))\n        return self.w_min + (self.w_max - self.w_min) * (diversity / np.max(diversity, initial=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.adaptive_inertia(self.positions, self.global_best_position)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:07:18.188571", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:07:24.036448", "content": "# Description: Enhance dynamic neighborhood adaptation and integrate a multi-strategy search mechanism to improve exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            # Multi-strategy search mechanism\n            if np.random.rand() < 0.2:\n                # Random mutation exploration\n                for i in range(self.pop_size):\n                    mutant = self.positions[i] + np.random.normal(0, 0.1, size=self.dim)\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_score = func(mutant)\n                    eval_count += 1\n                    if mutant_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = mutant_score\n                        self.personal_best_positions[i] = mutant\n                    if mutant_score < self.global_best_score:\n                        self.global_best_score = mutant_score\n                        self.global_best_position = mutant\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:07:48.787260", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:07:54.552792", "content": "# Description: Introduce stochastic restarts and adaptive mutation rates to enhance exploration and prevent premature convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedRestartAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.restart_threshold = 0.2\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n    \n    def restart_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.restart_population(lb, ub)\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Stochastic restart strategy\n            if np.random.rand() < self.restart_threshold:\n                if np.random.rand() < 0.5:  # Introduce restart based on stochastic decision\n                    self.restart_population(lb, ub)\n\n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:08:08.232225", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.1% of the code, which means if the code has 100 lines, you can only change 2.083333333333333 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 2 lines, the rest 94 lines should remain unchanged. This changing rate 2.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:08:13.932421", "content": "Certainly! Here is the refined version of the algorithm with a small adjustment to enhance its performance.\n\n# Description: Introduced an additional velocity update method influenced by a random elite particle for enhanced exploration.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            elite_idx = np.random.choice(self.pop_size)  # Select a random elite particle\n            elite_influence = 0.5 * (self.positions[elite_idx] - self.positions)  # New line for elite influence\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity + elite_influence\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:08:25.287068", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.1% of the code, which means if the code has 100 lines, you can only change 2.083333333333333 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 2 lines, the rest 94 lines should remain unchanged. This changing rate 2.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:08:29.803242", "content": "# Description: Enhanced exploration by dynamically adjusting inertia and incorporating a new random mutation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Dynamically adjusting inertia weight using cosine\n            w = self.w_max - (self.w_max - self.w_min) * (np.cos(eval_count / self.budget * np.pi / 2))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:08:41.215579", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:08:46.570238", "content": "# Description: Improved EnhancedHybridAdaptivePSOLevy with inertia weight adaptation and chaotic search for enhanced exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_search(self, dim):\n        z = np.random.rand(dim)\n        chaotic_sequence = np.sin(np.pi * z)\n        return chaotic_sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_min + (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if np.random.rand() < 0.05:\n                chaotic_step = self.chaotic_search(self.dim)\n                chaotic_positions = self.global_best_position + chaotic_step\n                chaotic_positions = np.clip(chaotic_positions, lb, ub)\n                chaotic_score = func(chaotic_positions)\n                eval_count += 1\n                if chaotic_score < self.global_best_score:\n                    self.global_best_score = chaotic_score\n                    self.global_best_position = chaotic_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:08:57.815389", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:09:03.518753", "content": "# Description: Incorporate dynamic inertia weights and an adaptive mutation strategy to enhance exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.1\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.2 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.4 + np.random.rand() * 0.6\n                indices = np.random.choice(self.pop_size, 4, replace=False)\n                mutant_positions = (self.personal_best_positions[indices[0]] + \n                                    f * (self.personal_best_positions[indices[1]] - self.personal_best_positions[indices[2]]))\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:09:14.470749", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.2% of the code, which means if the code has 100 lines, you can only change 4.166666666666666 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 4 lines, the rest 92 lines should remain unchanged. This changing rate 4.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:09:19.414648", "content": "# Description: Improved exploration by introducing a probabilistic mutation in the update phase for broader search coverage.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r3 = np.random.uniform(0, 1, (self.pop_size, self.dim))  # New random vector\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            mutation_velocity = 0.1 * r3 * (ub - lb) * np.random.normal(0, 1, (self.pop_size, self.dim))  # Mutation term\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity + mutation_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:09:31.141755", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:09:36.858029", "content": "# Description: Enhanced dynamic neighborhood adjustment with hybrid crossover and mutation strategies for diverse exploration.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Introduce crossover between randomly selected individuals\n            if np.random.rand() < 0.1:\n                parent1, parent2 = np.random.choice(self.pop_size, 2, replace=False)\n                crossover_point = np.random.randint(1, self.dim-1)\n                child_position = np.concatenate(\n                    (self.positions[parent1][:crossover_point], self.positions[parent2][crossover_point:])\n                )\n                child_position = np.clip(child_position, lb, ub)\n                child_score = func(child_position)\n                eval_count += 1\n                if child_score < self.global_best_score:\n                    self.global_best_score = child_score\n                    self.global_best_position = child_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:09:49.035045", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.1% of the code, which means if the code has 100 lines, you can only change 2.083333333333333 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 2 lines, the rest 94 lines should remain unchanged. This changing rate 2.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:09:54.835694", "content": "# Description: Enhanced local search by incorporating random restarts when improvement stalls.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        no_improvement_counter = 0 # Added to track improvements\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    no_improvement_counter = 0 # Reset on improvement\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            no_improvement_counter += 1\n            if no_improvement_counter > self.pop_size: # Added random restarts\n                self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                no_improvement_counter = 0\n        \n        return self.global_best_position, self.global_best_score\n```\n"}
{"role": "client", "time": "2025-12-20 11:10:06.875552", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:10:11.533211", "content": "# Description: Introduced elite particle learning and adaptive mutation to accelerate convergence while maintaining diversity.\n# Code:\n```python\nimport numpy as np\n\nclass EliteAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            elite_idx = np.argmin(self.personal_best_scores)\n            elite_position = self.personal_best_positions[elite_idx]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.2:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (elite_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:10:21.540862", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:10:27.064768", "content": "# Description: Introduced multi-phase strategy with initial global search and adaptive local refinement using dynamic mutation rates.\n# Code:\n```python\nimport numpy as np\n\nclass MultiPhaseAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n        eval_count = 0\n        phase_switch = int(self.budget * 0.6)\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if eval_count < phase_switch:\n                # Global search phase\n                mutation_prob = 0.2\n            else:\n                # Local refinement phase\n                mutation_prob = 0.05\n\n            if np.random.rand() < mutation_prob:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:10:38.324386", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:10:44.630615", "content": "# Description: Introduce a self-adaptive mutation strategy based on historical performance to enhance exploration and balance between exploration and exploitation more effectively.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.mutation_strategy_threshold = 0.1 # Probability threshold for mutation\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < self.mutation_strategy_threshold:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < self.mutation_strategy_threshold:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Self-adapting the mutation strategy threshold based on historical performance\n            improvement = np.mean(self.personal_best_scores) - self.global_best_score\n            if improvement > 0:\n                self.mutation_strategy_threshold *= 0.9\n            else:\n                self.mutation_strategy_threshold *= 1.1\n            self.mutation_strategy_threshold = np.clip(self.mutation_strategy_threshold, 0.05, 0.3)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:10:56.313506", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:11:02.330617", "content": "# Description: Enhanced the adaptive neighborhood by introducing a dynamic inertia weight based on swarm diversity to balance exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedDiversePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.positions, axis=0)\n        diversity = np.mean(np.linalg.norm(self.positions - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            diversity = self.calculate_diversity()\n            w = self.w_max - (self.w_max - self.w_min) * (diversity / np.linalg.norm(ub - lb))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:11:13.849204", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:11:20.581353", "content": "# Description: Enhanced neighborhood adaptation and diversity introduction using chaotic sequences for improved local search and convergence stability.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyChaotic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.chaos_sequence = self.generate_chaos_sequence(self.budget)\n\n    def generate_chaos_sequence(self, length, z0=0.7):\n        sequence = [z0]\n        for i in range(1, length):\n            sequence.append(4 * sequence[-1] * (1 - sequence[-1]))\n        return np.array(sequence)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = self.chaos_sequence[eval_count] * np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = self.chaos_sequence[eval_count] * np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:11:22.091396", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 8.3% of the code, which means if the code has 100 lines, you can only change 8.333333333333332 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 8 lines, the rest 88 lines should remain unchanged. This changing rate 8.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:11:27.942106", "content": "# Description: Introduced stochastic adaptive inertia weight adjustment and incorporated chaotic local search for enhanced exploration and convergence balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_local_search(self, lb, ub):\n        chaos_factor = np.random.rand(self.dim)\n        chaotic_positions = lb + (ub - lb) * chaos_factor\n        return chaotic_positions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            cognitive_influence = np.random.rand()  # Stochastic cognitive influence\n            w = self.w_max - (self.w_max - self.w_min) * cognitive_influence * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if np.random.rand() < 0.05:\n                chaotic_positions = self.chaotic_local_search(lb, ub)\n                chaotic_score = func(chaotic_positions)\n                eval_count += 1\n                if chaotic_score < self.global_best_score:\n                    self.global_best_score = chaotic_score\n                    self.global_best_position = chaotic_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:11:39.413266", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:11:45.720406", "content": "# Description: Introduced a dynamic inertia weight factor based on swarm diversity to improve exploration-exploitation balance in PSO-Levy.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def diversity(self, positions):\n        mean_position = np.mean(positions, axis=0)\n        return np.mean(np.linalg.norm(positions - mean_position, axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            swarm_diversity = self.diversity(self.positions)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - swarm_diversity)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:11:55.481395", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:12:00.671801", "content": "# Description: Introduced a dynamic exploration-exploitation trade-off by integrating adaptive velocity scaling and multi-strategy search to improve convergence.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            adaptive_scaling = 1 + (1 - eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + adaptive_scaling * (cognitive_velocity + social_velocity)\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n\n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:12:10.074997", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.0% of the code, which means if the code has 100 lines, you can only change 1.0416666666666665 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 1 lines, the rest 95 lines should remain unchanged. This changing rate 1.0% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:12:15.213390", "content": "# Description: Adjusted inertia weight formula to improve convergence speed in early iterations.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) ** 2\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:12:24.744682", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:12:30.969346", "content": "# Description: Implemented an adaptive inertia weight strategy and an elite strategy, selecting top individuals for local searching to improve convergence speed.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            # Select the top-performing particles\n            elite_indices = np.argsort(self.personal_best_scores)[:max(2, self.pop_size // 5)]\n            elite_positions = self.personal_best_positions[elite_indices]\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)**2  # Use squared progress for inertia weight adaptation\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Levy flight to elite solutions\n            for elite_pos in elite_positions:\n                step = self.levy_flight(self.dim)\n                levy_positions = elite_pos + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:12:40.813014", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:12:49.084531", "content": "# Description: Enhanced by incorporating a multi-arm bandit strategy to dynamically allocate exploration and exploitation efforts for improved global search.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOBandit:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.arm_rewards = np.zeros(2)  # Two strategies: DE mutation and Levy flight\n        self.arm_counts = np.ones(2)  # Initial count to avoid division by zero\n        self.explore_probability = 0.1\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def select_arm(self):\n        total_counts = np.sum(self.arm_counts)\n        ucb_values = self.arm_rewards / self.arm_counts + np.sqrt(2 * np.log(total_counts) / self.arm_counts)\n        return np.argmax(ucb_values)\n\n    def update_arm(self, arm, reward):\n        self.arm_counts[arm] += 1\n        n = self.arm_counts[arm]\n        value = self.arm_rewards[arm]\n        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward\n        self.arm_rewards[arm] = new_value\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < self.explore_probability:\n                arm = self.select_arm()\n            else:\n                arm = np.random.choice(2)\n            \n            if arm == 0:  # DE mutation\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                improvement = self.personal_best_scores[indices[0]] - mutant_score\n                if mutation_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            elif arm == 1:  # Levy flight\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                improvement = self.global_best_score - levy_score\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            self.update_arm(arm, improvement)\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:12:49.117261", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.1% of the code, which means if the code has 100 lines, you can only change 2.083333333333333 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 2 lines, the rest 94 lines should remain unchanged. This changing rate 2.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:12:54.222509", "content": "# Description: Enhance global exploration by adapting mutation probability and incorporate global diversity check.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < (0.15 + 0.05 * (1 - eval_count / self.budget)):  # Adjusted mutation probability\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:13:03.836329", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 11.5% of the code, which means if the code has 100 lines, you can only change 11.458333333333332 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 11 lines, the rest 85 lines should remain unchanged. This changing rate 11.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:13:08.662373", "content": "# Description: Modified the update rule for velocities to incorporate an additional hybrid component, improving convergence speed via a diversity preservation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            hybrid_component = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity + 0.3 * hybrid_component\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:13:17.419227", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.1% of the code, which means if the code has 100 lines, you can only change 2.083333333333333 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 2 lines, the rest 94 lines should remain unchanged. This changing rate 2.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:13:22.959768", "content": "# Description: Incorporate a dynamic inertia weight adjustment and a small mutation step in the cognitive component to enhance exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) ** 2\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            mutation_step = 0.01 * (ub - lb) * np.random.normal(size=(self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions + mutation_step)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:13:26.574337", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:13:33.152038", "content": "# Description: Introduce a dynamic inertia weight and hybridize with simulated annealing to enhance exploration-exploitation balance during optimization.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedDynamicHybridPSOAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def simulated_annealing(self, current_pos, current_score, temperature, lb, ub, func):\n        new_pos = current_pos + np.random.uniform(-1, 1, size=self.dim)\n        new_pos = np.clip(new_pos, lb, ub)\n        new_score = func(new_pos)\n        if new_score < current_score:\n            return new_pos, new_score\n        elif np.random.rand() < np.exp((current_score - new_score) / temperature):\n            return new_pos, new_score\n        else:\n            return current_pos, current_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        init_temp = 100\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            temperature = init_temp * (1 - eval_count / self.budget)\n            for i in range(self.pop_size):\n                self.positions[i], _ = self.simulated_annealing(self.positions[i], func(self.positions[i]), temperature, lb, ub, func)\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:13:36.368308", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:13:41.147155", "content": "# Description: Introduced time-varying control parameters and dynamic subgroup formations to enhance exploration-exploitation balance and diversity.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedDynamicSubgroupPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1_initial = 2.5\n        self.c2_initial = 1.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            # Update control parameters dynamically\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (eval_count / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (eval_count / self.budget)\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # Form dynamic subgroups\n            group_size = max(2, int(self.pop_size * 0.1 + np.random.rand() * 0.2))\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, group_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:13:44.706796", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.0% of the code, which means if the code has 100 lines, you can only change 1.0416666666666665 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 1 lines, the rest 95 lines should remain unchanged. This changing rate 1.0% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:13:50.002359", "content": "# Description: Introduced random scaling on velocities to explore new regions intermittently.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            \n            if np.random.rand() < 0.05:  # Random scaling added\n                self.velocities *= np.random.uniform(0.5, 1.5, size=(self.pop_size, self.dim))\n                \n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:13:53.602191", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.1% of the code, which means if the code has 100 lines, you can only change 3.125 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 3 lines, the rest 93 lines should remain unchanged. This changing rate 3.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:13:59.027104", "content": "# Description: Enhanced convergence by introducing mutation strategy based on the fitness of the population.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n                    \n            # Introduce mutation based on global best\n            if np.random.rand() < 0.1:\n                mutation_step = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                mutation_positions = self.global_best_position + mutation_step\n                mutation_positions = np.clip(mutation_positions, lb, ub)\n                mutation_score = func(mutation_positions)\n                eval_count += 1\n                if mutation_score < self.global_best_score:\n                    self.global_best_score = mutation_score\n                    self.global_best_position = mutation_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:14:02.641025", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:14:08.242693", "content": "# Description: Implements a multi-phase dynamic adaptation strategy combining velocity adjustment and hybrid exploration to enhance convergence.\n# Code:\n```python\nimport numpy as np\n\nclass AdvancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, int(self.pop_size * 0.2))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.2 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.4 + np.random.rand() * 0.6\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:14:11.852253", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.2% of the code, which means if the code has 100 lines, you can only change 4.166666666666666 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 4 lines, the rest 92 lines should remain unchanged. This changing rate 4.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:14:16.881810", "content": "# Description: Enhanced global search by introducing random reinitialization for stagnating particles to improve exploration.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            # Random reinitialization for stagnating particles\n            stagnation_threshold = 20\n            if eval_count % stagnation_threshold == 0:\n                reinit_indices = np.random.choice(self.pop_size, size=int(self.pop_size * 0.1), replace=False)\n                self.positions[reinit_indices] = np.random.uniform(lb, ub, (len(reinit_indices), self.dim))\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:14:20.493034", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.2% of the code, which means if the code has 100 lines, you can only change 4.166666666666666 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 4 lines, the rest 92 lines should remain unchanged. This changing rate 4.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:14:26.142850", "content": "# Description: Improved the adaptive mutation strategy by introducing a stochastic element to better escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (np.random.rand() * (self.positions[indices[1]] - self.positions[indices[2]]) +\n                                                                     np.random.rand() * (self.positions[indices[3]] - self.positions[indices[4]]))  # Changed line\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:14:29.749147", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.2% of the code, which means if the code has 100 lines, you can only change 4.166666666666666 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 4 lines, the rest 92 lines should remain unchanged. This changing rate 4.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:14:34.994299", "content": "# Description: Improved exploration by increasing the mutation factor and adding adaptive velocity clamping.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.8 + np.random.rand() * 0.7  # Increased mutation factor\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            velocity_clamp = (ub - lb) * (0.1 + 0.4 * (1 - eval_count / self.budget)) # Velocity clamping\n            self.velocities = np.clip(w * self.velocities + cognitive_velocity + social_velocity, -velocity_clamp, velocity_clamp)\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:14:38.579707", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:14:43.427136", "content": "# Description: Introduced dynamic inertia weight adjustment based on population diversity to balance exploration and exploitation more effectively.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSODynamicInertia:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            population_var = np.var(self.positions, axis=0).mean()\n            w = self.w_max - (self.w_max - self.w_min) * population_var / (population_var + 1e-9)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:14:47.107815", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities. (Score: 0.06247779723107204)\n\nThe selected solution to update is:\nIntroduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 11.5% of the code, which means if the code has 100 lines, you can only change 11.458333333333332 lines, and the rest of the lines should remain unchanged. This input code has 96 lines, so you can only change 11 lines, the rest 85 lines should remain unchanged. This changing rate 11.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:14:53.919270", "content": "# Description: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:14:57.537378", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:15:04.028946", "content": "# Description: Incorporate adaptive mutation strategies and enhanced neighborhood exploration to improve convergence and escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n        \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_mutation(self, candidate, lb, ub):\n        step_size = np.random.uniform(0.1, 0.5) * (ub - lb)\n        mutation = candidate + step_size * np.random.normal(size=self.dim)\n        return np.clip(mutation, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = self.adaptive_mutation(self.positions[i], lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:15:07.636416", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:15:13.213972", "content": "# Description: Introduced a dynamic inertia weight and adaptive mutation strategy to enhance exploration and exploitation balance in multi-population PSO with Levy flights.\n# Code: \n```python\nimport numpy as np\n\nclass RefinedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:15:16.856789", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.6% of the code, which means if the code has 100 lines, you can only change 4.587155963302752 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 5 lines, the rest 104 lines should remain unchanged. This changing rate 4.6% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:15:24.104934", "content": "# Description: Enhanced local search exploitation through adaptive mutation strategies to improve the convergence rate.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n\n            # Adaptive mutation for enhanced local exploitation\n            if np.random.rand() < 0.05:\n                mutant_index = np.random.choice(self.pop_size)\n                sigma = 0.1 * (ub - lb) * (1 - eval_count / self.budget)\n                mutation = np.random.normal(0, sigma, self.dim)\n                mutated_position = self.positions[mutant_index] + mutation\n                mutated_position = np.clip(mutated_position, lb, ub)\n                mutated_score = func(mutated_position)\n                eval_count += 1\n                if mutated_score < self.personal_best_scores[mutant_index]:\n                    self.personal_best_scores[mutant_index] = mutated_score\n                    self.personal_best_positions[mutant_index] = mutated_position\n                if mutated_score < self.global_best_score:\n                    self.global_best_score = mutated_score\n                    self.global_best_position = mutated_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:15:27.687682", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 0.9% of the code, which means if the code has 100 lines, you can only change 0.9174311926605505 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 1 lines, the rest 108 lines should remain unchanged. This changing rate 0.9% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:15:33.282306", "content": "# Description: Adjust dynamic neighborhood size to improve information sharing and convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.5 * (1 - eval_count / self.budget)))  # Adjusted from 0.3 to 0.5\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:15:36.874084", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.8% of the code, which means if the code has 100 lines, you can only change 1.834862385321101 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 2 lines, the rest 107 lines should remain unchanged. This changing rate 1.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:15:42.046556", "content": "# Description: Introduced dynamic inertia weight and crossover mutation to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4  # Changed from 0.3 to 0.4\n        self.w_max = 0.9  # Changed from 0.8 to 0.9\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:15:45.623138", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:15:49.501218", "content": "# Description: Integrate adaptive inertia weight and chaos theory-based initialization to enhance exploration and convergence balance.\n# Code:\n```python\nimport numpy as np\n\nclass AdvancedAdaptiveChaosPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def chaos_init(self, lb, ub, size):\n        return lb + (ub - lb) * np.random.rand(size)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = self.chaos_init(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                score = func(self.positions[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n\n            self.positions = np.clip(self.positions, lb, ub)\n\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:15:49.503624", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.8% of the code, which means if the code has 100 lines, you can only change 1.834862385321101 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 2 lines, the rest 107 lines should remain unchanged. This changing rate 1.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:15:55.389392", "content": "# Description: Enhanced exploration by dynamically adjusting mutation factor in differential evolution strategy.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + (1-eval_count/self.budget) * 0.5  # Changed line for dynamic mutation factor\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:16:06.743541", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:16:14.054239", "content": "# Description: Introduced adaptive Levy flight strategy based on global best improvement rate to enhance exploration in early stages and exploitation in later stages.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n        self.last_global_best_score = float('inf')\n        self.improvement_rate_threshold = 0.01\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_levy_probability(self, eval_count):\n        global_improvement_rate = (self.last_global_best_score - self.global_best_score) / self.last_global_best_score\n        self.last_global_best_score = self.global_best_score\n        if global_improvement_rate > self.improvement_rate_threshold:\n            return 0.2  # Higher exploration if improvement rate is significant\n        else:\n            return 0.05  # Lower exploration if improvement rate is small\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < self.adaptive_levy_probability(eval_count):\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:16:39.843879", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:16:48.189406", "content": "# Description: Introduced adaptive learning rates for different subpopulations to enhance exploration-exploitation balance and improve convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedSubpopAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.base_c1 = 1.5\n        self.base_c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Adaptive learning rates for different subpopulations\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n        self.c1 = np.full(self.num_subpops, self.base_c1)\n        self.c2 = np.full(self.num_subpops, self.base_c2)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            # Update velocities and positions with adaptive learning rates\n            for subpop in range(self.num_subpops):\n                start = subpop * self.subpop_size\n                end = start + self.subpop_size\n                r1 = np.random.uniform(0, 1, (self.subpop_size, self.dim))\n                r2 = np.random.uniform(0, 1, (self.subpop_size, self.dim))\n                c1 = self.c1[subpop]\n                c2 = self.c2[subpop]\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[start:end] - self.positions[start:end])\n                social_velocity = c2 * r2 * (local_best_positions[start:end] - self.positions[start:end])\n                self.velocities[start:end] = w * self.velocities[start:end] + cognitive_velocity + social_velocity\n                self.positions[start:end] += self.velocities[start:end]\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n                # Adjust learning rates adaptively based on performance\n                for subpop in range(self.num_subpops):\n                    subpop_scores = self.personal_best_scores[subpop*self.subpop_size:(subpop+1)*self.subpop_size]\n                    if np.mean(subpop_scores) < self.global_best_score:\n                        self.c1[subpop] *= 1.05\n                        self.c2[subpop] *= 0.95\n                    else:\n                        self.c1[subpop] *= 0.95\n                        self.c2[subpop] *= 1.05\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:16:59.764881", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 0.9% of the code, which means if the code has 100 lines, you can only change 0.9174311926605505 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 1 lines, the rest 108 lines should remain unchanged. This changing rate 0.9% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:17:06.339208", "content": "# Description: Enhanced exploitation with adaptive learning factor for improved convergence in PSO-Levy.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            c_adaptive = (self.c1 + self.c2) / 2 + (self.c2 - self.c1) * (eval_count / self.budget)  # Changed line\n            cognitive_velocity = c_adaptive * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:17:17.500227", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:17:24.940972", "content": "# Description: Introduced dynamic adaptive parameter tuning and synergy-based crossover strategies to enhance search diversity and convergence rate.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedSynergyAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1_initial = 1.5\n        self.c2_initial = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, max(2, int(self.pop_size * 0.3)), replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = self.c1_initial + (2 - 2 * (eval_count / self.budget)) * np.random.rand()\n            c2 = self.c2_initial + (2 * (eval_count / self.budget)) * np.random.rand()\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Synergy-based crossover between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            # Crossover operation\n                            alpha = np.random.rand()\n                            self.positions[i] = alpha * self.positions[i] + (1 - alpha) * best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:17:37.134772", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance. (Score: 0.06247779939945365)\n\nThe selected solution to update is:\nIntroduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 0.9% of the code, which means if the code has 100 lines, you can only change 0.9174311926605505 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 1 lines, the rest 108 lines should remain unchanged. This changing rate 0.9% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:17:42.173941", "content": "# Description: Improved local best selection by considering more neighbors for better adaptability.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:17:54.178790", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:18:00.402508", "content": "# Description: Introducing adaptive mutation strategies and dynamic subpopulation interaction to improve exploration and exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_mutation(self, pos, lb, ub, intensity=0.05):\n        mutation_scale = intensity * (ub - lb)\n        mutation = np.random.normal(0, mutation_scale, pos.shape)\n        mutated_pos = np.clip(pos + mutation, lb, ub)\n        return mutated_pos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  \n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n\n            if np.random.rand() < 0.2:\n                mutated_positions = self.adaptive_mutation(self.global_best_position, lb, ub, intensity=0.1)\n                mutated_score = func(mutated_positions)\n                eval_count += 1\n                if mutated_score < self.global_best_score:\n                    self.global_best_score = mutated_score\n                    self.global_best_position = mutated_positions\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n\n                    if np.random.rand() < 0.2:\n                        random_subpop = np.random.randint(0, self.num_subpops)\n                        random_start = random_subpop * self.subpop_size\n                        random_end = random_start + self.subpop_size\n                        random_best_idx = np.argmin(self.personal_best_scores[random_start:random_end])\n                        random_best_position = self.personal_best_positions[random_start + random_best_idx]\n                        self.positions[start:end] = random_best_position\n            \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:18:11.833152", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:18:17.005322", "content": "# Description: Introduced dynamic adaptation of velocity coefficients and stochastic perturbations for enhanced convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            dynamic_c1 = 1.5 + 0.5 * np.random.rand() * (1 - eval_count / self.budget)\n            dynamic_c2 = 2.5 - 0.5 * np.random.rand() * (eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = dynamic_c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = dynamic_c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:18:28.460711", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:18:32.582314", "content": "# Description: Utilize adaptive learning rates and elite-guided exploration to enhance convergence speed and solution quality.\n# Code:\n```python\nimport numpy as np\n\nclass OptimizedAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = np.random.uniform(0, 1, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n    \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.positions[i])\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.positions[i])\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                elite_step = self.levy_flight(self.dim)\n                elite_position = self.global_best_position + elite_step\n                elite_position = np.clip(elite_position, lb, ub)\n                elite_score = func(elite_position)\n                eval_count += 1\n                if elite_score < self.global_best_score:\n                    self.global_best_score = elite_score\n                    self.global_best_position = elite_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:18:41.785124", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:18:47.084341", "content": "# Description: Enhanced multi-population strategy with adaptive mutation rate and dynamic neighborhood adjustment for improved exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        adaptive_mutation_rate = 0.1\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < adaptive_mutation_rate:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                adaptive_mutation_rate = 0.1 + 0.3 * np.random.rand()\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:18:58.992552", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.8% of the code, which means if the code has 100 lines, you can only change 1.834862385321101 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 2 lines, the rest 107 lines should remain unchanged. This changing rate 1.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:19:04.577041", "content": "# Description: Enhance mutation strategy by increasing mutation probability for better exploration.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.20:  # Changed line to increase mutation probability\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:19:16.033243", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:19:22.165474", "content": "# Description: Introduce adaptive mutation and dynamic neighborhood adjustment to enhance exploration and exploitation balance in metaheuristic search.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_position = self.personal_best_positions[best_neighbor]\n                dynamic_mutation = 0.1 + 0.9 * (1 - eval_count / self.budget)\n                if np.random.rand() < dynamic_mutation:\n                    mutated_dim = np.random.randint(self.dim)\n                    mutation_step = np.random.uniform(-1, 1) * (ub[mutated_dim] - lb[mutated_dim])\n                    local_best_position[mutated_dim] += mutation_step\n                self.personal_best_positions[i] = local_best_position\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.personal_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:19:33.943256", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 0.9% of the code, which means if the code has 100 lines, you can only change 0.9174311926605505 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 1 lines, the rest 108 lines should remain unchanged. This changing rate 0.9% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:19:39.103236", "content": "# Description: Enhanced adaptability by increasing the mutation chance slightly to explore more.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.2:  # Changed line: increase mutation chance slightly\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:19:50.477780", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.8% of the code, which means if the code has 100 lines, you can only change 2.7522935779816518 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 3 lines, the rest 106 lines should remain unchanged. This changing rate 2.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:19:56.126632", "content": "# Description: Introduced a dynamic mutation factor and adaptive neighborhood size for enhanced convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - (eval_count / self.budget) ** 0.5)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5 * (1 - eval_count / self.budget)  # Changed line\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:20:07.728366", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.8% of the code, which means if the code has 100 lines, you can only change 1.834862385321101 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 2 lines, the rest 107 lines should remain unchanged. This changing rate 1.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:20:13.619964", "content": "# Description: Improved velocity update by adding adaptive inertia weight based on velocity variance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.std(self.velocities) / np.max(np.std(self.velocities)))  # Changed line\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:20:25.549457", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.8% of the code, which means if the code has 100 lines, you can only change 1.834862385321101 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 2 lines, the rest 107 lines should remain unchanged. This changing rate 1.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:20:30.956842", "content": "# Description: Introducing an adaptive inertia mechanism to enhance convergence speed and balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * ((eval_count / self.budget) ** 2)  # Changed line\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:20:40.461473", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.8% of the code, which means if the code has 100 lines, you can only change 1.834862385321101 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 2 lines, the rest 107 lines should remain unchanged. This changing rate 1.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:20:46.437536", "content": "# Description: Introduced dynamic inertia weight adjustment based on local best score improvements to enhance convergence speed.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget))) \n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Dynamic inertia weight adjustment based on local best improvement\n            improvement_factor = 1 - (self.global_best_score / (min(self.personal_best_scores) + 1e-10))\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget)) * improvement_factor\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:20:55.849251", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:21:02.737323", "content": "# Description: Introduced adaptive learning rates and hyper-sphere distribution to enhance exploration and exploitation balance in particle movement.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_learning_rate(self, eval_count):\n        return self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n    def hypersphere_sampling(self, center, radius):\n        direction = np.random.normal(0, 1, self.dim)\n        unit_vector = direction / np.linalg.norm(direction)\n        return center + unit_vector * radius\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.adaptive_learning_rate(eval_count)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = self.hypersphere_sampling(best_subpop_position, np.linalg.norm(ub - lb) * 0.1)\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:21:11.901370", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.7% of the code, which means if the code has 100 lines, you can only change 3.669724770642202 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 4 lines, the rest 105 lines should remain unchanged. This changing rate 3.7% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:21:18.154139", "content": "# Description: Refined EnhancedHybridAdaptivePSOLevy with dynamically adjusted cognitive and social coefficients for improved convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget))) \n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            # Refined coefficients adjustment\n            self.c1 = 1.5 + 1.0 * (eval_count / self.budget)\n            self.c2 = 2.5 - 1.0 * (eval_count / self.budget)\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:21:27.809947", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:21:33.831354", "content": "# Description: Introduce dynamic leader selection and adaptive turbulence to enhance exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.2 + 0.1 * np.sin(np.pi * eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:21:43.466557", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.6% of the code, which means if the code has 100 lines, you can only change 4.587155963302752 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 5 lines, the rest 104 lines should remain unchanged. This changing rate 4.6% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:21:49.476366", "content": "# Description: Enhanced adaptive neighborhood and dynamic levy flight balance for improved exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.2:  # Increased probability\n                step = self.levy_flight(self.dim, beta=1.3)  # Adjusted beta\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:21:58.990150", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:22:05.876700", "content": "# Description: Enhanced dynamic neighborhood adaptation and differential evolution mutation for improved convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(5, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.2:  # Increase the probability of mutation\n                f = 0.5 + np.random.rand() * 0.7\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:  # Increase the frequency of Levy flights\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.1:  # Increase interaction frequency\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
{"role": "client", "time": "2025-12-20 11:22:10.424773", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the similar problems of a real-world problem. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb and func.bounds.ub. The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridAdaptivePSOLevy: Improved local best selection by considering more neighbors for better adaptability. (Score: 0.062477799978949505)\n\nThe selected solution to update is:\nImproved local best selection by considering more neighbors for better adaptability.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n\nThe algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.6% of the code, which means if the code has 100 lines, you can only change 4.587155963302752 lines, and the rest of the lines should remain unchanged. This input code has 109 lines, so you can only change 5 lines, the rest 104 lines should remain unchanged. This changing rate 4.6% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-20 11:22:16.160713", "content": "# Description: Introduced adaptive inertia weight adjustment and increased mutation diversity to refine exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = (self.w_max - self.w_min) * np.cos(eval_count / self.budget * np.pi) + self.w_min  # Changed line\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:  # Changed line\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score\n```"}
