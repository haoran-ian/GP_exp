{"id": "77fe6499-e50b-4942-a830-7a67dddc1ed2", "fitness": 0.062475774829794196, "name": "AdaptivePSO", "description": "A dynamic particle swarm optimization (PSO) variant that adaptively adjusts particles' cognitive and social components based on performance feedback to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of coefficients\n            if eval_count % (self.budget // 10) == 0:\n                success_rate = np.sum(self.personal_best_scores < self.global_best_score) / self.pop_size\n                if success_rate < 0.2:\n                    self.c1 *= 1.1\n                    self.c2 *= 0.9\n                elif success_rate > 0.8:\n                    self.c1 *= 0.9\n                    self.c2 *= 1.1\n                \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06247434227862991, 0.06246891130667975, 0.06248407116424526, 0.06247434222607651, 0.0624689112543122, 0.06248407111190646, 0.06247434207074387, 0.06246891109901298, 0.06248407095654085]}}
{"id": "c4b5af5f-67e4-4d42-b7f8-5ad376a33a0f", "fitness": 0.062474486534855225, "name": "EnhancedPSO", "description": "EnhancedPSO: An improved dynamic PSO algorithm with adaptive inertia weight and velocity clamping to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n            \n            # Velocity clamping\n            vmax = 0.1 * (ub - lb)\n            self.velocities = np.clip(self.velocities, -vmax, vmax)\n            \n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["77fe6499-e50b-4942-a830-7a67dddc1ed2"], "operator": null, "metadata": {"aucs": [0.06247378931047631, 0.062465309008770675, 0.06248436154534465, 0.0624737892581444, 0.06246530895642577, 0.062484361493034934, 0.0624737891028021, 0.06246530880109136, 0.06248436133760682]}}
{"id": "432e8b24-af8f-4194-9156-aacfbdffd135", "fitness": 0.06247687484462842, "name": "EnhancedAdaptivePSO", "description": "An enhanced PSO variant that dynamically adjusts inertia weight and incorporates an opposition-based learning strategy for faster convergence and better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["77fe6499-e50b-4942-a830-7a67dddc1ed2"], "operator": null, "metadata": {"aucs": [0.06247398799495685, 0.06247237221703994, 0.06248426458197376, 0.062473987942605946, 0.06247237216469592, 0.062484264529511835, 0.062473987787276974, 0.06247237200936173, 0.06248426437423282]}}
{"id": "3e7b134d-fd6a-49c5-a62c-2d863bed4977", "fitness": 0.062476673249905454, "name": "EnhancedAdaptivePSO", "description": "Enhanced PSO with dynamic social coefficient reducing over time for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = (self.c2 * (1 - eval_count / self.budget)) * r2 * (self.global_best_position - self.positions)  # Adjusted line\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["432e8b24-af8f-4194-9156-aacfbdffd135"], "operator": null, "metadata": {"aucs": [0.06247420745484644, 0.06247143129604393, 0.062484381258914756, 0.06247420740253273, 0.06247143124369414, 0.062484381206396544, 0.06247420724714614, 0.062471431088374274, 0.06248438105120013]}}
{"id": "503e0d85-ed6b-4cd6-86ec-db71e2efbf18", "fitness": 0.06247521691413468, "name": "EnhancedAdaptivePSO", "description": "Introduce a random mutation strategy to enhance diversity when updating positions.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities + np.random.normal(0, 0.1 * (ub - lb), self.positions.shape)  # Added random mutation\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["432e8b24-af8f-4194-9156-aacfbdffd135"], "operator": null, "metadata": {"aucs": [0.06247254928210233, 0.06246931933953581, 0.062483782381105524, 0.06247254922955092, 0.062469319286971414, 0.0624837823287645, 0.062472549074197414, 0.06246931913159315, 0.06248378217339101]}}
{"id": "fcf96181-7744-4bad-a836-ed0e3b334580", "fitness": 0.06247599470286705, "name": "EnhancedAdaptivePSO", "description": "Enhanced PSO with adaptive velocity clamping for improved stability and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            # Adaptive velocity clamping\n            max_velocity = (ub - lb) * 0.1\n            self.velocities = np.clip(self.velocities, -max_velocity, max_velocity)\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["432e8b24-af8f-4194-9156-aacfbdffd135"], "operator": null, "metadata": {"aucs": [0.06247333032899671, 0.06247035528821232, 0.062484298751533496, 0.062473330276714645, 0.06247035523565436, 0.0624842986990225, 0.06247333012131884, 0.062470355080524675, 0.06248429854382587]}}
{"id": "e2b3fb16-ee7b-43c5-9f7b-52a6ca40c7ae", "fitness": 0.062475623749590814, "name": "EnhancedAdaptivePSO", "description": "Introduced a decay factor in the cognitive and social coefficients to enhance convergence by reducing emphasis on personal and global bests over time.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            decay_factor = 1 - (eval_count / self.budget)\n            cognitive_velocity = self.c1 * r1 * decay_factor * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * decay_factor * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["432e8b24-af8f-4194-9156-aacfbdffd135"], "operator": null, "metadata": {"aucs": [0.06247254088525289, 0.06247040086349509, 0.06248392976009076, 0.062472540832936296, 0.06247040081113886, 0.06248392970771599, 0.06247254067758734, 0.062470400655805225, 0.06248392955229487]}}
{"id": "2ef9f9eb-cb78-4a95-9d85-2ce9b5c19381", "fitness": -Infinity, "name": "EnhancedAdaptiveDualPSO", "description": "A dual-population PSO that alternates between original and opposition-based learning strategies, with dynamic inertia and velocity clamping for enhanced convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDualPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.v_max = 0.2 * (func.bounds.ub - func.bounds.lb)  # Max velocity\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        toggle_flag = True  # Toggle flag for dual population strategy\n        while eval_count < self.budget:\n            if toggle_flag:\n                population = self.positions\n            else:\n                # Opposition-based population\n                population = lb + ub - self.positions\n            \n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(population[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = population[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = population[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            \n            # Velocity clamping\n            self.velocities = np.clip(self.velocities, -self.v_max, self.v_max)\n            \n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Toggle flag to switch between original and opposition population\n            toggle_flag = not toggle_flag\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["432e8b24-af8f-4194-9156-aacfbdffd135"], "operator": null, "metadata": {}}
{"id": "b0850cee-50fb-4929-86a6-aa9a615f3142", "fitness": -Infinity, "name": "EnhancedAdaptivePSO", "description": "Enhanced PSO with additional local search using Levy flight to improve exploration.", "code": "import numpy as np\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Levy flight local search\n            if np.random.rand() < 0.1:  # 10% chance to perform Levy flight\n                levy_step = np.random.uniform(-1, 1, self.dim) * (np.random.normal(size=self.dim) / np.power(np.random.normal(size=self.dim), 1.5))\n                temp_position = self.positions + levy_step\n                temp_position = np.clip(temp_position, lb, ub)\n                temp_score = func(temp_position)\n                eval_count += 1\n                if temp_score < self.global_best_score:\n                    self.global_best_score = temp_score\n                    self.global_best_position = temp_position\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "An exception occurred: TypeError(\"'<' not supported between instances of 'list' and 'float'\").", "error": "TypeError(\"'<' not supported between instances of 'list' and 'float'\")", "parent_ids": ["432e8b24-af8f-4194-9156-aacfbdffd135"], "operator": null, "metadata": {}}
{"id": "429772c7-ac10-4e8d-ad85-a52796fcfb83", "fitness": 0.062476953383788794, "name": "ImprovedAdaptivePSO", "description": "Incorporating a dynamic neighborhood topology and an adaptive learning rate to improve exploratory behavior and convergence efficiency in the enhanced PSO framework.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["432e8b24-af8f-4194-9156-aacfbdffd135"], "operator": null, "metadata": {"aucs": [0.06247540901962845, 0.062471208299146985, 0.06248424309269118, 0.06247540896729864, 0.0624712082466542, 0.062484243040338505, 0.06247540881190938, 0.062471208091452124, 0.06248424288497967]}}
{"id": "79ea5605-df14-4b09-a9ee-bec4f1f1c03e", "fitness": 0.06247647823495047, "name": "EnhancedAdaptivePSO", "description": "Introducing a self-adaptive mechanism for dynamically adjusting cognitive and social coefficients, alongside enhanced neighborhood exploration through diversity-enriched local search strategies.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  \n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 2.0, 3.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            diversity = np.std(self.positions, axis=0).mean()\n            c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - diversity)\n            c2 = self.c2_min + (self.c2_max - self.c2_min) * diversity\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.06247469054304278, 0.062470331205570884, 0.06248441321643361, 0.06247469049051746, 0.06247033115322542, 0.062484413163894525, 0.06247469033528974, 0.062470330997882684, 0.062484413008697115]}}
{"id": "035cab9d-bbdb-4207-ac68-b3f43f14217c", "fitness": 0.062476953383788794, "name": "ImprovedAdaptivePSO", "description": "Fine-tuning the dynamic neighborhood size for better adaptability and convergence efficiency in the enhanced PSO framework.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(4, self.pop_size // 5)  # Adjusted dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.06247540901962845, 0.062471208299146985, 0.06248424309269118, 0.06247540896729864, 0.0624712082466542, 0.062484243040338505, 0.06247540881190938, 0.062471208091452124, 0.06248424288497967]}}
{"id": "e77b2808-96aa-485d-87d2-7c6c4211055a", "fitness": 0.062475719785351526, "name": "ImprovedAdaptivePSO", "description": "Introduce a dynamic adaptive mechanism to adjust the social coefficient based on the current evaluation progress to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight and social coefficient\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            self.c2 = 1.5 + (2.5 - 1.5) * (eval_count / self.budget)  # Adaptive social coefficient\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.06247238592185589, 0.06247050800802145, 0.06248426568625798, 0.06247238586955406, 0.06247050795547515, 0.062484265633924174, 0.06247238571420166, 0.06247050780033003, 0.062484265478543355]}}
{"id": "c4a317a4-7e51-4759-bf74-8331efe4f6fd", "fitness": 0.06247692013877715, "name": "ImprovedAdaptivePSO", "description": "Introduce a non-linear inertia weight decay for more balanced exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight using non-linear decay\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) ** 2\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.06247372109263294, 0.06247257337881107, 0.062484466204916544, 0.06247372104029658, 0.06247257332649514, 0.06248446615260295, 0.06247372088495973, 0.06247257317110455, 0.06248446599717483]}}
{"id": "2acefc01-f60e-4a0e-9fe3-1082c8dd3ccf", "fitness": 0.062475879600706365, "name": "EnhancedQuantumPSO", "description": "Introducing multi-swarm interaction with adaptive velocity clamping and quantum-behaved particles to enhance search diversity and convergence in the ImprovedAdaptivePSO framework.", "code": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.velocity_clamp = 0.1  # Adaptive velocity clamp\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.05:  # 5% chance for quantum-behaved exploration\n                quantum_positions = lb + np.random.rand(self.pop_size, self.dim) * (ub - lb) * 0.5\n                quantum_scores = np.array([func(pos) for pos in quantum_positions])\n                eval_count += len(quantum_positions)\n                improved_indices = quantum_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = quantum_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = quantum_positions[improved_indices]\n                if np.min(quantum_scores) < self.global_best_score:\n                    self.global_best_score = np.min(quantum_scores)\n                    self.global_best_position = quantum_positions[np.argmin(quantum_scores)]\n                \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            \n            # Adaptive velocity clamping\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.06247542895500513, 0.06246787634674078, 0.06248433376054019, 0.06247542890242341, 0.06246787629443884, 0.06248433370816986, 0.06247542874711587, 0.062467876139085776, 0.062484333552837446]}}
{"id": "c7ff85d6-df70-4829-a71c-57e65f3d214d", "fitness": -Infinity, "name": "ImprovedAdaptivePSO", "description": "Incorporating multi-leader dynamics with variable neighborhood learning to enhance search diversity and convergence in PSO.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.multi_leaders = None  # New: Keep track of multiple leaders\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.multi_leaders = np.full((self.neighborhood_size, self.dim), float('inf'))  # New\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                score = func(self.positions[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    # Update multi-leaders\n                    if score < np.max(self.multi_leaders):\n                        worst_leader_idx = np.argmax(self.multi_leaders)\n                        self.multi_leaders[worst_leader_idx] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Variable neighborhood learning\n                neighborhood_indices = np.random.choice(self.pop_size, np.random.randint(1, self.neighborhood_size), replace=False)\n                best_neighbor = min(neighborhood_indices, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n\n            self.positions = np.clip(self.positions, lb, ub)\n\n        return np.min(self.multi_leaders), self.global_best_score", "configspace": "", "generation": 15, "feedback": "An exception occurred: IndexError('index 45 is out of bounds for axis 0 with size 4').", "error": "IndexError('index 45 is out of bounds for axis 0 with size 4')", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {}}
{"id": "f8a232a5-e0d5-474f-8170-4803c29594d3", "fitness": 0.062475463889897616, "name": "ImprovedAdaptivePSO", "description": "Enhancing adaptive PSO with a chaotic local search mechanism and neighborhood mutation to improve exploration and convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  \n        self.c1 = 1.5  \n        self.c2 = 2.5  \n        self.w_min = 0.4  \n        self.w_max = 0.9  \n        self.neighborhood_size = max(3, self.pop_size // 5)  \n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n                if np.random.rand() < 0.2:  # 20% chance to mutate neighborhood\n                    local_best_positions[i] = lb + np.random.rand(self.dim) * (ub - lb)\n\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.062475893172851626, 0.062466689102838924, 0.06248380965415168, 0.06247589312044122, 0.062466689050322266, 0.062483809601814655, 0.06247589296504097, 0.0624666888951928, 0.0624838094464244]}}
{"id": "2d461364-f2fa-42cd-8dfe-5f5adf615fe1", "fitness": 0.062475582486448654, "name": "RefinedAdaptivePSO", "description": "Incorporating a self-adaptive mutation strategy with a diversity preservation mechanism to enhance the exploratory capability and convergence of the improved PSO framework.", "code": "import numpy as np\n\nclass RefinedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.5  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.5  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 5)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Self-adaptive mutation strategy\n            mutation_probability = 0.2 * (1 - eval_count / self.budget)\n            for i in range(self.pop_size):\n                if np.random.rand() < mutation_probability:\n                    mutation_vector = np.random.uniform(-1, 1, self.dim)\n                    self.positions[i] += mutation_vector * (ub - lb) * 0.1\n            \n            # Diversity preservation\n            if np.random.rand() < 0.1:\n                diversity_vector = np.mean(self.positions, axis=0)\n                self.positions += (diversity_vector - self.positions) * 0.1\n            \n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm RefinedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.062474762125446226, 0.06246774210814954, 0.06248424348582271, 0.062474762073023604, 0.062467742055839826, 0.062484243433456266, 0.0624747619177467, 0.06246774190046123, 0.06248424327809177]}}
{"id": "e153e43f-5bac-474d-8d53-1a99748cf3ff", "fitness": 0.06247662897243764, "name": "RefinedAdaptivePSO", "description": "Introducing local search diversification and velocity clamping to enhance convergence and exploitation in dynamic PSO.", "code": "import numpy as np\n\nclass RefinedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, self.pop_size // 5)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.velocity_clamp = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Velocity clamping\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n\n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Local search diversification\n            if np.random.rand() < 0.1:\n                perturbations = np.random.normal(0, 0.1, self.positions.shape)\n                perturbed_positions = self.positions + perturbations\n                perturbed_positions = np.clip(perturbed_positions, lb, ub)\n                perturbed_scores = np.array([func(pos) for pos in perturbed_positions])\n                eval_count += len(perturbed_positions)\n                improved_indices = perturbed_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = perturbed_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = perturbed_positions[improved_indices]\n                if np.min(perturbed_scores) < self.global_best_score:\n                    self.global_best_score = np.min(perturbed_scores)\n                    self.global_best_position = perturbed_positions[np.argmin(perturbed_scores)]\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm RefinedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.06247594660101563, 0.06246988389653274, 0.062484056679878996, 0.06247594654865862, 0.06246988384420771, 0.06248405662737466, 0.06247594639326581, 0.062469883688833217, 0.06248405647217137]}}
{"id": "c6feeee6-9b35-4db9-bb1a-a2ce72c32143", "fitness": -Infinity, "name": "ImprovedMultiSwarmPSO", "description": "Introducing a multi-swarm strategy with adaptive learning coefficients and random orthogonal exploration to simultaneously enhance global search diversity and convergence efficiency.", "code": "import numpy as np\n\nclass ImprovedMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.num_swarms = 2  # Number of swarms\n        self.positions = [np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim)) for _ in range(self.num_swarms)]\n        self.velocities = [np.random.uniform(-1, 1, (self.pop_size, self.dim)) for _ in range(self.num_swarms)]\n        self.personal_best_positions = [np.copy(p) for p in self.positions]\n        self.personal_best_scores = [np.full(self.pop_size, float('inf')) for _ in range(self.num_swarms)]\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.c1_max, self.c1_min = 2.5, 1.5\n        self.c2_max, self.c2_min = 2.5, 1.5\n        self.w_min, self.w_max = 0.4, 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                for i in range(self.pop_size):\n                    if eval_count >= self.budget:\n                        break\n                    \n                    # Evaluate current position\n                    score = func(self.positions[swarm_idx][i])\n                    eval_count += 1\n                    \n                    # Update personal bests\n                    if score < self.personal_best_scores[swarm_idx][i]:\n                        self.personal_best_scores[swarm_idx][i] = score\n                        self.personal_best_positions[swarm_idx][i] = self.positions[swarm_idx][i]\n                    \n                    # Update global best\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best_position = self.positions[swarm_idx][i]\n                \n                # Adaptive adjustment of coefficients\n                progress = eval_count / self.budget\n                c1 = self.c1_max - (self.c1_max - self.c1_min) * progress\n                c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n                w = self.w_max - (self.w_max - self.w_min) * progress\n\n                # Random orthogonal exploration technique\n                if np.random.rand() < 0.2:  # 20% chance for orthogonal exploration\n                    ortho_positions = self.positions[swarm_idx] + np.random.rand(*self.positions[swarm_idx].shape) * (ub - lb) / 5\n                    ortho_scores = np.array([func(pos) for pos in ortho_positions])\n                    eval_count += len(ortho_positions)\n                    improved_indices = ortho_scores < self.personal_best_scores[swarm_idx]\n                    self.personal_best_scores[swarm_idx][improved_indices] = ortho_scores[improved_indices]\n                    self.personal_best_positions[swarm_idx][improved_indices] = ortho_positions[improved_indices]\n                    if np.min(ortho_scores) < self.global_best_score:\n                        self.global_best_score = np.min(ortho_scores)\n                        self.global_best_position = ortho_positions[np.argmin(ortho_scores)]\n                \n                # Update velocities and positions\n                r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n                r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[swarm_idx] - self.positions[swarm_idx])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[swarm_idx])\n                self.velocities[swarm_idx] = w * self.velocities[swarm_idx] + cognitive_velocity + social_velocity\n                self.positions[swarm_idx] += self.velocities[swarm_idx]\n                \n                # Clip to bounds\n                self.positions[swarm_idx] = np.clip(self.positions[swarm_idx], lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {}}
{"id": "d3d44139-fa70-4aef-94f7-4cc7f5ad757c", "fitness": 0.062477181221836466, "name": "ImprovedAdaptivePSO", "description": "Enhanced adaptive learning coefficients and dynamic neighborhood size adjustments for improved convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["429772c7-ac10-4e8d-ad85-a52796fcfb83"], "operator": null, "metadata": {"aucs": [0.06247486498197796, 0.06247247558566249, 0.0624842033579488, 0.06247486492947263, 0.062472475533356886, 0.062484203305592234, 0.06247486477431452, 0.06247247537798084, 0.06248420315022185]}}
{"id": "846e59e0-ae32-4412-8d88-bdc445b0aa26", "fitness": 0.062473551093662705, "name": "ImprovedAdaptivePSO", "description": "Incorporate a stochastic weight adjustment to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                # Update personal bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            # Dynamic neighborhood topology\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Adaptive adjustment of inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) + np.random.uniform(-0.1, 0.1)\n            \n            # Opposition-based learning strategy\n            if np.random.rand() < 0.1:  # 10% chance to explore opposition solutions\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            # Update velocities and positions\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            # Clip to bounds\n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["d3d44139-fa70-4aef-94f7-4cc7f5ad757c"], "operator": null, "metadata": {"aucs": [0.062474619545969445, 0.06246184496175433, 0.0624841890333363, 0.06247461949366895, 0.0624618449093014, 0.06248418898097108, 0.06247461933830689, 0.06246184475407446, 0.06248418882558149]}}
{"id": "207cbcb5-b1bc-4238-8fd9-25999bf83f37", "fitness": 0.06247702722151156, "name": "ImprovedAdaptivePSO", "description": "Integrate a dynamic adjustment of cognitive and social coefficients during iterations for improved exploitation and exploration balance.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))  # Population size\n        self.c1 = 1.8  # Lower Cognitive coefficient for better global exploration\n        self.c2 = 2.2  # Higher Social coefficient for improved convergence\n        self.w_min = 0.4  # Min inertia weight\n        self.w_max = 0.9  # Max inertia weight\n        self.neighborhood_size = max(3, self.pop_size // 4)  # Dynamic neighborhood size\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.1:\n                opposite_positions = lb + ub - self.positions\n                opposite_scores = np.array([func(pos) for pos in opposite_positions])\n                eval_count += len(opposite_positions)\n                improved_indices = opposite_scores < self.personal_best_scores\n                self.personal_best_scores[improved_indices] = opposite_scores[improved_indices]\n                self.personal_best_positions[improved_indices] = opposite_positions[improved_indices]\n                if np.min(opposite_scores) < self.global_best_score:\n                    self.global_best_score = np.min(opposite_scores)\n                    self.global_best_position = opposite_positions[np.argmin(opposite_scores)]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            self.c1 = 1.8 + 0.4 * (eval_count / self.budget)  # Dynamic adjustment of cognitive coefficient\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["d3d44139-fa70-4aef-94f7-4cc7f5ad757c"], "operator": null, "metadata": {"aucs": [0.062474378810864484, 0.062472537143080764, 0.06248416597066453, 0.0624743787585067, 0.06247253709066236, 0.06248416591835326, 0.06247437860312133, 0.06247253693539867, 0.062484165762951904]}}
{"id": "62c01d4e-6f06-4414-a9d2-3743bdd6f306", "fitness": 0.062477394760682065, "name": "EnhancedImprovedAdaptivePSO", "description": "Enhanced ImprovedAdaptivePSO with dynamic inertia weight adjustment, adaptive selection, and differential evolution-inspired mutation for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["d3d44139-fa70-4aef-94f7-4cc7f5ad757c"], "operator": null, "metadata": {"aucs": [0.06247425771856174, 0.062473667205082184, 0.062484259618478144, 0.062474257666258026, 0.062473667152581513, 0.06248425956616788, 0.06247425751087399, 0.062473666997395205, 0.06248425941073987]}}
{"id": "c09d55f0-4b33-4678-a6de-5737144bc8fa", "fitness": 0.0624775830456452, "name": "HybridAdaptivePSOLevy", "description": "Hybrid Adaptive PSO with Lvy Flights for enhanced exploration-exploitation balance, leveraging stochastic flight paths for escaping local optima.", "code": "import numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["62c01d4e-6f06-4414-a9d2-3743bdd6f306"], "operator": null, "metadata": {"aucs": [0.06247507644332817, 0.06247367327174913, 0.06248399968200846, 0.06247507639101846, 0.06247367321919328, 0.06248399962970996, 0.06247507623565818, 0.06247367306383356, 0.062483999474307605]}}
{"id": "65934a57-27e4-4619-b568-944370dd5c86", "fitness": 0.06247491732099594, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced Hybrid PSO with Lvy Flights integrating adaptive mutation and dynamic neighborhood topology for superior exploration-exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_fraction = 0.25\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            sorted_indices = np.argsort(self.personal_best_scores)\n            top_indices = sorted_indices[:int(self.pop_size * self.neighborhood_fraction)]\n            local_best_positions = self.personal_best_positions[top_indices]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                if np.random.rand() < 0.15:\n                    f = 0.5 + np.random.rand() * 0.5\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                    mutant_positions = np.clip(mutant_positions, lb, ub)\n                    mutant_score = func(mutant_positions)\n                    eval_count += 1\n                    if mutant_score < self.personal_best_scores[indices[0]]:\n                        self.personal_best_scores[indices[0]] = mutant_score\n                        self.personal_best_positions[indices[0]] = mutant_positions\n                    if mutant_score < self.global_best_score:\n                        self.global_best_score = mutant_score\n                        self.global_best_position = mutant_positions\n\n                r1 = np.random.uniform(0, 1, (self.dim,))\n                r2 = np.random.uniform(0, 1, (self.dim,))\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (local_best_positions[i % len(local_best_positions)] - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n                self.positions[i] += self.velocities[i]\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["c09d55f0-4b33-4678-a6de-5737144bc8fa"], "operator": null, "metadata": {"aucs": [0.06247508268432367, 0.06246533800868137, 0.06248433153005484, 0.0624750826319691, 0.062465337956276734, 0.06248433147769239, 0.06247508247663247, 0.0624653378010116, 0.06248433132232134]}}
{"id": "2ddb7a7d-5a28-4647-a9c0-fe4001879d44", "fitness": 0.06247727965441582, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced Hybrid Adaptive PSO with Lvy Flights and Dynamic Population to improve convergence by balancing exploration and exploitation with adaptive population size adjustments.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def dynamic_population_adjustment(self):\n        if np.random.rand() < 0.1:\n            self.pop_size = min(max(5, int(self.pop_size * (0.9 + 0.2 * np.random.rand()))), 2 * self.pop_size)\n            self.neighborhood_size = max(3, self.pop_size // 4)\n            self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n            self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n            self.personal_best_positions = np.copy(self.positions)\n            self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["c09d55f0-4b33-4678-a6de-5737144bc8fa"], "operator": null, "metadata": {"aucs": [0.062474186883965, 0.062473562768154856, 0.062484089571233414, 0.06247418683165007, 0.06247356271581983, 0.062484089518693664, 0.062474186676292454, 0.0624735625604268, 0.062484089363506246]}}
{"id": "a0e5a247-ab00-42f8-874d-5a02302110bc", "fitness": 0.0624773331075683, "name": "HybridAdaptivePSOLevy", "description": "Hybrid Adaptive PSO with Lvy Flights and adaptive mutation rate for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15 + (0.25 * (1 - eval_count / self.budget)): # Changed line\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["c09d55f0-4b33-4678-a6de-5737144bc8fa"], "operator": null, "metadata": {"aucs": [0.06247515325575781, 0.06247316338605091, 0.06248368294099804, 0.062475153203414124, 0.06247316333373798, 0.06248368288846218, 0.0624751530480816, 0.06247316317835938, 0.062483682733252666]}}
{"id": "40f111d0-fde4-4d82-b441-9068570f27f2", "fitness": 0.06247741483315123, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced Hybrid Adaptive PSO integrates dynamic parameter tuning and adaptive Lvy flight based on fitness improvements for superior exploration-exploitation synergy.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.leap_probability = 0.1\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            self.adaptive_leap_probability(eval_count)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < self.leap_probability:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n\n    def adaptive_leap_probability(self, eval_count):\n        improvement_rate = (self.global_best_score - np.min(self.personal_best_scores)) / max(self.global_best_score, 1e-9)\n        self.leap_probability = 0.1 + 0.1 * (1 - improvement_rate) * (eval_count / self.budget)", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["c09d55f0-4b33-4678-a6de-5737144bc8fa"], "operator": null, "metadata": {"aucs": [0.06247507644332817, 0.062473665504223175, 0.06248350281198101, 0.06247507639101846, 0.062473665451664884, 0.062483502759697274, 0.06247507623565818, 0.06247366529650977, 0.06248350260428015]}}
{"id": "4d8be083-2630-470a-b820-cabb698a09f7", "fitness": 0.06247410390000886, "name": "HybridAdaptivePSOLevy", "description": "Optimized Hybrid Adaptive PSO with Lvy Flights by adjusting mutation strategy and employing adaptive neighborhood influence for improved convergence.", "code": "import numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(3, self.pop_size // 4)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) # Line 1\n                \n            if np.random.rand() < 0.1: # Line 2\n                f = 0.6 + np.random.rand() * 0.4 # Line 3\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["c09d55f0-4b33-4678-a6de-5737144bc8fa"], "operator": null, "metadata": {"aucs": [0.062473054654393456, 0.06246491959159439, 0.062484337714139526, 0.06247305460209063, 0.062464919539245045, 0.06248433766168049, 0.06247305444669693, 0.062464919383918294, 0.062484337506320986]}}
{"id": "eb7a52b7-272f-41b9-8f0c-587a42f02ee7", "fitness": 0.06247652619711129, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced Hybrid Adaptive PSO with Lvy Flights incorporating dynamic neighborhood and mutation probability for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.dynamic_mutation_prob = 0.1\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            dynamic_neighborhood_size = max(3, int((self.pop_size / 4) * (1 - eval_count / self.budget)))\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            mutation_prob = self.dynamic_mutation_prob + (1.0 - self.dynamic_mutation_prob) * (eval_count / self.budget)\n            \n            if np.random.rand() < mutation_prob:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["c09d55f0-4b33-4678-a6de-5737144bc8fa"], "operator": null, "metadata": {"aucs": [0.06247183658527844, 0.062473662213404335, 0.06248408005280015, 0.06247183653275934, 0.062473662161042776, 0.062484080000420605, 0.062471836377601786, 0.06247366200569071, 0.06248407984500348]}}
{"id": "4f7f4ad8-4ac7-4a24-b354-595e5f9d4559", "fitness": 0.062477781145056074, "name": "HybridAdaptivePSOLevy", "description": "Implemented a different neighborhood size calculation to potentially improve local optima escape in Hybrid Adaptive PSO with Lvy Flights.", "code": "import numpy as np\n\nclass HybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))  # Modified neighborhood size calculation\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Lvy flight for additional exploration\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm HybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["c09d55f0-4b33-4678-a6de-5737144bc8fa"], "operator": null, "metadata": {"aucs": [0.06247531524906158, 0.062473662213404335, 0.062484366232883226, 0.06247531519655236, 0.062473662161042776, 0.06248436618034392, 0.062475315041382484, 0.06247366200569071, 0.06248436602514329]}}
{"id": "995b4f98-a0e9-4278-86f9-4cd5e850dbc4", "fitness": 0.06247633765609531, "name": "HybridAdaptivePSOLevyDynamic", "description": "Introducing a dynamic neighborhood size adjustment strategy and adaptive mutation rate to improve global optima convergence in Hybrid Adaptive PSO with Lvy Flights.", "code": "import numpy as np\n\nclass HybridAdaptivePSOLevyDynamic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                self.dynamic_neighborhood_size(eval_count)\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < self.adaptive_mutation_rate(eval_count):\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score\n    \n    def dynamic_neighborhood_size(self, eval_count):\n        progress = eval_count / self.budget\n        if progress < 0.5:\n            self.neighborhood_size = max(2, int(self.pop_size * (0.3 + 0.2 * progress)))\n        else:\n            self.neighborhood_size = max(2, int(self.pop_size * (0.5 - 0.2 * (progress - 0.5))))\n\n    def adaptive_mutation_rate(self, eval_count):\n        progress = eval_count / self.budget\n        return 0.15 * (1 - progress) + 0.05 * progress", "configspace": "", "generation": 32, "feedback": "The algorithm HybridAdaptivePSOLevyDynamic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4f7f4ad8-4ac7-4a24-b354-595e5f9d4559"], "operator": null, "metadata": {"aucs": [0.062474280009199745, 0.062470512671081835, 0.06248422054809977, 0.06247427995687116, 0.06247051261867653, 0.0624842204957311, 0.06247427980147846, 0.06247051246336943, 0.06248422034034973]}}
{"id": "e21b8d2d-7819-4b03-a6cf-705016017fe5", "fitness": 0.062477784172413564, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Combine Adaptive PSO with Lvy Flights and an Enhanced Differential Mutation strategy to improve exploration and exploitation balance in high-dimensional search spaces.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["4f7f4ad8-4ac7-4a24-b354-595e5f9d4559"], "operator": null, "metadata": {"aucs": [0.062475322042065407, 0.06247366450243863, 0.062484366232883226, 0.06247532198964778, 0.06247366445008262, 0.06248436618034392, 0.06247532183438631, 0.06247366429473089, 0.06248436602514329]}}
{"id": "a201cf1a-d179-424b-8f8e-9a4ea6a78ca0", "fitness": 0.06247700442338008, "name": "EnhancedDynamicNeighborhoodPSOLevy", "description": "Integrate Adaptive PSO, Lvy Flights, and a Dynamic Neighborhood Search with Random Walks to enhance diversification and intensification in solving complex optimization problems.", "code": "import numpy as np\n\nclass EnhancedDynamicNeighborhoodPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.dynamic_neighborhood = True\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def random_walk(self, position, bounds):\n        step_size = np.random.uniform(0, 1, self.dim)\n        direction = np.random.choice([-1, 1], self.dim)\n        new_position = position + direction * step_size\n        return np.clip(new_position, bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            if self.dynamic_neighborhood:\n                neighborhood_size = max(2, int(self.pop_size * (0.1 + 0.4 * (1 - eval_count / self.budget))))\n                local_best_positions = np.copy(self.personal_best_positions)\n                for i in range(self.pop_size):\n                    neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                    best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                    local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            else:\n                local_best_positions = np.copy(self.personal_best_positions)\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            if np.random.rand() < 0.05:\n                for i in range(self.pop_size):\n                    new_position = self.random_walk(self.positions[i], func.bounds)\n                    new_score = func(new_position)\n                    eval_count += 1\n                    if new_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = new_score\n                        self.personal_best_positions[i] = new_position\n                    if new_score < self.global_best_score:\n                        self.global_best_score = new_score\n                        self.global_best_position = new_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedDynamicNeighborhoodPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["e21b8d2d-7819-4b03-a6cf-705016017fe5"], "operator": null, "metadata": {"aucs": [0.06247519896472398, 0.06247138484655945, 0.06248442971897994, 0.06247519891235975, 0.06247138479425507, 0.062484429666390895, 0.06247519875705099, 0.06247138463889068, 0.062484429511209916]}}
{"id": "a341a6dd-98ef-42d8-b872-c11d3866a1a5", "fitness": -Infinity, "name": "EnhancedHybridAdaptivePSOLevyV2", "description": "Integrate dynamic neighborhood adjustment and chaotic map initialization to enhance diversity and convergence in the search process.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = self.chaotic_map_init(func.bounds.lb, func.bounds.ub)\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_map_init(self, lb, ub):\n        x = np.random.rand(self.pop_size, self.dim)\n        return lb + (ub - lb) * np.sin(np.pi * x)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            neighborhood_size = int(self.pop_size * np.random.uniform(0.2, 0.6))\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["e21b8d2d-7819-4b03-a6cf-705016017fe5"], "operator": null, "metadata": {}}
{"id": "7c05110a-9ea8-4178-bd54-29eb3cd90641", "fitness": 0.06247779723107204, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced an adaptive neighborhood size based on the current iteration to enhance local search capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["e21b8d2d-7819-4b03-a6cf-705016017fe5"], "operator": null, "metadata": {"aucs": [0.06247533253370541, 0.062473662213404335, 0.06248439720622079, 0.06247533248133996, 0.062473662161042776, 0.062484397153754534, 0.06247533232599989, 0.06247366200569071, 0.062484396998489955]}}
{"id": "d027f575-3230-42f3-9cb3-bd816708836f", "fitness": 0.06247625584801025, "name": "ImprovedHybridAdaptivePSOLevy", "description": "Introduced an adaptive inertia weight influenced by swarm diversity and dynamic neighborhood to boost global exploration and local exploitation.", "code": "import numpy as np\n\nclass ImprovedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_inertia(self, current_positions, global_best_position):\n        diversity = np.mean(np.linalg.norm(current_positions - global_best_position, axis=1))\n        return self.w_min + (self.w_max - self.w_min) * (diversity / np.max(diversity, initial=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.adaptive_inertia(self.positions, self.global_best_position)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm ImprovedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062474950440622457, 0.062470052431547685, 0.062483764931989705, 0.062474950388298645, 0.062470052379053675, 0.062483764879482484, 0.06247495023293126, 0.06247005222387758, 0.06248376472428874]}}
{"id": "b7867e8f-1d0b-401c-ba81-27fedfc1ffa6", "fitness": 0.06247457884218139, "name": "EnhancedHybridAdaptivePSOLevyImproved", "description": "Enhance dynamic neighborhood adaptation and integrate a multi-strategy search mechanism to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            # Multi-strategy search mechanism\n            if np.random.rand() < 0.2:\n                # Random mutation exploration\n                for i in range(self.pop_size):\n                    mutant = self.positions[i] + np.random.normal(0, 0.1, size=self.dim)\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_score = func(mutant)\n                    eval_count += 1\n                    if mutant_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = mutant_score\n                        self.personal_best_positions[i] = mutant\n                    if mutant_score < self.global_best_score:\n                        self.global_best_score = mutant_score\n                        self.global_best_position = mutant\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevyImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062475584477325485, 0.06246388861892671, 0.06248426369036675, 0.06247558442496892, 0.06246388856648022, 0.062484263637990756, 0.06247558426966138, 0.06246388841125694, 0.062484263482655344]}}
{"id": "429ad2de-0275-462a-b244-9bcf26702bd6", "fitness": 0.06247761158681648, "name": "EnhancedRestartAdaptivePSOLevy", "description": "Introduce stochastic restarts and adaptive mutation rates to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedRestartAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.restart_threshold = 0.2\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n    \n    def restart_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.restart_population(lb, ub)\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Stochastic restart strategy\n            if np.random.rand() < self.restart_threshold:\n                if np.random.rand() < 0.5:  # Introduce restart based on stochastic decision\n                    self.restart_population(lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedRestartAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247516131176967, 0.06247358421011573, 0.06248408949863182, 0.06247516125941066, 0.0624735841578099, 0.06248408944622896, 0.062475161104079024, 0.06247358400240777, 0.06248408929089477]}}
{"id": "07dc5c29-724c-46c6-8952-54b5515f6816", "fitness": 0.062474777398803534, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced an additional velocity update method influenced by a random elite particle for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            elite_idx = np.random.choice(self.pop_size)  # Select a random elite particle\n            elite_influence = 0.5 * (self.positions[elite_idx] - self.positions)  # New line for elite influence\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity + elite_influence\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247412204750169, 0.062466476694991946, 0.06248373371398297, 0.06247412199515501, 0.062466476642638824, 0.062483733661628627, 0.06247412183980994, 0.06246647648726722, 0.06248373350625558]}}
{"id": "cae03b5d-2fe9-4883-bd47-14dfc7ce0b96", "fitness": 0.06247537263946295, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced exploration by dynamically adjusting inertia and incorporating a new random mutation strategy.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Dynamically adjusting inertia weight using cosine\n            w = self.w_max - (self.w_max - self.w_min) * (np.cos(eval_count / self.budget * np.pi / 2))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247072515993546, 0.062471225246854334, 0.0624841677717044, 0.06247072510749074, 0.0624712251945162, 0.0624841677193364, 0.062470724952217394, 0.06247122503918945, 0.062484167563922166]}}
{"id": "6fef2360-35c1-4a35-9241-efd675e56497", "fitness": 0.06247517084812995, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Improved EnhancedHybridAdaptivePSOLevy with inertia weight adaptation and chaotic search for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_search(self, dim):\n        z = np.random.rand(dim)\n        chaotic_sequence = np.sin(np.pi * z)\n        return chaotic_sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_min + (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if np.random.rand() < 0.05:\n                chaotic_step = self.chaotic_search(self.dim)\n                chaotic_positions = self.global_best_position + chaotic_step\n                chaotic_positions = np.clip(chaotic_positions, lb, ub)\n                chaotic_score = func(chaotic_positions)\n                eval_count += 1\n                if chaotic_score < self.global_best_score:\n                    self.global_best_score = chaotic_score\n                    self.global_best_position = chaotic_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.0624758711335498, 0.062465842189055265, 0.062483799481857005, 0.06247587108123642, 0.06246584213659545, 0.06248379942949178, 0.0624758709258717, 0.062465841981382275, 0.062483799274129836]}}
{"id": "2bac50ce-d50c-4f9d-baba-f4b6d1f8120a", "fitness": 0.06247623813545317, "name": "EnhancedHybridAdaptivePSOLevyV2", "description": "Incorporate dynamic inertia weights and an adaptive mutation strategy to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.1\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.2 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.4 + np.random.rand() * 0.6\n                indices = np.random.choice(self.pop_size, 4, replace=False)\n                mutant_positions = (self.personal_best_positions[indices[0]] + \n                                    f * (self.personal_best_positions[indices[1]] - self.personal_best_positions[indices[2]]))\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevyV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247323965960583, 0.062471074074508026, 0.06248440093237573, 0.06247323960708717, 0.062471074022111606, 0.062484400880010504, 0.062473239451941054, 0.06247107386679007, 0.06248440072464856]}}
{"id": "fcae3a1f-8e8d-432c-8b9b-b027530a3425", "fitness": 0.062475955093860426, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Improved exploration by introducing a probabilistic mutation in the update phase for broader search coverage.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r3 = np.random.uniform(0, 1, (self.pop_size, self.dim))  # New random vector\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            mutation_velocity = 0.1 * r3 * (ub - lb) * np.random.normal(0, 1, (self.pop_size, self.dim))  # Mutation term\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity + mutation_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247588905349588, 0.06246774317697423, 0.06248423331119435, 0.06247588900113621, 0.06246774312464487, 0.06248423325883978, 0.06247588884574362, 0.06246774296929203, 0.06248423310342288]}}
{"id": "73832a21-9f7e-4c4c-bdab-fe34b6903174", "fitness": 0.06247720844927142, "name": "EnhancedHybridAdaptivePSOLevyV2", "description": "Enhanced dynamic neighborhood adjustment with hybrid crossover and mutation strategies for diverse exploration.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Introduce crossover between randomly selected individuals\n            if np.random.rand() < 0.1:\n                parent1, parent2 = np.random.choice(self.pop_size, 2, replace=False)\n                crossover_point = np.random.randint(1, self.dim-1)\n                child_position = np.concatenate(\n                    (self.positions[parent1][:crossover_point], self.positions[parent2][crossover_point:])\n                )\n                child_position = np.clip(child_position, lb, ub)\n                child_score = func(child_position)\n                eval_count += 1\n                if child_score < self.global_best_score:\n                    self.global_best_score = child_score\n                    self.global_best_position = child_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevyV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247530729069839, 0.06247196760083962, 0.06248435071635117, 0.062475307238342825, 0.06247196754843809, 0.06248435066401237, 0.06247530708299864, 0.06247196739313077, 0.06248435050863088]}}
{"id": "e10403b4-c595-41c9-b719-c11d38752807", "fitness": 0.06247779723107204, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced local search by incorporating random restarts when improvement stalls.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        no_improvement_counter = 0 # Added to track improvements\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                    no_improvement_counter = 0 # Reset on improvement\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            no_improvement_counter += 1\n            if no_improvement_counter > self.pop_size: # Added random restarts\n                self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                no_improvement_counter = 0\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247533253370541, 0.062473662213404335, 0.06248439720622079, 0.06247533248133996, 0.062473662161042776, 0.062484397153754534, 0.06247533232599989, 0.06247366200569071, 0.062484396998489955]}}
{"id": "bb8a1e9f-c1b6-4d8b-8bdd-3dd5fb71a9e8", "fitness": 0.062476746021148055, "name": "EliteAdaptivePSO", "description": "Introduced elite particle learning and adaptive mutation to accelerate convergence while maintaining diversity.", "code": "import numpy as np\n\nclass EliteAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            elite_idx = np.argmin(self.personal_best_scores)\n            elite_position = self.personal_best_positions[elite_idx]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.2:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (elite_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EliteAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247290483797974, 0.06247287327067752, 0.06248446021483989, 0.06247290478568113, 0.06247287321829953, 0.06248446016251685, 0.06247290463029864, 0.06247287306292648, 0.06248446000711272]}}
{"id": "f3b3bfeb-add8-4c90-9fc3-e9bd7de6a1f2", "fitness": 0.06247730340619711, "name": "MultiPhaseAdaptivePSOLevy", "description": "Introduced multi-phase strategy with initial global search and adaptive local refinement using dynamic mutation rates.", "code": "import numpy as np\n\nclass MultiPhaseAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n        eval_count = 0\n        phase_switch = int(self.budget * 0.6)\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if eval_count < phase_switch:\n                # Global search phase\n                mutation_prob = 0.2\n            else:\n                # Local refinement phase\n                mutation_prob = 0.05\n\n            if np.random.rand() < mutation_prob:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm MultiPhaseAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247508878652941, 0.06247243342146758, 0.06248438827059932, 0.062475088734227024, 0.06247243336916164, 0.0624843882182855, 0.0624750885788401, 0.06247243321379492, 0.06248438806286849]}}
{"id": "76f3dbc1-25fe-4320-aceb-b4bd48cab43f", "fitness": 0.062477476917925, "name": "EnhancedHybridAdaptivePSOLevyV2", "description": "Introduce a self-adaptive mutation strategy based on historical performance to enhance exploration and balance between exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.mutation_strategy_threshold = 0.1 # Probability threshold for mutation\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < self.mutation_strategy_threshold:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < self.mutation_strategy_threshold:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Self-adapting the mutation strategy threshold based on historical performance\n            improvement = np.mean(self.personal_best_scores) - self.global_best_score\n            if improvement > 0:\n                self.mutation_strategy_threshold *= 0.9\n            else:\n                self.mutation_strategy_threshold *= 1.1\n            self.mutation_strategy_threshold = np.clip(self.mutation_strategy_threshold, 0.05, 0.3)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevyV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247464527569413, 0.06247366816686306, 0.06248411757136574, 0.06247464522333701, 0.0624736681145015, 0.06248411751883498, 0.06247464506794054, 0.06247366795914944, 0.06248411736363857]}}
{"id": "78b082f7-fade-4401-ac8e-3a65cf9cd21d", "fitness": 0.06247571998158078, "name": "EnhancedDiversePSOLevy", "description": "Enhanced the adaptive neighborhood by introducing a dynamic inertia weight based on swarm diversity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDiversePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.positions, axis=0)\n        diversity = np.mean(np.linalg.norm(self.positions - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            diversity = self.calculate_diversity()\n            w = self.w_max - (self.w_max - self.w_min) * (diversity / np.linalg.norm(ub - lb))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedDiversePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062475272619805344, 0.062468063817321284, 0.06248382376782402, 0.06247527256743546, 0.062468063764860804, 0.06248382371524308, 0.06247527241210327, 0.06246806360959256, 0.06248382356004123]}}
{"id": "a92e74f8-77f0-4968-95d6-993b30862810", "fitness": -Infinity, "name": "EnhancedHybridAdaptivePSOLevyChaotic", "description": "Enhanced neighborhood adaptation and diversity introduction using chaotic sequences for improved local search and convergence stability.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyChaotic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.chaos_sequence = self.generate_chaos_sequence(self.budget)\n\n    def generate_chaos_sequence(self, length, z0=0.7):\n        sequence = [z0]\n        for i in range(1, length):\n            sequence.append(4 * sequence[-1] * (1 - sequence[-1]))\n        return np.array(sequence)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = self.chaos_sequence[eval_count] * np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = self.chaos_sequence[eval_count] * np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "An exception occurred: IndexError('index 4500 is out of bounds for axis 0 with size 4500').", "error": "IndexError('index 4500 is out of bounds for axis 0 with size 4500')", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {}}
{"id": "19306368-9155-481b-ad4f-eb799272714c", "fitness": 0.0624766120274766, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced stochastic adaptive inertia weight adjustment and incorporated chaotic local search for enhanced exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_local_search(self, lb, ub):\n        chaos_factor = np.random.rand(self.dim)\n        chaotic_positions = lb + (ub - lb) * chaos_factor\n        return chaotic_positions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            cognitive_influence = np.random.rand()  # Stochastic cognitive influence\n            w = self.w_max - (self.w_max - self.w_min) * cognitive_influence * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if np.random.rand() < 0.05:\n                chaotic_positions = self.chaotic_local_search(lb, ub)\n                chaotic_score = func(chaotic_positions)\n                eval_count += 1\n                if chaotic_score < self.global_best_score:\n                    self.global_best_score = chaotic_score\n                    self.global_best_position = chaotic_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062473536435571075, 0.062472221038798015, 0.062484078868279114, 0.062473536383228834, 0.06247222098623895, 0.06248407881570106, 0.06247353622787177, 0.06247222083109594, 0.06248407866050465]}}
{"id": "568e7072-e380-4346-bc74-116438d1d771", "fitness": 0.06247419197597363, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced a dynamic inertia weight factor based on swarm diversity to improve exploration-exploitation balance in PSO-Levy.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def diversity(self, positions):\n        mean_position = np.mean(positions, axis=0)\n        return np.mean(np.linalg.norm(positions - mean_position, axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            swarm_diversity = self.diversity(self.positions)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - swarm_diversity)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247275332160951, 0.0624654568750409, 0.06248436599138363, 0.062472753269279147, 0.06246545682251159, 0.062484365939018405, 0.06247275311393141, 0.062465456667360475, 0.06248436578362759]}}
{"id": "4d16a5db-3c03-4fd1-9045-bbceb57d5bd5", "fitness": 0.06247616539166102, "name": "ImprovedHybridAdaptivePSOLevy", "description": "Introduced a dynamic exploration-exploitation trade-off by integrating adaptive velocity scaling and multi-strategy search to improve convergence.", "code": "import numpy as np\n\nclass ImprovedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            adaptive_scaling = 1 + (1 - eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + adaptive_scaling * (cognitive_velocity + social_velocity)\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n\n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm ImprovedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247475314465489, 0.06246957940457287, 0.06248416388590705, 0.062474753092090385, 0.06246957935224273, 0.062484163833578577, 0.062474752936843236, 0.062469579196859804, 0.062484163678199645]}}
{"id": "f7532853-396a-4cdd-abd4-46b3d2ef384e", "fitness": 0.06247663417031535, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Adjusted inertia weight formula to improve convergence speed in early iterations.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) ** 2\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247533197025612, 0.062470256083417164, 0.0624843147173787, 0.06247533191795207, 0.06247025603092349, 0.06248431466501336, 0.062475331762550934, 0.06247025587574695, 0.06248431450959935]}}
{"id": "3e83559a-ce3b-435d-a102-6cc1ecdbaac9", "fitness": 0.06247572778597124, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Implemented an adaptive inertia weight strategy and an elite strategy, selecting top individuals for local searching to improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            # Select the top-performing particles\n            elite_indices = np.argsort(self.personal_best_scores)[:max(2, self.pop_size // 5)]\n            elite_positions = self.personal_best_positions[elite_indices]\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)**2  # Use squared progress for inertia weight adaptation\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            # Apply Levy flight to elite solutions\n            for elite_pos in elite_positions:\n                step = self.levy_flight(self.dim)\n                levy_positions = elite_pos + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247556764063744, 0.062467204298201406, 0.062484411679090024, 0.06247556758832762, 0.06246720424590524, 0.06248441162672291, 0.062475567432962675, 0.062467204090531414, 0.06248441147136241]}}
{"id": "b0b1ba07-cb30-4c82-8436-a5acc4e30c2b", "fitness": -Infinity, "name": "EnhancedHybridAdaptivePSOBandit", "description": "Enhanced by incorporating a multi-arm bandit strategy to dynamically allocate exploration and exploitation efforts for improved global search.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOBandit:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.arm_rewards = np.zeros(2)  # Two strategies: DE mutation and Levy flight\n        self.arm_counts = np.ones(2)  # Initial count to avoid division by zero\n        self.explore_probability = 0.1\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def select_arm(self):\n        total_counts = np.sum(self.arm_counts)\n        ucb_values = self.arm_rewards / self.arm_counts + np.sqrt(2 * np.log(total_counts) / self.arm_counts)\n        return np.argmax(ucb_values)\n\n    def update_arm(self, arm, reward):\n        self.arm_counts[arm] += 1\n        n = self.arm_counts[arm]\n        value = self.arm_rewards[arm]\n        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward\n        self.arm_rewards[arm] = new_value\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < self.explore_probability:\n                arm = self.select_arm()\n            else:\n                arm = np.random.choice(2)\n            \n            if arm == 0:  # DE mutation\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                improvement = self.personal_best_scores[indices[0]] - mutant_score\n                if mutation_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            elif arm == 1:  # Levy flight\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                improvement = self.global_best_score - levy_score\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            self.update_arm(arm, improvement)\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "An exception occurred: NameError(\"name 'mutation_score' is not defined\").", "error": "NameError(\"name 'mutation_score' is not defined\")", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {}}
{"id": "c05ca4a2-7d77-45dc-852e-853d62755bc1", "fitness": 0.06247735856516264, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhance global exploration by adapting mutation probability and incorporate global diversity check.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < (0.15 + 0.05 * (1 - eval_count / self.budget)):  # Adjusted mutation probability\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062475082397786985, 0.06247260528713616, 0.06248438827059932, 0.062475082345428534, 0.062472605234824674, 0.0624843882182855, 0.06247508219009679, 0.062472605079437304, 0.06248438806286849]}}
{"id": "9f2ee5fd-2a14-44ad-84b0-684e06f1d8f8", "fitness": 0.06247444537003428, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Modified the update rule for velocities to incorporate an additional hybrid component, improving convergence speed via a diversity preservation strategy.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            hybrid_component = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity + 0.3 * hybrid_component\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247491679321082, 0.06246415136991057, 0.0624842682073371, 0.06247491674064498, 0.06246415131742211, 0.06248426815480346, 0.06247491658531423, 0.062464151162275994, 0.06248426799938922]}}
{"id": "e1de5f2b-d46b-49c4-877a-3a34f1737b87", "fitness": 0.062474513357229325, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Incorporate a dynamic inertia weight adjustment and a small mutation step in the cognitive component to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) ** 2\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            mutation_step = 0.01 * (ub - lb) * np.random.normal(size=(self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions + mutation_step)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062472897375585146, 0.06246622172312044, 0.06248442123302467, 0.06247289732323835, 0.06246622167082483, 0.062484421180659666, 0.06247289716791515, 0.06246622151545045, 0.06248442102524521]}}
{"id": "04d1d1f1-17b5-419f-b7ad-4ab6ace678a7", "fitness": 0.062474918360058106, "name": "EnhancedDynamicHybridPSOAnnealing", "description": "Introduce a dynamic inertia weight and hybridize with simulated annealing to enhance exploration-exploitation balance during optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicHybridPSOAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def simulated_annealing(self, current_pos, current_score, temperature, lb, ub, func):\n        new_pos = current_pos + np.random.uniform(-1, 1, size=self.dim)\n        new_pos = np.clip(new_pos, lb, ub)\n        new_score = func(new_pos)\n        if new_score < current_score:\n            return new_pos, new_score\n        elif np.random.rand() < np.exp((current_score - new_score) / temperature):\n            return new_pos, new_score\n        else:\n            return current_pos, current_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        init_temp = 100\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            temperature = init_temp * (1 - eval_count / self.budget)\n            for i in range(self.pop_size):\n                self.positions[i], _ = self.simulated_annealing(self.positions[i], func(self.positions[i]), temperature, lb, ub, func)\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedDynamicHybridPSOAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062472001466499116, 0.06246840773505291, 0.06248434613875342, 0.06247200141418918, 0.06246840768264195, 0.06248434608619047, 0.06247200125884678, 0.0624684075273475, 0.062484345931001606]}}
{"id": "fd5a84f2-ada7-4870-937d-e4db257c463b", "fitness": 0.06247490783860786, "name": "EnhancedDynamicSubgroupPSOLevy", "description": "Introduced time-varying control parameters and dynamic subgroup formations to enhance exploration-exploitation balance and diversity.", "code": "import numpy as np\n\nclass EnhancedDynamicSubgroupPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1_initial = 2.5\n        self.c2_initial = 1.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            # Update control parameters dynamically\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (eval_count / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (eval_count / self.budget)\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # Form dynamic subgroups\n            group_size = max(2, int(self.pop_size * 0.1 + np.random.rand() * 0.2))\n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, group_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedDynamicSubgroupPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247305285797178, 0.06246757735769659, 0.06248409356020679, 0.06247305280561444, 0.06246757730539909, 0.06248409350785933, 0.06247305265023295, 0.06246757715004747, 0.062484093352442316]}}
{"id": "6c126061-9b93-41b6-8d24-45e2ef2315fc", "fitness": 0.062477377766645935, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced random scaling on velocities to explore new regions intermittently.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            \n            if np.random.rand() < 0.05:  # Random scaling added\n                self.velocities *= np.random.uniform(0.5, 1.5, size=(self.pop_size, self.dim))\n                \n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247433312829853, 0.062473470486573035, 0.062484329945120765, 0.06247433307594996, 0.06247347043424778, 0.06248432989275576, 0.062474332920607445, 0.06247347027886363, 0.06248432973739648]}}
{"id": "85b6f395-abee-4190-a67c-579187ad6f78", "fitness": 0.06247699095951144, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced convergence by introducing mutation strategy based on the fitness of the population.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n                    \n            # Introduce mutation based on global best\n            if np.random.rand() < 0.1:\n                mutation_step = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                mutation_positions = self.global_best_position + mutation_step\n                mutation_positions = np.clip(mutation_positions, lb, ub)\n                mutation_score = func(mutation_positions)\n                eval_count += 1\n                if mutation_score < self.global_best_score:\n                    self.global_best_score = mutation_score\n                    self.global_best_position = mutation_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062474631627373434, 0.06247242908448747, 0.06248391242681772, 0.062474631575010986, 0.06247242903193995, 0.06248391237447892, 0.0624746314196265, 0.06247242887680371, 0.06248391221906424]}}
{"id": "7c8bbf0b-f74c-4df1-bd6f-252ef5dd445b", "fitness": 0.06247625041117247, "name": "AdvancedHybridAdaptivePSOLevy", "description": "Implements a multi-phase dynamic adaptation strategy combining velocity adjustment and hybrid exploration to enhance convergence.", "code": "import numpy as np\n\nclass AdvancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.neighborhood_size = max(3, int(self.pop_size * 0.2))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.2 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.4 + np.random.rand() * 0.6\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm AdvancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247390531625363, 0.062471395676499175, 0.062483450500886994, 0.0624739052637322, 0.06247139562412973, 0.062483450448532984, 0.06247390510856021, 0.06247139546879832, 0.06248345029315894]}}
{"id": "ad0877b4-df26-4342-b810-d43adbd3de65", "fitness": 0.06247770901825958, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced global search by introducing random reinitialization for stagnating particles to improve exploration.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n            # Random reinitialization for stagnating particles\n            stagnation_threshold = 20\n            if eval_count % stagnation_threshold == 0:\n                reinit_indices = np.random.choice(self.pop_size, size=int(self.pop_size * 0.1), replace=False)\n                self.positions[reinit_indices] = np.random.uniform(lb, ub, (len(reinit_indices), self.dim))\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.062475055462484885, 0.06247367538618187, 0.06248439646619852, 0.062475055410113, 0.062473675333846734, 0.06248439641374248, 0.06247505525477981, 0.06247367517849489, 0.062484396258494]}}
{"id": "4365d372-0b3b-4316-8dd5-e791a4dbcb0b", "fitness": 0.06247767033288162, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Improved the adaptive mutation strategy by introducing a stochastic element to better escape local optima.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (np.random.rand() * (self.positions[indices[1]] - self.positions[indices[2]]) +\n                                                                     np.random.rand() * (self.positions[indices[3]] - self.positions[indices[4]]))  # Changed line\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247497388909218, 0.0624736632138968, 0.06248437415586261, 0.06247497383674838, 0.06247366316153502, 0.062484374103328744, 0.06247497368141475, 0.06247366300614132, 0.06248437394791473]}}
{"id": "7c426f2b-1916-4d04-9958-716b4aad715f", "fitness": 0.06247274369616467, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Improved exploration by increasing the mutation factor and adding adaptive velocity clamping.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                # Dynamically adapting neighborhood size based on iterations\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.8 + np.random.rand() * 0.7  # Increased mutation factor\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            velocity_clamp = (ub - lb) * (0.1 + 0.4 * (1 - eval_count / self.budget)) # Velocity clamping\n            self.velocities = np.clip(w * self.velocities + cognitive_velocity + social_velocity, -velocity_clamp, velocity_clamp)\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247504793686509, 0.06245895493417675, 0.06248422847752266, 0.06247504788454217, 0.06245895488164932, 0.06248422842518586, 0.06247504772917434, 0.062458954726549165, 0.0624842282698167]}}
{"id": "c9ec0cdb-2143-4f5f-a16b-f5c0fe28c704", "fitness": 0.062476310687579924, "name": "EnhancedHybridAdaptivePSODynamicInertia", "description": "Introduced dynamic inertia weight adjustment based on population diversity to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSODynamicInertia:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            population_var = np.var(self.positions, axis=0).mean()\n            w = self.w_max - (self.w_max - self.w_min) * population_var / (population_var + 1e-9)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHybridAdaptivePSODynamicInertia got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247316599562991, 0.0624714551830281, 0.06248431114418784, 0.062473165943234155, 0.062471455130698406, 0.06248431109181929, 0.062473165787862994, 0.06247145497535311, 0.062484310936405496]}}
{"id": "aa36b3c6-5894-4887-953f-6caedd96cc72", "fitness": 0.06247779939945365, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced a multi-population approach with occasional information exchange to enhance exploration while maintaining convergence performance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["7c05110a-9ea8-4178-bd54-29eb3cd90641"], "operator": null, "metadata": {"aucs": [0.06247534049236758, 0.062473662213404335, 0.062484395752624766, 0.06247534044003478, 0.062473662161042776, 0.06248439570030917, 0.062475340284688485, 0.06247366200569071, 0.062484395544920246]}}
{"id": "a609f6ec-0f1c-4437-8a5d-db71750f401a", "fitness": 0.06247268207048082, "name": "RefinedAdaptivePSOLevy", "description": "Incorporate adaptive mutation strategies and enhanced neighborhood exploration to improve convergence and escape local optima.", "code": "import numpy as np\n\nclass RefinedAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n        \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_mutation(self, candidate, lb, ub):\n        step_size = np.random.uniform(0.1, 0.5) * (ub - lb)\n        mutation = candidate + step_size * np.random.normal(size=self.dim)\n        return np.clip(mutation, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n            \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = self.adaptive_mutation(self.positions[i], lb, ub)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm RefinedAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.06247100609679146, 0.06246286640940002, 0.06248417396540007, 0.06247100604445077, 0.06246286635685683, 0.0624841739130253, 0.06247100588909804, 0.06246286620166053, 0.06248417375764437]}}
{"id": "57ecc631-bfee-4379-977d-71bd82bd6c2e", "fitness": 0.06247468461466821, "name": "RefinedHybridAdaptivePSOLevy", "description": "Introduced a dynamic inertia weight and adaptive mutation strategy to enhance exploration and exploitation balance in multi-population PSO with Levy flights.", "code": "import numpy as np\n\nclass RefinedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm RefinedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.062473210523036005, 0.0624670607404898, 0.06248378284055234, 0.06247321047067855, 0.06246706068813612, 0.062483782788204656, 0.06247321031529729, 0.06246706053276774, 0.06248378263285137]}}
{"id": "873bbd96-a547-49b5-8501-7aa7f2a1e35b", "fitness": 0.062477546446764336, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced local search exploitation through adaptive mutation strategies to improve the convergence rate.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n\n            # Adaptive mutation for enhanced local exploitation\n            if np.random.rand() < 0.05:\n                mutant_index = np.random.choice(self.pop_size)\n                sigma = 0.1 * (ub - lb) * (1 - eval_count / self.budget)\n                mutation = np.random.normal(0, sigma, self.dim)\n                mutated_position = self.positions[mutant_index] + mutation\n                mutated_position = np.clip(mutated_position, lb, ub)\n                mutated_score = func(mutated_position)\n                eval_count += 1\n                if mutated_score < self.personal_best_scores[mutant_index]:\n                    self.personal_best_scores[mutant_index] = mutated_score\n                    self.personal_best_positions[mutant_index] = mutated_position\n                if mutated_score < self.global_best_score:\n                    self.global_best_score = mutated_score\n                    self.global_best_position = mutated_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.062475161054352135, 0.06247324040068958, 0.0624842381454398, 0.06247516100184658, 0.06247324034835544, 0.06248423809284964, 0.062475160846673594, 0.062473240193016366, 0.062484237937655895]}}
{"id": "565fb57c-a447-41b4-b7d5-ac6ef520fda6", "fitness": 0.0624758150099126, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Adjust dynamic neighborhood size to improve information sharing and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.5 * (1 - eval_count / self.budget)))  # Adjusted from 0.3 to 0.5\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.06246971889562847, 0.06247330921760297, 0.062484417176551954, 0.0624697188432789, 0.062473309165261504, 0.06248441712419239, 0.06246971868795659, 0.06247330900989034, 0.06248441696885032]}}
{"id": "0fc0ebd8-3f87-4264-9791-7a5542b5316d", "fitness": 0.06247410663738432, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced dynamic inertia weight and crossover mutation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.4  # Changed from 0.3 to 0.4\n        self.w_max = 0.9  # Changed from 0.8 to 0.9\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.06247307804338176, 0.06246502640274032, 0.06248421572617513, 0.06247307799102786, 0.062465026350272734, 0.062484215673809684, 0.06247307783567235, 0.06246502619495775, 0.062484215518421315]}}
{"id": "5d2ac241-5bb0-487e-9bfa-98d0b2fda13e", "fitness": -Infinity, "name": "AdvancedAdaptiveChaosPSOLevy", "description": "Integrate adaptive inertia weight and chaos theory-based initialization to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass AdvancedAdaptiveChaosPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def chaos_init(self, lb, ub, size):\n        return lb + (ub - lb) * np.random.rand(size)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = self.chaos_init(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                score = func(self.positions[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n\n            self.positions = np.clip(self.positions, lb, ub)\n\n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "An exception occurred: TypeError(\"'tuple' object cannot be interpreted as an integer\").", "error": "TypeError(\"'tuple' object cannot be interpreted as an integer\")", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {}}
{"id": "16faeff1-7d84-4572-9469-5905ebf0897f", "fitness": 0.062476855440830245, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced exploration by dynamically adjusting mutation factor in differential evolution strategy.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + (1-eval_count/self.budget) * 0.5  # Changed line for dynamic mutation factor\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.062472546297534626, 0.06247366990543757, 0.06248435037963562, 0.06247254624504539, 0.06247366985310243, 0.06248435032732291, 0.06247254608971975, 0.0624736696977507, 0.06248435017192322]}}
{"id": "0d53670f-bd2b-470f-a73d-b48000cfe93f", "fitness": 0.06247777444003929, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced adaptive Levy flight strategy based on global best improvement rate to enhance exploration in early stages and exploitation in later stages.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n        self.last_global_best_score = float('inf')\n        self.improvement_rate_threshold = 0.01\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_levy_probability(self, eval_count):\n        global_improvement_rate = (self.last_global_best_score - self.global_best_score) / self.last_global_best_score\n        self.last_global_best_score = self.global_best_score\n        if global_improvement_rate > self.improvement_rate_threshold:\n            return 0.2  # Higher exploration if improvement rate is significant\n        else:\n            return 0.05  # Lower exploration if improvement rate is small\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < self.adaptive_levy_probability(eval_count):\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.06247526993053809, 0.062473665379041754, 0.06248438827059932, 0.06247526987817886, 0.06247366532668008, 0.0624843882182855, 0.06247526972283335, 0.06247366517132813, 0.06248438806286849]}}
{"id": "feffeec0-13b9-4fc2-ad04-b29ab25383d0", "fitness": 0.062476302069252906, "name": "EnhancedSubpopAdaptivePSOLevy", "description": "Introduced adaptive learning rates for different subpopulations to enhance exploration-exploitation balance and improve convergence.", "code": "import numpy as np\n\nclass EnhancedSubpopAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.base_c1 = 1.5\n        self.base_c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Adaptive learning rates for different subpopulations\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n        self.c1 = np.full(self.num_subpops, self.base_c1)\n        self.c2 = np.full(self.num_subpops, self.base_c2)\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            # Update velocities and positions with adaptive learning rates\n            for subpop in range(self.num_subpops):\n                start = subpop * self.subpop_size\n                end = start + self.subpop_size\n                r1 = np.random.uniform(0, 1, (self.subpop_size, self.dim))\n                r2 = np.random.uniform(0, 1, (self.subpop_size, self.dim))\n                c1 = self.c1[subpop]\n                c2 = self.c2[subpop]\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[start:end] - self.positions[start:end])\n                social_velocity = c2 * r2 * (local_best_positions[start:end] - self.positions[start:end])\n                self.velocities[start:end] = w * self.velocities[start:end] + cognitive_velocity + social_velocity\n                self.positions[start:end] += self.velocities[start:end]\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n                # Adjust learning rates adaptively based on performance\n                for subpop in range(self.num_subpops):\n                    subpop_scores = self.personal_best_scores[subpop*self.subpop_size:(subpop+1)*self.subpop_size]\n                    if np.mean(subpop_scores) < self.global_best_score:\n                        self.c1[subpop] *= 1.05\n                        self.c2[subpop] *= 0.95\n                    else:\n                        self.c1[subpop] *= 0.95\n                        self.c2[subpop] *= 1.05\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedSubpopAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.062474073139341835, 0.06247042885945486, 0.062484404468977184, 0.06247407308702224, 0.062470428807099854, 0.06248440441666714, 0.06247407293168161, 0.06247042865176622, 0.062484404261265225]}}
{"id": "b3191619-8c27-4c09-a59d-a9661effed2d", "fitness": 0.0624769935509534, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced exploitation with adaptive learning factor for improved convergence in PSO-Levy.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(2, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            c_adaptive = (self.c1 + self.c2) / 2 + (self.c2 - self.c1) * (eval_count / self.budget)  # Changed line\n            cognitive_velocity = c_adaptive * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.06247328907756011, 0.06247356023984629, 0.062484131595530346, 0.062473289025193224, 0.062473560187430666, 0.06248413154319821, 0.062473288869865806, 0.062473560032133446, 0.062484131387822495]}}
{"id": "6986b79a-4286-462d-a431-6311fbfa3f79", "fitness": 0.06247703935761387, "name": "EnhancedSynergyAdaptivePSOLevy", "description": "Introduced dynamic adaptive parameter tuning and synergy-based crossover strategies to enhance search diversity and convergence rate.", "code": "import numpy as np\n\nclass EnhancedSynergyAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1_initial = 1.5\n        self.c2_initial = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, max(2, int(self.pop_size * 0.3)), replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = self.c1_initial + (2 - 2 * (eval_count / self.budget)) * np.random.rand()\n            c2 = self.c2_initial + (2 * (eval_count / self.budget)) * np.random.rand()\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Synergy-based crossover between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            # Crossover operation\n                            alpha = np.random.rand()\n                            self.positions[i] = alpha * self.positions[i] + (1 - alpha) * best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedSynergyAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.062475613328088375, 0.06247117857181261, 0.06248432643299118, 0.062475613275766784, 0.0624711785194807, 0.0624843263806627, 0.06247561312038241, 0.06247117836409499, 0.062484326225245024]}}
{"id": "a475cd63-c45e-458d-8132-ca92114504d9", "fitness": 0.062477799978949505, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Improved local best selection by considering more neighbors for better adaptability.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["aa36b3c6-5894-4887-953f-6caedd96cc72"], "operator": null, "metadata": {"aucs": [0.06247534049236758, 0.062473662213404335, 0.062484397491121, 0.06247534044003478, 0.062473662161042776, 0.062484397438779204, 0.062475340284688485, 0.06247366200569071, 0.062484397283416704]}}
{"id": "87f2ad1c-41a0-4f46-8b13-c405259ba200", "fitness": 0.06247700635924912, "name": "EnhancedHybridAdaptivePSOLevyV2", "description": "Introducing adaptive mutation strategies and dynamic subpopulation interaction to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_mutation(self, pos, lb, ub, intensity=0.05):\n        mutation_scale = intensity * (ub - lb)\n        mutation = np.random.normal(0, mutation_scale, pos.shape)\n        mutated_pos = np.clip(pos + mutation, lb, ub)\n        return mutated_pos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  \n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n\n            if np.random.rand() < 0.2:\n                mutated_positions = self.adaptive_mutation(self.global_best_position, lb, ub, intensity=0.1)\n                mutated_score = func(mutated_positions)\n                eval_count += 1\n                if mutated_score < self.global_best_score:\n                    self.global_best_score = mutated_score\n                    self.global_best_position = mutated_positions\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n\n                    if np.random.rand() < 0.2:\n                        random_subpop = np.random.randint(0, self.num_subpops)\n                        random_start = random_subpop * self.subpop_size\n                        random_end = random_start + self.subpop_size\n                        random_best_idx = np.argmin(self.personal_best_scores[random_start:random_end])\n                        random_best_position = self.personal_best_positions[random_start + random_best_idx]\n                        self.positions[start:end] = random_best_position\n            \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevyV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.062473621035303295, 0.06247335375710561, 0.06248404454537293, 0.062473620982991585, 0.062473353704756596, 0.06248404449303391, 0.06247362082760444, 0.06247335354940753, 0.06248404433766619]}}
{"id": "c4120e35-c08f-4618-b65b-4c5fe9e5f251", "fitness": 0.062477437392374296, "name": "EnhancedHybridAdaptivePSOLevyV2", "description": "Introduced dynamic adaptation of velocity coefficients and stochastic perturbations for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            dynamic_c1 = 1.5 + 0.5 * np.random.rand() * (1 - eval_count / self.budget)\n            dynamic_c2 = 2.5 - 0.5 * np.random.rand() * (eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = dynamic_c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = dynamic_c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevyV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.062475345862416765, 0.062472943341798426, 0.06248402323303104, 0.0624753458098789, 0.06247294328945063, 0.0624840231806878, 0.062475345654676606, 0.06247294313410301, 0.06248402302532552]}}
{"id": "54569d38-b583-4013-80c5-141e40b6ae73", "fitness": 0.06247478800860221, "name": "OptimizedAdaptivePSOLevy", "description": "Utilize adaptive learning rates and elite-guided exploration to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass OptimizedAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = np.random.uniform(0, 1, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n    \n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.positions[i])\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.positions[i])\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                elite_step = self.levy_flight(self.dim)\n                elite_position = self.global_best_position + elite_step\n                elite_position = np.clip(elite_position, lb, ub)\n                elite_score = func(elite_position)\n                eval_count += 1\n                if elite_score < self.global_best_score:\n                    self.global_best_score = elite_score\n                    self.global_best_position = elite_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm OptimizedAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06246537636011329, 0.06247441112009233, 0.06248457680568831, 0.062465376307686005, 0.06247441106772911, 0.06248457675333585, 0.06246537615242187, 0.06247441091239747, 0.0624845765979557]}}
{"id": "f8a9b646-1049-4fd8-b264-9455f5ec8444", "fitness": 0.06247747042975041, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced multi-population strategy with adaptive mutation rate and dynamic neighborhood adjustment for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        adaptive_mutation_rate = 0.1\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < adaptive_mutation_rate:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                adaptive_mutation_rate = 0.1 + 0.3 * np.random.rand()\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.062474514917781776, 0.062473662213404335, 0.06248423441813045, 0.062474514865475506, 0.062473662161042776, 0.06248423436575956, 0.06247451471007659, 0.06247366200569071, 0.06248423421039195]}}
{"id": "8ea22bb4-c55a-45a9-a35d-48260b6589b1", "fitness": 0.062477350622320404, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhance mutation strategy by increasing mutation probability for better exploration.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.20:  # Changed line to increase mutation probability\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247508878652941, 0.06247257481858126, 0.06248438852185856, 0.062475088734227024, 0.06247257476625767, 0.06248438846957127, 0.0624750885788401, 0.06247257461086442, 0.06248438831415393]}}
{"id": "cc37b80d-6e7d-4f50-8aa5-adbc8997e30a", "fitness": 0.06247394719194689, "name": "RefinedHybridAdaptivePSOLevy", "description": "Introduce adaptive mutation and dynamic neighborhood adjustment to enhance exploration and exploitation balance in metaheuristic search.", "code": "import numpy as np\n\nclass RefinedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_position = self.personal_best_positions[best_neighbor]\n                dynamic_mutation = 0.1 + 0.9 * (1 - eval_count / self.budget)\n                if np.random.rand() < dynamic_mutation:\n                    mutated_dim = np.random.randint(self.dim)\n                    mutation_step = np.random.uniform(-1, 1) * (ub[mutated_dim] - lb[mutated_dim])\n                    local_best_position[mutated_dim] += mutation_step\n                self.personal_best_positions[i] = local_best_position\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (self.personal_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm RefinedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.0624691396833964, 0.06246843578308203, 0.06248426636955584, 0.06246913963105327, 0.062468435730590244, 0.06248426631699555, 0.06246913947568611, 0.06246843557543391, 0.06248426616172864]}}
{"id": "81d6ccd4-d37f-4c5c-bb85-e7ef3a6fb0e6", "fitness": 0.062477350622320404, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced adaptability by increasing the mutation chance slightly to explore more.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.2:  # Changed line: increase mutation chance slightly\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247508878652941, 0.06247257481858126, 0.06248438852185856, 0.062475088734227024, 0.06247257476625767, 0.06248438846957127, 0.0624750885788401, 0.06247257461086442, 0.06248438831415393]}}
{"id": "743c42ca-849f-4430-99ec-a0d23aa22538", "fitness": 0.062477536797190446, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced a dynamic mutation factor and adaptive neighborhood size for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - (eval_count / self.budget) ** 0.5)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5 * (1 - eval_count / self.budget)  # Changed line\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.062475130744654384, 0.062473663857000705, 0.06248381604998998, 0.06247513069229593, 0.06247366380466557, 0.06248381599762476, 0.06247513053696119, 0.06247366364931384, 0.062483815842207635]}}
{"id": "3ac7ecfa-da02-4512-9b06-c513cc1a5054", "fitness": 0.06247632817998513, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Improved velocity update by adding adaptive inertia weight based on velocity variance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.std(self.velocities) / np.max(np.std(self.velocities)))  # Changed line\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.0624732198093233, 0.06247145372169749, 0.062484311268965476, 0.0624732197569956, 0.06247145366934137, 0.062484311216626454, 0.06247321960165331, 0.06247145351399597, 0.06248431106126717]}}
{"id": "61d60fe3-330f-41ee-bdda-5bf44bc9a141", "fitness": 0.062476673315127344, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introducing an adaptive inertia mechanism to enhance convergence speed and balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * ((eval_count / self.budget) ** 2)  # Changed line\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247539317430928, 0.062470272720671516, 0.062484354310563095, 0.06247539312198935, 0.06247027266815164, 0.06248435425819787, 0.062475392966604204, 0.0624702725128754, 0.062484354102783746]}}
{"id": "6cbf79d9-b9ea-414f-982d-35ca47b27554", "fitness": 0.062476133387993925, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced dynamic inertia weight adjustment based on local best score improvements to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget))) \n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            # Dynamic inertia weight adjustment based on local best improvement\n            improvement_factor = 1 - (self.global_best_score / (min(self.personal_best_scores) + 1e-10))\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget)) * improvement_factor\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247456768978721, 0.06247007271965832, 0.06248376001457212, 0.06247456763742776, 0.062470072667317744, 0.062483759962226215, 0.06247456748209512, 0.06247007251198966, 0.06248375980687115]}}
{"id": "60f73f2c-c8e0-496f-bbb9-52e07d9905b7", "fitness": 0.062476378610733505, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced adaptive learning rates and hyper-sphere distribution to enhance exploration and exploitation balance in particle movement.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_learning_rate(self, eval_count):\n        return self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n    def hypersphere_sampling(self, center, radius):\n        direction = np.random.normal(0, 1, self.dim)\n        unit_vector = direction / np.linalg.norm(direction)\n        return center + unit_vector * radius\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.adaptive_learning_rate(eval_count)\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = self.hypersphere_sampling(best_subpop_position, np.linalg.norm(ub - lb) * 0.1)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247419961730194, 0.0624705557225651, 0.0624843807523533, 0.062474199565002, 0.06247055567022286, 0.062484380699980746, 0.06247419940963339, 0.06247055551489389, 0.06248438054464833]}}
{"id": "12ad49c3-49e0-41ed-831b-778c7de6a7c9", "fitness": 0.06247725345363053, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Refined EnhancedHybridAdaptivePSOLevy with dynamically adjusted cognitive and social coefficients for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget))) \n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            # Refined coefficients adjustment\n            self.c1 = 1.5 + 1.0 * (eval_count / self.budget)\n            self.c2 = 2.5 - 1.0 * (eval_count / self.budget)\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.1:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247423012263065, 0.062473543809584586, 0.0624839866887823, 0.06247423007014108, 0.06247354375724934, 0.062483986636416966, 0.06247422991495544, 0.06247354360185653, 0.06248398648105791]}}
{"id": "7b3ff1c9-d3e6-479c-8533-23ba00819c45", "fitness": 0.062476692693186314, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduce dynamic leader selection and adaptive turbulence to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.2 + 0.1 * np.sin(np.pi * eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            if np.random.rand() < 0.2:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247443865586544, 0.062471401156032225, 0.062484238527781955, 0.06247443860332569, 0.062471401103688984, 0.0624842384754134, 0.06247443844815903, 0.06247140094835779, 0.06248423832005234]}}
{"id": "09f35df3-cb9d-40e5-8afc-4a65b9322f54", "fitness": 0.06247745283107405, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced adaptive neighborhood and dynamic levy flight balance for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.2:  # Increased probability\n                step = self.levy_flight(self.dim, beta=1.3)  # Adjusted beta\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247531524906158, 0.062472689792471, 0.062484353711833474, 0.06247531519655236, 0.062472689740183496, 0.06248435365929916, 0.062475315041382484, 0.06247268958479035, 0.06248435350409254]}}
{"id": "d512200f-f9bb-447b-accb-8e4944547472", "fitness": 0.06247750350488653, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Enhanced dynamic neighborhood adaptation and differential evolution mutation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(5, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = self.w_max - (self.w_max - self.w_min) * (np.sqrt(eval_count / self.budget))\n            \n            if np.random.rand() < 0.2:  # Increase the probability of mutation\n                f = 0.5 + np.random.rand() * 0.7\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:  # Increase the frequency of Levy flights\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.1:  # Increase interaction frequency\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.062474670082484085, 0.06247344754016049, 0.06248439315205623, 0.062474670030177815, 0.06247344748785533, 0.062484393099690116, 0.06247466987478223, 0.06247344733246207, 0.06248439294431041]}}
{"id": "97f27ce4-d73d-4646-bbc1-4f92bf169df7", "fitness": 0.06247676671590378, "name": "EnhancedHybridAdaptivePSOLevy", "description": "Introduced adaptive inertia weight adjustment and increased mutation diversity to refine exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(self.dim))\n        self.c1 = 1.5\n        self.c2 = 2.5\n        self.w_min = 0.3\n        self.w_max = 0.8\n        self.neighborhood_size = max(2, int(self.pop_size * 0.3))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        # Multi-population variables\n        self.num_subpops = 3\n        self.subpop_size = self.pop_size // self.num_subpops\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                \n            local_best_positions = np.copy(self.personal_best_positions)\n            for i in range(self.pop_size):\n                dynamic_neighborhood = max(3, int(self.pop_size * 0.3 * (1 - eval_count / self.budget)))  # Changed line\n                neighbors = np.random.choice(self.pop_size, dynamic_neighborhood, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: self.personal_best_scores[x])\n                local_best_positions[i] = self.personal_best_positions[best_neighbor]\n            \n            w = (self.w_max - self.w_min) * np.cos(eval_count / self.budget * np.pi) + self.w_min  # Changed line\n            \n            if np.random.rand() < 0.15:\n                f = 0.5 + np.random.rand() * 0.5\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                mutant_positions = self.positions[indices[0]] + f * (self.positions[indices[1]] - self.positions[indices[2]] +\n                                                                     self.positions[indices[3]] - self.positions[indices[4]])\n                mutant_positions = np.clip(mutant_positions, lb, ub)\n                mutant_score = func(mutant_positions)\n                eval_count += 1\n                if mutant_score < self.personal_best_scores[indices[0]]:\n                    self.personal_best_scores[indices[0]] = mutant_score\n                    self.personal_best_positions[indices[0]] = mutant_positions\n                if mutant_score < self.global_best_score:\n                    self.global_best_score = mutant_score\n                    self.global_best_position = mutant_positions\n\n            r1 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            r2 = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions - self.positions)\n            social_velocity = self.c2 * r2 * (local_best_positions - self.positions)\n            self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n            self.positions += self.velocities\n            \n            self.positions = np.clip(self.positions, lb, ub)\n            \n            if np.random.rand() < 0.15:  # Changed line\n                step = self.levy_flight(self.dim)\n                levy_positions = self.global_best_position + step\n                levy_positions = np.clip(levy_positions, lb, ub)\n                levy_score = func(levy_positions)\n                eval_count += 1\n                if levy_score < self.global_best_score:\n                    self.global_best_score = levy_score\n                    self.global_best_position = levy_positions\n            \n            # Occasional information exchange between subpopulations\n            if eval_count % (self.budget // 10) == 0:\n                for subpop in range(self.num_subpops):\n                    start = subpop * self.subpop_size\n                    end = start + self.subpop_size\n                    best_subpop_idx = np.argmin(self.personal_best_scores[start:end])\n                    best_subpop_position = self.personal_best_positions[start + best_subpop_idx]\n                    for i in range(self.pop_size):\n                        if np.random.rand() < 0.05:\n                            self.positions[i] = best_subpop_position\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedHybridAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["a475cd63-c45e-458d-8132-ca92114504d9"], "operator": null, "metadata": {"aucs": [0.06247564636379688, 0.06247028800679011, 0.06248436603717866, 0.06247564631149505, 0.062470287954467296, 0.06248436598470486, 0.0624756461561331, 0.06247028779912478, 0.06248436582944328]}}
