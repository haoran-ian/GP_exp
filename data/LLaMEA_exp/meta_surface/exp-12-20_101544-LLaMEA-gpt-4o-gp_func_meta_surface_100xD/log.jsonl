{"id": "2cafa20e-ca63-44cb-a943-02e61a157ac4", "fitness": 0.06246662127660105, "name": "HybridDEPSO", "description": "A hybrid metaheuristic algorithm combining Differential Evolution (DE) and Particle Swarm Optimization (PSO) for balanced exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # You can adjust this parameter\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.8   # Differential weight\n        self.inertia_weight = 0.5  # Inertia weight for PSO\n        self.cognitive = 1.5      # Cognitive coefficient for PSO\n        self.social = 1.5         # Social coefficient for PSO\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + self.F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.062481578577727626, 0.06245196943484799, 0.06246631607728603, 0.06248157852529479, 0.06245196938256092, 0.062466316024934465, 0.06248157836996926, 0.062451969227216186, 0.062466315869572187]}}
{"id": "4f55b173-63a9-4b65-a906-332a86d9dff0", "fitness": 0.062432542435266525, "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid metaheuristic algorithm integrating Differential Evolution (DE) and Particle Swarm Optimization (PSO) with adaptive parameters for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.8\n        self.inertia_weight = 0.5\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.adaptive_CR = self.CR\n        self.adaptive_F = self.F\n        self.adaptive_inertia_weight = self.inertia_weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.adaptive_CR = 0.9 - 0.5 * (evaluations / self.budget)\n            self.adaptive_F = 0.8 + 0.4 * (evaluations / self.budget)\n            self.adaptive_inertia_weight = 0.5 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                indices = np.arange(self.population_size)\n                np.random.shuffle(indices)\n                indices = indices[indices != i]\n                a, b, c = self.population[indices[:3]]\n                mutant_vector = a + self.adaptive_F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                crossover_mask = np.random.rand(self.dim) < self.adaptive_CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = self.adaptive_inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06243 with standard deviation 0.00005.", "error": "", "parent_ids": ["2cafa20e-ca63-44cb-a943-02e61a157ac4"], "operator": null, "metadata": {"aucs": [0.062368536650356354, 0.0624565706301502, 0.06247252028511807, 0.0623685365981449, 0.06245657057783338, 0.0624725202327886, 0.06236853644302409, 0.06245657042254915, 0.06247252007743398]}}
{"id": "87b0399b-b2a8-4f91-bb25-775e45492bd9", "fitness": 0.06247482444922784, "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid algorithm integrating Dynamic Inertia Weight PSO and Adaptive Differential Evolution to optimize exploration-exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive DE parameters\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4  # Dynamic PSO parameters\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Update inertia weight dynamically\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00002.", "error": "", "parent_ids": ["2cafa20e-ca63-44cb-a943-02e61a157ac4"], "operator": null, "metadata": {"aucs": [0.06248848389807671, 0.06245162628337153, 0.06248436342626762, 0.0624884838457177, 0.0624516262310747, 0.06248436337390173, 0.06248848369034188, 0.062451626075761935, 0.06248436321853679]}}
{"id": "5a87606a-7329-4cdb-a8a4-6c1863770706", "fitness": 0.0624848790174924, "name": "EnhancedHybridDEPSOWithOBL", "description": "Integrated Adaptive Opposition-Based Learning with Enhanced Hybrid DEPSO for improved exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithOBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive DE parameters\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4  # Dynamic PSO parameters\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population = self.opposition_based_learning(self.population, lb, ub)\n            for i in range(self.population_size):\n                opp_score = func(opp_population[i])\n                if opp_score < self.best_scores[i]:\n                    self.best_scores[i] = opp_score\n                    self.best_positions[i] = opp_population[i]\n                if opp_score < self.global_best_score:\n                    self.global_best_score = opp_score\n                    self.global_best_position = opp_population[i]\n\n            # Update inertia weight dynamically\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridDEPSOWithOBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["87b0399b-b2a8-4f91-bb25-775e45492bd9"], "operator": null, "metadata": {"aucs": [0.06249280721047623, 0.06247697229643101, 0.06248485780561164, 0.062492807158131325, 0.06247697224407123, 0.06248485775332868, 0.06249280700273896, 0.06247697208871983, 0.06248485759792266]}}
{"id": "cfa42391-053d-4905-a0ec-01cbed093735", "fitness": 0.06247672499080473, "name": "EnhancedHybridDEPSOWithOBLPlus", "description": "EnhancedHybridDEPSOWithOBLPlus implements adaptive scaling factors and multi-elitism to improve exploration, convergence, and global best diversity in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithOBLPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 0.95  # Updated adaptive DE parameters\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.1  # Extended dynamic PSO parameters\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = self.population[0]\n        self.global_best_score = func(self.global_best_position)\n        evaluations = 1\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population = self.opposition_based_learning(self.population, lb, ub)\n            for i in range(self.population_size):\n                opp_score = func(opp_population[i])\n                if opp_score < self.best_scores[i]:\n                    self.best_scores[i] = opp_score\n                    self.best_positions[i] = opp_population[i]\n                if opp_score < self.global_best_score:\n                    self.global_best_score = opp_score\n                    self.global_best_position = opp_population[i]\n\n            # Update inertia weight dynamically\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridDEPSOWithOBLPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["5a87606a-7329-4cdb-a8a4-6c1863770706"], "operator": null, "metadata": {"aucs": [0.062486654469430136, 0.06246479963158946, 0.06247872113163688, 0.06248665441706258, 0.06246479957907469, 0.062478721079111565, 0.06248665426168187, 0.062464799423714634, 0.06247872092394069]}}
{"id": "d438a4ad-8f0f-482c-8927-a71db8da208c", "fitness": 0.06248488836836589, "name": "EnhancedHybridDEPSOWithOBL", "description": "Introduced adaptive control for crossover rate (CR) in DE to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithOBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive DE parameters\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4  # Dynamic PSO parameters\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population = self.opposition_based_learning(self.population, lb, ub)\n            for i in range(self.population_size):\n                opp_score = func(opp_population[i])\n                if opp_score < self.best_scores[i]:\n                    self.best_scores[i] = opp_score\n                    self.best_positions[i] = opp_population[i]\n                if opp_score < self.global_best_score:\n                    self.global_best_score = opp_score\n                    self.global_best_position = opp_population[i]\n\n            # Update inertia weight dynamically\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Crossover with adaptive control\n                self.CR = 0.5 + 0.5 * (self.global_best_score / (self.global_best_score + 1e-10))\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridDEPSOWithOBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["5a87606a-7329-4cdb-a8a4-6c1863770706"], "operator": null, "metadata": {"aucs": [0.062492842082800815, 0.06247696469695696, 0.06248485858544395, 0.06249284203044447, 0.06247696464459718, 0.06248485853305541, 0.06249284187499349, 0.06247696448924578, 0.06248485837775497]}}
{"id": "77b2ec40-1662-4954-908b-66ec77a404a9", "fitness": 0.06245039311473994, "name": "RefinedHybridDEPSOWithChaoticInit", "description": "Introduced dynamic parameter adaptation and chaotic initialization to improve exploration and exploitation in DE and PSO hybrid.", "code": "import numpy as np\n\nclass RefinedHybridDEPSOWithChaoticInit:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive DE parameters\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4  # Dynamic PSO parameters\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def chaotic_initialization(self, lb, ub):\n        chaotic_seq = np.linspace(0.1, 0.9, self.population_size)\n        chaotic_seq = np.cos(2 * np.pi * chaotic_seq)\n        chaotic_seq = (chaotic_seq + 1) / 2  # Normalize to [0, 1]\n        return lb + chaotic_seq[:, np.newaxis] * (ub - lb)\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population = self.opposition_based_learning(self.population, lb, ub)\n            for i in range(self.population_size):\n                opp_score = func(opp_population[i])\n                if opp_score < self.best_scores[i]:\n                    self.best_scores[i] = opp_score\n                    self.best_positions[i] = opp_population[i]\n                if opp_score < self.global_best_score:\n                    self.global_best_score = opp_score\n                    self.global_best_position = opp_population[i]\n\n            # Update inertia weight dynamically\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Crossover with dynamic adaptation\n                self.CR = 0.5 + 0.5 * (self.global_best_score / (self.global_best_score + 1e-10))\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm RefinedHybridDEPSOWithChaoticInit got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06245 with standard deviation 0.00000.", "error": "", "parent_ids": ["d438a4ad-8f0f-482c-8927-a71db8da208c"], "operator": null, "metadata": {"aucs": [0.062450921015304584, 0.062448902290134, 0.06245135629871579, 0.0624509209629458, 0.06244890223782751, 0.06245135624641707, 0.06245092080762982, 0.06244890208257592, 0.06245135609110897]}}
{"id": "6988db70-b507-4a8e-9b2f-ec40d529ab93", "fitness": 0.062489724300509905, "name": "EnhancedHybridDEPSOWithDualPopulation", "description": "Introduce a dual-population strategy with adaptive scaling factors and inertia weights to enhance diversity and convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithDualPopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population1 = self.opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.opposition_based_learning(self.population2, lb, ub)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight1 * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight2 * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridDEPSOWithDualPopulation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["d438a4ad-8f0f-482c-8927-a71db8da208c"], "operator": null, "metadata": {"aucs": [0.06248110698930698, 0.06249341415671206, 0.062494652015634866, 0.0624811069369029, 0.062493414104341394, 0.06249465196332027, 0.0624811067815636, 0.06249341394890606, 0.062494651807901036]}}
{"id": "02c77b63-34de-4161-8ba1-a758bb5c60d6", "fitness": -Infinity, "name": "RefinedEnhancedHybridDEPSOWithDualPopulation", "description": "Introduce adaptive learning rates and elite reinitialization alongside dual-population strategy to further enhance exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridDEPSOWithDualPopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive_initial, self.social_initial = 1.5, 1.5\n        self.cognitive_final, self.social_final = 2.0, 2.0\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def elite_reinitialization(self, population, lb, ub, fraction=0.1):\n        num_individuals = int(fraction * len(population))\n        elite_indices = np.argsort([func(ind) for ind in population])[:num_individuals]\n        for idx in elite_indices:\n            population[idx] = np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            opp_population1 = self.opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.opposition_based_learning(self.population2, lb, ub)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            cognitive = self.cognitive_initial + (self.cognitive_final - self.cognitive_initial) * (evaluations / self.budget)\n            social = self.social_initial + (self.social_final - self.social_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight1 * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight2 * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            if evaluations % (self.budget // 10) == 0:\n                self.elite_reinitialization(self.population1, lb, ub)\n                self.elite_reinitialization(self.population2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["6988db70-b507-4a8e-9b2f-ec40d529ab93"], "operator": null, "metadata": {}}
{"id": "506b2575-08ff-4c8d-99b4-1b1cd2d48696", "fitness": 0.06248974356670098, "name": "EnhancedHybridDEPSOWithDualPopulation", "description": "Introduce a strategy to dynamically adjust the crossover rate for improved exploration in the dual-population scheme.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithDualPopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population1 = self.opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.opposition_based_learning(self.population2, lb, ub)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight1 * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight2 * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridDEPSOWithDualPopulation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["6988db70-b507-4a8e-9b2f-ec40d529ab93"], "operator": null, "metadata": {"aucs": [0.06248116507936685, 0.06249341386518148, 0.062494652015634866, 0.06248116502701573, 0.06249341381281093, 0.06249465196332027, 0.06248116487167599, 0.062493413657401686, 0.062494651807901036]}}
{"id": "2de609c3-afea-4bbe-afc4-060612157e3e", "fitness": -Infinity, "name": "EnhancedHybridDEPSOWithAdaptivePopulation", "description": "Introduce an adaptive inertia weight adjustment scheme and a variable population size strategy to enhance exploration and exploitation balance over the optimization process.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithAdaptivePopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        self.population1 = np.random.uniform(lb, ub, (population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (population_size, self.dim))\n        self.velocities1 = np.zeros((population_size, self.dim))\n        self.velocities2 = np.zeros((population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(population_size, np.inf)\n        self.best_scores2 = np.full(population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population1 = self.opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.opposition_based_learning(self.population2, lb, ub)\n            for i in range(population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Adaptive Inertia Weight and Population Size\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            population_size = self.initial_population_size - int((self.initial_population_size - 5) * (evaluations / self.budget))\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight1 * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight2 * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (361,45) (450,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (361,45) (450,45) ')", "parent_ids": ["506b2575-08ff-4c8d-99b4-1b1cd2d48696"], "operator": null, "metadata": {}}
{"id": "0d138d3e-40d8-4f4a-adb2-7fe72c7d3cbe", "fitness": 0.0624897455863808, "name": "EnhancedHybridDEPSOWithDualPopulation", "description": "Introduce a self-adaptive inertia weight strategy to enhance convergence speed while maintaining exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithDualPopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population1 = self.opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.opposition_based_learning(self.population2, lb, ub)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridDEPSOWithDualPopulation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["506b2575-08ff-4c8d-99b4-1b1cd2d48696"], "operator": null, "metadata": {"aucs": [0.06248117119485752, 0.06249341386518148, 0.06249465195919568, 0.0624811711424752, 0.06249341381281093, 0.062494651906876086, 0.06248117098716688, 0.062493413657401686, 0.06249465175146174]}}
{"id": "96446f09-bd5a-48b3-8dd9-2788ec21333e", "fitness": -Infinity, "name": "EnhancedHybridDEPSOWithAdaptiveMutation", "description": "Introduced adaptive dual-phase mutation strategy and enhanced selection mechanism to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithAdaptiveMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def mutate_and_select(self, population, best_positions, lb, ub, global_best_score):\n        for i in range(self.population_size):\n            F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = a + F * (b - c)\n            mutant_vector = np.clip(mutant_vector, lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.CR\n\n            if not np.any(crossover_mask):\n                crossover_mask[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover_mask, mutant_vector, population[i])\n            trial_score = func(trial_vector)\n\n            if trial_score < best_scores[i]:\n                best_scores[i] = trial_score\n                best_positions[i] = trial_vector\n\n            if trial_score < global_best_score:\n                global_best_score = trial_score\n                self.global_best_position = trial_vector\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            opp_population1 = self.opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.opposition_based_learning(self.population2, lb, ub)\n\n            self.mutate_and_select(opp_population1, self.best_positions1, lb, ub, self.global_best_score)\n            self.mutate_and_select(opp_population2, self.best_positions2, lb, ub, self.global_best_score)\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            evaluations += 2 * self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["0d138d3e-40d8-4f4a-adb2-7fe72c7d3cbe"], "operator": null, "metadata": {}}
{"id": "8effb493-c076-4aff-9686-551ec4222fd4", "fitness": 0.06248975300738841, "name": "EnhancedHybridDEPSOWithDualPopulation", "description": "Integrate adaptive learning rates and tournament selection, enhancing exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOWithDualPopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Opposition-Based Learning\n            opp_population1 = self.opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.opposition_based_learning(self.population2, lb, ub)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using tournament selection\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n                competitor_score = func(self.population1[np.random.randint(self.population_size)])\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i] and trial_score1 < competitor_score:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using tournament selection\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n                competitor_score = func(self.population2[np.random.randint(self.population_size)])\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i] and trial_score2 < competitor_score:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridDEPSOWithDualPopulation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["0d138d3e-40d8-4f4a-adb2-7fe72c7d3cbe"], "operator": null, "metadata": {"aucs": [0.06248119345787784, 0.06249341386518148, 0.06249465195919568, 0.062481193405500624, 0.06249341381281093, 0.062494651906876086, 0.06248119325018964, 0.062493413657401686, 0.06249465175146174]}}
{"id": "ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4", "fitness": 0.06248975870791947, "name": "RefinedHybridDEPSO", "description": "Introduce stochastic ranking and adaptive opposition-based learning to balance exploration-exploitation and improve convergence in dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["8effb493-c076-4aff-9686-551ec4222fd4"], "operator": null, "metadata": {"aucs": [0.06248120141264901, 0.06249341445867862, 0.06249466051250763, 0.06248120136031299, 0.06249341440633438, 0.062494660460135076, 0.06248120120495815, 0.06249341425095212, 0.06249466030474726]}}
{"id": "e875b16b-0547-460f-8605-352d4081e02f", "fitness": 0.06247037074189605, "name": "EnhancedHybridDEPSO", "description": "Introduce chaotic sequences and adaptive multi-leader strategy to enhance diversification and convergence in dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def chaotic_sequence(self, generation):\n        return 0.5 * (1 - np.cos(np.pi * generation / self.budget))\n\n    def adaptive_multi_leader(self, population, scores):\n        sorted_indices = np.argsort(scores)\n        top_indices = sorted_indices[:max(1, len(sorted_indices) // 5)]\n        leaders = population[top_indices]\n        return leaders[np.random.randint(len(leaders))]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            chaos_factor = self.chaotic_sequence(generation)\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update with adaptive multi-leader\n            leader1 = self.adaptive_multi_leader(self.population1, self.best_scores1)\n            leader2 = self.adaptive_multi_leader(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (leader1 - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1 * chaos_factor\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (leader2 - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2 * chaos_factor\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00002.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06244827379416085, 0.06246667306326159, 0.06249616562830551, 0.062448273741823046, 0.062466673010937224, 0.06249616557589721, 0.06244827358653271, 0.06246667285560392, 0.06249616542054237]}}
{"id": "0210dd9e-a4d8-4da5-964e-6ba555b0629f", "fitness": 0.06248975870791947, "name": "RefinedHybridDEPSO", "description": "Enhance the algorithm by adjusting the inertia weights to adapt more dynamically to the current state of convergence, improving convergence speed and solution quality.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically based on current best score\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (self.global_best_score / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (self.global_best_score / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06248120141264901, 0.06249341445867862, 0.06249466051250763, 0.06248120136031299, 0.06249341440633438, 0.062494660460135076, 0.06248120120495815, 0.06249341425095212, 0.06249466030474726]}}
{"id": "80928f90-578c-457a-b06f-edfc711bf685", "fitness": -Infinity, "name": "RefinedHybridDEPSO", "description": "Introduce dynamic population size reduction as budget decreases to enhance convergence in RefinedHybridDEPSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        self.velocities1 = np.zeros((self.initial_population_size, self.dim))\n        self.velocities2 = np.zeros((self.initial_population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.initial_population_size, np.inf)\n        self.best_scores2 = np.full(self.initial_population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.initial_population_size)\n            # Dynamic population size reduction\n            self.population_size = max(4, int(self.initial_population_size * (1 - evaluations / self.budget)))\n\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (360,45) (450,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (360,45) (450,45) ')", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {}}
{"id": "f2eca0ff-9df2-439a-a875-0cb6ec7622ad", "fitness": 0.062489696170206624, "name": "RefinedHybridDEPSO", "description": "Enhance convergence by introducing diversity preservation through crowding distance sorting in DE mutation strategy.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                distances = np.linalg.norm(self.population1[indices1] - self.population1[i], axis=1)\n                sorted_indices = np.argsort(distances)\n                b1, c1 = self.population1[indices1][sorted_indices[:2]]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.062481016043611226, 0.06249341445867862, 0.06249465826848044, 0.06248101599108791, 0.06249341440633438, 0.06249465821615319, 0.06248101583584165, 0.06249341425095212, 0.062494658060720076]}}
{"id": "0f3061b1-08fc-452c-bff4-1e84339e39c2", "fitness": 0.062489751892962145, "name": "RefinedHybridDEPSO", "description": "Incorporate elite learning and dynamic CR adjustment to enhance convergence and diversity in hybrid DE-PSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def elite_learning(self, best_positions, global_best, lb, ub):\n        elite = best_positions + 0.1 * (global_best - best_positions)\n        return np.clip(elite, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (1 - evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Elite Learning\n            elite_population1 = self.elite_learning(self.best_positions1, self.global_best_position, lb, ub)\n            elite_population2 = self.elite_learning(self.best_positions2, self.global_best_position, lb, ub)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.062481190114621166, 0.06249341386518148, 0.06249465195919568, 0.06248119006225894, 0.06249341381281093, 0.062494651906876086, 0.062481189906851586, 0.062493413657401686, 0.06249465175146174]}}
{"id": "5a46afe2-9c3b-41eb-99d7-1e31920cf65e", "fitness": -Infinity, "name": "EnhancedHybridDEPSO", "description": "Integrate Lvy Flight and Self-Adaptive Crossover strategies to enhance global exploration and convergence speed in dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def self_adaptive_crossover_rate(self, evaluations):\n        return 0.7 + 0.3 * (evaluations / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Lvy Flight for global exploration\n                L = self.levy_flight(self.dim)\n                mutant_vector1 = np.clip(self.population1[i] + L * (self.population1[i] - self.global_best_position), lb, ub)\n                mutant_vector2 = np.clip(self.population2[i] + L * (self.population2[i] - self.global_best_position), lb, ub)\n\n                # Self-Adaptive Crossover\n                CR = self.self_adaptive_crossover_rate(evaluations)\n                crossover_mask1 = np.random.rand(self.dim) < CR\n                crossover_mask2 = np.random.rand(self.dim) < CR\n\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score1 = func(trial_vector1)\n                trial_score2 = func(trial_vector2)\n                evaluations += 2\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            self.velocities1 = inertia_weight1 * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            self.velocities2 = inertia_weight2 * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {}}
{"id": "8fe14ea0-7d7a-4ea5-99ec-db2841cfc0ae", "fitness": 0.06248972049656175, "name": "RefinedHybridDEPSO", "description": "Introduce Levy Flight and adaptive learning to enhance exploration and balance in dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def levy_flight(self, position, best_position):\n        alpha = 0.01\n        step = np.random.standard_normal(self.dim) * np.abs(best_position - position)\n        levy_step = alpha * step / np.linalg.norm(step)\n        return position + levy_step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Levy Flight for random exploration\n                self.population1[i] = self.levy_flight(self.population1[i], self.global_best_position)\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.062481090128413075, 0.06249341386518148, 0.06249465775636298, 0.06248109007585645, 0.06249341381281093, 0.0624946577038491, 0.0624810899205509, 0.062493413657401686, 0.06249465754862915]}}
{"id": "4d759b64-c4d8-45cd-8c7c-af188a7c17f3", "fitness": 0.06246371508742435, "name": "EnhancedDEPSO", "description": "Integrate chaotic maps and Lvy flight into dual-population DE-PSO with adaptive velocity to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def chaotic_map(self, size):\n        chaotic_sequence = np.random.rand(size)\n        for i in range(1, size):\n            chaotic_sequence[i] = 4 * chaotic_sequence[i - 1] * (1 - chaotic_sequence[i - 1])\n        return chaotic_sequence\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        # Initialize chaotic sequence for dynamic parameters\n        chaotic_sequence = self.chaotic_map(self.budget)\n        \n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            \n            # Adaptive velocity update with chaotic map\n            inertia_weight1 = self.inertia_weight_min + (chaotic_sequence[evaluations % self.budget] *\n                                                         (self.inertia_weight_max - self.inertia_weight_min))\n            inertia_weight2 = self.inertia_weight_min + ((1 - chaotic_sequence[evaluations % self.budget]) *\n                                                         (self.inertia_weight_max - self.inertia_weight_min))\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1) + self.levy_flight(self.dim)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2) + self.levy_flight(self.dim)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight1 * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight2 * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06246 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.062450819526642, 0.0624818327404133, 0.06245849325559705, 0.06245081947416975, 0.06248183268785179, 0.0624584932030664, 0.06245081931886021, 0.06248183253249728, 0.06245849304772133]}}
{"id": "8528c3f6-8a6a-4a19-9d36-117c17e36e97", "fitness": 0.06248975870791947, "name": "RefinedHybridDEPSO", "description": "Refine inertia weight update to enhance exploration-exploitation balance and convergence speed in dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            # Slight refinement to the formula for better balance\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * ((1 - evaluations / self.budget) ** 2)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * ((1 - evaluations / self.budget) ** 2)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06248120141264901, 0.06249341445867862, 0.06249466051250763, 0.06248120136031299, 0.06249341440633438, 0.062494660460135076, 0.06248120120495815, 0.06249341425095212, 0.06249466030474726]}}
{"id": "71d4ec8a-b105-43a7-9e24-bfa8b7865eba", "fitness": 0.062489755125251394, "name": "RefinedHybridDEPSO", "description": "Introduce dynamic adjustment of the social coefficient to enhance convergence adaptability in the RefinedHybridDEPSO algorithm.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        # Change 1: Adjust social coefficient dynamically\n        self.social_max, self.social_min = 2.0, 0.5\n        self.social = self.social_max\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Change 2: Update social coefficient dynamically\n            self.social = self.social_min + (self.social_max - self.social_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06248119066465352, 0.06249341445867862, 0.06249466051250763, 0.06248119061229129, 0.06249341440633438, 0.062494660460135076, 0.062481190456962654, 0.06249341425095212, 0.06249466030474726]}}
{"id": "3aa78c8c-d841-43ec-b17c-204f73c90d64", "fitness": 0.06248972769669815, "name": "EnhancedRefinedHybridDEPSO", "description": "Enhance convergence by integrating chaotic maps for parameter tuning and introducing a diversity preservation strategy using centroid-based learning in the dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass EnhancedRefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def chaotic_map(self, k):\n        return 4 * k * (1 - k)\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def centroid_based_learning(self, population):\n        centroid = np.mean(population, axis=0)\n        diversity_preserving_population = population + np.random.uniform(-0.1, 0.1, population.shape) * (centroid - population)\n        return np.clip(diversity_preserving_population, *population.shape)\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n        chaotic_seq = np.random.rand(self.budget)\n        \n        for i in range(1, len(chaotic_seq)):\n            chaotic_seq[i] = self.chaotic_map(chaotic_seq[i-1])\n        \n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            \n            # Diversity preservation through centroid-based learning\n            self.population1 = self.centroid_based_learning(self.population1)\n            self.population2 = self.centroid_based_learning(self.population2)\n            \n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically using chaotic sequence\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * chaotic_seq[evaluations]\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * chaotic_seq[evaluations]\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * chaotic_seq[evaluations]\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1 using chaotic sequence\n                self.CR = 0.7 + 0.3 * chaotic_seq[evaluations]\n\n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * chaotic_seq[evaluations]\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedRefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.062481117525902796, 0.06249341386518148, 0.06249465195919568, 0.06248111747331986, 0.06249341381281093, 0.062494651906876086, 0.062481117318133106, 0.062493413657401686, 0.06249465175146174]}}
{"id": "adc99f97-5041-4708-81bc-c968096b93fa", "fitness": 0.06246006883043425, "name": "QuantumChaosDEPSO", "description": "Enhance exploration-exploitation by incorporating quantum-inspired adaptive walks and chaotic local search in dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass QuantumChaosDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def chaotic_map(self, size):\n        x = np.random.rand(size)\n        return 4 * x * (1 - x)\n\n    def quantum_walk(self, position, lb, ub):\n        step_size = np.random.normal(0, 0.1, size=position.shape)\n        new_position = position + step_size\n        return np.clip(new_position, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Quantum-inspired mutation\n                mutant_vector1 = self.quantum_walk(self.population1[i], lb, ub)\n                mutant_vector2 = self.quantum_walk(self.population2[i], lb, ub)\n\n                # Chaotic local search\n                chaos1 = self.chaotic_map(self.dim)\n                chaos2 = self.chaotic_map(self.dim)\n                trial_vector1 = np.clip(mutant_vector1 + chaos1, lb, ub)\n                trial_vector2 = np.clip(mutant_vector2 + chaos2, lb, ub)\n\n                # Evaluate both populations\n                trial_score1 = func(trial_vector1)\n                trial_score2 = func(trial_vector2)\n                evaluations += 2\n\n                # Update best positions and scores\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                # Update global best position\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Update inertia weight and velocity for PSO update\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm QuantumChaosDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06246 with standard deviation 0.00004.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06249443809664179, 0.062409215131376206, 0.062476553523376666, 0.062494438044126355, 0.0624092150790313, 0.062476553471068175, 0.06249443788874631, 0.06240921492384832, 0.06247655331569313]}}
{"id": "0dea4fa0-4083-47e6-a27d-2eb7a68f469b", "fitness": -Infinity, "name": "RefinedHybridDEPSO", "description": "Enhance the RefinedHybridDEPSO algorithm by incorporating adaptive inertia weight adjustment and swarm intelligence crossover to better explore search space and converge more effectively within budget constraints.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # New Swarm Intelligence Crossover\n                trial_vector1 = self.swarm_crossover(trial_vector1, mutant_vector1, self.population1, i)\n                \n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # New Swarm Intelligence Crossover\n                trial_vector2 = self.swarm_crossover(trial_vector2, mutant_vector2, self.population2, i)\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score\n\n    def swarm_crossover(self, trial_vector, mutant_vector, population, i):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, mutant_vector, population[i])", "configspace": "", "generation": 27, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'trial_vector1' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'trial_vector1' referenced before assignment\")", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {}}
{"id": "0cb79b32-c039-4b07-acec-4f128a58157f", "fitness": 0.06248973538920169, "name": "RefinedHybridDEPSO", "description": "Integrate non-uniform mutation and dynamic parameter adjustment to enhance exploration and exploitation balance in hybrid DE-PSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.mutation_factor = 0.5 # Line changed for dynamic mutation factor\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                # Non-uniform mutation adjustment\n                F1 *= self.mutation_factor * (1 - evaluations / self.budget) # Line changed for non-uniform mutation\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                F2 *= self.mutation_factor * (1 - evaluations / self.budget) # Line changed for non-uniform mutation\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.062481140603314445, 0.06249341386518148, 0.06249465195919568, 0.06248114055095111, 0.06249341381281093, 0.062494651906876086, 0.062481140395622026, 0.062493413657401686, 0.06249465175146174]}}
{"id": "307e00e2-f884-4fcf-95ee-c4780f1d1fdf", "fitness": 0.06248975253563178, "name": "RefinedHybridDEPSO", "description": "Enhance convergence by refining DE mutation strategy with temporal scaling of F in RefinedHybridDEPSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06248119204259439, 0.06249341386518148, 0.06249465195919568, 0.062481191990260254, 0.06249341381281093, 0.062494651906876086, 0.06248119183490375, 0.062493413657401686, 0.06249465175146174]}}
{"id": "95174e23-d73b-4ed9-b876-774e4c35092b", "fitness": 0.06248973075923462, "name": "RefinedHybridDEPSO", "description": "Integrate an adaptive factor into the crossover rate to enhance exploration and exploitation balance adaptively. ", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (1 - (self.global_best_score / np.max(self.best_scores1)))  # Changed line\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06248112671349837, 0.06249341386518148, 0.06249465195919568, 0.06248112666103611, 0.06249341381281093, 0.062494651906876086, 0.06248112650564952, 0.062493413657401686, 0.06249465175146174]}}
{"id": "d8c1b2ff-e928-40c5-81de-57bde7179081", "fitness": -Infinity, "name": "EnhancedHybridDEPSO", "description": "Incorporate dynamic diversity control and multi-point adaptive mutation strategy to enhance exploration-exploitation balance and convergence speed in dual-population hybrid DE-PSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def dynamic_diversity_control(self, population, lb, ub, evaluations):\n        diversity_threshold = np.linalg.norm(ub - lb) * 0.1 * (1 - evaluations / self.budget)\n        for i in range(self.population_size):\n            if np.linalg.norm(population[i] - self.global_best_position) < diversity_threshold:\n                population[i] = np.random.uniform(lb, ub, self.dim)\n        return population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            self.population1 = self.dynamic_diversity_control(self.population1, lb, ub, evaluations)\n            self.population2 = self.dynamic_diversity_control(self.population2, lb, ub, evaluations)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Multi-point Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Multi-point Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'float' and 'NoneType'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'float' and 'NoneType'\")", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {}}
{"id": "3efeb5ce-755e-4357-9223-c4029d2d7ec8", "fitness": 0.06248973717602457, "name": "RefinedHybridDEPSO", "description": "Enhance diversity and convergence by introducing a dynamic population size and probabilistic mutation rate based on generation count.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            \n            # Dynamically adjust population size\n            dynamic_population_size = int(self.population_size * (1.0 - generation/self.budget))\n            \n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1[:dynamic_population_size], lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2[:dynamic_population_size], lb, ub, generation)\n            for i in range(dynamic_population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(dynamic_population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Probabilistic Crossover Rate for exploration\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Changed to introduce variability\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06248114596380627, 0.06249341386518148, 0.06249465195919568, 0.062481145911443825, 0.06249341381281093, 0.062494651906876086, 0.062481145756043466, 0.062493413657401686, 0.06249465175146174]}}
{"id": "3d3746b8-dd10-4a2a-af7a-74c38c09f2e8", "fitness": 0.06248975357405216, "name": "EnhancedHybridDEPSO", "description": "Enhance dual-population hybrid DE-PSO by introducing a dynamic search area reduction mechanism to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def dynamic_search_area_reduction(self, population, lb, ub, evaluations):\n        reduction_factor = 1 - evaluations / self.budget\n        center = (ub + lb) / 2\n        reduced_lb = center - reduction_factor * (center - lb)\n        reduced_ub = center + reduction_factor * (ub - center)\n        return np.clip(population, reduced_lb, reduced_ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.7 + 0.3 * (evaluations / self.budget)\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Dynamic Search Area Reduction for enhanced convergence\n            self.population1 = self.dynamic_search_area_reduction(self.population1, lb, ub, evaluations)\n            self.population2 = self.dynamic_search_area_reduction(self.population2, lb, ub, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.06248118601106456, 0.06249341445867862, 0.06249466051250763, 0.062481185958702334, 0.06249341440633438, 0.062494660460135076, 0.062481185803347494, 0.06249341425095212, 0.06249466030474726]}}
{"id": "5be4a34d-aae8-4b83-9b9a-d788db729e69", "fitness": 0.06248976205656084, "name": "RefinedHybridDEPSO", "description": "Enhance convergence by slightly increasing the crossover rate's adaptability over the budget.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            # Adaptive Opposition-Based Learning\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            # Update inertia weight dynamically\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation for population 1\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                # Dynamically updating Crossover Rate for population 1\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)  # Adjusted crossover rate to enhance adaptability\n                \n                # Crossover for population 1\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                # Selection for population 1 using stochastic ranking\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                # Adaptive Differential Evolution Mutation for population 2\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                # Crossover for population 2\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                # Selection for population 2 using stochastic ranking\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            # Stochastic ranking for maintaining diversity in the populations\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecf1ec7d-052c-41ab-a5b6-66bb7a24f9b4"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465400519838, 0.06248121791344541, 0.06249341440633438, 0.06249465395287879, 0.06248121775809323, 0.06249341425095212, 0.06249465379743824]}}
{"id": "ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920", "fitness": 0.062489762624609084, "name": "AdaptiveMemoryHybridDEPSO", "description": "Improve exploration and exploitation balance by introducing an adaptive memory mechanism for parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["5be4a34d-aae8-4b83-9b9a-d788db729e69"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.062494655709343205, 0.06248121791344541, 0.06249341440633438, 0.06249465565702339, 0.06248121775809323, 0.06249341425095212, 0.06249465550158306]}}
{"id": "27cd6c35-66c5-484f-aa7a-197f75c9f5f3", "fitness": 0.06248888344506233, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance exploration and exploitation by integrating a dynamic search space shrinkage mechanism and adaptive crossover rates.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 0.8\n        self.inertia_weight_max, self.inertia_weight_min = 0.8, 0.3\n        self.cognitive = 1.7\n        self.social = 1.7\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        shrink_factor = 1 - (generation / self.budget)\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * shrink_factor\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // self.population_size\n            opp_population = self.adaptive_opposition_based_learning(self.population, lb, ub, generation)\n\n            for i in range(self.population_size):\n                opp_score = func(opp_population[i])\n                if opp_score < self.best_scores[i]:\n                    self.best_scores[i] = opp_score\n                    self.best_positions[i] = opp_population[i]\n                if opp_score < self.global_best_score:\n                    self.global_best_score = opp_score\n                    self.global_best_position = opp_population[i]\n\n            inertia_weight = (self.inertia_weight_max - self.inertia_weight_min) * (1 - evaluations / self.budget) + self.inertia_weight_min\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.CR = 0.8 + 0.1 * np.random.rand()\n\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            self.population, self.best_scores = self.stochastic_ranking(self.population, self.best_scores)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00000.", "error": "", "parent_ids": ["ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920"], "operator": null, "metadata": {"aucs": [0.0624852710937458, 0.062490926107800604, 0.062490453393903134, 0.062485271041217816, 0.062490926055498996, 0.06249045334136505, 0.062485270886029176, 0.06249092590007099, 0.062490453185929384]}}
{"id": "6310be44-8f09-44f8-8ffc-08e19eb1ae1f", "fitness": 0.062489762624609084, "name": "EnhancedMemoryHybridDEPSO", "description": "Enhance exploration and exploitation by integrating a diversity-based adaptive mechanism and dynamic parameter tuning within a hybrid DE and PSO framework.", "code": "import numpy as np\n\nclass EnhancedMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        diversity_factor = np.std(population, axis=0)\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget * diversity_factor\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.062494655709343205, 0.06248121791344541, 0.06249341440633438, 0.06249465565702339, 0.06248121775809323, 0.06249341425095212, 0.06249465550158306]}}
{"id": "f5fc6c1e-d67e-46b8-9209-5c770769b500", "fitness": 0.06248976117672162, "name": "AdaptiveMemoryHybridDEPSO", "description": "Introducing a dynamic control factor in crossover probability to enhance exploration and balance convergence.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (np.sin(evaluations / self.budget * np.pi))  # Dynamic CR adjustment\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341386518148, 0.06249465195919568, 0.06248121791344541, 0.06249341381281093, 0.062494651906876086, 0.06248121775809323, 0.062493413657401686, 0.06249465175146174]}}
{"id": "945b1c67-9aa4-45ec-9005-25e49c905b9c", "fitness": 0.06248976146290556, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance memory diversity and adaptiveness by introducing varying memory influence.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.05 + 0.05 * (1 - evaluations/self.budget):  # Adjust influence based on progress\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.062493414709776984, 0.06249465197313964, 0.06248121791344541, 0.06249341465740654, 0.062494651920829924, 0.06248121775809323, 0.06249341450202417, 0.062494651765405806]}}
{"id": "b7071c2a-57c2-4638-8628-fcc33783ddc4", "fitness": 0.062474200447322895, "name": "EnhancedMemoryAdaptiveDEPSO", "description": "Enhance convergence speed by integrating adaptive differential mutation scaling and enhanced memory-based exploration strategies.", "code": "import numpy as np\n\nclass EnhancedMemoryAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.min_CR, self.max_CR = 0.7, 0.9\n        self.min_F, self.max_F = 0.4, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 2.0\n        self.social = 2.0\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_differential_mutation(self, population, lb, ub, i):\n        F = self.min_F + (self.max_F - self.min_F) * (1 - (i / self.budget) ** 2)\n        indices = [idx for idx in range(self.population_size) if idx != i]\n        a, b, c = population[np.random.choice(indices, 3, replace=False)]\n        mutant_vector = np.clip(a + F * (b - c), lb, ub)\n        return mutant_vector\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant_vector1 = self.adaptive_differential_mutation(self.population1, lb, ub, evaluations)\n                mutant_vector2 = self.adaptive_differential_mutation(self.population2, lb, ub, evaluations)\n\n                CR = self.min_CR + (self.max_CR - self.min_CR) * (evaluations / self.budget)\n                crossover_mask1 = np.random.rand(self.dim) < CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                crossover_mask2 = np.random.rand(self.dim) < CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (inertia_weight1) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (inertia_weight2) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedMemoryAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920"], "operator": null, "metadata": {"aucs": [0.06248473359427953, 0.062484623131265016, 0.0624532448764904, 0.062484733541919524, 0.06248462307890057, 0.06245324482414594, 0.06248473338652971, 0.06248462292353063, 0.06245324466884472]}}
{"id": "b32d2880-26e5-4339-9a05-82c292ecb87b", "fitness": 0.062489762624609084, "name": "RefinedMemoryHybridDEPSO", "description": "Enhance exploration and exploitation balance by incorporating a dynamic memory update mechanism and adaptive parameter control.", "code": "import numpy as np\n\nclass RefinedMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.global_best_position_memory = None  # Store best found position across iterations\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n            if self.global_best_position_memory is None or self.global_best_score < func(self.global_best_position_memory):\n                self.global_best_position_memory = self.global_best_position\n\n        return self.global_best_position_memory, self.global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm RefinedMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.062494655709343205, 0.06248121791344541, 0.06249341440633438, 0.06249465565702339, 0.06248121775809323, 0.06249341425095212, 0.06249465550158306]}}
{"id": "3a728450-ab8d-4c72-96d5-f4d033b2435e", "fitness": 0.06248976263024248, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance convergence efficiency by refining trial vector generation and adaptive opposition mechanism.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["ecbacffc-e1a6-4f2d-9fd2-ebdf8d295920"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341447559531, 0.062494655709343205, 0.06248121791344541, 0.062493414423201665, 0.06249465565702339, 0.06248121775809323, 0.0624934142678687, 0.06249465550158306]}}
{"id": "124dee5d-0d2c-42cd-9cbc-7fc6c161ac25", "fitness": 0.06248976263024248, "name": "AdaptiveMemoryHybridDEPSO", "description": "Introduce dynamic memory size adjustment based on optimization progress to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        self.memory_size = max(5, min(10, int(self.budget / 1000)))  # Adjust memory size dynamically\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["3a728450-ab8d-4c72-96d5-f4d033b2435e"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341447559531, 0.062494655709343205, 0.06248121791344541, 0.062493414423201665, 0.06249465565702339, 0.06248121775809323, 0.0624934142678687, 0.06249465550158306]}}
{"id": "fda30123-d1ca-450c-870d-b4e8c945b6d2", "fitness": 0.06248976293954289, "name": "AdaptiveMemoryHybridDEPSO", "description": "Improve exploration by introducing dynamic crossover probability and mutation scaling adjustments.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)  # Adjusted change rate\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["3a728450-ab8d-4c72-96d5-f4d033b2435e"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465665414111, 0.06248121791344541, 0.06249341440633438, 0.06249465660180553, 0.06248121775809323, 0.06249341425095212, 0.06249465644640728]}}
{"id": "7a08bd18-519e-4711-acc1-2b83afb514bf", "fitness": 0.06248976293954289, "name": "ImprovedAdaptiveMemoryHybridDEPSO", "description": "Enhance exploration and convergence through adaptive learning rates and memory-based diversity mechanisms.", "code": "import numpy as np\n\nclass ImprovedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)  # Adjusted change rate\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm ImprovedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["fda30123-d1ca-450c-870d-b4e8c945b6d2"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465665414111, 0.06248121791344541, 0.06249341440633438, 0.06249465660180553, 0.06248121775809323, 0.06249341425095212, 0.06249465644640728]}}
{"id": "3605a81a-8992-419b-ae43-b55d25f84169", "fitness": 0.062472099559932555, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance global exploration and convergence speed by integrating adaptive inertia weights and a self-adaptive mutation mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, generation):\n        lb, ub = self.bounds\n        exploration_factor = np.exp(-generation / (0.1 * self.budget))\n        opp_population = lb + ub - population + exploration_factor * np.random.uniform(-1, 1, population.shape)\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        lb, ub = self.bounds\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00002.", "error": "", "parent_ids": ["fda30123-d1ca-450c-870d-b4e8c945b6d2"], "operator": null, "metadata": {"aucs": [0.062490340676237266, 0.06248515175311997, 0.06244080651062722, 0.06249034062364767, 0.062485151700783836, 0.062440806458278764, 0.06249034046827906, 0.06248515154542289, 0.06244080630299631]}}
{"id": "442024ba-88db-43b5-80b3-d097cfd9a767", "fitness": 0.062489763626059874, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance algorithm convergence by tweaking the memory exploitation strategy in the velocity update phase.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)  # Adjusted change rate\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.15:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["fda30123-d1ca-450c-870d-b4e8c945b6d2"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465871383675, 0.06248121791344541, 0.06249341440633438, 0.06249465866128412, 0.06248121775809323, 0.06249341425095212, 0.06249465850588587]}}
{"id": "c2b70a8f-2557-41d1-a8c9-21a00d78353e", "fitness": 0.06248976308750925, "name": "RefinedAdaptiveMemoryHybridDEPSO", "description": "Introduce a dynamic memory allocation strategy and adaptive inertia control to further enhance convergence speed and solution quality in AdaptiveMemoryHybridDEPSO.", "code": "import numpy as np\n\nclass RefinedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = max(5, dim // 2)  # Dynamic memory allocation\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)  # Adjusted change rate\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            adaptive_inertia1 = 0.01 * (self.global_best_score / (1 + np.min(self.best_scores1)))\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1 + adaptive_inertia1 * (self.global_best_position - self.population1)\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            adaptive_inertia2 = 0.01 * (self.global_best_score / (1 + np.min(self.best_scores2)))\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2 + adaptive_inertia2 * (self.global_best_position - self.population2)\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.15:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm RefinedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["442024ba-88db-43b5-80b3-d097cfd9a767"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465709804014, 0.06248121791344541, 0.06249341440633438, 0.06249465704570467, 0.06248121775809323, 0.06249341425095212, 0.06249465689030631]}}
{"id": "b97d7488-409d-4ee0-8165-b71dfecb7c37", "fitness": -Infinity, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Integrate an entropy-based diversity measure to dynamically adjust exploration and exploitation balance in AdaptiveMemoryHybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def entropy_based_diversity(self, population):\n        hist, _ = np.histogramdd(population, bins=10)\n        prob = hist / np.sum(hist)\n        prob = prob[prob > 0]\n        return -np.sum(prob * np.log(prob))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            diversity1 = self.entropy_based_diversity(self.population1)\n            diversity2 = self.entropy_based_diversity(self.population2)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + diversity1 * (cognitive_component1 + social_component1)\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + diversity2 * (cognitive_component2 + social_component2)\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.15:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "An exception occurred: ValueError('maximum supported dimension for an ndarray is 32, found 45').", "error": "ValueError('maximum supported dimension for an ndarray is 32, found 45')", "parent_ids": ["442024ba-88db-43b5-80b3-d097cfd9a767"], "operator": null, "metadata": {}}
{"id": "69df5792-3293-46f0-9e5f-b1d1bd0f7eda", "fitness": 0.06248976293954289, "name": "EnhancedAdaptiveMemoryDEPSO", "description": "Improve convergence by dynamically adjusting mutation strategies and increasing exploration using adaptive memory with chaotic maps.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        chaos_factor = 0.7 * np.sin(generation / self.budget * np.pi)\n        opp_population = lb + ub - population + chaos_factor * np.random.uniform(-1, 1, population.shape)\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)  # Adjusted change rate\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with memory\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveMemoryDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["442024ba-88db-43b5-80b3-d097cfd9a767"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465665414111, 0.06248121791344541, 0.06249341440633438, 0.06249465660180553, 0.06248121775809323, 0.06249341425095212, 0.06249465644640728]}}
{"id": "02a790d1-b9bd-43cc-8e39-bbd3fd1adccb", "fitness": 0.06248420417411939, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Introduce a hybrid exploration-exploitation mechanism using adaptive weights and an elite archive to balance diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 * dim\n        self.CR = 0.8\n        self.F_min, self.F_max = 0.4, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.elite_size = max(1, self.population_size // 10)\n        self.elite_archive = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.35):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_elite_archive(self, position, score):\n        if len(self.elite_archive) < self.elite_size:\n            self.elite_archive.append((position, score))\n        else:\n            worst_idx = max(range(len(self.elite_archive)), key=lambda x: self.elite_archive[x][1])\n            if score < self.elite_archive[worst_idx][1]:\n                self.elite_archive[worst_idx] = (position, score)\n        self.elite_archive.sort(key=lambda x: x[1])\n\n    def select_from_elite(self):\n        if self.elite_archive:\n            idx = np.random.randint(0, len(self.elite_archive))\n            return self.elite_archive[idx][0]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_elite_archive(self.global_best_position, self.global_best_score)\n\n            elite_position = self.select_from_elite()\n            if elite_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(elite_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(elite_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["442024ba-88db-43b5-80b3-d097cfd9a767"], "operator": null, "metadata": {"aucs": [0.062484226718966585, 0.06247214197497586, 0.06249624408851817, 0.062484226666650766, 0.06247214192261974, 0.062496244036129744, 0.062484226511259955, 0.06247214176727056, 0.06249624388068309]}}
{"id": "a47b3f92-f2d5-49bb-8fe8-ebe1ab320a3c", "fitness": 0.06248976293954289, "name": "EnhancedMemoryDynamicDEPSO", "description": "Integrate dynamic population resizing and enhanced memory influence to boost convergence and exploration in optimization.", "code": "import numpy as np\n\nclass EnhancedMemoryDynamicDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def dynamic_population_size(self, evaluations):\n        max_size = self.initial_population_size\n        min_size = self.dim\n        size_range = max_size - min_size\n        return int(min_size + size_range * (1 - evaluations / self.budget))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evaluations = 0\n\n        population_size = self.initial_population_size\n        self.population1 = np.random.uniform(lb, ub, (population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (population_size, self.dim))\n        self.velocities1 = np.zeros((population_size, self.dim))\n        self.velocities2 = np.zeros((population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(population_size, np.inf)\n        self.best_scores2 = np.full(population_size, np.inf)\n\n        while evaluations < self.budget:\n            population_size = self.dynamic_population_size(evaluations)\n            self.population1 = self.population1[:population_size]\n            self.population2 = self.population2[:population_size]\n            self.velocities1 = self.velocities1[:population_size]\n            self.velocities2 = self.velocities2[:population_size]\n            self.best_positions1 = self.best_positions1[:population_size]\n            self.best_positions2 = self.best_positions2[:population_size]\n            self.best_scores1 = self.best_scores1[:population_size]\n            self.best_scores2 = self.best_scores2[:population_size]\n\n            generation = evaluations // (2 * population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n\n            for i in range(population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedMemoryDynamicDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["442024ba-88db-43b5-80b3-d097cfd9a767"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465665414111, 0.06248121791344541, 0.06249341440633438, 0.06249465660180553, 0.06248121775809323, 0.06249341425095212, 0.06249465644640728]}}
{"id": "3994733f-4568-4ec1-bf84-ae138e05fa08", "fitness": 0.06248972388591862, "name": "AdaptiveMemoryHybridDEPSO", "description": "Incorporate a dynamic parameter adaptation strategy to improve convergence by adjusting memory utilization rate and crossover rate based on current performance metrics.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 5\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.argmin(self.memory_scores)]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                dynamic_CR = 0.8 + 0.2 * (1 - (self.global_best_score / np.mean(self.best_scores1)))  # Dynamic crossover rate\n\n                crossover_mask1 = np.random.rand(self.dim) < dynamic_CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < dynamic_CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            # Update memory with current global best position\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            # Encourage exploration with dynamic memory utilization rate\n            memory_utilization_rate = 0.1 + 0.1 * (1 - (self.global_best_score / np.mean(self.best_scores1)))\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < memory_utilization_rate:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["442024ba-88db-43b5-80b3-d097cfd9a767"], "operator": null, "metadata": {"aucs": [0.062481105881524446, 0.06249341407718667, 0.06249465195919568, 0.06248110582907107, 0.06249341402481612, 0.062494651906876086, 0.06248110567375509, 0.062493413869380676, 0.06249465175146174]}}
{"id": "7b442f07-95c3-49dc-9407-e4a447c02974", "fitness": 0.062489763699253235, "name": "AdaptiveMemoryHybridDEPSO", "description": "Refine the memory utilization and introduce diversity-increasing strategies to enhance exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["442024ba-88db-43b5-80b3-d097cfd9a767"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465893341566, 0.06248121791344541, 0.06249341440633438, 0.062494658880864806, 0.06248121775809323, 0.06249341425095212, 0.062494658725466556]}}
{"id": "969f5b86-13e8-4d7e-993d-6e44967869e5", "fitness": 0.06248976342862933, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance dynamic population management and adaptive parameter tuning to improve convergence speed and precision.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.05 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.5):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def dynamic_population(self, generation):\n        if generation % 10 == 0:\n            return max(1, self.population_size - generation // 10)\n        return self.population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            current_population_size = self.dynamic_population(generation)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1[:current_population_size], lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2[:current_population_size], lb, ub, generation)\n            for i in range(current_population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(current_population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(current_population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(current_population_size, self.dim), np.random.rand(current_population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1[:current_population_size] - self.population1[:current_population_size])\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1[:current_population_size])\n            self.velocities1[:current_population_size] = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1[:current_population_size] + cognitive_component1 + social_component1\n            self.population1[:current_population_size] = np.clip(self.population1[:current_population_size] + self.velocities1[:current_population_size], lb, ub)\n\n            r3, r4 = np.random.rand(current_population_size, self.dim), np.random.rand(current_population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2[:current_population_size] - self.population2[:current_population_size])\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2[:current_population_size])\n            self.velocities2[:current_population_size] = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2[:current_population_size] + cognitive_component2 + social_component2\n            self.population2[:current_population_size] = np.clip(self.population2[:current_population_size] + self.velocities2[:current_population_size], lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(current_population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465812145916, 0.06248121791344541, 0.06249341440633438, 0.062494658068947384, 0.06248121775809323, 0.06249341425095212, 0.06249465791372533]}}
{"id": "06a7b6a4-3c84-43ff-be01-223a30a68e7b", "fitness": 0.062489763699253235, "name": "AdaptiveMemoryHybridDEPSO", "description": "Fine-tune the inertia weight adjustment for differential evolution to improve convergence stability and performance.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + 0.5 * (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465893341566, 0.06248121791344541, 0.06249341440633438, 0.062494658880864806, 0.06248121775809323, 0.06249341425095212, 0.062494658725466556]}}
{"id": "aa084f7e-d356-4bec-bbb6-8cb47a61263d", "fitness": 0.06248974887598039, "name": "AdaptiveMemoryHybridDEPSO", "description": "Improve diversification by introducing Lvy flight for enhanced global exploration in the DE mutation phase.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (\n            np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1) + self.levy_flight(self.dim)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2) + self.levy_flight(self.dim)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248117603535419, 0.06249341386518148, 0.06249465698749335, 0.06248117598304881, 0.06249341381281093, 0.06249465693514622, 0.06248117582765367, 0.062493413657401686, 0.062494656779733204]}}
{"id": "e4477405-0166-4450-a939-714d8f7c868f", "fitness": 0.06248970087713966, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Implement a dynamic memory update strategy and adaptive parameter tuning to enhance the exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR_init = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_max, self.inertia_min = 0.9, 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def dynamic_update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            probabilities = np.exp(-np.array(self.memory_scores) / np.max(self.memory_scores))\n            probabilities /= probabilities.sum()\n            idx = np.random.choice(len(self.memory_pos), p=probabilities)\n            return self.memory_pos[idx]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_max - (self.inertia_max - self.inertia_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_min + (self.inertia_max - self.inertia_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                CR1 = self.CR_init * (1 - evaluations / self.budget)\n                crossover_mask1 = np.random.rand(self.dim) < CR1\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                CR2 = self.CR_init * (evaluations / self.budget)\n                crossover_mask2 = np.random.rand(self.dim) < CR2\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive_coeff * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social_coeff * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive_coeff * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social_coeff * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.dynamic_update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Adjusted memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Modified variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Modified variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248103237226921, 0.06249341386518148, 0.06249465665414111, 0.062481032319713914, 0.06249341381281093, 0.06249465660180553, 0.06248103216452583, 0.062493413657401686, 0.06249465644640728]}}
{"id": "d8a8215c-19fe-4acf-a3c7-9a203fe5f05f", "fitness": -Infinity, "name": "EnhancedAdaptiveMemoryDEPSO", "description": "Integrate adaptive mutation scaling and enhanced memory utilization to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 1.0  # Adaptive mutation scaling\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Enhanced memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {}}
{"id": "59416f2f-49e4-4a3b-b118-1ce8947b5a71", "fitness": 0.062489763699253235, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Incorporate a dynamic feedback mechanism to tune strategy parameters based on convergence trends, enhancing adaptability and performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.prev_global_best_score = np.inf\n        self.feedback_params = {'learning_rate': 0.1, 'convergence_threshold': 1e-5}\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n            # Dynamic feedback mechanism\n            if abs(self.prev_global_best_score - self.global_best_score) < self.feedback_params['convergence_threshold']:\n                self.F_min = max(0.1, self.F_min - self.feedback_params['learning_rate'] * (evaluations / self.budget))\n                self.F_max = min(0.9, self.F_max + self.feedback_params['learning_rate'] * (evaluations / self.budget))\n            self.prev_global_best_score = self.global_best_score\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465893341566, 0.06248121791344541, 0.06249341440633438, 0.062494658880864806, 0.06248121775809323, 0.06249341425095212, 0.062494658725466556]}}
{"id": "fc9615a5-173a-4eaf-b13b-470ccde9b70d", "fitness": 0.06248974512343158, "name": "ImprovedAdaptiveMemoryHybridDEPSO", "description": "Introduce dynamic parameter adaptation and cooperative dual swarms with inter-swarm communication for enhanced convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            dynamic_F_range = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + dynamic_F_range * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + dynamic_F_range * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm ImprovedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248116980602103, 0.06249341386518148, 0.06249465195919568, 0.062481169753658805, 0.06249341381281093, 0.062494651906876086, 0.062481169598276765, 0.062493413657401686, 0.06249465175146174]}}
{"id": "f09cd2a4-1174-401e-9287-f2e708c41a1e", "fitness": -Infinity, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance exploration and exploitation balance by integrating adaptive elitism and dynamic crossover strategies to improve convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR_min, self.CR_max = 0.8, 0.95\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Enhanced memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_population2[i]\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = self.CR_min + (self.CR_max - self.CR_min) * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Enhanced memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {}}
{"id": "b21bef9a-343e-4b7d-872c-bdedf764207c", "fitness": 0.06248976310841054, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance adaptive memory integration and introduce dynamic parameter adjustment for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def dynamic_adjustment(self, evaluations):\n        return self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n    def dynamic_CR_adjustment(self, evaluations):\n        return 0.8 + 0.15 * (evaluations / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight = self.dynamic_adjustment(evaluations)\n            self.CR = self.dynamic_CR_adjustment(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.062494657160761524, 0.06248121791344541, 0.06249341440633438, 0.06249465710839974, 0.06248121775809323, 0.06249341425095212, 0.06249465695300149]}}
{"id": "1d5b06ef-0fc3-4f20-ba15-ce216711988a", "fitness": 0.06248969381347627, "name": "EnhancedLevyAdaptiveDEPSO", "description": "Enhance population diversity and convergence speed by incorporating Lvy flight-inspired mutation and adaptive parameter tuning for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedLevyAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1) + 0.1 * self.levy_flight(self.dim)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2) + 0.1 * self.levy_flight(self.dim)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedLevyAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248101587623711, 0.06249341386518148, 0.06249465195919568, 0.062481015823654174, 0.06249341381281093, 0.062494651906876086, 0.06248101566846753, 0.062493413657401686, 0.06249465175146174]}}
{"id": "03695210-570d-4321-a53f-e33459c62795", "fitness": 0.062489715824297694, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance selection by applying a slight change to the crossover probability update.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.85 + 0.1 * (evaluations / self.budget)  # Changed from 0.8 to 0.85\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248108034596733, 0.06249341386518148, 0.06249465352189332, 0.06248108029351995, 0.06249341381281093, 0.062494653469573724, 0.06248108013819764, 0.062493413657401686, 0.062494653314133175]}}
{"id": "7cafd248-8297-4e90-9fa1-db2b5eb879bb", "fitness": 0.06247924858860437, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance exploration and convergence by integrating dynamic parameter adjustment and improved diversity mechanisms. ", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 1.2  # Expanded F range for diversity\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.3  # Wider inertia range\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Larger memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape)\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Further increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Even larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Even larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00002.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06246190567974175, 0.06247177574375529, 0.06250406460249969, 0.062461905627415604, 0.0624717756914015, 0.06250406454998081, 0.06246190547207553, 0.06247177553604366, 0.0625040643945255]}}
{"id": "f5fc842f-2aad-4a59-be93-3eac7ea2920f", "fitness": 0.06248976294416269, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance exploration by integrating Lvy flight mechanism and fine-tuning opposition parameters to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.05 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1 + self.levy_flight((self.population_size, self.dim)), lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2 + self.levy_flight((self.population_size, self.dim)), lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248121797974471, 0.06249341445867862, 0.06249465665414111, 0.06248121792738226, 0.06249341440633438, 0.06249465660180553, 0.062481217772018205, 0.06249341425095212, 0.06249465644640728]}}
{"id": "f25f2b9e-ab3f-4057-946f-0a652de90639", "fitness": 0.062489763699253235, "name": "AdaptiveMemoryHybridDEPSO", "description": "Introduce a small exploration-enhancing mechanism by adjusting the variance of the memory-based perturbation.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Adjusted variance for exploration\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465893341566, 0.06248121791344541, 0.06249341440633438, 0.062494658880864806, 0.06248121775809323, 0.06249341425095212, 0.062494658725466556]}}
{"id": "72c68055-6c06-4ce2-83c7-26185b51e1bb", "fitness": 0.06248976346962121, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance the exploitation by adjusting the memory utilization strategy and diversity introduction.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            sorted_indices = np.argsort(self.memory_scores)\n            return self.memory_pos[sorted_indices[0]]  # Select best from memory\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Adjusted memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Reduced variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Reduced variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.0624946582443936, 0.06248121791344541, 0.06249341440633438, 0.062494658192031705, 0.06248121775809323, 0.06249341425095212, 0.062494658036633455]}}
{"id": "0c4051ff-f23c-4e4a-9d9e-78d5975abf2e", "fitness": 0.06248976314814415, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Introduce adaptive reinforcement strategies and dynamic parameter control to enhance search efficiency and convergence quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores) - 1):\n            for j in range(len(scores) - 1 - i):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Enhanced memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Optimized variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Optimized variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.0624946572799856, 0.06248121791344541, 0.06249341440633438, 0.06249465722758896, 0.06248121775809323, 0.06249341425095212, 0.06249465707219071]}}
{"id": "099a4ae8-0857-49df-ad5a-7a5366de8617", "fitness": 0.06247910055956444, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance adaptive memory usage and update algorithm parameters to improve solution quality.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Slightly increased population size\n        self.CR = 0.85  # Adjusted crossover probability\n        self.F_min, self.F_max = 0.4, 0.8  # Adjusted mutation factors\n        self.inertia_weight_max, self.inertia_weight_min = 0.85, 0.35  # Adjusted inertia weights\n        self.cognitive = 1.6  # Adjusted cognitive coefficient\n        self.social = 1.6  # Adjusted social coefficient\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Further increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248287549609688, 0.06246292166708456, 0.0624915047755733, 0.06248287544372644, 0.06246292161473721, 0.06249150472325793, 0.06248287528833374, 0.06246292145941168, 0.062491504567858236]}}
{"id": "18da3f4b-0002-48bd-8f62-c99d16b17939", "fitness": 0.062489763470260536, "name": "AdaptiveMemoryHybridDEPSO", "description": "Minor adjustment in memory utilization rate to enhance exploration and diversity.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341446061407, 0.0624946582443936, 0.06248121791344541, 0.06249341440824374, 0.062494658192031705, 0.06248121775809323, 0.06249341425286126, 0.062494658036633455]}}
{"id": "8c418391-87c3-46f5-81bf-507d074c49eb", "fitness": 0.06248976347630337, "name": "EnhancedMemoryAdaptiveDEPSO", "description": "Enhance exploration and exploitation balance by adapting velocities using history-based learning and multi-stage differential mutation strategies.", "code": "import numpy as np\n\nclass EnhancedMemoryAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedMemoryAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.062494658264440006, 0.06248121791344541, 0.06249341440633438, 0.062494658212078225, 0.06248121775809323, 0.06249341425095212, 0.062494658056679975]}}
{"id": "dc04aa96-771f-4f1e-bdbb-6b263bb267e3", "fitness": 0.06248973257586871, "name": "AdaptiveMemoryHybridDEPSO", "description": "Introduce adaptive mutation scaling and enhanced learning strategies to improve exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adjusted mutation scaling factor\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.7  # Slightly increased cognitive component\n        self.social = 1.5\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget  # Enhanced scaling\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248113162774194, 0.06249341386518148, 0.06249465249479347, 0.062481131575393145, 0.06249341381281093, 0.06249465244246377, 0.06248113141999867, 0.062493413657401686, 0.062494652287033325]}}
{"id": "61680400-cfe4-4596-aa46-514d796c7225", "fitness": 0.06247915930484739, "name": "DynamicMutationAdaptiveMemoryDEPSO", "description": "Incorporate a dynamic mutation strategy and adaptive memory updating for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass DynamicMutationAdaptiveMemoryDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 0.95  # Expanded range for F\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        # Enhanced with a dynamic factor based on generation\n        dynamic_factor = 0.1 * (1 - generation / self.budget)\n        opp_population = lb + ub - population + dynamic_factor * np.random.uniform(-1, 1, population.shape)\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.4):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  \n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)  # Dynamic scaling\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)  # Dynamic scaling\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm DynamicMutationAdaptiveMemoryDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00002.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06246183446042297, 0.06247173288327945, 0.06250391083093498, 0.06246183440812658, 0.06247173283085894, 0.06250391077852835, 0.062461834252756754, 0.06247173267560113, 0.06250391062311733]}}
{"id": "f952d933-8743-4b3d-a21f-438d11246dde", "fitness": -Infinity, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Introduce a dynamic population adaptation mechanism and enhance global search by combining adaptive random walks with memory-driven perturbations for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 5 * dim\n        self.population_size = self.base_population_size\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.15 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def dynamic_population_adaptation(self, evaluations):\n        shrink_factor = 0.5 + 0.5 * (evaluations / self.budget)\n        self.population_size = int(self.base_population_size * shrink_factor)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.dynamic_population_adaptation(evaluations)\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (112,45) (225,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (112,45) (225,45) ')", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {}}
{"id": "a0d1efec-64f6-49d2-90b8-f323f65cffcd", "fitness": 0.0624897623060722, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance exploration by integrating a self-adaptive mechanism for parameter tuning and dynamic population management within a hybrid DE and PSO framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.5):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            \n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.062493414630399924, 0.06249465458201986, 0.06248121791344541, 0.06249341457802948, 0.062494654529700266, 0.06248121775809323, 0.06249341442267342, 0.06249465437425983]}}
{"id": "2e76ac05-91a9-421f-b17d-03d087771930", "fitness": 0.06248976237407844, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance crossover diversity and memory usage variability within a limited change allowance.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.15 * (evaluations / self.budget)  # Modified crossover rate\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Modified memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.062494654957766516, 0.06248121791344541, 0.06249341440633438, 0.06249465490542394, 0.06248121775809323, 0.06249341425095212, 0.06249465474998339]}}
{"id": "81e9654c-339f-47e8-8e75-2590832684ff", "fitness": 0.0624897384086465, "name": "EnhancedMemoryAdaptiveDEPSO", "description": "Enhance memory-driven exploration and adaptive parameter tuning for increased search efficiency.", "code": "import numpy as np\n\nclass EnhancedMemoryAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.memory_size = 15  # Increased memory size for better diversity\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.5):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.choice(len(self.memory_pos), p=self.memory_scores/np.sum(self.memory_scores))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight = 0.5 + (0.5 * (1 - evaluations / self.budget))  # Simplified inertia weight\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = 1.5 * r1 * (self.best_positions1 - self.population1)\n            social_component1 = 1.5 * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = 1.5 * r3 * (self.best_positions2 - self.population2)\n            social_component2 = 1.5 * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # More frequent memory utilization\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedMemoryAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481146362581286, 0.06249341386518148, 0.062494655258317766, 0.06248114631024526, 0.06249341381281093, 0.062494655205880933, 0.06248114615484157, 0.062493413657401686, 0.062494655050557624]}}
{"id": "9dc8e3e6-3ba8-4b5f-816d-d7e8a9a1f5b8", "fitness": 0.0624897232721971, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance the diversity-increasing strategy by modifying the mutation factor range for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.6, 0.9  # Adjusted the minimum mutation factor from 0.5 to 0.6\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248110168349663, 0.06249341425389221, 0.062494654139393924, 0.06248110163107756, 0.06249341420154797, 0.06249465408698329, 0.06248110147572694, 0.06249341404611253, 0.062494653931542854]}}
{"id": "ecafaa80-0352-4c5d-b03d-1a4409f3d217", "fitness": 0.06248976298473071, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance exploration by increasing memory utilization rate slightly.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10 \n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.22:  # Slightly increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  \n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  \n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341459435753, 0.06249465665414111, 0.06248121791344541, 0.06249341454184021, 0.06249465660180553, 0.06248121775809323, 0.062493414386457724, 0.06249465644640728]}}
{"id": "240fdf95-78ad-41f9-96e8-a372ff4eea87", "fitness": 0.06248974805865491, "name": "AdaptiveMemoryHybridDEPSO", "description": "Introduce adaptive CR and probabilistic mutation to enhance exploration while maintaining convergence stability.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.7 + 0.25 * (evaluations / self.budget)  # Adjusted CR adaptively\n\n                if np.random.rand() < 0.15:  # Added probabilistic mutation\n                    mutant_vector1 += np.random.normal(0, 0.1, self.dim)\n                    \n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248117018344801, 0.06249341386518148, 0.06249466038751439, 0.06248117013091403, 0.06249341381281093, 0.06249466033514217, 0.06248116997572728, 0.062493413657401686, 0.06249466017975425]}}
{"id": "df811868-24c4-4768-a59c-7b65069fdf17", "fitness": 0.06248976274170167, "name": "AdaptiveMemoryHybridDEPSO", "description": "Apply a novel adaptive scaling factor for diversity, enhancing convergence precision by fine-tuning the exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand() * 0.9  # Refined adaptive scaling factor\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341386518148, 0.06249465665414111, 0.06248121791344541, 0.06249341381281093, 0.06249465660180553, 0.06248121775809323, 0.062493413657401686, 0.06249465644640728]}}
{"id": "b8777c46-a7d8-40d8-aa00-0383f33c7b77", "fitness": 0.062489761374562844, "name": "AdaptiveMemoryHybridDEPSO", "description": "Incorporate a dynamic crossover rate to balance exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.2 * np.sin((np.pi / 2) * (evaluations / self.budget))  # Dynamic change\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465195919568, 0.06248121791344541, 0.06249341440633438, 0.062494651906876086, 0.06248121775809323, 0.06249341425095212, 0.06249465175146174]}}
{"id": "dce6cb3e-5146-4afc-9fae-b70a80453c1f", "fitness": 0.06248976352362101, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance stochastic ranking by adjusting the probability parameter to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.5):  # Adjusted probability\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.0624946584064342, 0.06248121791344541, 0.06249341440633438, 0.06249465835392243, 0.06248121775809323, 0.06249341425095212, 0.06249465819870037]}}
{"id": "bbc33025-7130-4d6d-a1fe-d6e70a5442a6", "fitness": 0.0624897399151701, "name": "RefinedMemoryHybridDEPSO", "description": "Introduce dynamic parameter tuning and hybridized crossover strategies to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass RefinedMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR_min, self.CR_max = 0.7, 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_min, self.inertia_weight_max = 0.4, 0.9\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Further increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for _ in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                CR1 = self.CR_min + (self.CR_max - self.CR_min) * (evaluations / self.budget)\n                crossover_mask1 = np.random.rand(self.dim) < CR1\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                CR2 = self.CR_max - (self.CR_max - self.CR_min) * (evaluations / self.budget)\n                crossover_mask2 = np.random.rand(self.dim) < CR2\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Adjusted memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Reduced variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)  # Reduced variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm RefinedMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248115418122868, 0.06249341386518148, 0.06249465195919568, 0.062481154128879, 0.06249341381281093, 0.062494651906876086, 0.06248115397349563, 0.062493413657401686, 0.06249465175146174]}}
{"id": "1399cdcd-f01b-4b67-99ab-af460504ca21", "fitness": 0.062489763470260536, "name": "AdaptiveMemoryHybridDEPSO", "description": "Refine the strategy by slightly increasing the memory utilization rate to enhance exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Slightly increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341446061407, 0.0624946582443936, 0.06248121791344541, 0.06249341440824374, 0.062494658192031705, 0.06248121775809323, 0.06249341425286126, 0.062494658036633455]}}
{"id": "ba35950e-778e-4a5f-b89a-0843a36b6de4", "fitness": 0.06248969647735535, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance adaptive memory utilization and incorporate self-adaptive parameters to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR_min, self.CR_max = 0.8, 1.0\n        self.F_min, self.F_max = 0.5, 1.0\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive_min, self.cognitive_max = 1.0, 2.0\n        self.social_min, self.social_max = 1.0, 2.0\n        self.memory_size = 20  # Enlarged memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.cognitive_min + (self.cognitive_max - self.cognitive_min) * np.random.rand()\n            social = self.social_min + (self.social_max - self.social_min) * np.random.rand()\n\n            cognitive_component1 = cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248102386783694, 0.06249341386518148, 0.06249465195919568, 0.06248102381534004, 0.06249341381281093, 0.062494651906876086, 0.06248102366009356, 0.062493413657401686, 0.06249465175146174]}}
{"id": "0f49070e-a3a4-490c-8eeb-49d6acae568d", "fitness": 0.062479158562366535, "name": "EnhancedDynamicHybridDEPSO", "description": "Introduce dynamic population adjustments and adaptive mutation strategies to enhance exploration and exploitation balance in hybrid DE-PSO.", "code": "import numpy as np\n\nclass EnhancedDynamicHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation_factor):\n        adaptation_factor = 0.1 + 0.9 * generation_factor\n        opp_population = lb + ub - population + adaptation_factor * np.random.uniform(-1, 1, population.shape)\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.5):\n        indices = np.arange(len(scores))\n        for _ in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation_factor = evaluations / self.budget\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation_factor)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation_factor)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * generation_factor\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * generation_factor\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                dynamic_F = self.F_min + (self.F_max - self.F_min) * generation_factor\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + dynamic_F * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.7 + 0.3 * generation_factor  # Dynamic CR\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + dynamic_F * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = inertia_weight1 * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = inertia_weight2 * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            if generation_factor > 0.5:\n                self.population_size = max(5 * self.dim, int(self.initial_population_size * (1 - generation_factor)))\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedDynamicHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00002.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.0624619007226771, 0.062471738213142114, 0.06250383701134177, 0.06246190067038049, 0.06247173816085527, 0.06250383695885164, 0.062461900515011104, 0.06247173800549033, 0.06250383680354898]}}
{"id": "8fa6840f-7683-43a9-a256-ba7f3432015c", "fitness": 0.06241392505743764, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance exploration by integrating dynamic parameter adaptation and crossover diversity mechanisms.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.3, 0.9  # Changed range for F\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 2.0  # Updated cognitive component\n        self.social = 2.0  # Updated social component\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        diversity_factor = np.std(population, axis=0) * (1 - generation / self.budget)  # Added dynamic diversity\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget + diversity_factor\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.5):  # Adjusted probability\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * np.sin(evaluations / self.budget * np.pi)  # Sinusoidal variation\n                \n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Adjusted memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm AdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06241 with standard deviation 0.00005.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06244837056112007, 0.062454578727909826, 0.062338826143116366, 0.06244837050886776, 0.06245457867536064, 0.0623388260908766, 0.06244837035355466, 0.06245457852027436, 0.06233882593585849]}}
{"id": "be7c3569-a86a-47f8-bcc7-8ee6d1245689", "fitness": 0.06248488934119632, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Introduce dynamic parameter tuning with diversity-preserving mechanisms to enhance exploration and exploitation balance in AdaptiveMemoryHybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 0.9  # More dynamic range for F.\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.population)\n        self.best_scores = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // self.population_size\n            opp_population = self.adaptive_opposition_based_learning(self.population, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score = func(opp_population[i])\n                if opp_score < self.best_scores[i]:\n                    self.best_scores[i] = opp_score\n                    self.best_positions[i] = opp_population[i]\n                if opp_score < self.global_best_score:\n                    self.global_best_score = opp_score\n                    self.global_best_position = opp_population[i]\n\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            self.CR = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic CR reduction\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = a + F * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < self.best_scores[i]:\n                    self.best_scores[i] = trial_score\n                    self.best_positions[i] = trial_vector\n\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            self.population, self.best_scores = self.stochastic_ranking(self.population, self.best_scores)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive * r1 * (self.best_positions - self.population)\n            social_component = self.social * r2 * (self.global_best_position - self.population)\n            self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n            self.population = np.clip(self.population + self.velocities, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        self.population[i] = np.clip(memory_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062492849022140584, 0.06247696469695696, 0.06248485456455821, 0.062492848969769255, 0.06247696464459718, 0.062484854512248944, 0.062492848814380775, 0.06247696448924578, 0.062484854356869235]}}
{"id": "f9e2e689-548a-4888-909f-76c931ae47e1", "fitness": 0.06248973440753131, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Introduce dynamic parameter tuning and explore-exploit balancing to improve convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget  # Changed factor\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.35):  # Changed probability\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.85 + 0.05 * (evaluations / self.budget)  # Modified range\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Changed memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248113744863926, 0.06249341386518148, 0.06249465216889316, 0.06248113739627703, 0.06249341381281093, 0.06249465211657357, 0.062481137240871676, 0.062493413657401686, 0.06249465196113302]}}
{"id": "e3a0fa0f-f42d-439e-8cc0-a1031d715f6e", "fitness": 0.06248973853525133, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance the memory strategy and adaptively tune control parameters for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.4, 0.9  # Adjusted F_min\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.2  # Adjusted weights\n        self.cognitive = 1.7  # Adjusted cognitive component\n        self.social = 1.3  # Adjusted social component\n        self.memory_size = 15  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.2 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.5):  # Adjusted probability\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Further increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481150041523104, 0.06249341386518148, 0.06249465195919568, 0.06248114998899901, 0.06249341381281093, 0.062494651906876086, 0.062481149833812255, 0.062493413657401686, 0.06249465175146174]}}
{"id": "bda524cf-c511-4e33-8376-02fc65b9dd6c", "fitness": -Infinity, "name": "AdaptiveMemoryHybridDEPSO", "description": "Slightly adjusted the inertia weight calculation to enhance exploration in later stages of optimization.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10  # Increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]  # Random selection for diversity\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_population2[i]\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (1 - evaluations / self.budget)  # Changed\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:  # Increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)  # Larger variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {}}
{"id": "b7bafa4e-3a17-43fb-98af-04970fd06561", "fitness": 0.0624897630328867, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Introduce dynamic parameter adaptation and hybrid crossover strategies to enhance diversity and convergence rate.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.3, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.062494656934181325, 0.06248121791344541, 0.06249341440633438, 0.06249465688181932, 0.06248121775809323, 0.06249341425095212, 0.062494656726447495]}}
{"id": "cfcfadb6-2e1a-4e3c-af98-173724fd2d73", "fitness": 0.062489727238776584, "name": "DynamicLearningAdaptiveDEPSO", "description": "Introduce a dynamic learning phase and adaptive crossover strategy to enhance both exploration and exploitation in the algorithm.", "code": "import numpy as np\n\nclass DynamicLearningAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR_min, self.CR_max = 0.6, 1.0\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive, self.social = 1.5, 1.5\n        self.memory_size = 10\n        self.memory_pos, self.memory_scores = [], []\n        self.population1, self.population2 = None, None\n        self.velocities1, self.velocities2 = None, None\n        self.best_positions1, self.best_positions2 = None, None\n        self.best_scores1, self.best_scores2 = None, None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.learning_phase = True\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def adaptive_crossover_rate(self, evaluations):\n        return self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.budget)\n\n    def dynamic_learning_phase(self, evaluations):\n        if self.learning_phase and evaluations > (self.budget // 3):\n            self.learning_phase = False\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.dynamic_learning_phase(evaluations)\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = self.adaptive_crossover_rate(evaluations)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm DynamicLearningAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481116152077854, 0.06249341386518148, 0.06249465195919568, 0.062481116099628475, 0.06249341381281093, 0.062494651906876086, 0.06248111594435535, 0.062493413657401686, 0.06249465175146174]}}
{"id": "27b0afdd-4d19-4f10-9464-ca89fba764c6", "fitness": -Infinity, "name": "AdaptiveMemoryHybridDEPSO", "description": "Enhance hybrid algorithm by fine-tuning exploration through a dynamic memory utilization strategy.", "code": "import numpy as np\n\nclass AdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 10\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_population2[i]\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Slightly increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.15, self.dim), lb, ub)  # Adjusted variance\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {}}
{"id": "2bc6c0a3-9453-447e-ae43-2202f388e608", "fitness": 0.06248976293954289, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Utilize dynamic parameter adaptation and a hybrid strategy to enhance convergence and exploration in optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR = 0.9\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 2.0\n        self.memory_size = 15  # Further increased memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = 0.8 + 0.1 * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Further increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.2, self.dim), lb, ub)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.062481217966028346, 0.06249341445867862, 0.06249465665414111, 0.06248121791344541, 0.06249341440633438, 0.06249465660180553, 0.06248121775809323, 0.06249341425095212, 0.06249465644640728]}}
{"id": "5bb37a39-f254-43d0-818f-87f247226b56", "fitness": 0.06248976366670732, "name": "EnhancedAdaptiveMemoryHybridDEPSO", "description": "Enhance the AdaptiveMemoryHybridDEPSO by incorporating dynamic crossover adaptation and elite preservation for improved convergence and diversity balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemoryHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.CR_min, self.CR_max = 0.8, 0.95\n        self.F_min, self.F_max = 0.5, 0.9\n        self.inertia_weight_max, self.inertia_weight_min = 0.9, 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.memory_size = 15  # Expanded memory size\n        self.memory_pos = []\n        self.memory_scores = []\n        self.population1 = None\n        self.population2 = None\n        self.velocities1 = None\n        self.velocities2 = None\n        self.best_positions1 = None\n        self.best_positions2 = None\n        self.best_scores1 = None\n        self.best_scores2 = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def adaptive_opposition_based_learning(self, population, lb, ub, generation):\n        opp_population = lb + ub - population + 0.1 * np.random.uniform(-1, 1, population.shape) * generation / self.budget\n        opp_population = np.clip(opp_population, lb, ub)\n        return opp_population\n\n    def stochastic_ranking(self, population, scores, probability=0.45):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (scores[indices[j]] > scores[indices[j + 1]]) or (np.random.rand() < probability):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n        return population[indices], scores[indices]\n\n    def update_memory(self, position, score):\n        if len(self.memory_scores) < self.memory_size:\n            self.memory_pos.append(position)\n            self.memory_scores.append(score)\n        else:\n            worst_idx = np.argmax(self.memory_scores)\n            if score < self.memory_scores[worst_idx]:\n                self.memory_pos[worst_idx] = position\n                self.memory_scores[worst_idx] = score\n\n    def select_from_memory(self):\n        if self.memory_scores:\n            return self.memory_pos[np.random.randint(len(self.memory_pos))]\n        return None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population1 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population2 = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities1 = np.zeros((self.population_size, self.dim))\n        self.velocities2 = np.zeros((self.population_size, self.dim))\n        self.best_positions1 = np.copy(self.population1)\n        self.best_positions2 = np.copy(self.population2)\n        self.best_scores1 = np.full(self.population_size, np.inf)\n        self.best_scores2 = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            generation = evaluations // (2 * self.population_size)\n            opp_population1 = self.adaptive_opposition_based_learning(self.population1, lb, ub, generation)\n            opp_population2 = self.adaptive_opposition_based_learning(self.population2, lb, ub, generation)\n            for i in range(self.population_size):\n                opp_score1 = func(opp_population1[i])\n                opp_score2 = func(opp_population2[i])\n                if opp_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = opp_score1\n                    self.best_positions1[i] = opp_population1[i]\n                if opp_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = opp_score2\n                    self.best_positions2[i] = opp_population2[i]\n                if opp_score1 < self.global_best_score:\n                    self.global_best_score = opp_score1\n                    self.global_best_position = opp_population1[i]\n                if opp_score2 < self.global_best_score:\n                    self.global_best_score = opp_score2\n                    self.global_best_position = opp_population2[i]\n\n            inertia_weight1 = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            inertia_weight2 = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                F1 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices1 = [idx for idx in range(self.population_size) if idx != i]\n                a1, b1, c1 = self.population1[np.random.choice(indices1, 3, replace=False)]\n                mutant_vector1 = a1 + F1 * (b1 - c1)\n                mutant_vector1 = np.clip(mutant_vector1, lb, ub)\n\n                self.CR = self.CR_min + (self.CR_max - self.CR_min) * (evaluations / self.budget)\n\n                crossover_mask1 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask1):\n                    crossover_mask1[np.random.randint(0, self.dim)] = True\n                trial_vector1 = np.where(crossover_mask1, mutant_vector1, self.population1[i])\n\n                trial_score1 = func(trial_vector1)\n                evaluations += 1\n\n                if trial_score1 < self.best_scores1[i]:\n                    self.best_scores1[i] = trial_score1\n                    self.best_positions1[i] = trial_vector1\n\n                if trial_score1 < self.global_best_score:\n                    self.global_best_score = trial_score1\n                    self.global_best_position = trial_vector1\n\n                F2 = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                indices2 = [idx for idx in range(self.population_size) if idx != i]\n                a2, b2, c2 = self.population2[np.random.choice(indices2, 3, replace=False)]\n                mutant_vector2 = a2 + F2 * (b2 - c2)\n                mutant_vector2 = np.clip(mutant_vector2, lb, ub)\n\n                crossover_mask2 = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover_mask2):\n                    crossover_mask2[np.random.randint(0, self.dim)] = True\n                trial_vector2 = np.where(crossover_mask2, mutant_vector2, self.population2[i])\n\n                trial_score2 = func(trial_vector2)\n                evaluations += 1\n\n                if trial_score2 < self.best_scores2[i]:\n                    self.best_scores2[i] = trial_score2\n                    self.best_positions2[i] = trial_vector2\n\n                if trial_score2 < self.global_best_score:\n                    self.global_best_score = trial_score2\n                    self.global_best_position = trial_vector2\n\n            self.population1, self.best_scores1 = self.stochastic_ranking(self.population1, self.best_scores1)\n            self.population2, self.best_scores2 = self.stochastic_ranking(self.population2, self.best_scores2)\n\n            elite_threshold = np.percentile(np.append(self.best_scores1, self.best_scores2), 10)\n            elite_positions = np.append(self.population1[self.best_scores1 <= elite_threshold],\n                                        self.population2[self.best_scores2 <= elite_threshold], axis=0)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component1 = self.cognitive * r1 * (self.best_positions1 - self.population1)\n            social_component1 = self.social * r2 * (self.global_best_position - self.population1)\n            self.velocities1 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities1 + cognitive_component1 + social_component1\n            self.population1 = np.clip(self.population1 + self.velocities1, lb, ub)\n\n            r3, r4 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_component2 = self.cognitive * r3 * (self.best_positions2 - self.population2)\n            social_component2 = self.social * r4 * (self.global_best_position - self.population2)\n            self.velocities2 = (0.5 * (inertia_weight1 + inertia_weight2)) * self.velocities2 + cognitive_component2 + social_component2\n            self.population2 = np.clip(self.population2 + self.velocities2, lb, ub)\n\n            self.update_memory(self.global_best_position, self.global_best_score)\n\n            memory_position = self.select_from_memory()\n            if memory_position is not None:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Further increased memory utilization rate\n                        self.population1[i] = np.clip(memory_position + np.random.normal(0, 0.25, self.dim), lb, ub)  # Increased variance\n                        self.population2[i] = np.clip(memory_position + np.random.normal(0, 0.25, self.dim), lb, ub)  # Increased variance\n\n            if len(elite_positions) < self.population_size:\n                elite_indices = np.random.choice(len(elite_positions), self.population_size - len(elite_positions), replace=True)\n                self.population1[:len(elite_positions)] = elite_positions\n                self.population2[:len(elite_positions)] = elite_positions\n                self.population1[len(elite_positions):] = elite_positions[elite_indices]\n                self.population2[len(elite_positions):] = elite_positions[elite_indices]\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveMemoryHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06249 with standard deviation 0.00001.", "error": "", "parent_ids": ["7b442f07-95c3-49dc-9407-e4a447c02974"], "operator": null, "metadata": {"aucs": [0.06248121796914696, 0.06249341498554595, 0.062494658305611295, 0.06248121791663941, 0.06249341493320426, 0.06249465825323408, 0.062481217761287344, 0.062493414777819334, 0.06249465809787724]}}
