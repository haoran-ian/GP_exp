{"id": "cd91f486-70df-4f41-affe-411c7cc3f089", "fitness": 0.42319004803914523, "name": "HybridPSODE", "description": "A hybrid metaheuristic that combines Particle Swarm Optimization (PSO) with Differential Evolution (DE) to efficiently explore and exploit search spaces by dynamically adjusting strategies based on population diversity.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive constant for PSO\n        self.c2 = 1.5  # Social constant for PSO\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (personal_best - population) +\n                        self.c2 * r2 * (global_best - population))\n            population = population + velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42319 with standard deviation 0.35629.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18529239955088028, 0.9268011499863927, 0.1574765945801625]}}
{"id": "65438a0c-e5b0-4b62-902f-ec3df1d60486", "fitness": 0.9526557617997828, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimization algorithm that integrates Adaptive Particle Swarm Optimization with Differential Evolution and dynamic parameter tuning to balance exploration and exploitation effectively for diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95266 with standard deviation 0.03134.", "error": "", "parent_ids": ["cd91f486-70df-4f41-affe-411c7cc3f089"], "operator": null, "metadata": {"aucs": [0.9112173176200266, 0.9597561684016596, 0.9869937993776624]}}
{"id": "43468f36-0565-49c8-9c97-738b3cd8c021", "fitness": 0.424740643024676, "name": "EnhancedHybridPSODE", "description": "An improved hybrid optimization algorithm that incorporates dynamic neighborhood selection and adaptive parameter scaling to enhance search capability and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.neighborhood_size = 5  # New: size of neighborhood for local best\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n            adaptive_F = self.F * (1 - evaluations / self.budget)  # New: adaptive mutation factor\n\n            # Dynamic neighborhood selection\n            local_bests = np.zeros_like(personal_best)\n            for i in range(self.population_size):\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda idx: personal_best_values[idx])\n                local_bests[i] = personal_best[best_neighbor]\n\n            # Particle Swarm Optimization update with local best\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (local_bests - population) +  # Modified: use local best\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + adaptive_F * (x1 - x2)  # Use adaptive_F\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42474 with standard deviation 0.34239.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9087515443527736, 0.17057936661366924, 0.19489101810758513]}}
{"id": "6d90b565-6bc6-4fe7-8aa1-9687455d20bd", "fitness": 0.9181331584260879, "name": "EnhancedHybridPSODE", "description": "Integration of a novel adaptive inertia weight strategy and selective breeding for stronger convergence in EnhancedHybridPSODE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight strategy\n            w = self.w_max - ((self.w_max - self.w_min) * ((evaluations / self.budget) ** 2))\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91813 with standard deviation 0.07005.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.822026195738926, 0.9453794801616754, 0.9869937993776624]}}
{"id": "beeb828d-502f-456b-90c5-df5314e68271", "fitness": 0.7473194191020349, "name": "EnhancedHybridPSODE", "description": "Utilize Adaptive Levy Flight and Fitness Sharing to enhance exploration in diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.levy_alpha = 1.5\n        self.epsilon = 1e-8\n\n    def levy_flight(self, dim):\n        u = np.random.normal(0, 1, dim) * (self.epsilon / np.abs(np.random.normal(0, 1)))**(1/self.levy_alpha)\n        return u\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            if evaluations < self.budget:\n                levy_steps = self.levy_flight(self.dim)\n                for i in range(self.population_size):\n                    population[i] += levy_steps * (population[i] - global_best)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74732 with standard deviation 0.06868.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.6881451043761352, 0.8436034304007335, 0.7102097225292359]}}
{"id": "706a7926-8567-40b1-9d54-3b254848d9b3", "fitness": 0.8867476180166793, "name": "AdvancedMultiStrategyPSODE", "description": "An advanced multi-strategy optimizer combining Adaptive Particle Swarm Optimization, Differential Evolution, and a novel local search mechanism for enhanced convergence speed and accuracy across diverse problem landscapes.", "code": "import numpy as np\n\nclass AdvancedMultiStrategyPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Local search refinement on the global best\n            if evaluations < self.budget:\n                perturbation = np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                local_trial = np.clip(global_best + perturbation, lb, ub)\n                local_trial_value = func(local_trial)\n                evaluations += 1\n\n                if local_trial_value < global_best_value:\n                    global_best = local_trial\n                    global_best_value = local_trial_value\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm AdvancedMultiStrategyPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88675 with standard deviation 0.05624.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8833562671288194, 0.8196236017817252, 0.9572629851394934]}}
{"id": "6067fe26-e370-49eb-89f8-d4da65ee6818", "fitness": 0.9337145040504402, "name": "RefinedHybridPSODE", "description": "A refined Hybrid PSO-DE algorithm with adaptive inertia weight decay and enhanced mutation strategy for improved convergence in diverse search spaces.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.2  # Reduced minimum inertia weight for more exploration\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w_decay_rate = (self.w_max - self.w_min) / self.budget\n            w = self.w_max - (w_decay_rate * evaluations)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Enhanced Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice([idx for idx in range(self.population_size) if idx != i], 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93371 with standard deviation 0.02060.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.96270866873734, 0.9216610407474816, 0.916773802666499]}}
{"id": "2f8f5046-2ed9-4a2c-b490-2f28521d9e93", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "A refined hybrid algorithm that adds local search with Lévy flight strategy to improve exploration capabilities, maintaining the balance of exploration and exploitation with adaptive parameter tuning.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Lévy flight local search\n            if evaluations < self.budget:\n                L = 0.01  # Scale factor for Lévy flight\n                for i in range(self.population_size):\n                    levy_step = self.levy_flight(L)\n                    candidate = personal_best[i] + levy_step\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    evaluations += 1\n                    if candidate_value < personal_best_values[i]:\n                        personal_best[i] = candidate\n                        personal_best_values[i] = candidate_value\n                        if candidate_value < global_best_value:\n                            global_best = candidate\n                            global_best_value = candidate_value\n\n        return global_best", "configspace": "", "generation": 7, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {}}
{"id": "2569b92e-1d43-430b-b05b-cd1d79113a93", "fitness": 0.7375444115329621, "name": "EnhancedHybridPSODE", "description": "Optimized EnhancedHybridPSODE by incorporating a self-adaptive mutation factor and varying population size to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, self.dim * 2)  # Vary population size based on dim\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Self-adaptive mutation factor\n            F = self.F_base + (0.9 - self.F_base) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)  # Use self-adaptive F\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73754 with standard deviation 0.00323.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.733670628976383, 0.7415717700126195, 0.7373908356098837]}}
{"id": "28aaadcd-39aa-45c3-9b8c-98b1c2ab765c", "fitness": 0.9040364907782963, "name": "AdvancedHybridPSODE", "description": "Introducing an adaptive learning factor and chaotic mutation strategy to further improve exploration-exploitation balance in EnhancedHybridPSODE for diverse search spaces.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.learning_rate = 0.1  # Learning rate for adaptive changes\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        r_adaptive = np.random.rand(self.population_size, self.dim)\n\n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Apply chaotic mutation\n                r_adaptive = self.learning_rate * r_adaptive * (1 - r_adaptive)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i] + r_adaptive[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90404 with standard deviation 0.01329.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8961436240877038, 0.9227573057852696, 0.8932085424619154]}}
{"id": "b5522ab7-db36-4ce6-863f-b92283a67f4a", "fitness": 0.9309124038858746, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimization algorithm that improves exploration by modifying the crossover probability dynamically in Differential Evolution while integrating Adaptive Particle Swarm Optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n            CR = 0.9 - (0.5 * evaluations / self.budget)  # Modified line for dynamic CR\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93091 with standard deviation 0.04117.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8893143902880387, 0.9164290219919224, 0.9869937993776624]}}
{"id": "be68609f-78b1-40b9-aecd-0f0a7f6e33fa", "fitness": 0.9322796902172309, "name": "EnhancedHybridPSODE", "description": "Enhanced Adaptive PSO-DE with Levy Flight and Elite Reinforcement, integrating Levy flights for better exploration and elite strategy to refine convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.elitism_rate = 0.1  # Rate for elite reinforcement\n\n    def levy_flight(self, lam=1.5):\n        u = np.random.normal(0, 1, size=self.dim) * (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) /\n                                                      (np.math.gamma((1 + lam) / 2) * lam * 2 ** ((lam - 1) / 2))) ** (1 / lam)\n        v = np.random.normal(0, 1, size=self.dim)\n        return u / np.abs(v) ** (1 / lam)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.elitism_rate:\n                    population[i] += self.levy_flight()\n                    population[i] = np.clip(population[i], lb, ub)\n                \n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93228 with standard deviation 0.00601.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9251423135145023, 0.9398562337909627, 0.9318405233462279]}}
{"id": "ed3f4657-e4ff-46e8-916a-510e5c3be643", "fitness": -Infinity, "name": "AdvancedHybridPSODE", "description": "An advanced synergy of Adaptive Particle Swarm Optimization and Differential Evolution with chaotic initialization and Lévy flight for enhanced exploration-exploitation balance across complex search landscapes.", "code": "import numpy as np\nfrom scipy.stats import levy\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8\n        self.CR = 0.9\n\n    def chaos_initialization(self, lb, ub):\n        return lb + (ub - lb) * (np.sin(np.arange(1, self.population_size + 1) * np.pi / self.population_size))\n\n    def levy_flight(self, x, best):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return x + 0.01 * step * (x - best)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.chaos_initialization(lb, ub)\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n                \n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial = self.levy_flight(trial, global_best)\n                trial = np.clip(trial, lb, ub)\n                \n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 12, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (45,) (20,) ').", "error": "ValueError('operands could not be broadcast together with shapes (45,) (20,) ')", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {}}
{"id": "aa7af6fa-c9d7-4271-a189-0bd3e23d7dcf", "fitness": 0.6877016216898388, "name": "EnhancedHybridPSODE", "description": "Improved parameter tuning and adaptive mutation strategy to enhance exploitation and global convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                # Update mutation factor for better exploration\n                F_adaptive = 0.5 + 0.3 * np.exp(-evaluations / self.budget)\n                mutant = x0 + F_adaptive * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68770 with standard deviation 0.35509.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.18883700635579892, 0.8872740593360551, 0.9869937993776624]}}
{"id": "252c7a45-b7ac-4720-926d-6bdb13ee0358", "fitness": 0.8678785066396212, "name": "RefinedHybridPSODE", "description": "A refined hybrid optimization algorithm that integrates Adaptive Particle Swarm Optimization with Differential Evolution and Levy Flight distribution for random walks to enhance exploration and convergence speed in diverse search spaces.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy flight distribution\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution with Levy Flights\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Apply Levy Flight to enhance exploration\n                if np.random.rand() < 0.3:  # 30% chance to perform Levy Flight\n                    mutant += self.levy_flight(self.dim)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 14, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86788 with standard deviation 0.04822.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8596786672371557, 0.930611279635605, 0.8133455730461031]}}
{"id": "fcf18696-e141-4f96-951e-27c5d70a28b1", "fitness": -Infinity, "name": "EnhancedHybridPSODEV2", "description": "EnhancedHybridPSODE with adaptive population size and velocity scaling, improving convergence by dynamically adjusting exploration and exploitation according to budget usage.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.initial_population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            progress_ratio = evaluations / self.budget\n            w = self.w_max - ((self.w_max - self.w_min) * progress_ratio)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * progress_ratio)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * progress_ratio)\n            # Adaptive population size\n            population_size = int(self.initial_population_size * (1 + progress_ratio / 2))\n            if population_size > self.initial_population_size:\n                additional_pop = np.random.uniform(lb, ub, (population_size - self.initial_population_size, self.dim))\n                additional_vel = np.random.uniform(-1, 1, (population_size - self.initial_population_size, self.dim))\n                population = np.vstack((population, additional_pop))\n                velocity = np.vstack((velocity, additional_vel))\n                personal_best = np.vstack((personal_best, additional_pop))\n                additional_best_values = np.array([func(ind) for ind in additional_pop])\n                personal_best_values = np.concatenate((personal_best_values, additional_best_values))\n                evaluations += (population_size - self.initial_population_size)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 15, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,45) (22,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,45) (22,45) ')", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {}}
{"id": "67883663-d900-4102-98d7-679fe19fde37", "fitness": 0.941982975425638, "name": "EnhancedHybridPSODE", "description": "Improved balance between exploration and exploitation by dynamically adjusting the Differential Evolution crossover probability.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Dynamic crossover probability adjustment\n                trial = np.where(np.random.rand(self.dim) < (self.CR - 0.4 * evaluations / self.budget), mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94198 with standard deviation 0.03215.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9138830687000921, 0.9250720581991598, 0.9869937993776624]}}
{"id": "77a67533-888e-49ec-a003-34a2129ccb5a", "fitness": 0.8731164473715544, "name": "DynamicAdaptiveHybridPSODE", "description": "Dynamic Adaptive Hybrid PSODE with Lévy Flight and Self-Adaptive Mutation Factor for enhanced exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.stats import levy\n\nclass DynamicAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.CR = 0.9\n        self.F_min = 0.4\n        self.F_max = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n            F = self.F_min + np.random.rand() * (self.F_max - self.F_min)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    levy_step = levy.rvs(size=self.dim) * (population[i] - global_best)\n                    mutant += levy_step\n                    mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "The algorithm DynamicAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87312 with standard deviation 0.03637.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9245491285703031, 0.8476558949264897, 0.8471443186178701]}}
{"id": "fa53c7c0-7fee-4b9b-9322-69ea9d88a489", "fitness": 0.9006872884841274, "name": "EnhancedHybridPSODE", "description": "Introduced a momentum factor to the velocity update, enhancing the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.momentum = 0.5  # Added momentum factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.momentum * velocity +  # Apply momentum\n                        w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90069 with standard deviation 0.03421.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.941658038155108, 0.9024818076477454, 0.8579220196495291]}}
{"id": "d1f03853-960d-4f2e-a053-e1058694baca", "fitness": 0.39864954982362927, "name": "EnhancedHybridPSODE", "description": "Improved EnhancedHybridPSODE by incorporating an adaptive learning strategy with Leader-Based Opposition to enhance convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n            \n            # Leader-Based Opposition\n            leader_opposition = np.clip(2 * global_best - population, lb, ub)\n            leader_opposition_values = np.array([func(ind) for ind in leader_opposition])\n            evaluations += self.population_size\n            \n            # Substitute worse personal bests with leader oppositions if better\n            for i in range(self.population_size):\n                if leader_opposition_values[i] < personal_best_values[i]:\n                    personal_best[i] = leader_opposition[i]\n                    personal_best_values[i] = leader_opposition_values[i]\n                    if leader_opposition_values[i] < global_best_value:\n                        global_best = leader_opposition[i]\n                        global_best_value = leader_opposition_values[i]\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39865 with standard deviation 0.39872.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9625082955138304, 0.12017641560333314, 0.11326393835372406]}}
{"id": "7ce6f0c7-726e-43a8-979b-93503d4a8b69", "fitness": 0.9076108137852431, "name": "RefinedHybridPSODE", "description": "A refined hybrid algorithm that introduces Lévy flight for enhanced exploration in Adaptive Particle Swarm Optimization combined with Differential Evolution, ensuring improved convergence and robustness in diverse optimization problems.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.beta = 1.5  # Parameter for Lévy flight\n\n    def levy_flight(self, size):\n        # Lévy flight step\n        sigma1 = np.power((np.math.gamma(1 + self.beta) * np.sin(np.pi * self.beta / 2)) /\n                          (np.math.gamma((1 + self.beta) / 2) * self.beta * np.power(2, (self.beta - 1) / 2)), 1 / self.beta)\n        u = np.random.normal(0, sigma1, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.power(np.abs(v), 1 / self.beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update with Lévy flight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n                        \n            population += velocity + self.levy_flight((self.population_size, self.dim))\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 20, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90761 with standard deviation 0.06228.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9462144277194466, 0.9568748048427019, 0.8197432087935806]}}
{"id": "b966bc76-aea6-42ef-b8f6-8b1ae5486d81", "fitness": 0.9384372154094508, "name": "EnhancedHybridPSODE", "description": "A novel algorithm that enhances Adaptive Particle Swarm Optimization with Differential Evolution, incorporating an elitist strategy and adaptive mutation for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.elite_size = 2  # Number of elite individuals\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Preserve elite individuals\n            elite_indices = np.argsort(personal_best_values)[:self.elite_size]\n            elites = population[elite_indices]\n\n            # Differential Evolution with adaptive mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices or any(x in elite_indices for x in indices):\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    adaptive_F = self.F * (1 - evaluations/self.budget)  # Adaptive mutation factor\n                    mutant = x0 + adaptive_F * (x1 - x2)\n                    mutant = np.clip(mutant, lb, ub)\n\n                    trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                    trial_value = func(trial)\n                    evaluations += 1\n\n                    if trial_value < personal_best_values[i]:\n                        personal_best[i] = trial\n                        personal_best_values[i] = trial_value\n                        if trial_value < global_best_value:\n                            global_best = trial\n                            global_best_value = trial_value\n\n                    if evaluations >= self.budget:\n                        break\n\n            # Reinstate elites\n            population[elite_indices] = elites\n            personal_best[elite_indices] = elites\n            personal_best_values[elite_indices] = [func(elite) for elite in elites]\n\n        return global_best", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93844 with standard deviation 0.04604.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8752035435730613, 0.9834875059325202, 0.9566205967227711]}}
{"id": "86e4f444-9d3a-47d2-be2a-c2ee3e82399b", "fitness": 0.9360218183390715, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimization algorithm that integrates Adaptive Particle Swarm Optimization with Differential Evolution and introduces a nonlinear dynamic parameter tuning for better balancing exploration and exploitation across diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Nonlinear dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget) ** 2)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * (evaluations / self.budget) ** 2)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * (evaluations / self.budget) ** 2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93602 with standard deviation 0.03688.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9009938968259482, 0.920077758813604, 0.9869937993776624]}}
{"id": "df451f51-7a90-41ae-9afd-10e38383d4a4", "fitness": 0.9526557617997828, "name": "ImprovedAdaptiveHybridPSODE", "description": "ImprovedAdaptiveHybridPSODE: An improved hybrid algorithm merging Adaptive Particle Swarm Optimization with Differential Evolution, incorporating self-adaptive parameter control and a stochastic restart mechanism for enhanced global exploration and convergence stability.", "code": "import numpy as np\n\nclass ImprovedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.restart_threshold = 0.1  # Stochastic restart threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        no_improvement_counter = 0\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n                        no_improvement_counter = 0\n                    else:\n                        no_improvement_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n            \n            if no_improvement_counter > self.restart_threshold * self.budget:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                personal_best = population.copy()\n                personal_best_values = np.array([func(ind) for ind in population])\n                global_best = personal_best[np.argmin(personal_best_values)]\n                global_best_value = np.min(personal_best_values)\n                no_improvement_counter = 0\n\n        return global_best", "configspace": "", "generation": 23, "feedback": "The algorithm ImprovedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95266 with standard deviation 0.03134.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9112173176200266, 0.9597561684016596, 0.9869937993776624]}}
{"id": "6c87cea5-bfb0-4895-bf28-4a58cc41769c", "fitness": 0.25161099396986636, "name": "HybridGradientGuidedPSODE", "description": "Hybrid Gradient-Guided PSODE: An innovative extension of EnhancedHybridPSODE that incorporates gradient approximation for local search intensification and adaptive scaling for improved convergence across diverse problem landscapes.", "code": "import numpy as np\n\nclass HybridGradientGuidedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.gradient_step_size = 1e-5\n\n    def approximate_gradient(self, func, x):\n        grad = np.zeros(self.dim)\n        fx = func(x)\n        for i in range(self.dim):\n            x_step = np.copy(x)\n            x_step[i] += self.gradient_step_size\n            grad[i] = (func(x_step) - fx) / self.gradient_step_size\n        return grad\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Gradient-based local search intensification\n            for i in range(self.population_size):\n                grad = self.approximate_gradient(func, personal_best[i])\n                local_search_candidate = personal_best[i] - self.gradient_step_size * grad\n                local_search_candidate = np.clip(local_search_candidate, lb, ub)\n                local_search_value = func(local_search_candidate)\n                evaluations += 1\n\n                if local_search_value < personal_best_values[i]:\n                    personal_best[i] = local_search_candidate\n                    personal_best_values[i] = local_search_value\n                    if local_search_value < global_best_value:\n                        global_best = local_search_candidate\n                        global_best_value = local_search_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 24, "feedback": "The algorithm HybridGradientGuidedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25161 with standard deviation 0.24565.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.07239723049976421, 0.08348719049377862, 0.5989485609160562]}}
{"id": "71a81b42-63a0-4467-b708-5b12d658c6bb", "fitness": 0.9650103529536427, "name": "EnhancedHybridPSODEv2", "description": "EnhancedHybridPSODEv2: A refined hybrid algorithm combining Adaptive Particle Swarm Optimization with Differential Evolution and a chaotic map-based parameter adaptation for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Chaotic dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            w = self.w_min + (self.w_max - self.w_min) * chaos_param\n            c1 = self.c1_initial + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial + chaos_param * (3.0 - self.c2_initial)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96501 with standard deviation 0.00652.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.961306708783771, 0.9595451766148516, 0.9741791734623051]}}
{"id": "dd660fba-8515-41e5-b486-e9ccf74fcb07", "fitness": 0.943765676033021, "name": "QuantumInspiredHybridPSODEv3", "description": "Quantum-Inspired Hybrid PSO-DE: Introducing quantum-based position update with adaptive chaotic parameter tuning for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass QuantumInspiredHybridPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.evaluations = 0\n        self.alpha = 0.1  # Learning parameter for quantum-inspired update\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def quantum_update(self, position, personal_best, global_best):\n        return position + self.alpha * np.sign(np.random.rand(self.dim) - 0.5) * (personal_best - global_best)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            w = self.w_min + (self.w_max - self.w_min) * chaos_param\n            c1 = self.c1_initial + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial + chaos_param * (3.0 - self.c2_initial)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Quantum-inspired position update\n            for i in range(self.population_size):\n                updated_position = self.quantum_update(population[i], personal_best[i], global_best)\n                updated_position = np.clip(updated_position, lb, ub)\n                updated_value = func(updated_position)\n                self.evaluations += 1\n\n                if updated_value < personal_best_values[i]:\n                    personal_best[i] = updated_position\n                    personal_best_values[i] = updated_value\n                    if updated_value < global_best_value:\n                        global_best = updated_position\n                        global_best_value = updated_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 26, "feedback": "The algorithm QuantumInspiredHybridPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94377 with standard deviation 0.02598.", "error": "", "parent_ids": ["71a81b42-63a0-4467-b708-5b12d658c6bb"], "operator": null, "metadata": {"aucs": [0.976337628638685, 0.9421889539884558, 0.9127704454719219]}}
{"id": "bb59941d-ab20-4425-abd4-90176c61a9f9", "fitness": 0.9800367504362107, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE: An improved algorithm integrating dynamic adaptive inertia and learning parameters with enhanced differential evolution for superior convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["71a81b42-63a0-4467-b708-5b12d658c6bb"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "011892f0-8225-4585-8726-9929ce5f04bc", "fitness": 0.7118317001466776, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with Adaptive Mutation and Crossover: An optimization algorithm that integrates adaptive mutation and crossover rates based on population diversity for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            \n            # Adaptive mutation and crossover rates based on diversity\n            diversity = np.mean(np.linalg.norm(population - global_best, axis=1))\n            F = self.F_initial * (1 - diversity / (np.linalg.norm(ub - lb) / 2))\n            CR = self.CR_initial * (1 - diversity / (np.linalg.norm(ub - lb) / 2))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71183 with standard deviation 0.37817.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9856694072383688, 0.9727595660401455, 0.17706612716151848]}}
{"id": "d09d611e-115e-4e6e-ae8e-2ab2b84ce2eb", "fitness": -Infinity, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with chaotic local search and enhanced exploration via Lévy flights for better convergence in diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n    \n    def levy_flight(self, lam=1.5, size=1):\n        sigma = (np.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.gamma((1 + lam) / 2) * lam * 2 ** ((lam - 1) / 2))) ** (1 / lam)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        return u / np.abs(v) ** (1 / lam)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n                \n                # Apply Lévy flight for enhanced exploration\n                if np.random.rand() < 0.1:\n                    levy_step = self.levy_flight(size=self.dim)\n                    trial = np.clip(global_best + levy_step, lb, ub)\n                    trial_value = func(trial)\n                    self.evaluations += 1\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n        return global_best", "configspace": "", "generation": 29, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {}}
{"id": "8fd53590-bcfb-4a1c-997f-dd45e6b52eba", "fitness": 0.9800367504362107, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Incorporate a dynamic crossover probability adjustment based on chaos to boost exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param  # Adjusted line for dynamic CR adjustment\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "a063ea85-ee93-4976-a541-eac73ab172eb", "fitness": 0.665310126544907, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with chaotic local search integration to improve exploitation and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def chaotic_local_search(self, individual, lb, ub, func):\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n        new_solution = individual + perturbation\n        new_solution = np.clip(new_solution, lb, ub)\n        return new_solution if func(new_solution) < func(individual) else individual\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial = self.chaotic_local_search(trial, lb, ub, func)\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66531 with standard deviation 0.28719.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9393833344410565, 0.7878441285258638, 0.26870291666780055]}}
{"id": "fee89774-afeb-4e66-8b5f-e42cc8ae6e34", "fitness": 0.9557042073865016, "name": "EnhancedAdaptiveDynPSO_DE_MultiChaos", "description": "Enhanced Adaptive DynPSO-DE with Multi-level Chaos Control: A refinement utilizing multi-level chaotic sequences for enhanced exploration and exploitation balance in dynamic parameter tuning.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_MultiChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n    \n    def sinusoidal_map(self, x):\n        return 2.3 * x * (1 - x**2)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param1 = np.random.rand()\n        chaos_param2 = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Multi-level chaotic parameter adjustment\n            chaos_param1 = self.logistic_map(chaos_param1)\n            chaos_param2 = self.sinusoidal_map(chaos_param2)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param1 * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param2 * (3.0 - self.c2_initial)\n            F = self.F_initial * (chaos_param1 + chaos_param2) / 2\n            CR = self.CR_initial * (chaos_param1 + chaos_param2) / 2\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_MultiChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95570 with standard deviation 0.00943.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.952952152425008, 0.9457782015691069, 0.9683822681653899]}}
{"id": "62828127-5323-4717-aceb-7362350a2394", "fitness": 0.6999663453248663, "name": "EnhancedAdaptiveDynPSO_DE_SA", "description": "EnhancedAdaptiveDynPSO_DE_SA: Introducing simulated annealing-inspired temperature-based adaptation to balance exploration and exploitation dynamically for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n        self.temperature_initial = 1.0  # Start temperature for annealing\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def temperature_decay(self, t):\n        return t * 0.95  # Simulated annealing decay\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n        temperature = self.temperature_initial\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                acceptance_prob = np.exp((personal_best_values[i] - trial_value) / temperature)\n                if trial_value < personal_best_values[i] or np.random.rand() < acceptance_prob:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                temperature = self.temperature_decay(temperature)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69997 with standard deviation 0.36191.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9783428690172034, 0.9327285016151149, 0.1888276653422808]}}
{"id": "36302a58-b3ff-48e4-8497-daac69882837", "fitness": 0.9436987197127782, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Introducing a mutation operator using a Gaussian distribution to enhance exploration capabilities subtly.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                \n                # Gaussian mutation added\n                mutant += np.random.normal(0, 0.1, self.dim)\n                \n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94370 with standard deviation 0.01275.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9294152384339858, 0.9413142002434982, 0.9603667204608506]}}
{"id": "f9c46b3b-a216-4c25-bfb8-31d23df1b47d", "fitness": 0.9540219850150021, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE-Refined: A refined version of EnhancedAdaptiveDynPSO-DE with adaptive crossover probability adjustment for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * (1 - progress_ratio)  # Change: adaptive CR adjustment\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95402 with standard deviation 0.00796.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9476089248257656, 0.9652376536579825, 0.9492193765612584]}}
{"id": "a76cfdad-6ad1-44ae-8bc8-f544a02ede43", "fitness": 0.8837320908971916, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO_DE with Chaotic Opposition-Based Learning for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def opposition_based_learning(self, population, lb, ub):\n        opp_population = lb + ub - population\n        return np.clip(opp_population, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Chaotic Opposition-Based Learning\n            opp_population = self.opposition_based_learning(population, lb, ub)\n            for i, opp_ind in enumerate(opp_population):\n                opp_value = func(opp_ind)\n                self.evaluations += 1\n                if opp_value < personal_best_values[i]:\n                    personal_best[i] = opp_ind\n                    personal_best_values[i] = opp_value\n                    if opp_value < global_best_value:\n                        global_best = opp_ind\n                        global_best_value = opp_value\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88373 with standard deviation 0.03133.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.8953825707392299, 0.8408865920333485, 0.9149271099189963]}}
{"id": "040735d1-c24f-4bf7-98b4-45d4409d7ff4", "fitness": 0.7082299130833841, "name": "ChaosEnhancedDynPSO_DE", "description": "ChaosEnhancedDynPSO-DE: A refined algorithm leveraging a chaotic logistic map for dynamic parameter tuning in PSO and DE, enhancing convergence efficiency.", "code": "import numpy as np\n\nclass ChaosEnhancedDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment with chaos\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (2.5 - self.c1_initial)\n            c2 = self.c2_initial * progress_ratio + chaos_param * (2.5 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # DE update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 37, "feedback": "The algorithm ChaosEnhancedDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70823 with standard deviation 0.35524.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9564512158406934, 0.9623766272803539, 0.20586189612910488]}}
{"id": "1388d1f4-cca4-4186-b9c2-6a49b29f24b8", "fitness": 0.9613489272125731, "name": "ImprovedAdaptiveDynPSO_DE", "description": "Improved Adaptive PSO-DE integrating chaotic logistic map for enhanced diversity and exploration.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * (1 - chaos_param)\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 38, "feedback": "The algorithm ImprovedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96135 with standard deviation 0.02827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9789870715017874, 0.9835974612923946, 0.9214622488435376]}}
{"id": "acf79834-3230-401e-a059-fb248ddb7d8a", "fitness": 0.8051430664831161, "name": "QuantumInspiredEnhancedAdaptiveDynPSO_DE", "description": "Quantum-Inspired EnhancedAdaptiveDynPSO-DE: Introducing quantum probability-based exploration to EnhancedAdaptiveDynPSO-DE for superior exploitation and exploration balance.", "code": "import numpy as np\n\nclass QuantumInspiredEnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n        self.q_prob = 0.05  # Quantum probability for exploration\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def quantum_exploration(self, candidate, global_best, lb, ub):\n        # Introduce quantum-inspired exploration\n        if np.random.rand() < self.q_prob:\n            return np.random.uniform(lb, ub, self.dim)\n        return candidate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = self.quantum_exploration(np.clip(mutant, lb, ub), global_best, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 39, "feedback": "The algorithm QuantumInspiredEnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80514 with standard deviation 0.15539.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.5856354368406187, 0.9059902347172868, 0.9238035278914428]}}
{"id": "ba4a3969-2bbc-4050-8063-952cdd5b7c1e", "fitness": 0.9534388072560849, "name": "HybridAdaptivePSO_DE", "description": "HybridAdaptivePSO_DE: A novel hybrid algorithm incorporating adaptive chaotic inertia and dynamic crossover-mutation strategy for enhanced exploration-exploitation balance in optimization tasks.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * (progress_ratio + chaos_param * 0.1)\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (0.5 + 0.5 * chaos_param)\n            CR = self.CR_initial * (0.5 + 0.5 * chaos_param)\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 40, "feedback": "The algorithm HybridAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95344 with standard deviation 0.02253.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9219523974259244, 0.9734456222602552, 0.964918402082075]}}
{"id": "86add29f-0efd-4235-94ce-acce823190af", "fitness": 0.9644402568093166, "name": "HybridChaosDrivenPSO_DE", "description": "Hybrid Chaos-Driven PSO-DE: Integrating chaos theory for dynamic parameter adaptation within a hybrid Particle Swarm Optimization and Differential Evolution framework, improving exploration and convergence.", "code": "import numpy as np\n\nclass HybridChaosDrivenPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (2.5 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (2.5 - self.c2_initial)\n            F = self.F_initial * (0.5 + chaos_param / 2)  # Modified for deeper exploration\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 41, "feedback": "The algorithm HybridChaosDrivenPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96444 with standard deviation 0.00506.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9709363264235114, 0.9637778056096037, 0.9586066383948344]}}
{"id": "99254923-6a57-42dc-b97f-d776d4dc30ce", "fitness": 0.9549963679389908, "name": "AdvancedChaoticDynPSO_DE", "description": "AdvancedChaoticDynPSO-DE: A refined hybrid algorithm blending chaotic dynamics and adaptive strategies in PSO and enhanced DE for optimal convergence and exploration.", "code": "import numpy as np\n\nclass AdvancedChaoticDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def chaotic_map(self, x):\n        return np.sin(np.pi * x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.chaotic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (0.5 + chaos_param / 2)  # Adjusted F for more exploration\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 42, "feedback": "The algorithm AdvancedChaoticDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95500 with standard deviation 0.02656.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9762956655033047, 0.9711392058782014, 0.9175542324354664]}}
{"id": "dc2d8b12-08a1-4090-8b2f-314b4d1e9915", "fitness": 0.9351446251112971, "name": "HybridChaosPSO_DE", "description": "HybridChaosPSO_DE: A refined algorithm that integrates chaotic sequences and adaptive parameter control to enhance exploration and convergence efficiency.", "code": "import numpy as np\n\nclass HybridChaosPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (2.5 - self.c1_initial)  # Modified\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (1.0 - self.c2_initial)  # Modified\n            F = self.F_initial * (1.0 + 0.5 * chaos_param)  # Modified\n            CR = self.CR_initial * (1.0 - 0.5 * chaos_param)  # Modified\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 43, "feedback": "The algorithm HybridChaosPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93514 with standard deviation 0.01782.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9285101132142448, 0.9174020670267242, 0.9595216950929226]}}
{"id": "a8d60c73-c388-4b9b-bb80-e7d17d4c1c3a", "fitness": -Infinity, "name": "EnhancedAdaptiveDynPSO_VL", "description": "EnhancedAdaptiveDynPSO-VL: Integrates velocity limit and chaotic mutation step to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_VL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.vel_limit = 0.1 * (func.bounds.ub - func.bounds.lb)  # Velocity limit\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def chaotic_mutation(self, x):\n        return x + np.random.uniform(-0.1, 0.1, self.dim)  # Chaotic step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            velocity = np.clip(velocity, -self.vel_limit, self.vel_limit)\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = self.chaotic_mutation(mutant)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 44, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {}}
{"id": "07783331-c5ef-4c3f-ac84-4a16665f56c8", "fitness": 0.9774965855634665, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Introduced adaptive chaos-based scaling for dynamic parameter adjustment to enhance exploration and convergence.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param * (1 + 0.5 * progress_ratio)  # Changed\n            CR = self.CR_initial * chaos_param * (1 + 0.5 * progress_ratio)  # Changed\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97750 with standard deviation 0.01133.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784517498378682, 0.9908679677121588, 0.9631700391403724]}}
{"id": "e48a912b-b92b-4e38-857e-7b83de6fd871", "fitness": 0.38499253540187955, "name": "EnhancedAdaptiveDynPSO_SA", "description": "EnhancedAdaptiveDynPSO-SA: Integrates simulated annealing into adaptive PSO-DE for improved exploration and convergence through temperature-based probability controls.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n        self.temperature_initial = 100  # Initial temperature for SA\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def simulated_annealing_acceptance(self, candidate_value, current_value, temperature):\n        if candidate_value < current_value:\n            return True\n        else:\n            return np.random.rand() < np.exp((current_value - candidate_value) / temperature)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            temperature = self.temperature_initial * (1 - progress_ratio)\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if self.simulated_annealing_acceptance(trial_value, personal_best_values[i], temperature):\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveDynPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38499 with standard deviation 0.41574.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9729013998445795, 0.09664847802220988, 0.08542772833884937]}}
{"id": "5295bbec-c625-474d-9406-eceea3941ddb", "fitness": 0.9502164318625961, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO_DE with Self-Adaptive Chaos-driven Exploration: Incorporating chaotic maps for self-adaptive exploration dynamics to enhance diversity and prevent premature convergence for improved solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_params = np.random.rand(self.population_size)\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_params = self.logistic_map(chaos_params)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_params * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_params * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_params\n            CR = self.CR_initial * chaos_params\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1[:, None] * r1 * (personal_best - population) +\n                        c2[:, None] * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR[i], mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95022 with standard deviation 0.00868.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9564234062183451, 0.956286357726843, 0.9379395316426001]}}
{"id": "d1c713d8-d62f-4408-ae68-cb2ff2ad36bb", "fitness": 0.9656128176252624, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptivePSO_DE with chaotic initialization and hybrid exploration-exploitation strategy to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n    \n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        chaos_param = np.random.rand()\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial + chaos_param * (1 - self.F_initial)\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96561 with standard deviation 0.01183.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9583296292588482, 0.9562148407742886, 0.9822939828426507]}}
{"id": "a59048e9-e1aa-4fe6-8d86-1e1df740c535", "fitness": 0.9403221039640156, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Enhanced integration of chaotic dynamics and hybrid exploration-exploitation strategies for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def tent_map(self, x):  # Added new chaotic map\n        return 2 * x if x < 0.5 else 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.tent_map(chaos_param)  # Switched to tent map for chaotic behavior\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94032 with standard deviation 0.03542.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9763983663939262, 0.8921854446575691, 0.9523825008405511]}}
{"id": "eb280104-9f69-4503-a42d-bd8d0c346a1c", "fitness": 0.7238587526406536, "name": "EnhancedAdaptiveDynPSO_DE_Chaos", "description": "EnhancedAdaptiveDynPSO-DE-Chaos: Incorporates multi-chaotic maps for diversified exploration and adaptive parameter tuning to refine global search capabilities.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Chaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n    \n    def tent_map(self, x):\n        return 2 * x if x < 0.5 else 2 * (1 - x)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param_logistic = np.random.rand()\n        chaos_param_tent = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param_logistic = self.logistic_map(chaos_param_logistic)\n            chaos_param_tent = self.tent_map(chaos_param_tent)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param_logistic * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param_tent * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param_logistic\n            CR = self.CR_initial * chaos_param_tent\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_Chaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72386 with standard deviation 0.32039.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9630923350520975, 0.27100409460036545, 0.9374798282694975]}}
{"id": "456b2d38-cecd-4b6c-9acc-809eac1a2400", "fitness": -Infinity, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with chaotic local search and adaptive population size for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.max_population_size = 40\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def chaotic_local_search(self, individual, lb, ub):\n        # Add chaotic perturbation for local search\n        chaos_val = np.random.rand(self.dim)\n        return np.clip(individual + 0.1 * chaos_val, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial = self.chaotic_local_search(trial, lb, ub)\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Adaptive population size adjustment\n            if self.evaluations / self.budget < 0.5:\n                self.population_size = min(self.max_population_size, self.population_size + 1)\n\n        return global_best", "configspace": "", "generation": 51, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,45) (20,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,45) (20,45) ')", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {}}
{"id": "fa5f4527-6f62-4911-9174-67563d11f109", "fitness": 0.9101287387728227, "name": "ImprovedChaoticHybridPSO_DE", "description": "ImprovedChaoticHybridPSO-DE: Introduces chaotic maps and adaptive nonlinear strategies to enhance convergence and exploration balance in a hybrid PSO-DE framework.", "code": "import numpy as np\n\nclass ImprovedChaoticHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def sinusoidal_map(self, x):\n        return np.mod(np.sin(np.pi * x), 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.sinusoidal_map(chaos_param)\n            progress_ratio = np.sqrt(self.evaluations / self.budget)\n            w = self.w_initial * (1 - progress_ratio) + self.w_final * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * progress_ratio\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (1 - progress_ratio)\n            F = self.F_initial * chaos_param * (1 - progress_ratio)\n            CR = self.CR_initial * chaos_param * progress_ratio\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 52, "feedback": "The algorithm ImprovedChaoticHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91013 with standard deviation 0.06639.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9291275350810984, 0.9802629260042962, 0.8209957552330737]}}
{"id": "256dfc1f-3795-47e3-b116-5c2bfc9f7ab4", "fitness": 0.9403221039640156, "name": "EnhancedHybridChaoticPSO_DE", "description": "EnhancedHybridChaoticPSO-DE: A refined hybrid optimization algorithm blending chaotic maps and adaptive strategies within PSO and DE frameworks for efficient global search.", "code": "import numpy as np\n\nclass EnhancedHybridChaoticPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def tent_map(self, x):\n        return 2 * x if x < 0.5 else 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.tent_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridChaoticPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94032 with standard deviation 0.03542.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9763983663939262, 0.8921854446575691, 0.9523825008405511]}}
{"id": "72eb46bc-c6d8-4a28-8bc5-8f378f908a00", "fitness": 0.9398704154838317, "name": "EnhancedAdaptiveDynPSO_DE_Improved", "description": "EnhancedAdaptiveDynPSO_DE with chaotic maps and adaptive mutation to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def tent_map(self, x):\n        return 2 * x if x < 0.5 else 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.tent_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (0.5 + 0.5 * np.sin(np.pi * chaos_param))\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93987 with standard deviation 0.03167.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9759808190851049, 0.9447558058785945, 0.8988746214877955]}}
{"id": "db77bc5d-8c09-4932-9e6f-77d974fd5726", "fitness": 0.9407817308297314, "name": "ChaoticDynamicPSO_DE", "description": "ChaoticDynamicPSO_DE: Integrates chaotic maps with adaptive learning rates in a hybrid PSO-DE framework to enhance exploration and exploitation dynamics for improved convergence.", "code": "import numpy as np\n\nclass ChaoticDynamicPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def tent_map(self, x):\n        return 2 * x if x < 0.5 else 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment with chaotic maps\n            chaos_param = self.logistic_map(chaos_param)\n            chaos_param2 = self.tent_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param2 * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param2\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 55, "feedback": "The algorithm ChaoticDynamicPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94078 with standard deviation 0.00778.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9434178405999981, 0.9487086219862303, 0.9302187299029658]}}
{"id": "a3bf57ca-6c62-490c-9694-104acebc70a3", "fitness": 0.6969984826931066, "name": "ImprovedEnhancedAdaptiveDynPSO_DE", "description": "ImprovedEnhancedAdaptiveDynPSO-DE: Introduces adaptive velocity clamping and diversity promotion to enhance exploration and convergence.", "code": "import numpy as np\n\nclass ImprovedEnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n        self.velocity_clamp_factor = 0.1  # New: Velocity clamp factor\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            \n            # New: Apply velocity clamping\n            velocity = np.clip(velocity, -self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb))\n\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # New: Diversity promotion\n            if np.allclose(population.std(axis=0), 0, atol=1e-4):\n                population += np.random.uniform(-0.1, 0.1, population.shape)\n\n        return global_best", "configspace": "", "generation": 56, "feedback": "The algorithm ImprovedEnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69700 with standard deviation 0.37228.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9288407642840117, 0.9904317764675337, 0.17172290732777462]}}
{"id": "33724261-70bf-48e0-8023-628ca68d223c", "fitness": -Infinity, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO_DE with adaptive population size and chaos-enhanced differential evolution for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.base_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            if progress_ratio < 0.5:  # Increase exploration in the first half\n                population_size = min(int(self.base_population_size * 1.5), 40)\n            else:  # Increase exploitation in the second half\n                population_size = max(int(self.base_population_size * 0.5), 10)\n            \n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 57, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (30,45) (20,45) ').", "error": "ValueError('operands could not be broadcast together with shapes (30,45) (20,45) ')", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {}}
{"id": "f8cb1a82-18f4-48b7-b9f1-e593de03f720", "fitness": 0.7280531264646192, "name": "EnhancedAdaptiveDynPSO_DE_Chaos_Crowding", "description": "EnhancedAdaptiveDynPSO-DE with Chaos Crowding: Integrates dynamic parameter adjustment with chaos theory and crowding distance to maintain diversity and enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Chaos_Crowding:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def crowding_distance(self, population):\n        distances = np.zeros(self.population_size)\n        sorted_idx = np.argsort([np.linalg.norm(ind) for ind in population])\n        for i in range(1, self.population_size - 1):\n            distances[sorted_idx[i]] = (np.linalg.norm(population[sorted_idx[i + 1]] - population[sorted_idx[i - 1]]))\n        distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n        return distances\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            crowding_distances = self.crowding_distance(population)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i] or crowding_distances[i] == float('inf'):\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_Chaos_Crowding got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72805 with standard deviation 0.35791.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.971278091020732, 0.9908679677121588, 0.22201332066096668]}}
{"id": "301bfa12-b2e4-4161-8218-34e0d3eae156", "fitness": -Infinity, "name": "EnhancedAdaptiveDynPSO_DE_Levy", "description": "EnhancedAdaptiveDynPSO_DE_Lévy: Integrates Lévy flights in exploration for a more diverse search with adaptive dynamic parameters.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n\n            # Particle Swarm Optimization with Levy Flight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            levy_step = self.levy_flight(self.dim)  # Added Lévy flight\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population)) + levy_step\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 59, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {}}
{"id": "85efeed3-7040-4b39-b8cc-ea2d3efbfc0b", "fitness": 0.9434179158327968, "name": "EnhancedAdaptiveDynPSO_DE_v2", "description": "EnhancedAdaptiveDynPSO-DE_v2: A refined hybrid algorithm improving convergence by introducing Lévy flight and adaptive chaotic mutation to optimize exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n    \n    def levy_flight(self, L):\n        # Levy flight for exploration\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.power(np.fabs(v), 1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2) + self.levy_flight(F)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94342 with standard deviation 0.02769.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9819752949216658, 0.9182134121940589, 0.9300650403826655]}}
{"id": "4e3489a9-4429-4c57-86a6-9f408aa8536b", "fitness": 0.8761616227672758, "name": "EnhancedAdaptiveDynPSO_DE_OBL", "description": "EnhancedAdaptiveDynPSO-DE with Opposition-Based Learning: An advanced algorithm incorporating opposition-based learning to enhance exploration and exploitative capabilities for improved convergence in complex optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_OBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def opposition_based_learning(self, population, lb, ub):\n        opposite_population = lb + ub - population\n        opposite_population = np.clip(opposite_population, lb, ub)\n        return opposite_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Opposition-Based Learning\n            opposite_population = self.opposition_based_learning(population, lb, ub)\n            opposite_values = np.array([func(ind) for ind in opposite_population])\n            self.evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if opposite_values[i] < personal_best_values[i]:\n                    personal_best[i], personal_best_values[i] = opposite_population[i], opposite_values[i]\n                    if opposite_values[i] < global_best_value:\n                        global_best, global_best_value = opposite_population[i], opposite_values[i]\n\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_OBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87616 with standard deviation 0.01820.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.8505038200826185, 0.8872356012727844, 0.8907454469464247]}}
{"id": "c6fd4539-087f-4484-acdf-3d576828528e", "fitness": 0.7054765219703084, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Introducing a small stochastic adjustment to the crossover probability (CR) enhances diversity and exploration, improving convergence in the DE component.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param + np.random.uniform(-0.1, 0.1, self.population_size)  # Adjusted CR\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR[i], mutant, population[i])  # Adjusted\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70548 with standard deviation 0.33926.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9384796711879103, 0.22575405365306178, 0.9521958410699536]}}
{"id": "edb7d985-e379-4f95-81ec-d267c3e17b68", "fitness": 0.6480618874378778, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Integration of Lévy flight perturbation for enriched exploration and convergence in EnhancedAdaptiveDynPSO-DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def levy_flight(self, L, size):\n        u = np.random.randn(size) * L**(-1/3)\n        return u\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                # Apply Lévy flight perturbation\n                trial += self.levy_flight(0.01, self.dim) \n                trial_value = func(np.clip(trial, lb, ub))\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64806 with standard deviation 0.32744.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9408190700117898, 0.1909650513071014, 0.8124015409947425]}}
{"id": "f3dbe80a-24be-4c41-aff6-1011de0b9ff3", "fitness": 0.9800367504362107, "name": "HybridChaoDynPSO_DE", "description": "HybridChaoDynPSO-DE: Incorporates a chaotic sequence and adaptive learning mechanism to enhance search space exploration and exploit the best solutions in PSO-DE hybrids.", "code": "import numpy as np\n\nclass HybridChaoDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def chaotic_sequence(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment with chaos\n            chaos_param = self.chaotic_sequence(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 64, "feedback": "The algorithm HybridChaoDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "e76e35f0-cb7f-4fd7-8bf4-dce293e5b38c", "fitness": 0.9362383794103728, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with chaotic local search integration for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def chaotic_local_search(self, solution, lb, ub):\n        chaos = np.sin(1 / (np.random.rand(self.dim) + 1e-10))\n        new_solution = solution + chaos * 0.1\n        return np.clip(new_solution, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations % (self.population_size // 2) == 0:\n                    local_search_solution = self.chaotic_local_search(global_best, lb, ub)\n                    local_search_value = func(local_search_solution)\n                    self.evaluations += 1\n                    if local_search_value < global_best_value:\n                        global_best = local_search_solution\n                        global_best_value = local_search_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93624 with standard deviation 0.03408.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9816972556783545, 0.8996394463985903, 0.9273784361541735]}}
{"id": "069619f8-4d79-489c-8316-fedf2f277110", "fitness": 0.9338999269057098, "name": "HybridDynAdaptivePSO_DE_Levy", "description": "Hybrid Dynamic Adaptive PSO-DE with Lévy Flights: Integrates dynamic parameter adaptation and enhanced exploration using Lévy flight patterns for improved global optimization performance.", "code": "import numpy as np\n\nclass HybridDynAdaptivePSO_DE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n        self.levy_beta = 1.5\n        \n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n    \n    def levy_flight(self, size):\n        sigma_u = (np.math.gamma(1 + self.levy_beta) * \n                   np.sin(np.pi * self.levy_beta / 2) /\n                   (np.math.gamma((1 + self.levy_beta) / 2) * \n                   self.levy_beta * 2 ** ((self.levy_beta - 1) / 2))) ** (1 / self.levy_beta)\n        sigma_v = 1\n        u = np.random.normal(0, sigma_u, size)\n        v = np.random.normal(0, sigma_v, size)\n        step = u / abs(v) ** (1 / self.levy_beta)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2) + self.levy_flight(self.dim)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 66, "feedback": "The algorithm HybridDynAdaptivePSO_DE_Levy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93390 with standard deviation 0.05227.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9812348389572503, 0.9594032021069482, 0.8610617396529308]}}
{"id": "8f2f8900-ff01-4afd-aba4-ded319b4181d", "fitness": 0.7087160398493002, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with Self-adaptive Parameters: Integrating self-adaptive learning and mutation strategies to dynamically optimize parameter settings for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n                        # Self-adaptive parameter adjustment\n                        self.c1_initial = np.clip(self.c1_initial * 0.99 + 0.01 * np.random.rand(), 1.5, 2.5)\n                        self.c2_initial = np.clip(self.c2_initial * 0.99 + 0.01 * np.random.rand(), 0.4, 1.5)\n                        self.F_initial = np.clip(self.F_initial * 0.99 + 0.01 * np.random.rand(), 0.5, 0.9)\n                        self.CR_initial = np.clip(self.CR_initial * 0.99 + 0.01 * np.random.rand(), 0.7, 1.0)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70872 with standard deviation 0.35776.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9825086608211598, 0.9402812842535312, 0.20335817447320947]}}
{"id": "9491d1f6-5de2-4d14-9c29-0f8b50533f1e", "fitness": 0.9662818279106653, "name": "ImprovedAdaptiveDynPSO_DE", "description": "ImprovedAdaptiveDynPSO-DE with Adaptive Differential Mutation: A refined algorithm incorporating adaptive differential mutation and chaos-driven learning for enhanced exploration and convergence stability.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_min = 0.5\n        self.F_max = 1.0\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_min + chaos_param * (self.F_max - self.F_min)\n            CR = self.CR_initial * chaos_param\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 68, "feedback": "The algorithm ImprovedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96628 with standard deviation 0.01596.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9702548897173501, 0.983535734253074, 0.9450548597615719]}}
{"id": "38566bc7-3663-4e7d-a92f-54e166058cb6", "fitness": 0.9403221039640156, "name": "ChaosEnhancedAdaptiveDynPSO_DE", "description": "Chaos-Enhanced Adaptive DynPSO-DE: Integrates chaotic maps and adaptive parameter control in PSO and DE for dynamic exploration and convergence improvements.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def tent_map(self, x):\n        return 2 * x if x < 0.5 else 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.tent_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 69, "feedback": "The algorithm ChaosEnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94032 with standard deviation 0.03542.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9763983663939262, 0.8921854446575691, 0.9523825008405511]}}
{"id": "91f0c260-314e-4357-99ab-0454ce5c9f4e", "fitness": 0.9577853253225221, "name": "QuantumInspiredEnhancedPSO_DE", "description": "Quantum-Inspired Enhanced PSO-DE: Integrates quantum-inspired mechanisms with adaptive parameters for improved exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass QuantumInspiredEnhancedPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def quantum_perturbation(self, position, global_best, lb, ub):\n        beta = 0.05  # Quantum perturbation factor\n        new_position = position + beta * (np.random.rand(self.dim) - 0.5) * (global_best - position)\n        return np.clip(new_position, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial = self.quantum_perturbation(trial, global_best, lb, ub)\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 70, "feedback": "The algorithm QuantumInspiredEnhancedPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95779 with standard deviation 0.00965.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.957339871465305, 0.9461990826728988, 0.9698170218293625]}}
{"id": "c65570ab-f350-4121-94b8-8263769da6e2", "fitness": 0.9577943642312817, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Improved parameter adaptation by introducing a nonlinear time-varying chaos-based mutation factor adjustment to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (1 - np.sin(progress_ratio * np.pi / 2))  # Nonlinear adjustment\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95779 with standard deviation 0.02239.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9609508677723636, 0.9835024046446085, 0.9289298202768728]}}
{"id": "35f51cc4-e2e0-4fc7-a85c-0c7f96d2a7d6", "fitness": 0.9582384349809363, "name": "EnhancedAdaptiveDynPSO_DE_v2", "description": "EnhancedAdaptiveDynPSO_DE_v2: Introduces adaptive velocity scaling and chaotic sequence tuning for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n        self.velocity_scaling_factor = 0.5  # Additional velocity scaling factor\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            velocity *= self.velocity_scaling_factor  # Apply additional velocity scaling\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95824 with standard deviation 0.00455.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9551478908192793, 0.9548904966776323, 0.9646769174458973]}}
{"id": "223534cd-58c0-49b8-b6ce-f0f09d44dbd8", "fitness": 0.9800367504362107, "name": "EnhancedAdaptiveDynPSO_DE_ALR", "description": "EnhancedAdaptiveDynPSO-DE-ALR: An advanced optimizer integrating adaptive learning rates and a chaotic logistic map to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_ALR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_ALR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "00a1fb37-c447-4453-a727-b694a3004615", "fitness": 0.7196857595416724, "name": "EnhancedAdaptiveDynPSO_DE_Perturbation", "description": "EnhancedAdaptiveDynPSO_DE_Perturbation: Incorporates a perturbation mechanism to escape local optima and improve convergence by dynamically adjusting strategy parameters based on performance feedback.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Perturbation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n        self.perturbation_factor = 0.05  # New perturbation factor\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n        last_best_value = global_best_value\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Perturbation mechanism: escape local optima\n            if abs(last_best_value - global_best_value) < 1e-6:\n                perturbation = np.random.uniform(-self.perturbation_factor, self.perturbation_factor, self.dim)\n                population += perturbation\n                population = np.clip(population, lb, ub)\n            last_best_value = global_best_value\n\n        return global_best", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_Perturbation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71969 with standard deviation 0.35959.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9566629622262286, 0.9908679677121588, 0.21152634868662956]}}
{"id": "bee5e543-8827-4c1a-95be-121bd5acd772", "fitness": 0.9192139830346727, "name": "EnhancedAdaptiveDynPSO_DEv2", "description": "EnhancedAdaptiveDynPSO_DEv2: An improved adaptive hybrid algorithm leveraging chaotic maps and adaptive learning for enhanced global search and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def sinusoidal_map(self, x):\n        return 2.3 * np.sin(np.pi * x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment using chaos maps\n            chaos_param = self.sinusoidal_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91921 with standard deviation 0.03231.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9648563637086609, 0.8981469818129066, 0.8946386035824507]}}
{"id": "ff7e6508-6192-402c-ba8c-bb97587760f0", "fitness": -Infinity, "name": "EnhancedAdaptiveDynPSO_DE_Levy", "description": "EnhancedAdaptiveDynPSO_DE with Lévy Flight: Integrates dynamic parameter tuning and differential evolution with Lévy flight for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity + self.levy_flight(self.dim)\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 76, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {}}
{"id": "0889a04b-d5a6-4358-8c2d-733b21f38087", "fitness": 0.4339594376635774, "name": "EnhancedChaosDrivenPSO_DE", "description": "Enhanced Chaos-driven PSO-DE: Introducing adaptive chaotic perturbations and a differential mutation scope for more robust and efficient exploration.", "code": "import numpy as np\n\nclass EnhancedChaosDrivenPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n        self.chaos_param = np.random.rand()\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = self.chaos_param\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - chaos_param) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (1 + chaos_param)\n            CR = self.CR_initial * (1 - chaos_param) + 0.1  # Ensure CR doesn't drop too low\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2 + chaos_param * (global_best - x0))\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedChaosDrivenPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43396 with standard deviation 0.35831.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.26518187901007784, 0.9321257256202774, 0.10457070836037707]}}
{"id": "1895b3a7-dfae-4b65-9ae8-aa41e3ac8a5f", "fitness": 0.9800367504362107, "name": "EnhancedAdaptiveDynPSO_DEC", "description": "EnhancedAdaptiveDynPSO-DE-C: An improved algorithm with chaotic logistic map for dynamic parameter adaptation and hybrid PSO-DE integration for superior convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DEC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment with chaotic mapping\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DEC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "d90cdeee-c311-4911-b3e9-cbabca1f74d7", "fitness": 0.9800367504362107, "name": "ChaosDrivenDynAdaptivePSO_DE", "description": "Chaos-Driven Dynamic Adaptive PSO-DE: A refined hybrid algorithm employing logistic chaos for enhanced parameter tuning and synergistic PSO-DE operations for improved convergence and exploration.", "code": "import numpy as np\n\nclass ChaosDrivenDynAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment using chaos\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # PSO update with chaos-enhanced velocity\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # DE update with chaos-driven trial vector generation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 79, "feedback": "The algorithm ChaosDrivenDynAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "a9bbf137-59ea-4b07-832d-c2c8ff6963de", "fitness": 0.9102932791184476, "name": "EnhancedDynPSO_DE_StochasticRanking", "description": "EnhancedDynPSO_DE with Stochastic Ranking: Integrates stochastic ranking to balance exploration-exploitation trade-off by encouraging diversity and reducing premature convergence.", "code": "import numpy as np\n\nclass EnhancedDynPSO_DE_StochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n        self.sr_probability = 0.45  # Probability for stochastic ranking\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def stochastic_ranking(self, population, values):\n        size = len(population)\n        for i in range(size):\n            for j in range(size - 1):\n                rand = np.random.rand()\n                if (rand < self.sr_probability and values[j] > values[j + 1]) or (\n                    rand >= self.sr_probability and np.linalg.norm(population[j]) > np.linalg.norm(population[j + 1])):\n                    population[j], population[j + 1] = population[j + 1], population[j]\n                    values[j], values[j + 1] = values[j + 1], values[j]\n        return population, values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Apply stochastic ranking\n            population, personal_best_values = self.stochastic_ranking(population, personal_best_values)\n\n        return global_best", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedDynPSO_DE_StochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91029 with standard deviation 0.08654.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9797889634074782, 0.9627871338346872, 0.7883037401131775]}}
{"id": "6cd1efcf-47fe-4ca3-b0ed-7f857aedd7a1", "fitness": 0.962769684889304, "name": "HybridDynamicPSO_DE", "description": "HybridDynamicPSO_DE: Integrates a refined chaotic dynamic strategy and adaptive learning rates with a hybridization of PSO and DE for enhanced search efficiency and convergence.", "code": "import numpy as np\n\nclass HybridDynamicPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.chaotic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial * (1 - progress_ratio) + self.w_final * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (2.5 - self.c1_initial)\n            c2 = self.c2_initial * progress_ratio + chaos_param * (2.5 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * (1 - progress_ratio)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 81, "feedback": "The algorithm HybridDynamicPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96277 with standard deviation 0.01763.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9379407970509084, 0.9770964529430843, 0.9732718046739193]}}
{"id": "94f17848-7629-4a33-8a09-23643f27b123", "fitness": 0.9800367504362107, "name": "HybridDynamicPSO_DE", "description": "HybridDynamicPSO-DE: A hybrid algorithm leveraging dynamic chaos-based parameter adaptation and multi-leader DE to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass HybridDynamicPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best_indices = np.argsort(personal_best_values)[:3]\n        global_best_values = personal_best_values[global_best_indices]\n        global_bests = personal_best[global_best_indices]\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_bests[0] - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_values[0]:\n                        global_bests[0] = trial\n                        global_best_values[0] = trial_value\n                        sorted_indices = np.argsort(global_best_values)\n                        global_bests = global_bests[sorted_indices]\n                        global_best_values = global_best_values[sorted_indices]\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_bests[0]", "configspace": "", "generation": 82, "feedback": "The algorithm HybridDynamicPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "8ec70bcb-ebdb-4021-856a-434e670eb31c", "fitness": 0.9119964797280998, "name": "AdaptiveChaoticHybridPSO_DE", "description": "AdaptiveChaoticHybridPSO-DE: This improved hybrid algorithm leverages adaptive chaotic maps for fine-tuning inertia, learning parameters, and DE parameters, enhancing exploration and convergence balance.", "code": "import numpy as np\n\nclass AdaptiveChaoticHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_max = 0.9  # Max Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def chaotic_map(self, x):\n        return np.sin(np.pi * x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment with chaotic map\n            chaos_param = self.chaotic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_max * chaos_param\n            CR = self.CR_initial * (0.5 + 0.5 * chaos_param)\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 83, "feedback": "The algorithm AdaptiveChaoticHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91200 with standard deviation 0.02710.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.923647478320625, 0.8745479102336594, 0.937794050630015]}}
{"id": "65121707-545a-451c-9888-de0599566411", "fitness": 0.7066883476745563, "name": "EnhancedAdaptiveDynPSO_PLUS", "description": "EnhancedAdaptiveDynPSO_PLUS: An advanced hybrid algorithm leveraging dynamic chaotic maps for enhanced exploration and a novel local search strategy for better exploitation to improve convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_PLUS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def chaotic_map(self, x):\n        a = 3.67  # Adjusted parameter for chaotic map\n        return a * x * (1 - x)\n\n    def local_search(self, individual, func, lb, ub):\n        \"\"\"Performs a simple local search to refine solutions.\"\"\"\n        perturbed = individual + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n        perturbed = np.clip(perturbed, lb, ub)\n        if func(perturbed) < func(individual):\n            return perturbed\n        return individual\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.chaotic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Apply local search to a subset of individuals\n            for i in range(int(self.population_size * 0.2)):\n                individual_index = np.random.randint(0, self.population_size)\n                refined = self.local_search(personal_best[individual_index], func, lb, ub)\n                refined_value = func(refined)\n                self.evaluations += 1\n                if refined_value < personal_best_values[individual_index]:\n                    personal_best[individual_index] = refined\n                    personal_best_values[individual_index] = refined_value\n                    if refined_value < global_best_value:\n                        global_best = refined\n                        global_best_value = refined_value\n\n        return global_best", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveDynPSO_PLUS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70669 with standard deviation 0.35137.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9786262873683799, 0.9309025490765851, 0.2105362065787041]}}
{"id": "8d7fdbe9-6784-4aec-928d-c1c9a394ea75", "fitness": 0.9700289947584461, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Introduced adaptive chaotic factors for dynamic control of DE parameters to enhance exploration capabilities. ", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (1.0 + 0.1 * np.sin(chaos_param * np.pi))  # Adjusted line\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97003 with standard deviation 0.01642.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784317197499454, 0.984574416080112, 0.947080848445281]}}
{"id": "0df73012-d91d-42fa-92bf-e343777d2a74", "fitness": 0.9535801098778184, "name": "ChaoticAdaptivePSO_DE", "description": "ChaoticAdaptivePSO-DE: A refined integration of chaotic maps for dynamic parameter control, enhancing exploration and convergence in mixed PSO-DE strategies.", "code": "import numpy as np\n\nclass ChaoticAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def sin_map(self, x):\n        return 0.5 * (np.sin(np.pi * x) + 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment using chaotic maps\n            chaos_param = self.sin_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 86, "feedback": "The algorithm ChaoticAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95358 with standard deviation 0.00989.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9670089662364291, 0.9502568799346751, 0.9434744834623507]}}
{"id": "5cfb3972-05c6-41aa-bff9-dfb20120d186", "fitness": 0.8279403586107629, "name": "EnhancedChaosHybridPSO_DE", "description": "EnhancedChaosHybridPSO_DE: An advanced algorithm integrating chaotic dynamic inertia and parameter adaptation with hybridization of PSO and DE for robust exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedChaosHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment with chaos\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity_update = (w * velocity +\n                               c1 * r1 * (personal_best - population) +\n                               c2 * r2 * (global_best - population))\n            population_update = np.clip(population + velocity_update, lb, ub)\n            \n            # Hybrid PSO and DE update\n            for i in range(self.population_size):\n                if np.random.rand() < 0.5:\n                    # Use PSO update\n                    trial = population_update[i]\n                else:\n                    # Use DE update\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F * (x1 - x2)\n                    mutant = np.clip(mutant, lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedChaosHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82794 with standard deviation 0.10079.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.690498876679432, 0.9293847552158679, 0.8639374439369887]}}
{"id": "5bf87a97-d31c-4e74-882b-a2a00d1d5eee", "fitness": 0.7294144632670231, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Improved parameter adjustment by modifying chaos mechanism to enhance convergence and reduce stagnation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = np.sin(self.logistic_map(chaos_param))  # Modified chaos mechanism\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72941 with standard deviation 0.35748.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9734114955030351, 0.9908679677121588, 0.22396392658587516]}}
{"id": "f26a5c4e-2a47-440b-8e2b-b02ca2dd1ec5", "fitness": 0.945502724501632, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with chaotic perturbations and adaptive mutation scaling for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n    \n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (0.5 + chaos_param * 0.5) # Adjusted scaling factor\n            CR = self.CR_initial * (0.5 + chaos_param * 0.5) # Adjusted crossover rate\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94550 with standard deviation 0.00909.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9376116263007727, 0.9582423126125587, 0.9406542345915648]}}
{"id": "0a5b1d3c-7bf4-44d3-a41c-2fbe2f8456e5", "fitness": 0.9523194970316483, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with hybrid velocity update, introducing an additional chaotic component for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n        \n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population) +\n                        chaos_param * (np.random.rand(self.population_size, self.dim) - 0.5))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95232 with standard deviation 0.01966.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9800406130171444, 0.9402895686828616, 0.9366283093949388]}}
{"id": "68fb48a5-865e-4046-b46f-b71f5ed8dfa2", "fitness": 0.9607256240654577, "name": "HybridAdaptivePSO_DE", "description": "HybridAdaptivePSO-DE: A novel hybrid algorithm that integrates chaotic maps for parameter adaptation and dynamic local search intensification to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def dynamic_local_search(self, individual, func, lb, ub):\n        perturbation_strength = 0.1 * (ub - lb)\n        trial = individual + np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n        trial = np.clip(trial, lb, ub)\n        trial_value = func(trial)\n        self.evaluations += 1\n        return trial, trial_value\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n                        global_best, global_best_value = self.dynamic_local_search(global_best, func, lb, ub)\n                \n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 91, "feedback": "The algorithm HybridAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96073 with standard deviation 0.00699.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9660315251361768, 0.9652921375195861, 0.9508532095406103]}}
{"id": "b70b163c-a66b-4cfe-a2f6-87e56c429654", "fitness": -Infinity, "name": "EnhancedAdaptiveDynPSO_DE_2", "description": "EnhancedAdaptiveDynPSO_DE_2: Introduces a Lévy flight-based diversification strategy to improve exploration-exploitation balance and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v)**(1/beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Lévy flight-based diversification\n            if self.evaluations < self.budget:\n                levy_step = self.levy_flight(size=self.dim)\n                new_position = global_best + levy_step\n                new_position = np.clip(new_position, lb, ub)\n                new_value = func(new_position)\n                self.evaluations += 1\n                \n                if new_value < global_best_value:\n                    global_best = new_position\n                    global_best_value = new_value\n\n        return global_best", "configspace": "", "generation": 92, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {}}
{"id": "2c32dc48-170f-4cb4-ae90-81c38a5901f3", "fitness": 0.722336635458456, "name": "EnhancedAdaptiveDynPSO_DE", "description": "EnhancedAdaptiveDynPSO-DE with Adaptive Population Size: Integrating adaptive population size adjustment based on convergence progress to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Adaptive population size\n            self.population_size = max(5, int(20 * (1 - progress_ratio)))\n            population = np.resize(population, (self.population_size, self.dim))\n            velocity = np.resize(velocity, (self.population_size, self.dim))\n            personal_best = np.resize(personal_best, (self.population_size, self.dim))\n            personal_best_values = np.resize(personal_best_values, self.population_size)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72234 with standard deviation 0.36209.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9911147410621837, 0.2104836832304522, 0.9654114820827321]}}
{"id": "ab447b84-2edc-4aea-8b56-d3cd7e1bb168", "fitness": 0.7139147467693844, "name": "EnhancedAdaptiveDynPSO_DE_Refined", "description": "Chaotic and Adaptive Hybrid PSO-DE with Multi-Perturbation: A refined algorithm using chaotic maps, adaptive parameters, and multi-perturbation strategies to enhance exploration and exploitation capabilities for superior optimization performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # DE Update with multi-perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 5, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                x0, x1, x2, x3, x4 = population[indices]\n                mutant = x0 + F * (x1 - x2) + F * (x3 - x4)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71391 with standard deviation 0.36336.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.20058350337815, 0.9908650297053743, 0.950295707224629]}}
{"id": "d530c0d4-bc63-4ad0-b3e3-dddd4b8151e4", "fitness": 0.7140144312125081, "name": "EnhancedAdaptiveDynPSO_DE", "description": "Slightly enhance exploration by tuning initial inertia weight to 0.92 for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.92  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71401 with standard deviation 0.37852.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9723593310801248, 0.9908650297053743, 0.17881893285202521]}}
{"id": "922d62fe-cd04-4cfe-8f9f-3ffad00b02d4", "fitness": 0.9015808958126185, "name": "EnhancedChaoticAdaptivePSO_DE", "description": "EnhancedChaoticAdaptivePSO-DE: A novel hybrid algorithm combining chaotic maps with dynamic adaptive parameters for improved exploration and exploitation in PSO-DE.", "code": "import numpy as np\n\nclass EnhancedChaoticAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def sine_map(self, x):\n        return 2.3 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Chaotic and dynamic parameter adjustment\n            chaos_param = self.sine_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedChaoticAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90158 with standard deviation 0.11475.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9854954208821448, 0.9799141687505105, 0.7393330978052]}}
{"id": "6244af7a-28da-4f3b-8aad-8095dcc40f5b", "fitness": 0.7238587526406536, "name": "ChaoticEnhancedDynPSO_DE", "description": "ChaoticEnhancedDynPSO_DE: Incorporates chaotic maps for adaptive parameter tuning and integrates enhanced differential evolution for improved global convergence.", "code": "import numpy as np\n\nclass ChaoticEnhancedDynPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def tent_map(self, x):\n        return 2 * x if x < 0.5 else 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param1, chaos_param2 = np.random.rand(), np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Chaos-based dynamic parameter adjustment\n            chaos_param1 = self.logistic_map(chaos_param1)\n            chaos_param2 = self.tent_map(chaos_param2)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param1 * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param2 * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param1\n            CR = self.CR_initial * chaos_param2\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 97, "feedback": "The algorithm ChaoticEnhancedDynPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72386 with standard deviation 0.32039.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9630923350520975, 0.27100409460036545, 0.9374798282694975]}}
{"id": "d7a1447c-01c0-446a-86ea-5da501140927", "fitness": 0.9800367504362107, "name": "DynamicHybridPSO_DE", "description": "DynamicHybridPSO-DE: A hybrid algorithm combining dynamically adjusted inertia, cognitive, and social parameters in PSO with adaptive DE employing chaos theory for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8\n        self.CR_initial = 0.9\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            # Dynamic parameter adjustment using chaos\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * chaos_param\n            CR = self.CR_initial * chaos_param\n            \n            # PSO update with adaptive cognitive and social components\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # DE update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 98, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98004 with standard deviation 0.00827.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.9784574776083234, 0.9908679677121588, 0.9707848059881503]}}
{"id": "1e13b68c-2e20-4e09-b2c6-4d63242d654d", "fitness": 0.9450277035453515, "name": "EnhancedAdaptiveDynPSO_DE_Plus", "description": "EnhancedAdaptiveDynPSO-DE-Plus: Integrating chaotic search and adaptive mutation scaling into the existing hybrid PSO-DE framework for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynPSO_DE_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_initial = 0.8  # Initial Mutation factor for DE\n        self.CR_initial = 0.9  # Initial Crossover probability for DE\n        self.evaluations = 0\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        self.evaluations += self.population_size\n        chaos_param = np.random.rand()\n\n        while self.evaluations < self.budget:\n            chaos_param = self.logistic_map(chaos_param)\n            progress_ratio = self.evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress_ratio\n            c1 = self.c1_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c1_initial)\n            c2 = self.c2_initial * (1 - progress_ratio) + chaos_param * (3.0 - self.c2_initial)\n            F = self.F_initial * (0.5 + chaos_param)\n            CR = self.CR_initial * chaos_param\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Chaotic Search\n            if np.random.rand() < chaos_param:\n                random_idx = np.random.randint(self.population_size)\n                chaotic_candidate = lb + (ub - lb) * np.random.rand(self.dim)\n                chaotic_value = func(chaotic_candidate)\n                self.evaluations += 1\n                if chaotic_value < personal_best_values[random_idx]:\n                    personal_best[random_idx] = chaotic_candidate\n                    personal_best_values[random_idx] = chaotic_value\n                    if chaotic_value < global_best_value:\n                        global_best = chaotic_candidate\n                        global_best_value = chaotic_value\n\n        return global_best", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveDynPSO_DE_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94503 with standard deviation 0.03296.", "error": "", "parent_ids": ["bb59941d-ab20-4425-abd4-90176c61a9f9"], "operator": null, "metadata": {"aucs": [0.990185282421631, 0.9324334708079338, 0.9124643574064897]}}
