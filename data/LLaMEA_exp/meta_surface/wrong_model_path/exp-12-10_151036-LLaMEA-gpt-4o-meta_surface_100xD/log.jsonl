{"id": "c26ac09a-a405-4034-9513-22db7b046709", "fitness": 0.3811683526351499, "name": "AdaptiveHybridOptimizer", "description": "An adaptive hybrid metaheuristic combining particle swarm optimization and simulated annealing for efficient black-box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n        \n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38117 with standard deviation 0.38452.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13225940462978358, 0.9243294936025064, 0.0869161596731598]}}
{"id": "c4e01432-a8f4-4a5c-aa44-b27d89a5c107", "fitness": 0.4881071053551222, "name": "EnhancedAdaptiveHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer leveraging dynamic parameter adaptation and a diversity preservation mechanism to improve black-box optimization performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48811 with standard deviation 0.32570.", "error": "", "parent_ids": ["c26ac09a-a405-4034-9513-22db7b046709"], "operator": null, "metadata": {"aucs": [0.48159827011630385, 0.8902246204249304, 0.09249842552413212]}}
{"id": "7edf5284-8b28-4d7e-a983-83c1399e6c56", "fitness": 0.10631593228969034, "name": "RefinedAdaptiveHybridOptimizer", "description": "A refined adaptive hybrid optimizer with dynamic neighborhood adaptation and a quantum-inspired diversity mechanism for enhanced black-box optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.neighborhood_radius = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Quantum-inspired diversity mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                perturbation_radius = np.random.uniform(0, self.neighborhood_radius, self.dim)\n                quantum_particles = global_best + perturbation_radius * (np.random.rand(self.dim) - 0.5)\n                quantum_particles = np.clip(quantum_particles, lb, ub)\n                quantum_value = func(quantum_particles)\n                eval_count += 1\n                \n                if quantum_value < best_value:\n                    global_best = quantum_particles\n                    best_value = quantum_value\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm RefinedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10632 with standard deviation 0.02543.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.1356398446806295, 0.10967986661497953, 0.07362808557346201]}}
{"id": "caf7f9b0-d8c9-4f1e-9a6f-f3c609441c9f", "fitness": 0.4385128709528961, "name": "EnhancedAdaptiveHybridOptimizer", "description": "Introduced a linear decrease in cognitive and social coefficients over time to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n\n            # Linear decrease of coefficients\n            t = eval_count / self.budget\n            self.cognitive_coeff = 1.5 * (1 - t)\n            self.social_coeff = 2.0 * (1 - t)\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43851 with standard deviation 0.28653.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.4630629802901455, 0.7765161850486729, 0.07595944751986983]}}
{"id": "0b48a2b7-dd86-40f4-a2f2-0dd7194601be", "fitness": 0.4151516349199415, "name": "SynergyBasedOptimizer", "description": "A synergy-based optimizer that harmonizes evolutionary strategies and adaptive annealing with a focus on maintaining diversity and improving convergence.", "code": "import numpy as np\n\nclass SynergyBasedOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.9  # Slightly slower cooling rate for more gradual adaptation\n        self.diversity_threshold = 0.1\n        self.mutation_rate = 0.05  # Introduce mutation\n        self.elitism_rate = 0.1  # Preserve top solutions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Mutation operation\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    particles[i] = np.clip(particles[i] + mutation_vector, lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n\n            # Adaptive annealing\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n\n            self.temperature *= self.cooling_rate\n\n            # Diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n\n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n\n            # Elitism - retain best solutions\n            elite_count = int(self.elitism_rate * self.num_particles)\n            elite_indices = np.argsort(personal_best_values)[:elite_count]\n            elite_particles = personal_best[elite_indices]\n            elite_velocities = velocities[elite_indices]\n\n            # Replace worst performing particles with elite\n            worst_indices = np.argsort(personal_best_values)[-elite_count:]\n            particles[worst_indices] = elite_particles\n            velocities[worst_indices] = elite_velocities\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm SynergyBasedOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41515 with standard deviation 0.38526.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.17517787067409452, 0.11152270833826217, 0.9587543257474679]}}
{"id": "9f467b0c-e779-4c3b-96f8-624a98ad7db9", "fitness": 0.7143030039248415, "name": "EnhancedAdaptiveHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer with improved exploration via adaptive velocity scaling and increased diversity through probabilistic particle reset.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Improved diversity preservation mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (self.num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71430 with standard deviation 0.22636.", "error": "", "parent_ids": ["c4e01432-a8f4-4a5c-aa44-b27d89a5c107"], "operator": null, "metadata": {"aucs": [0.8048793974223831, 0.4031147481609765, 0.9349148661911648]}}
{"id": "70ef8831-c972-4cd5-b7c3-2622ab4758eb", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridOptimizerV2", "description": "Introducing a dynamic multi-faceted velocity update mechanism and adaptive population sizing to enhance exploration and exploitation balance in particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = self.initial_particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = num_particles\n        \n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                # Introduce velocity clamping for more stable convergence\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Improved diversity and population size adjustment\n            if np.std(personal_best_values) < self.diversity_threshold:\n                additional_particles = np.random.uniform(lb, ub, (num_particles // 5, self.dim))\n                additional_values = np.array([func(x) for x in additional_particles])\n                eval_count += len(additional_particles)\n                \n                for j, val in enumerate(additional_values):\n                    if val < best_value or np.random.rand() < 0.1:\n                        global_best = additional_particles[j]\n                        best_value = val\n                        break\n                # Increase population size adaptively to escape stagnation\n                num_particles = min(num_particles + num_particles // 10, self.budget - eval_count)\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["9f467b0c-e779-4c3b-96f8-624a98ad7db9"], "operator": null, "metadata": {}}
{"id": "ab80fdd8-96d0-44e0-98d4-fa9b419496bf", "fitness": 0.6147198617272477, "name": "ImprovedHybridOptimizer", "description": "A hybrid optimizer with enhanced local search through quadratic interpolation and improved convergence using adaptive population resizing.", "code": "import numpy as np\n\nclass ImprovedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_num_particles = 50\n        self.max_num_particles = 100\n        self.min_num_particles = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = self.init_num_particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = num_particles\n        \n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adaptation\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired temperature adjustment\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Improved diversity preservation and population adjustment mechanism\n            if np.std(personal_best_values) < self.diversity_threshold:\n                random_particles = np.random.uniform(lb, ub, (num_particles // 5, self.dim))\n                random_values = np.array([func(x) for x in random_particles])\n                eval_count += len(random_particles)\n                \n                for j in range(len(random_particles)):\n                    if random_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = random_particles[j]\n                        best_value = random_values[j]\n                        break\n\n                # Adaptive population resizing\n                num_particles = min(self.max_num_particles, max(self.min_num_particles, num_particles + 5))\n                particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n                velocities = np.zeros((num_particles, self.dim))\n                personal_best = particles.copy()\n                personal_best_values = np.array([func(x) for x in personal_best])\n                eval_count += num_particles - len(personal_best_values)\n        \n        return global_best", "configspace": "", "generation": 7, "feedback": "The algorithm ImprovedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61472 with standard deviation 0.19415.", "error": "", "parent_ids": ["9f467b0c-e779-4c3b-96f8-624a98ad7db9"], "operator": null, "metadata": {"aucs": [0.4038563138260478, 0.8724383831822466, 0.5678648881734487]}}
{"id": "49032317-2983-4a6c-9a8b-242ea1db2f21", "fitness": 0.9122986376703599, "name": "AdvancedParticleOptimizer", "description": "An advanced particle swarm optimizer enhanced with adaptive compression control and elite leader selection to boost convergence and robustness.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91230 with standard deviation 0.01105.", "error": "", "parent_ids": ["9f467b0c-e779-4c3b-96f8-624a98ad7db9"], "operator": null, "metadata": {"aucs": [0.89890730347514, 0.9259770236574656, 0.9120115858784739]}}
{"id": "8c7cba38-713f-4939-9560-380e30529a5a", "fitness": 0.10938737233847666, "name": "QuantumEnhancedParticleOptimizer", "description": "A hybrid optimizer combining Quantum-inspired Particle Swarm with dynamic inertia and enhanced diversity to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass QuantumEnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.warmup = 0.3 * budget\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic inertia weight adjustment\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * (1 - eval_count / self.budget))\n            \n            # Quantum-inspired exploration\n            if eval_count > self.warmup and np.std(personal_best_values) < self.diversity_threshold:\n                Q = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n                quantum_particles = global_best + Q * (particles - global_best)\n                quantum_particles = np.clip(quantum_particles, lb, ub)\n                quantum_values = np.array([func(x) for x in quantum_particles])\n                eval_count += len(quantum_particles)\n\n                for j in range(len(quantum_particles)):\n                    if quantum_values[j] < best_value:\n                        global_best = quantum_particles[j]\n                        best_value = quantum_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm QuantumEnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10939 with standard deviation 0.02824.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.14507556993557724, 0.10705920576646699, 0.07602734131338573]}}
{"id": "007e5016-4889-4874-9135-b89f0bda43a5", "fitness": 0.6903642188737921, "name": "EnhancedParticleSwarmOptimizer", "description": "An enhanced particle swarm optimizer incorporating dynamic neighborhood topology and evolutionary learning for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neighborhood_size = 5  # New parameter for dynamic neighborhood\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Dynamic Neighborhood Selection\n                neighbors = self.get_neighbors(i, self.neighborhood_size)\n                local_best = min(neighbors, key=lambda x: personal_best_values[x])\n\n                r1, r2, r3 = np.random.rand(3)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (personal_best[local_best] - particles[i]))\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n            \n            # Evolutionary Learning Step\n            self.evolutionary_learning(particles, personal_best, lb, ub)\n        \n        return global_best\n    \n    def get_neighbors(self, index, size):\n        # Select neighbors in a cyclic manner\n        return [(index + offset) % self.num_particles for offset in range(-size//2, size//2 + 1) if offset != 0]\n\n    def evolutionary_learning(self, particles, personal_best, lb, ub):\n        # Introduce genetic algorithm inspired crossover\n        for i in range(0, self.num_particles, 2):\n            if i + 1 < self.num_particles:\n                crossover_point = np.random.randint(1, self.dim - 1)\n                parent1, parent2 = personal_best[i], personal_best[i + 1]\n                offspring1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n                offspring2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n                \n                # Mutation\n                if np.random.rand() < self.learning_rate:\n                    mutation_point = np.random.randint(0, self.dim)\n                    offspring1[mutation_point] += np.random.randn()\n                    offspring2[mutation_point] += np.random.randn()\n                \n                particles[i], particles[i + 1] = np.clip(offspring1, lb, ub), np.clip(offspring2, lb, ub)", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69036 with standard deviation 0.20884.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.39648934255916524, 0.8627874994088034, 0.8118158146534077]}}
{"id": "b43d00c9-9011-44d1-8fd2-0696ba476b9a", "fitness": 0.3756364221844562, "name": "AdvancedParticleOptimizer", "description": "An enhanced particle optimizer with adaptive neighborhood strategies for better exploration and convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n            # New adaptive neighborhood strategy\n            if eval_count < self.budget:  # Ensure we are within budget\n                neighborhood_size = np.maximum(1, int(self.num_particles * 0.1))\n                local_best = min(personal_best_values[np.random.choice(self.num_particles, neighborhood_size, replace=False)])\n                if local_best < best_value:\n                    global_best = personal_best[np.argmin(personal_best_values)]\n                    best_value = min(personal_best_values)\n\n        return global_best", "configspace": "", "generation": 11, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37564 with standard deviation 0.15659.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.15759007035014783, 0.518183778181846, 0.4511354180213748]}}
{"id": "652fcd77-356d-481f-ad39-9c36f205a094", "fitness": 0.5274535106187589, "name": "HybridParticleOptimizer", "description": "A hybrid particle swarm optimizer enhanced with adaptive momentum control, elite leader selection, and gradient-based refinement for improved convergence.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.gradient_coeff = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Gradient-based refinement\n                gradient = np.random.normal(size=self.dim)\n                particles[i] = np.clip(particles[i] - self.gradient_coeff * gradient, lb, ub)\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 12, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52745 with standard deviation 0.21946.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.21736414525272763, 0.6937126748641769, 0.6712837117393721]}}
{"id": "5bfe3a3e-fa37-4676-961f-f5b2f05d1995", "fitness": 0.6041123658638026, "name": "HybridParticleEvolutionOptimizer", "description": "Hybrid Particle-Evolution Strategy Optimizer synergizing particle swarm dynamics with differential evolution for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridParticleEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.f = 0.5  # Differential evolution scaling factor\n        self.cr = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Differential Evolution Mutation and Crossover\n                indices = list(range(self.num_particles))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(personal_best[a] + self.f * (personal_best[b] - personal_best[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                trial = np.where(cross_points, mutant, particles[i])\n\n                # Evaluate Trial Individual\n                trial_value = func(trial)\n                eval_count += 1\n\n                # Update Personal Best\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < best_value:\n                        global_best = trial\n                        best_value = trial_value\n\n                # Update Velocity and Position using Particle Swarm\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(trial_value - best_value) / self.temperature):\n                global_best = trial\n                best_value = trial_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 13, "feedback": "The algorithm HybridParticleEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60411 with standard deviation 0.29367.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.6870716403445072, 0.21020751313729702, 0.9150579441096035]}}
{"id": "8c260ac5-b0dc-4c8e-8db7-380de8dd8894", "fitness": 0.7731308060757858, "name": "AdvancedParticleOptimizer", "description": "Improved the diversity threshold check to enhance exploration and diversity preservation.  ", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.05  # Changed from 0.1 to 0.05\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 14, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.77313 with standard deviation 0.06626.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.8446492342255777, 0.7898155577322143, 0.6849276262695654]}}
{"id": "0e1ce0c3-91ae-40a4-a2e0-20d56d72f9f6", "fitness": 0.5983326007252576, "name": "AdvancedParticleOptimizer", "description": "Enhanced adaptive inertia weight adjustment and a new cognitive-social coefficient balance strategy to improve convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.6  # Changed from 1.5 to 1.6\n        self.social_coeff = 1.8  # Changed from 2.0 to 1.8\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 15, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.59833 with standard deviation 0.31617.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.16816156008005934, 0.9190404860940665, 0.7077957560016469]}}
{"id": "3b83f2ae-a6fe-484f-bc84-acb6f2a04bff", "fitness": 0.7087252866616893, "name": "AdvancedParticleOptimizer", "description": "A refined particle swarm optimizer with a hyperbolic tangent adaptive inertia and diversity-enhanced compression to improve convergence and solution quality.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction using hyperbolic tangent\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            self.inertia_weight *= 1 - np.tanh(eval_count / self.budget)\n            \n            # Enhanced diversity preservation with dynamic compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 16, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70873 with standard deviation 0.19136.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.7597843474156261, 0.9133507928074341, 0.453040719762008]}}
{"id": "efdbed68-efa7-4eca-be58-a4a58a0fcfb2", "fitness": 0.4187692571458553, "name": "AdvancedParticleOptimizer", "description": "An advanced particle swarm optimizer with adaptive compression control, elite leader selection, and enhanced velocity update for improved exploration and convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.6  # Changed from 1.5 to 1.6\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                # Enhanced velocity update with particle-specific inertia weight\n                inertia_component = (self.inertia_weight_min + (self.inertia_weight - self.inertia_weight_min) * np.random.rand()) * velocities[i]\n                velocities[i] = (inertia_component +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41877 with standard deviation 0.34946.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.16175189441373305, 0.9128396419410996, 0.18171623508273327]}}
{"id": "7b57a0fc-da7b-4ef6-a1f8-75724603cb7a", "fitness": 0.37366084928486537, "name": "AdvancedParticleOptimizer", "description": "Enhanced convergence strategy by updating cognitive and social coefficients dynamically to speed up optimization.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Dynamic update of cognitive and social coefficients\n                self.cognitive_coeff = 1.5 + 0.5 * np.random.rand()\n                self.social_coeff = 1.5 + 0.5 * np.random.rand()\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 18, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37366 with standard deviation 0.16210.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.1756277586637055, 0.37266134593235123, 0.5726934432585393]}}
{"id": "e708ecba-93fb-4af4-94d7-5fbf57e769ee", "fitness": 0.40165018624169385, "name": "EnhancedParticleOptimizer", "description": "Enhanced Particle Swarm Optimizer with dynamic inertia weight adjustment and multi-leader selection to improve convergence and adaptability.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.inertia_weight_max = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.diversity_threshold = 0.1\n        self.multi_leader_count = 5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        multi_leaders = personal_best[np.argsort(personal_best_values)[:self.multi_leader_count]]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adjustment based on diversity\n            self.inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (eval_count / self.budget)\n            \n            # Multi-leader selection\n            if np.std(personal_best_values) < self.diversity_threshold:\n                indices = np.random.choice(self.num_particles, self.multi_leader_count)\n                multi_leaders = personal_best[indices]\n                global_best = multi_leaders[np.argmin([func(x) for x in multi_leaders])]\n                best_value = func(global_best)\n\n        return global_best", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40165 with standard deviation 0.40085.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.14509284999477323, 0.9677190991055427, 0.0921386096247655]}}
{"id": "ac3ef336-14ca-4fd8-b9a6-10ef1ea48b11", "fitness": 0.7533696570579979, "name": "HybridParticleOptimizer", "description": "A multi-strategy particle optimizer using hybridized exploration-exploitation with dynamic neighborhood adaptation and selective restart to enhance global search efficiency.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neighborhood_size = 5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Determine local best from neighborhood\n                neighborhood = np.random.choice(self.num_particles, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood[np.argmin(personal_best_values[neighborhood])]]\n\n                r1, r2, r3 = np.random.rand(3)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (local_best - particles[i]) +\n                                 self.social_coeff * r3 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n            \n            # Selective restart strategy\n            if eval_count < self.budget and np.random.rand() < 0.05:\n                worst_indices = np.argsort(personal_best_values)[-self.num_particles//5:]\n                particles[worst_indices] = np.random.uniform(lb, ub, (len(worst_indices), self.dim))\n                velocities[worst_indices] = np.zeros((len(worst_indices), self.dim))\n                for idx in worst_indices:\n                    personal_best[idx] = particles[idx]\n                    personal_best_values[idx] = func(particles[idx])\n                    eval_count += 1\n\n        return global_best", "configspace": "", "generation": 20, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75337 with standard deviation 0.15919.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.6345652200089793, 0.9783819886040044, 0.64716176256101]}}
{"id": "d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80", "fitness": 0.9123962494912942, "name": "AdvancedParticleOptimizer", "description": "An advanced particle swarm optimizer enhanced with adaptive compression control, elite leader selection, and modified inertia weight strategy for improved convergence and robustness.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 21, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91240 with standard deviation 0.01117.", "error": "", "parent_ids": ["49032317-2983-4a6c-9a8b-242ea1db2f21"], "operator": null, "metadata": {"aucs": [0.89890730347514, 0.9262698591202685, 0.9120115858784739]}}
{"id": "d0160a99-24ba-4812-9cf8-26e7ae09701a", "fitness": 0.6340538684041046, "name": "AdvancedParticleOptimizer", "description": "Enhanced AdvancedParticleOptimizer with dynamic cognitive and social coefficients for better adaptability and convergence speed.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                # Dynamic adjustment of coefficients\n                self.cognitive_coeff = 1.5 + 0.5 * np.abs(global_best - particles[i]).mean()\n                self.social_coeff = 2.0 - 0.5 * np.abs(global_best - particles[i]).mean()\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 22, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63405 with standard deviation 0.32561.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.18585554718913855, 0.9496592015208998, 0.7666468565022755]}}
{"id": "bdb511ad-9bd5-4a9e-8650-bdbc9d10d319", "fitness": 0.5847222183575905, "name": "AdvancedParticleOptimizer", "description": "Enhanced global convergence by dynamically adjusting social coefficient based on diversity.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n            # Dynamically adjust social coefficient based on diversity\n            self.social_coeff = 2.0 + 3.0 * (1 - np.std(personal_best_values) / self.diversity_threshold)\n\n        return global_best", "configspace": "", "generation": 23, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58472 with standard deviation 0.31034.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.16973871895744663, 0.9159418053257191, 0.6684861307896057]}}
{"id": "705fbe16-4811-485f-bf42-dbfdbedfd9e0", "fitness": 0.8999230500214752, "name": "AdvancedParticleOptimizer", "description": "Improved convergence and robustness through adaptive neighborhood search and inertia weight strategy refinement.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = personal_best + self.compression_factor * np.random.randn(*particles.shape) # Modified\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 24, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89992 with standard deviation 0.01239.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.8992118048563591, 0.8851152712075789, 0.9154420740004876]}}
{"id": "327540ae-51e6-4af7-82fb-a666a8298289", "fitness": -Infinity, "name": "EnhancedParticleOptimizer", "description": "Enhanced Particle Swarm Optimizer with dynamic population scaling, adaptive learning rates, and multi-phase exploration-exploitation balancing for improved adaptation and convergence.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_particles = 50\n        self.max_particles = 100\n        self.min_particles = 25\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.exploration_coeff = 0.3\n        self.exploitation_coeff = 0.7\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = self.initial_particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = num_particles\n        \n        while eval_count < self.budget:\n            exploration_phase = eval_count < self.budget * self.exploration_coeff\n            if exploration_phase:\n                num_particles = min(self.max_particles, num_particles + 1)\n            else:\n                num_particles = max(self.min_particles, num_particles - 1)\n            particles = particles[:num_particles]\n            velocities = velocities[:num_particles]\n            personal_best = personal_best[:num_particles]\n            personal_best_values = personal_best_values[:num_particles]\n\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 25, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {}}
{"id": "c084f280-ec31-44d1-b189-990148fc8e35", "fitness": 0.8551818677184443, "name": "HybridParticleGeneticOptimizer", "description": "A hybrid optimizer incorporating adaptive particle dynamics with a genetic algorithm-inspired crossover and mutation strategy for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridParticleGeneticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.mutation_probability = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n            \n            # Genetic algorithm-inspired crossover and mutation\n            if self.diversity_threshold < np.std(personal_best_values) < 0.2 and eval_count + self.num_particles < self.budget:\n                idx1, idx2 = np.random.choice(self.num_particles, 2, replace=False)\n                crossover_point = np.random.randint(1, self.dim)\n                child = np.concatenate((personal_best[idx1][:crossover_point],\n                                        personal_best[idx2][crossover_point:]))\n                \n                if np.random.rand() < self.mutation_probability:\n                    mutation_idx = np.random.randint(self.dim)\n                    child[mutation_idx] = np.random.uniform(lb[mutation_idx], ub[mutation_idx])\n                \n                child_value = func(child)\n                eval_count += 1\n\n                if child_value < best_value:\n                    global_best = child\n                    best_value = child_value\n\n        return global_best", "configspace": "", "generation": 26, "feedback": "The algorithm HybridParticleGeneticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85518 with standard deviation 0.09064.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.7272641581565906, 0.9262698591202685, 0.9120115858784739]}}
{"id": "4a87a2c3-8fd5-432c-bad8-f5211ed5a1ec", "fitness": 0.11906123307314538, "name": "AdvancedParticleOptimizer", "description": "A refined particle swarm optimizer with enhanced diversity preservation using adaptive velocity scaling.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with adaptive velocity scaling\n            if np.std(personal_best_values) < self.diversity_threshold:\n                velocities *= (1 + self.compression_factor * np.random.rand())\n                compressed_particles = particles + velocities\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 27, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11906 with standard deviation 0.05623.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.1981904867598947, 0.07266402317423026, 0.08632918928531119]}}
{"id": "976b60d0-42c7-4e8c-87d1-8794dc8836ea", "fitness": 0.46306868103262605, "name": "EnhancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with adaptive velocity scaling, periodic re-initialization, and adaptive noise injection for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.reinit_period = 50\n        self.noise_scale = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        iteration = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                velocities[i] *= (1.0 / (1.0 + np.linalg.norm(velocities[i])))  # Adaptive velocity scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n\n            # Periodic re-initialization\n            if iteration % self.reinit_period == 0:\n                elite_fraction = 0.2\n                elite_count = int(self.num_particles * elite_fraction)\n                indices = np.argsort(personal_best_values)\n                particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n                particles[:elite_count] = personal_best[indices[:elite_count]]\n                velocities = np.zeros((self.num_particles, self.dim))\n\n            # Adaptive noise injection for diversity\n            if np.std(personal_best_values) < self.diversity_threshold:\n                noise = self.noise_scale * np.random.randn(*particles.shape)\n                particles += noise\n                particles = np.clip(particles, lb, ub)\n\n            iteration += 1\n\n        return global_best", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46307 with standard deviation 0.29945.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.40908272698103265, 0.8538184082801732, 0.12630490783667225]}}
{"id": "f7ff7046-a1a8-45ae-807c-9de90461c7d6", "fitness": 0.3845401763876613, "name": "AdvancedParticleOptimizerEnhanced", "description": "An advanced particle swarm optimizer with dynamic neighborhood topology adaptation, enhanced particle memory, and stochastic inertia reduction for improved exploration and convergence efficiency.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizerEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neighborhood_topology = 'global'  # 'global' or 'local'\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            neighborhood_best = self._get_neighborhood_best(particles, personal_best_values)\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (neighborhood_best[i] - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate * (1 - np.random.rand() * 0.1))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best\n    \n    def _get_neighborhood_best(self, particles, personal_best_values):\n        if self.neighborhood_topology == 'global':\n            best_index = np.argmin(personal_best_values)\n            return np.array([particles[best_index]] * self.num_particles)\n        else:\n            neighborhood_best = []\n            for i in range(self.num_particles):\n                neighbors = self._get_neighbors(i)\n                best_neighbor_index = neighbors[np.argmin(personal_best_values[neighbors])]\n                neighborhood_best.append(particles[best_neighbor_index])\n            return np.array(neighborhood_best)\n\n    def _get_neighbors(self, index):\n        return [(index - 1) % self.num_particles, index, (index + 1) % self.num_particles]", "configspace": "", "generation": 29, "feedback": "The algorithm AdvancedParticleOptimizerEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38454 with standard deviation 0.36440.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.16478730218075321, 0.8980960724797188, 0.09073715450251196]}}
{"id": "8226a37c-8617-497d-b466-267bb968a904", "fitness": 0.665501740246787, "name": "AdvancedParticleOptimizer", "description": "Enhanced global exploration through adaptive velocity scaling for improved convergence and diversity.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                # Introducing adaptive velocity scaling\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]) * (1 + np.std(personal_best_values)))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 30, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66550 with standard deviation 0.34256.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.18233847890431432, 0.8764921951614393, 0.9376745466746075]}}
{"id": "557f8d3b-9341-4b7c-a248-b3a0721b3cca", "fitness": 0.6333753735244342, "name": "AdvancedParticleOptimizer", "description": "Enhance convergence by dynamically adapting cognitive and social coefficients based on particle performance.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                # Modified line: Adapt cognitive and social coefficients based on personal best performance\n                self.cognitive_coeff, self.social_coeff = 1.5 + 0.5 * (best_value - personal_best_values[i]) / best_value, 2.0 + 0.5 * (best_value - personal_best_values[i]) / best_value\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 31, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63338 with standard deviation 0.28508.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.23032951537349666, 0.8434807746595776, 0.8263158305402283]}}
{"id": "1910ccbe-2105-4c43-a706-d946759929a2", "fitness": 0.7132981234198899, "name": "AdvancedParticleOptimizer", "description": "An optimized particle swarm optimizer with adaptive learning rates and enhanced diversity maintenance for robust convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.01\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction with dynamic learning rate\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            # Enhanced diversity preservation with increased randomness\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.laplace(size=particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.15:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 32, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71330 with standard deviation 0.17722.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.534654939106465, 0.9548526377952288, 0.6503867933579759]}}
{"id": "8e12a0e2-bc1c-4eae-a0c7-c70f51c4bc4d", "fitness": 0.7251294804896485, "name": "AdvancedParticleOptimizer", "description": "An advanced particle swarm optimizer enhanced with adaptive compression control, elite leader selection, modified inertia weight strategy, and refined diversity threshold for improved convergence and robustness.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.05  # Adjusted for better diversity preservation\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 33, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72513 with standard deviation 0.08672.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.8446492342255777, 0.6892018629688937, 0.6415373442744741]}}
{"id": "931bb795-8ec6-4f1b-80af-5c4cda624b5a", "fitness": 0.5226314725030722, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer integrating adaptive memory reinforcement and dynamic neighborhood structure for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.memory_coeff = 0.2\n        self.neighborhood_size = 5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n        memory = np.zeros((self.num_particles, self.dim))\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Select neighborhood\n                neighbors_idx = np.random.choice(self.num_particles, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighbors_idx[np.argmin(personal_best_values[neighbors_idx])]]\n\n                r1, r2, r3 = np.random.rand(3)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (local_best - particles[i]) +\n                                 self.memory_coeff * r3 * memory[i])\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    memory[i] = particles[i] - personal_best[i]\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with memory influence\n            if np.std(personal_best_values) < self.diversity_threshold:\n                memory_influenced_particles = particles + memory + np.random.randn(*particles.shape)\n                memory_influenced_particles = np.clip(memory_influenced_particles, lb, ub)\n                memory_influenced_values = np.array([func(x) for x in memory_influenced_particles])\n                eval_count += len(memory_influenced_particles)\n                \n                for j in range(len(memory_influenced_particles)):\n                    if memory_influenced_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = memory_influenced_particles[j]\n                        best_value = memory_influenced_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 34, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52263 with standard deviation 0.28083.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.870517603150353, 0.5146163254868263, 0.182760488872037]}}
{"id": "da056365-dadf-4b6d-8e8e-4905aa683e6f", "fitness": 0.5280620703391455, "name": "HybridParticleDifferentialOptimizer", "description": "A hybrid optimizer combining particle swarm optimization with a differential evolution strategy for enhanced exploration and convergence. ", "code": "import numpy as np\n\nclass HybridParticleDifferentialOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.f = 0.8  # Differential evolution factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # PSO update\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n            \n            # Differential Evolution strategy\n            for i in range(self.num_particles):\n                indices = np.random.choice(self.num_particles, 3, replace=False)\n                a, b, c = particles[indices]\n                mutant_vector = np.clip(a + self.f * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cr\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n                trial_value = func(trial_vector)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial_vector\n                    personal_best_values[i] = trial_value\n                    if trial_value < best_value:\n                        global_best = trial_vector\n                        best_value = trial_value\n                \n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 35, "feedback": "The algorithm HybridParticleDifferentialOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52806 with standard deviation 0.31150.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.19592145493626523, 0.9447535062212764, 0.443511249859895]}}
{"id": "cc2e2c2f-1afa-4c2c-9a19-8705a51a03b0", "fitness": 0.36439611775911285, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer leveraging adaptive velocity clamping, enhanced diversity maintenance via chaotic local search, and dynamically adjusting exploration-exploitation balance for improved convergence and robustness.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.velocity_clamp = 0.1 \n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.exploration_exploitation_balance = 0.5\n        self.chaotic_search_factor = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            self.exploration_exploitation_balance *= self.cooling_rate\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                chaotic_particles = particles + self.chaotic_search_factor * (np.random.uniform(0, 1, particles.shape) - 0.5)\n                chaotic_particles = np.clip(chaotic_particles, lb, ub)\n                chaotic_values = np.array([func(x) for x in chaotic_particles])\n                eval_count += len(chaotic_particles)\n                \n                for j in range(len(chaotic_particles)):\n                    if chaotic_values[j] < best_value or np.random.rand() < self.exploration_exploitation_balance:\n                        global_best = chaotic_particles[j]\n                        best_value = chaotic_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 36, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36440 with standard deviation 0.33359.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.11904875628937983, 0.8360382026537391, 0.13810139433421953]}}
{"id": "9aedbfd8-e476-457e-854f-9532aec043f1", "fitness": 0.5635257640015278, "name": "EnhancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with dynamic parameter tuning using neural-inspired feedback and stochastic restarts for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neural_adaption_rate = 0.1\n        self.stochastic_restart_probability = 0.05\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Neural-inspired feedback for parameter tuning\n            feedback_gain = (best_value - np.mean(personal_best_values)) * self.neural_adaption_rate\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + feedback_gain)\n            \n            # Stochastic restarts\n            if np.random.rand() < self.stochastic_restart_probability:\n                random_particle_index = np.random.randint(self.num_particles)\n                particles[random_particle_index] = np.random.uniform(lb, ub, self.dim)\n                velocities[random_particle_index] = np.zeros(self.dim)\n                current_value = func(particles[random_particle_index])\n                eval_count += 1\n                if current_value < best_value:\n                    global_best = particles[random_particle_index]\n                    best_value = current_value\n\n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.56353 with standard deviation 0.30631.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.17626129031042348, 0.5890545399639187, 0.9252614617302412]}}
{"id": "258a169d-6bd4-4299-b4e2-9a82cdcd9c4e", "fitness": 0.8909082474584421, "name": "HybridParticleOptimizer", "description": "A hybrid particle optimizer combining adaptive swarm dynamics, elite reinforcement learning, and environmental feedback for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate = 0.01\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                adaptive_cognitive = self.cognitive_coeff + self.learning_rate * (personal_best_values[i] - best_value)\n                adaptive_social = self.social_coeff - self.learning_rate * (personal_best_values[i] - best_value)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 adaptive_cognitive * r1 * (personal_best[i] - particles[i]) +\n                                 adaptive_social * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            acceptance_probability = np.exp(-abs(current_value - best_value) / self.temperature)\n            if np.random.rand() < acceptance_probability:\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 38, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89091 with standard deviation 0.04469.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.827860970069371, 0.9262698591202685, 0.9185939131856865]}}
{"id": "5c38bc59-b956-42f5-a8f8-e0c9fa677799", "fitness": -Infinity, "name": "MultiStrategyParticleOptimizer", "description": "A multi-strategy particle swarm optimizer harnessing adaptive velocity clamping, elite archiving, and contextual self-adaptation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass MultiStrategyParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.diversity_threshold = 0.1\n        self.alpha = 0.1\n        self.epsilon = 1e-6\n        self.velocity_clamp = 0.2\n        self.elite_archive_size = 5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n        elite_archive = [global_best]\n        \n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = np.clip(\n                    self.inertia_weight * velocities[i] +\n                    self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                    self.social_coeff * r2 * (global_best - particles[i]),\n                    -self.velocity_clamp, self.velocity_clamp\n                )\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Update elite archive\n            if current_value < min(elite_archive, key=func):\n                elite_archive.append(global_best)\n                if len(elite_archive) > self.elite_archive_size:\n                    elite_archive.pop(0)\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight - self.alpha * (best_value - min(personal_best_values)) / (best_value + self.epsilon))\n\n            # Contextual self-adaptation strategy\n            if np.std(personal_best_values) < self.diversity_threshold:\n                perturbation = (ub - lb) * self.alpha * np.random.randn(self.num_particles, self.dim)\n                particles = np.clip(particles + perturbation, lb, ub)\n                perturbed_values = np.array([func(x) for x in particles])\n                eval_count += len(particles)\n                \n                for j in range(len(particles)):\n                    if perturbed_values[j] < best_value:\n                        global_best = particles[j]\n                        best_value = perturbed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 39, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {}}
{"id": "280503c2-d9e0-4a87-8afa-4c3e80b955c2", "fitness": 0.3907109018406902, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic elite selection, adaptive parameter tuning, and diversity-driven mutation for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.elite_fraction = 0.2\n        self.mutation_probability = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            elite_count = int(self.elite_fraction * self.num_particles)\n            elite_indices = np.argsort(personal_best_values)[:elite_count]\n            elite_global_best = personal_best[elite_indices[np.argmin(personal_best_values[elite_indices])]]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (elite_global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < self.mutation_probability:\n                    particles[i] += np.random.normal(0, 0.1, self.dim)\n                    particles[i] = np.clip(particles[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n            \n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n                \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 40, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39071 with standard deviation 0.38348.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.13046825289048325, 0.9328876021508609, 0.1087768504807266]}}
{"id": "59acd4ab-6715-436b-a2fd-14f5f6730c6f", "fitness": 0.830309636448301, "name": "EnhancedAdaptivePSO", "description": "An enhanced particle swarm optimizer with dynamic adaptive control of inertia and coefficients guided by evolutionary learning for improved exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.memory = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive control using evolutionary memory\n            self.memory.append(best_value)\n            if len(self.memory) > 5:\n                improvement_rate = (self.memory[-5] - self.memory[-1]) / 5\n                adaptive_scale = 1.0 + improvement_rate\n                self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate * adaptive_scale)\n                self.cognitive_coeff *= adaptive_scale\n                self.social_coeff *= adaptive_scale\n                self.memory.pop(0)\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83031 with standard deviation 0.06807.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.8425244484090264, 0.7415105507724653, 0.9068939101634115]}}
{"id": "24a685e6-3309-4dc6-9a00-1d0c9b14b1b6", "fitness": 0.8568242455198783, "name": "AdvancedParticleOptimizer", "description": "An advanced particle swarm optimizer enhanced with dynamic role allocation and elite particle reinforcement for improved convergence and robustness.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n            # Dynamic role allocation\n            elite_particle = personal_best[np.argmin(personal_best_values)]\n            self.cognitive_coeff, self.social_coeff = (1.5 + 0.5, 2.0 - 0.5) if best_value < np.median(personal_best_values) else (1.5, 2.0)\n            \n        return global_best", "configspace": "", "generation": 42, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85682 with standard deviation 0.08508.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.7370050818997061, 0.9262698591202685, 0.9071977955396602]}}
{"id": "e1ffc31a-888b-434e-84dd-399a4a0a7d53", "fitness": 0.48506395090689813, "name": "AdvancedParticleOptimizer", "description": "Enhanced global leader exploration by introducing a random dimension tweak during diversity preservation to improve convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    tweak = np.random.randn(self.dim) * 0.01  # Added tweak for global_best exploration\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j] + tweak\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 43, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48506 with standard deviation 0.24106.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.5899234403416862, 0.7135627931355111, 0.15170561924349713]}}
{"id": "5aa9c274-88bc-4f1d-b5b6-f84a5ecff8c7", "fitness": 0.840753134563113, "name": "EnhancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with dynamic neighborhood topology, adaptive velocity clamping, and stochastic restart mechanisms for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.velocity_clamp = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Define dynamic neighborhood\n                neighborhood_size = np.random.randint(1, self.num_particles // 5)\n                neighbors = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best[neighbors[np.argmin(personal_best_values[neighbors])]]\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (neighborhood_best - particles[i]))\n                \n                # Adaptive velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n            \n            # Stochastic restart mechanism\n            if eval_count / self.budget > 0.8 and np.std(personal_best_values) < self.diversity_threshold:\n                restart_indices = np.random.choice(self.num_particles, self.num_particles // 4, replace=False)\n                particles[restart_indices] = np.random.uniform(lb, ub, (len(restart_indices), self.dim))\n                velocities[restart_indices] = np.zeros((len(restart_indices), self.dim))\n                personal_best[restart_indices] = particles[restart_indices]\n                personal_best_values[restart_indices] = np.array([func(x) for x in personal_best[restart_indices]])\n                eval_count += len(restart_indices)\n        \n        return global_best", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84075 with standard deviation 0.09495.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.9748882546902046, 0.7791789679670283, 0.7681921810321062]}}
{"id": "837d52a8-1033-41d1-97a6-21c3e0ea7dfe", "fitness": 0.8502925755598986, "name": "AdvancedParticleOptimizer", "description": "An enhanced optimizer with improved diversity handling and adaptive social-cognitive balancing to boost convergence stability and solution quality.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n                self.social_coeff = 2.5  # Adjust social coefficient for better exploration\n\n        return global_best", "configspace": "", "generation": 45, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85029 with standard deviation 0.07557.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.9192521529023752, 0.8865155661005704, 0.7451100076767505]}}
{"id": "c583c93f-4d6d-4e89-8aaa-d60407d13968", "fitness": 0.41799805580862365, "name": "HybridAdvancedParticleOptimizer", "description": "A hybrid advanced particle swarm optimizer integrating Lvy flight for global exploration, adaptive mutation for local refinement, and probability-based dynamic parameter tuning for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass HybridAdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.mutation_rate = 0.1\n        \n    def levy_flight(self, size, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.math.gamma((1 + beta) / 2) * beta * \n                    2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma_u, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n            # Lvy flight for global exploration\n            if np.random.rand() < 0.2:\n                step = self.levy_flight(self.dim)\n                levy_step = global_best + step * (particles - global_best)\n                levy_step = np.clip(levy_step, lb, ub)\n                levy_values = np.array([func(x) for x in levy_step])\n                eval_count += len(levy_step)\n                \n                for k in range(len(levy_step)):\n                    if levy_values[k] < best_value or np.random.rand() < 0.1:\n                        global_best = levy_step[k]\n                        best_value = levy_values[k]\n                        break\n\n            # Adaptive mutation for local refinement\n            mutation = np.random.uniform(-1.0, 1.0, size=(self.num_particles, self.dim)) * self.mutation_rate\n            mutated_particles = particles + mutation\n            mutated_particles = np.clip(mutated_particles, lb, ub)\n            mutated_values = np.array([func(x) for x in mutated_particles])\n            eval_count += len(mutated_particles)\n            \n            for l in range(len(mutated_particles)):\n                if mutated_values[l] < best_value:\n                    global_best = mutated_particles[l]\n                    best_value = mutated_values[l]\n                    break\n\n        return global_best", "configspace": "", "generation": 46, "feedback": "The algorithm HybridAdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41800 with standard deviation 0.35787.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.19086702117330734, 0.9232490767108839, 0.13987806954167992]}}
{"id": "ee01e4e6-dc80-4e01-b4ec-ab9b60e41a82", "fitness": 0.5818003591201196, "name": "EnhancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with dynamic population resizing, improved exploration-exploitation balance, and adaptive learning coefficients for better convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_particles = 50\n        self.min_particles = 20\n        self.num_particles = self.initial_particles\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.inertia_weight_decay = 0.99\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.learning_rate = 0.5\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            # Adjust population size dynamically\n            if eval_count % 10 == 0 and self.num_particles > self.min_particles:\n                self.num_particles = max(self.min_particles, self.num_particles - 1)\n                particles = particles[:self.num_particles]\n                velocities = velocities[:self.num_particles]\n                personal_best = personal_best[:self.num_particles]\n                personal_best_values = personal_best_values[:self.num_particles]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adaptive learning coefficients to improve balance\n            self.cognitive_coeff = self.learning_rate * (1 + np.tanh((best_value - np.mean(personal_best_values)) / np.std(personal_best_values)))\n            self.social_coeff = self.learning_rate * (1 - np.tanh((best_value - np.mean(personal_best_values)) / np.std(personal_best_values)))\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.inertia_weight_decay)\n\n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58180 with standard deviation 0.29625.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.1667313767194285, 0.8386437397397739, 0.7400259609011562]}}
{"id": "28f778c4-c8bc-4b15-b38b-ace2465cfd1f", "fitness": 0.5900035233059661, "name": "AdvancedParticleOptimizer", "description": "A refined Advanced Particle Swarm Optimizer with dynamic cognitive and social coefficients for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                # Dynamic update of cognitive and social coefficients\n                self.cognitive_coeff = 1.5 + 0.5 * np.random.rand()\n                self.social_coeff = 2.0 + 0.5 * np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 48, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.59000 with standard deviation 0.30223.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.16957417450241996, 0.8668601205544257, 0.7335762748610526]}}
{"id": "d76b6ced-7f5d-4b31-81ca-1861693a9864", "fitness": 0.5895141665633226, "name": "SynergisticParticleOptimizer", "description": "A synergistic particle swarm optimizer with adaptive inertia weight, elite selection, and dynamic learning coefficients for enhanced exploration and exploitation balance, aiming for superior convergence in diverse optimization landscapes.", "code": "import numpy as np\n\nclass SynergisticParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.elitism_rate = 0.1  # Fraction of global best particles\n        self.learning_decay = 0.99  # Decay factor for learning coefficients\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n                        \n            # Elite selection and learning coefficient adjustment\n            elite_indices = personal_best_values.argsort()[:int(self.num_particles * self.elitism_rate)]\n            elite_particles = personal_best[elite_indices]\n            elite_values = personal_best_values[elite_indices]\n            elite_global_best = elite_particles[np.argmin(elite_values)]\n            \n            if np.random.rand() < 0.5:\n                global_best = elite_global_best\n                best_value = min(elite_values)\n            \n            # Dynamic adjustment of learning coefficients\n            self.cognitive_coeff *= self.learning_decay\n            self.social_coeff *= self.learning_decay\n\n        return global_best", "configspace": "", "generation": 49, "feedback": "The algorithm SynergisticParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58951 with standard deviation 0.28117.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.2028951478566754, 0.7023316463597509, 0.8633157054735413]}}
{"id": "61a98418-18c7-4462-b904-71be230f2ebf", "fitness": 0.7362940940125308, "name": "EnhancedParticleOptimizer", "description": "An improved particle swarm optimizer with dynamic leader selection, adaptive velocity updates, and hybrid exploration-to-exploitation balance for superior convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.exploration_exploitation_balance = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                \n                # Dynamic leader selection for social influence\n                leader_index = np.random.randint(self.num_particles)\n                leader = personal_best[leader_index]\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (leader - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate +\n                                      self.exploration_exploitation_balance * (best_value - min(personal_best_values)))\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73629 with standard deviation 0.08334.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.735650596520289, 0.6345518085634951, 0.8386798769538083]}}
{"id": "94549d47-c6ec-4e7c-b2de-46ab8a86eb7d", "fitness": 0.13239169102845635, "name": "HybridParticleOptimizer", "description": "A hybrid particle swarm optimizer with adaptive strategies, incorporating differential evolution mutations for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression and differential evolution\n            if np.std(personal_best_values) < self.diversity_threshold:\n                for j in range(self.num_particles):\n                    if eval_count >= self.budget:\n                        break\n                    # Differential evolution mutation\n                    idxs = np.random.choice(self.num_particles, 3, replace=False)\n                    x0, x1, x2 = particles[idxs]\n                    mutant = np.clip(x0 + self.mutation_factor * (x1 - x2), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.crossover_prob\n                    trial = np.where(cross_points, mutant, particles[j])\n                    trial_value = func(trial)\n                    eval_count += 1\n                    \n                    if trial_value < personal_best_values[j] or np.random.rand() < 0.1:\n                        particles[j] = trial\n                        personal_best[j] = trial\n                        personal_best_values[j] = trial_value\n                        if trial_value < best_value:\n                            global_best = trial\n                            best_value = trial_value\n\n        return global_best", "configspace": "", "generation": 51, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13239 with standard deviation 0.04609.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.14414067815110954, 0.18204172567975574, 0.07099266925450376]}}
{"id": "17885a37-4d58-44e5-bedc-3ba5063c60d2", "fitness": 0.6765198426722789, "name": "AdvancedParticleOptimizer", "description": "Enhanced the social coefficient dynamics to adapt based on diversity and improved global exploration by modifying the update rule for velocities.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            diversity_measure = np.std(personal_best_values)\n            self.social_coeff = 2.0 + diversity_measure * 0.5  # Adaptive social coefficient\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if diversity_measure < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 52, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67652 with standard deviation 0.34285.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.19171708342729255, 0.9258410164720319, 0.9120014281175125]}}
{"id": "413c29d4-5de7-433b-a6a3-4c3188360703", "fitness": 0.6366853400576052, "name": "AdvancedParticleOptimizer", "description": "An enhanced particle swarm optimizer refined with adaptive inertia scaling using the standard deviation of particle positions for improved convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n            # Additional line to adjust inertia weight based on the standard deviation of particle positions\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * (1 - np.std(particles) / self.dim))\n\n        return global_best", "configspace": "", "generation": 53, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63669 with standard deviation 0.33576.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.1657370096366627, 0.8196187820737054, 0.9247002284624478]}}
{"id": "df5dcc4e-1508-44da-80b7-bd450d993d0f", "fitness": 0.8066240227779816, "name": "AdvancedParticleOptimizer", "description": "Enhanced swarm optimizer with improved global-best update strategy for better convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Improved global-best update strategy\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = (global_best + particles[np.argmin(personal_best_values)]) / 2\n                best_value = min(current_value, best_value)\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 54, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80662 with standard deviation 0.15923.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.5815906233352026, 0.9262698591202685, 0.9120115858784739]}}
{"id": "e6bfe947-ddbf-440e-a9a0-3787e3349570", "fitness": 0.13818340578933716, "name": "IntelligentParticleOptimizer", "description": "An intelligent particle swarm optimizer enhanced with adaptive inertia weight, elite particle selection, and a hybrid exploration strategy combining differential evolution and particle swarm dynamics for superior convergence and robustness.", "code": "import numpy as np\n\nclass IntelligentParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced exploration strategy using differential evolution\n            if np.std(personal_best_values) < self.diversity_threshold:\n                for j in range(self.num_particles):\n                    indices = np.random.choice(self.num_particles, 3, replace=False)\n                    mutant_vector = personal_best[indices[0]] + 0.8 * (personal_best[indices[1]] - personal_best[indices[2]])\n                    trial_vector = np.where(np.random.rand(self.dim) < 0.5, mutant_vector, particles[j])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    trial_value = func(trial_vector)\n                    eval_count += 1\n                    \n                    if trial_value < personal_best_values[j]:\n                        personal_best[j] = trial_vector\n                        personal_best_values[j] = trial_value\n                        \n                        if trial_value < best_value:\n                            global_best = trial_vector\n                            best_value = trial_value\n                \n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 55, "feedback": "The algorithm IntelligentParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13818 with standard deviation 0.03640.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.187550973421451, 0.12611542169319978, 0.10088382225336068]}}
{"id": "a3b845ca-7da3-40e2-b834-67e0afb8711a", "fitness": 0.5830326257153216, "name": "EnhancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with adaptive inertia weight, elite preservation, and gradient boosting strategy to enhance global search and convergence rate.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.gradient_boost_factor = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                \n                # Gradient boosting\n                grad_approx = (func(particles[i] + self.gradient_boost_factor) - func(particles[i])) / self.gradient_boost_factor\n                velocities[i] += self.gradient_boost_factor * grad_approx\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58303 with standard deviation 0.31497.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.16282893541606702, 0.9211304238975522, 0.6651385178323455]}}
{"id": "4ccfd8f6-ac5c-4413-8c33-846e84ba7ac5", "fitness": 0.6116881234491343, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer utilizing a dynamic multi-strategy approach with adaptive neighborhood search and feedback-based parametric control for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 60\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.local_coeff = 1.0\n        self.cooling_rate = 0.99\n        self.temperature = 100\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n        local_best = personal_best.copy()\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(3)\n                \n                # Determine local best for adaptive neighborhood search\n                local_neighbors = np.random.choice(self.num_particles, size=5, replace=False)\n                local_best_value = min(personal_best_values[local_neighbors])\n                local_best[i] = personal_best[local_neighbors[np.argmin(personal_best_values[local_neighbors])]]\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]) +\n                                 self.local_coeff * r3 * (local_best[i] - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight based on feedback\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate +\n                                      0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with adaptive compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 57, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61169 with standard deviation 0.27489.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.23959925875037613, 0.7002179127819821, 0.8952471988150446]}}
{"id": "1ddb90ad-d678-4bab-a04a-43a6cc255110", "fitness": 0.4141648056399707, "name": "HybridParticleOptimizer", "description": "A hybrid particle swarm optimizer with adaptive learning strategies, quantum-inspired jump mechanism, and chaos-enhanced exploration for robust performance across complex landscapes.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with quantum-inspired jump\n            if np.std(personal_best_values) < self.diversity_threshold:\n                quantum_jump = particles + self.compression_factor * np.random.uniform(-1, 1, particles.shape)\n                quantum_jump = np.clip(quantum_jump, lb, ub)\n                quantum_values = np.array([func(x) for x in quantum_jump])\n                eval_count += len(quantum_jump)\n                \n                for j in range(len(quantum_jump)):\n                    if quantum_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = quantum_jump[j]\n                        best_value = quantum_values[j]\n                        break\n\n            # Chaos-enhanced exploration through logistic map\n            chaos_factor = 4 * np.random.rand()\n            for i in range(self.num_particles):\n                r1 = chaos_factor * r1 * (1 - r1)\n                r2 = chaos_factor * r2 * (1 - r2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return global_best", "configspace": "", "generation": 58, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41416 with standard deviation 0.35174.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.18799014544003845, 0.9109338672215613, 0.14357040425831247]}}
{"id": "393fe6c8-9315-4bf8-9f72-54bdc5f95072", "fitness": 0.41677721869044104, "name": "AdvancedParticleOptimizer", "description": "Enhanced elite leader selection and adaptive inertia strategy for improved optimization.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Enhanced elite leader selection\n            if current_value < best_value:\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 59, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41678 with standard deviation 0.35136.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.17368287036612773, 0.9136374705405588, 0.16301131516463652]}}
{"id": "8de6e9c4-4a9f-4935-b53c-ccfda4e77712", "fitness": -Infinity, "name": "RefinedParticleOptimizer", "description": "A multi-strategy particle optimizer integrating adaptive velocity scaling, neighborhood topology, and diversity-driven reinitialization to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.global_best_memory = []\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n            \n            # Neighborhood topology for local search\n            neighborhood_best_index = np.argmin(personal_best_values[:self.num_particles//2])\n            neighborhood_best = personal_best[neighborhood_best_index]\n            if func(neighborhood_best) < best_value:\n                global_best = neighborhood_best\n                best_value = func(neighborhood_best)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Diversity-driven reinitialization with history\n            self.global_best_memory.append(global_best)\n            diversity_index = np.std(personal_best_values)\n            if diversity_index < self.diversity_threshold:\n                random_particle = np.random.choice(self.global_best_memory)\n                particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n                particles[np.random.randint(0, self.num_particles)] = random_particle\n                velocities = np.zeros((self.num_particles, self.dim))\n\n        return global_best", "configspace": "", "generation": 60, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {}}
{"id": "6abcbd2f-f11f-44ab-a2b6-358c3a397fbf", "fitness": 0.37917448671425175, "name": "AdvancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with dynamic neighborhood topology and adaptive velocity adjustment using opposition-based learning for better convergence and exploration.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neighborhood_size = 5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                local_best = personal_best[np.argmin(personal_best_values[max(0, i - self.neighborhood_size):min(self.num_particles, i + self.neighborhood_size)])]  # Dynamic neighborhood topology\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (local_best - particles[i]))  # Use local best\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Opposition-based learning for enhanced exploration\n            opposite_particles = lb + ub - particles\n            opposite_values = np.array([func(x) for x in opposite_particles])\n            eval_count += len(opposite_particles)\n            \n            for j in range(len(opposite_particles)):\n                if opposite_values[j] < best_value:\n                    global_best = opposite_particles[j]\n                    best_value = opposite_values[j]\n                    break\n\n        return global_best", "configspace": "", "generation": 61, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37917 with standard deviation 0.41741.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.07308692595523869, 0.9693510397937477, 0.09508549439376879]}}
{"id": "722fe8b1-11d9-4b4f-9d51-8f4c4f64f474", "fitness": 0.6205012853717612, "name": "OptimizedParticleSwarm", "description": "A particle swarm optimizer optimized with inertia weight decay, enhanced diversity control, and adaptive focused exploration for faster convergence.", "code": "import numpy as np\n\nclass OptimizedParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.90\n        self.diversity_threshold = 0.05\n        self.compression_factor = 0.5\n        self.adaptive_exploration = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.cooling_rate)\n            \n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < self.adaptive_exploration:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 62, "feedback": "The algorithm OptimizedParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62050 with standard deviation 0.32187.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.18567756800119395, 0.9545077652083124, 0.721318522905777]}}
{"id": "22adafda-7e6e-4e3b-9efa-83c0654b31b4", "fitness": 0.7655152259389063, "name": "DynamicParticleOptimizer", "description": "A dynamic particle swarm optimizer with adaptive inertia, local turbulence, and convergence acceleration through a chaotic levy flight strategy for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.turbulence_intensity = 0.1\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Local turbulence for exploration\n                if np.random.rand() < self.turbulence_intensity:\n                    particles[i] += np.random.normal(0, (ub - lb) * 0.1, self.dim)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * 0.99 + 0.01 * (best_value - min(personal_best_values)))\n\n            # Chaotic Levy Flight for convergence acceleration\n            if np.std(personal_best_values) < self.diversity_threshold:\n                levy_flight = np.random.standard_cauchy((self.num_particles, self.dim))\n                particles += self.compression_factor * levy_flight\n                particles = np.clip(particles, lb, ub)\n                new_values = np.array([func(x) for x in particles])\n                eval_count += len(particles)\n                \n                for j in range(len(particles)):\n                    if new_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = particles[j]\n                        best_value = new_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 63, "feedback": "The algorithm DynamicParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.76552 with standard deviation 0.16303.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.861095033461835, 0.8994237277413222, 0.5360269166135616]}}
{"id": "74e42e4d-b393-4471-9f33-9d95614b6863", "fitness": 0.7901842951410188, "name": "AdvancedParticleOptimizer", "description": "Enhanced AdvancedParticleOptimizer using adaptive mutation strategy to maintain diversity under convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                # Adaptive mutation strategy\n                mutation_strength = 0.1 * (ub - lb) * np.random.randn(self.dim)\n                mutate_idx = np.random.randint(self.num_particles)\n                particles[mutate_idx] = np.clip(particles[mutate_idx] + mutation_strength, lb, ub)\n                current_value = func(particles[mutate_idx])\n                eval_count += 1\n\n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 64, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.79018 with standard deviation 0.11292.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.6888988599268592, 0.9477560260481027, 0.7338979994480949]}}
{"id": "d5fded2f-3ea5-4482-81b2-5b67b983dc1e", "fitness": 0.40333238428920265, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer integrating adaptive personal and global learning coefficients, dynamic neighborhood selection, and a novel diversity-enhancing mechanism for accelerated convergence and robustness.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff_min = 0.5\n        self.cognitive_coeff_max = 2.5\n        self.social_coeff_min = 0.5\n        self.social_coeff_max = 2.5\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.neighborhood_size = 5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                dynamic_cognitive_coeff = self.cognitive_coeff_min + (self.cognitive_coeff_max - self.cognitive_coeff_min) * np.random.rand()\n                dynamic_social_coeff = self.social_coeff_min + (self.social_coeff_max - self.social_coeff_min) * np.random.rand()\n                \n                local_best_neighbor = np.argmin(personal_best_values[max(0, i-self.neighborhood_size):min(self.num_particles, i+self.neighborhood_size)])\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 dynamic_cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 dynamic_social_coeff * r2 * (personal_best[local_best_neighbor] - particles[i]))\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate)\n\n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with random exploration\n            if np.std(personal_best_values) < self.diversity_threshold:\n                exploration_particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n                exploration_values = np.array([func(x) for x in exploration_particles])\n                eval_count += len(exploration_particles)\n                \n                for j in range(len(exploration_particles)):\n                    if exploration_values[j] < best_value:\n                        global_best = exploration_particles[j]\n                        best_value = exploration_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 65, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40333 with standard deviation 0.27878.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.19165349770804352, 0.7972255034539661, 0.22111815170559834]}}
{"id": "591921f4-50db-4d07-875b-92058d1fd081", "fitness": 0.20800658012093487, "name": "EnhancedPSOWithHierarchicalDisturbance", "description": "An enhanced particle swarm optimizer with adaptive grouping, hierarchical leader selection, and stochastic disturbance to maintain diversity and improve convergence.", "code": "import numpy as np\n\nclass EnhancedPSOWithHierarchicalDisturbance:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.05\n        self.compression_factor = 0.5\n        self.disturbance_factor = 0.1\n        self.group_size = 10\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            for i in range(0, self.num_particles, self.group_size):\n                group_particles = particles[i:i+self.group_size]\n                group_best_idx = np.argmin([func(p) for p in group_particles])\n                group_best = group_particles[group_best_idx]\n\n                for j in range(min(self.group_size, self.num_particles - i)):\n                    r1, r2 = np.random.rand(2)\n                    velocities[i+j] = (self.inertia_weight * velocities[i+j] +\n                                       self.cognitive_coeff * r1 * (personal_best[i+j] - particles[i+j]) +\n                                       self.social_coeff * r2 * (group_best - particles[i+j]))\n                    particles[i+j] = np.clip(particles[i+j] + velocities[i+j], lb, ub)\n\n                    current_value = func(particles[i+j])\n                    eval_count += 1\n\n                    if current_value < personal_best_values[i+j]:\n                        personal_best[i+j] = particles[i+j]\n                        personal_best_values[i+j] = current_value\n\n                        if current_value < best_value:\n                            global_best = particles[i+j]\n                            best_value = current_value\n\n                    if eval_count >= self.budget:\n                        break\n\n                # Apply a random disturbance for diversity\n                if np.std(personal_best_values[i:i+self.group_size]) < self.diversity_threshold:\n                    disturbance = self.disturbance_factor * np.random.randn(*group_particles.shape)\n                    group_particles += disturbance\n                    group_particles = np.clip(group_particles, lb, ub)\n                    for k in range(len(group_particles)):\n                        value = func(group_particles[k])\n                        eval_count += 1\n                        if value < personal_best_values[i+k]:\n                            personal_best[i+k] = group_particles[k]\n                            personal_best_values[i+k] = value\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedPSOWithHierarchicalDisturbance got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20801 with standard deviation 0.14393.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.12175857141706115, 0.41079531588064755, 0.09146585306509591]}}
{"id": "4091571a-8101-4f9d-898c-5c7186596d14", "fitness": -Infinity, "name": "AdvancedParticleOptimizer", "description": "Enhanced particle swarm optimizer with adaptive particle number and temperature update for improved convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n            # Adapt particle number and temperature based on diversity\n            self.num_particles = max(10, int(self.num_particles * (1.1 if np.std(personal_best_values) < 0.1 else 0.9)))\n            self.temperature = max(1, self.temperature * (0.9 if np.std(personal_best_values) < 0.1 else 1.1))\n                \n        return global_best", "configspace": "", "generation": 67, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {}}
{"id": "0018ed89-b5ec-4b24-8678-d7fb9df3adc8", "fitness": 0.38414042526649883, "name": "HybridParticleDifferentialOptimizer", "description": "A hybrid optimizer combining particle swarm optimization with a dynamically adjusting differential evolution strategy for enhanced exploration and fine-tuning of solutions.", "code": "import numpy as np\n\nclass HybridParticleDifferentialOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.num_differential = 10\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.cooling_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Step\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution Step\n            for _ in range(self.num_differential):\n                idxs = np.random.choice(self.num_particles, 3, replace=False)\n                x1, x2, x3 = particles[idxs]\n                mutant = np.clip(x1 + self.F * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, particles[idxs[0]])\n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < personal_best_values[idxs[0]]:\n                    personal_best[idxs[0]] = trial\n                    personal_best_values[idxs[0]] = trial_value\n\n                    if trial_value < best_value:\n                        global_best = trial\n                        best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n        return global_best", "configspace": "", "generation": 68, "feedback": "The algorithm HybridParticleDifferentialOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38414 with standard deviation 0.39616.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.13779567017229666, 0.9430874388874866, 0.07153816673971314]}}
{"id": "cb88672a-9733-418b-a8e2-25538bffab68", "fitness": 0.8589214540097038, "name": "AdvancedParticleOptimizer", "description": "Introduced adaptive social coefficient strategy to dynamically adjust exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n            \n            # Adaptive social coefficient\n            self.social_coeff = max(1.0, self.social_coeff * self.cooling_rate)  # Adjust social coefficient\n\n        return global_best", "configspace": "", "generation": 69, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85892 with standard deviation 0.04232.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.8659407087857303, 0.8039343947205637, 0.9068892585228173]}}
{"id": "6a65afea-363e-418e-9f65-f3755542dbde", "fitness": 0.8109897890167308, "name": "EnhancedParticleOptimizer", "description": "Enhanced Particle Swarm Optimizer utilizing dynamic neighborhood topology, adaptive inertia modulation, and diversity reintroduction for improved exploration and convergence stability.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neighborhood_size = 5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Dynamically changing neighborhood topology\n                neighbors = np.random.choice(self.num_particles, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_values[neighbors])]]\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (local_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight using exploration-exploitation balance\n            exploration = np.std(velocities)\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * (1 - exploration / (exploration + 1)) + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation through reintroduction\n            if np.std(personal_best_values) < self.diversity_threshold:\n                reintroduced_particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n                reintroduced_values = np.array([func(x) for x in reintroduced_particles])\n                eval_count += len(reintroduced_particles)\n                \n                for j in range(len(reintroduced_particles)):\n                    if reintroduced_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = reintroduced_particles[j]\n                        best_value = reintroduced_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81099 with standard deviation 0.17976.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.9374413144331277, 0.9387612310186715, 0.5567668215983932]}}
{"id": "2ebc2d08-63da-4718-b88b-3fa3eb235e23", "fitness": 0.3991022724396238, "name": "HybridQuantumParticleOptimizer", "description": "A hybrid particle swarm optimizer integrating adaptive quantum-inspired exploration, dynamic social learning adjustment, and stochastic perturbation for enhanced performance across diverse optimization landscapes.", "code": "import numpy as np\n\nclass HybridQuantumParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.quantum_prob = 0.2\n        self.diversity_threshold = 0.1\n        self.exploration_factor = 0.05\n        \n    def quantum_exploration(self, particle, global_best, lb, ub):\n        if np.random.rand() < self.quantum_prob:\n            new_position = global_best + np.random.randn(self.dim) * self.exploration_factor\n            return np.clip(new_position, lb, ub)\n        return particle\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Quantum-inspired exploration\n                particles[i] = self.quantum_exploration(particles[i], global_best, lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * 0.99 + 0.1 * (best_value - min(personal_best_values)))\n            \n            # Enhanced diversity preservation\n            if np.std(personal_best_values) < self.diversity_threshold:\n                perturbed_particles = particles + self.exploration_factor * np.random.randn(*particles.shape)\n                perturbed_particles = np.clip(perturbed_particles, lb, ub)\n                perturbed_values = np.array([func(x) for x in perturbed_particles])\n                eval_count += len(perturbed_particles)\n                \n                for j in range(len(perturbed_particles)):\n                    if perturbed_values[j] < best_value:\n                        global_best = perturbed_particles[j]\n                        best_value = perturbed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 71, "feedback": "The algorithm HybridQuantumParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39910 with standard deviation 0.38031.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.14570211928020016, 0.9366421078438869, 0.11496259019478439]}}
{"id": "e6cbecdc-f8e5-4f2e-9aae-df78f0c914ae", "fitness": 0.11091278649498759, "name": "EnhancedParticleOptimizer", "description": "A particle swarm optimization algorithm enhanced with adaptive learning rates, elite reinitialization, and dynamic neighborhood adjustment for improved convergence speed and solution diversity.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.learning_rate = 0.1\n        self.diversity_threshold = 0.1\n        self.neighborhood_size = 5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + self.learning_rate * velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * 0.95 + 0.1 * (best_value - min(personal_best_values)))\n\n            # Adaptive learning rate adjustment\n            self.learning_rate = max(0.01, (best_value - min(personal_best_values)) / best_value)\n            \n            # Elite reinitialization for diversity\n            if np.std(personal_best_values) < self.diversity_threshold:\n                elite_indices = np.argsort(personal_best_values)[:self.neighborhood_size]\n                for idx in elite_indices:\n                    particles[idx] = np.random.uniform(lb, ub, self.dim)\n                    eval_count += 1\n\n        return global_best", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11091 with standard deviation 0.03728.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.07629185655838266, 0.1626625589608035, 0.0937839439657766]}}
{"id": "d25e7e05-9abc-43aa-8686-f69f40a8a87e", "fitness": 0.6001838965036205, "name": "QuantumParticleOptimizer", "description": "A hybrid quantum-inspired particle optimizer combining quantum superposition principles with adaptive particle dynamics for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass QuantumParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.q_compression_factor = 0.5\n        self.epsilon = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.epsilon * (best_value - min(personal_best_values)))\n\n            # Quantum-inspired superposition principle\n            quantum_particles = particles + self.q_compression_factor * np.random.randn(*particles.shape)\n            quantum_particles = np.clip(quantum_particles, lb, ub)\n            quantum_values = np.array([func(x) for x in quantum_particles])\n            eval_count += len(quantum_particles)\n            \n            for j in range(len(quantum_particles)):\n                if quantum_values[j] < best_value or np.random.rand() < 0.1:\n                    global_best = quantum_particles[j]\n                    best_value = quantum_values[j]\n                    break\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n        \n        return global_best", "configspace": "", "generation": 73, "feedback": "The algorithm QuantumParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60018 with standard deviation 0.35355.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.8379333002024896, 0.8622332894905189, 0.10038509981785304]}}
{"id": "77be8e7a-9a77-48f2-82df-29305d0f9a5a", "fitness": 0.37802004135879136, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer integrating time-varying coefficients, elite perturbations, and multi-phase annealing for enhanced convergence and solution diversity.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.perturbation_factor = 0.1\n        self.time_varying_coeff_min = 0.5\n        self.time_varying_coeff_max = 2.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            t = eval_count / self.budget\n            self.cognitive_coeff = self.time_varying_coeff_min + (self.time_varying_coeff_max - self.time_varying_coeff_min) * (1 - t)\n            self.social_coeff = self.time_varying_coeff_max - (self.time_varying_coeff_max - self.time_varying_coeff_min) * (1 - t)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                elite_perturbations = global_best + self.perturbation_factor * np.random.randn(self.dim)\n                elite_perturbations = np.clip(elite_perturbations, lb, ub)\n                elite_value = func(elite_perturbations)\n                eval_count += 1\n                \n                if elite_value < best_value:\n                    global_best = elite_perturbations\n                    best_value = elite_value\n\n        return global_best", "configspace": "", "generation": 74, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37802 with standard deviation 0.31438.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.15241172613463727, 0.8226024031213061, 0.1590459948204308]}}
{"id": "2ce5e9f0-20f6-4d7e-a78e-6d5e6be2e4c5", "fitness": 0.9122865071301488, "name": "AdvancedParticleOptimizer", "description": "An advanced particle swarm optimizer with enhanced inertia weight adaptation for improved convergence efficiency.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction (modified line)\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.05 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 75, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91229 with standard deviation 0.01104.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.89890730347514, 0.9259406320368324, 0.9120115858784739]}}
{"id": "3839e8a6-3535-4af0-a846-cf4d2c7a0307", "fitness": 0.8486572436887693, "name": "AdvancedParticleOptimizer", "description": "A refined advanced particle swarm optimizer with adaptive cognitive coefficient adjustment for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 (self.cognitive_coeff * (1 - 0.5 * np.exp(-eval_count/self.budget))) * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 76, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84866 with standard deviation 0.06693.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.8763502462189711, 0.7564210621793745, 0.9132004226679622]}}
{"id": "f03babf7-7d76-4a71-b3a5-2f51431ca964", "fitness": 0.10269309494223049, "name": "AdvancedParticleOptimizer", "description": "Improved AdvancedParticleOptimizer with adaptive cognitive and social coefficients based on convergence rate.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Adjust cognitive and social coefficients\n            convergence_rate = np.std(personal_best_values) / (np.abs(best_value - min(personal_best_values)) + 1e-10)\n            self.cognitive_coeff = 1.5 + 0.5 * convergence_rate\n            self.social_coeff = 2.0 - 0.5 * convergence_rate\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 77, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10269 with standard deviation 0.01487.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.11408294212525794, 0.0816872259557383, 0.11230911674569521]}}
{"id": "98086254-a09f-4c8a-8a37-e081915c9803", "fitness": 0.9133650946642553, "name": "AdvancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with improved global best selection using an adaptive diversity threshold for refining convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)  # Change made here\n                        break\n\n        return global_best", "configspace": "", "generation": 78, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91337 with standard deviation 0.01122.", "error": "", "parent_ids": ["d66e5c0b-f9c1-4ca5-8070-4e66bc4e6a80"], "operator": null, "metadata": {"aucs": [0.89890730347514, 0.9262698591202685, 0.9149181213973573]}}
{"id": "8c90750b-0f3a-44ca-87b0-6fdb237dbcda", "fitness": 0.7566713929105364, "name": "AdvancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with refined diversity threshold adjustment and adaptive compression factor for improved convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                self.compression_factor *= 0.9  # Change made here\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)  # Change made here\n                        break\n\n        return global_best", "configspace": "", "generation": 79, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75667 with standard deviation 0.19189.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.8882204528703438, 0.8964601248839018, 0.4853336009773638]}}
{"id": "82f9ee33-21fc-457b-b758-87fb35f7b6e8", "fitness": 0.611045301198894, "name": "AdvancedParticleOptimizer", "description": "A multi-strategy particle optimizer integrating adaptive exploration-exploitation balance with local search enhancement for improved convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.local_search_prob = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)\n                        break\n            \n            # Local search enhancement\n            if np.random.rand() < self.local_search_prob:\n                local_particle = global_best + 0.1 * np.random.randn(self.dim)\n                local_particle = np.clip(local_particle, lb, ub)\n                local_value = func(local_particle)\n                eval_count += 1\n                if local_value < best_value:\n                    global_best = local_particle\n                    best_value = local_value\n\n        return global_best", "configspace": "", "generation": 80, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61105 with standard deviation 0.20596.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.32014965314270283, 0.7693481537246631, 0.7436380967293158]}}
{"id": "3a2af835-83a0-4435-a824-3f3ef922ca0f", "fitness": 0.4278644390460631, "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary algorithm integrating adaptive mutation and crossover techniques with a dynamic neighborhood strategy to enhance convergence and diversify search.", "code": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_individuals = 50\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.8\n        self.adaptive_factor = 0.5\n        self.diversity_threshold = 0.1\n        self.convergence_threshold = 0.01\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        individuals = np.random.uniform(lb, ub, (self.num_individuals, self.dim))\n        fitness_values = np.array([func(x) for x in individuals])\n        best_individual = individuals[np.argmin(fitness_values)]\n        best_value = min(fitness_values)\n        \n        eval_count = self.num_individuals\n        \n        while eval_count < self.budget:\n            new_individuals = []\n            for i in range(self.num_individuals):\n                if np.random.rand() < self.crossover_rate:\n                    idx1, idx2 = np.random.choice(self.num_individuals, 2, replace=False)\n                    crossover_point = np.random.randint(1, self.dim)\n                    new_individual = np.concatenate((individuals[idx1][:crossover_point],\n                                                     individuals[idx2][crossover_point:]))\n                else:\n                    new_individual = individuals[i].copy()\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.randn(self.dim) * self.adaptive_factor\n                    new_individual = np.clip(new_individual + mutation_vector, lb, ub)\n\n                new_individuals.append(new_individual)\n\n            new_fitness_values = np.array([func(x) for x in new_individuals])\n            eval_count += len(new_individuals)\n\n            for i in range(len(new_individuals)):\n                if new_fitness_values[i] < fitness_values[i]:\n                    individuals[i] = new_individuals[i]\n                    fitness_values[i] = new_fitness_values[i]\n                    \n                    if fitness_values[i] < best_value:\n                        best_individual = individuals[i]\n                        best_value = fitness_values[i]\n\n            if np.std(fitness_values) < self.diversity_threshold:\n                noise = np.random.randn(*individuals.shape) * self.adaptive_factor\n                individuals = np.clip(individuals + noise, lb, ub)\n                new_fitness_values = np.array([func(x) for x in individuals])\n                eval_count += len(individuals)\n\n                for i in range(len(individuals)):\n                    if new_fitness_values[i] < best_value or np.random.rand() < 0.1:\n                        best_individual = individuals[i]\n                        best_value = new_fitness_values[i]\n                        break\n\n            if best_value < self.convergence_threshold:\n                break\n\n        return best_individual", "configspace": "", "generation": 81, "feedback": "The algorithm HybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42786 with standard deviation 0.36155.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.19710858647324803, 0.14809063475128958, 0.9383940959136516]}}
{"id": "be120bac-12bb-4f45-8d9c-a97e3c04a2bd", "fitness": 0.5430741772066318, "name": "DynamicNeighborhoodOptimizer", "description": "Introduce a dynamic neighborhood topology for enhanced local exploration in the Advanced Particle Optimizer to improve convergence.", "code": "import numpy as np\n\nclass DynamicNeighborhoodOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.neighborhood_size = 5  # Number of neighbors to consider for local best\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                # Determine local best by checking a dynamic neighborhood\n                neighbors_indices = np.random.choice(self.num_particles, self.neighborhood_size, replace=False)\n                local_best = neighbors_indices[np.argmin([personal_best_values[j] for j in neighbors_indices])]\n                local_best_position = personal_best[local_best]\n\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (local_best_position - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)\n                        break\n\n        return global_best", "configspace": "", "generation": 82, "feedback": "The algorithm DynamicNeighborhoodOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54307 with standard deviation 0.30709.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.47042885568697823, 0.9502017171752444, 0.20859195875767278]}}
{"id": "fb959938-0c21-4b40-8b3f-b64d9081f3e9", "fitness": 0.8043212613129823, "name": "HybridParticleDifferentialOptimizer", "description": "A hybrid particle swarm and differential evolution optimizer with adaptive control of parameters for enhanced convergence and exploration.", "code": "import numpy as np\n\nclass HybridParticleDifferentialOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.F = 0.8  # Differential Evolution scaling factor\n        self.CR = 0.9  # Differential Evolution crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Particle Swarm Optimization update\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * r1 * (personal_best[i] - particles[i])\n                    + self.social_coeff * r2 * (global_best - particles[i])\n                )\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Differential Evolution mutation and crossover\n                if np.random.rand() < 0.5:  # Adding a probabilistic switch to DE\n                    indices = np.random.choice(self.num_particles, 3, replace=False)\n                    a, b, c = particles[indices]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    particles[i] = np.where(crossover, mutant, particles[i])\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(\n                self.inertia_weight_min,\n                self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)),\n            )\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n\n            self.temperature *= self.cooling_rate\n\n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n\n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)\n                        break\n\n        return global_best", "configspace": "", "generation": 83, "feedback": "The algorithm HybridParticleDifferentialOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80432 with standard deviation 0.06707.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.7892432305483417, 0.7307616394813568, 0.8929589139092486]}}
{"id": "9d1e2fdf-06b6-4523-a294-f5fc41458dd7", "fitness": 0.9133650946642553, "name": "AdvancedParticleOptimizer", "description": "A refined enhanced particle swarm optimizer with modified diversity threshold adjustment for dynamic convergence control.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.03, self.diversity_threshold * 0.85)  # Change made here\n                        break\n\n        return global_best", "configspace": "", "generation": 84, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91337 with standard deviation 0.01122.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.89890730347514, 0.9262698591202685, 0.9149181213973573]}}
{"id": "2541638a-8273-4c10-bc7c-1ac55f7728d4", "fitness": 0.40660036421199086, "name": "HybridParticleOptimizer", "description": "A hybrid particle swarm and differential evolution optimizer with adaptive inertia and random walking for enhanced convergence and diversity management.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with random walking\n            if np.std(personal_best_values) < self.diversity_threshold:\n                for j in range(self.num_particles):\n                    if np.random.rand() < self.crossover_rate:\n                        # Differential Evolution-like mutation\n                        indices = np.random.choice(self.num_particles, 3, replace=False)\n                        donor_vector = particles[indices[0]] + self.mutation_factor * (particles[indices[1]] - particles[indices[2]])\n                        trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, donor_vector, particles[j])\n                        trial_vector = np.clip(trial_vector, lb, ub)\n                        \n                        trial_value = func(trial_vector)\n                        eval_count += 1\n                        \n                        if trial_value < personal_best_values[j]:\n                            particles[j] = trial_vector\n                            personal_best[j] = trial_vector\n                            personal_best_values[j] = trial_value\n                            \n                            if trial_value < best_value:\n                                global_best = trial_vector\n                                best_value = trial_value\n                                \n                            if eval_count >= self.budget:\n                                break\n\n        return global_best", "configspace": "", "generation": 85, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40660 with standard deviation 0.36343.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.15988301221014856, 0.9204399029806292, 0.13947817744519497]}}
{"id": "9cd57010-664d-45a5-aa63-49bcb837c66c", "fitness": 0.37584814232756164, "name": "AdvancedParticleOptimizer", "description": "An enhanced particle swarm optimizer with improved global best selection using an adaptive diversity threshold and dynamic particle count for refining convergence.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)\n                        break\n\n            # Dynamic particle count reduction\n            if np.std(personal_best_values) < self.diversity_threshold:\n                self.num_particles = max(10, int(self.num_particles * 0.9))  # Change made here\n\n        return global_best", "configspace": "", "generation": 86, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37585 with standard deviation 0.37390.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.9043946045789979, 0.12497037211865836, 0.09817945028502861]}}
{"id": "ebb3a203-3f7e-4e73-aaac-22e5cfee6b5f", "fitness": 0.8802621473842592, "name": "DynamicParticleOptimizer", "description": "A dynamic particle optimizer that adapts its search strategy using both fitness diversity and momentum to balance exploration and exploitation for enhanced convergence.", "code": "import numpy as np\n\nclass DynamicParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.adaptive_momentum = np.zeros(self.num_particles)\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                self.adaptive_momentum[i] = (self.adaptive_momentum[i] * self.cooling_rate +\n                                             (personal_best_values[i] - best_value))\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]) +\n                                 0.1 * self.adaptive_momentum[i])\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Update inertia weight\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n            \n            # Dynamic diversity preservation\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)\n                        break\n\n        return global_best", "configspace": "", "generation": 87, "feedback": "The algorithm DynamicParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88026 with standard deviation 0.04499.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.9052468478677693, 0.9184425374666442, 0.8170970568183643]}}
{"id": "cbc73fc9-660a-4a55-b2b0-28bee80ac067", "fitness": 0.9129469271918936, "name": "EnhancedParticleOptimizer", "description": "An improved particle swarm optimizer with dynamic grouping, adaptive learning rates, and restart strategies for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_decay = 0.99\n        self.restart_threshold = 0.05 # Controls when to restart particles for diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)\n                        break\n\n            # Dynamic grouping and adaptive learning rates\n            if np.std(personal_best_values) < self.restart_threshold:\n                self.inertia_weight = 0.9\n                self.cognitive_coeff = 2.0\n                self.social_coeff = 2.5\n                random_indices = np.random.choice(self.num_particles, size=int(self.num_particles * 0.5), replace=False)\n                particles[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n                personal_best[random_indices] = particles[random_indices]\n                personal_best_values[random_indices] = np.array([func(x) for x in particles[random_indices]])\n                eval_count += len(random_indices)\n\n            self.cognitive_coeff *= self.learning_rate_decay\n            self.social_coeff *= self.learning_rate_decay\n\n        return global_best", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91295 with standard deviation 0.01923.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.9331459994864453, 0.8870864114472028, 0.9186083706420327]}}
{"id": "891b3f23-a810-4886-b502-22ca98a0075d", "fitness": 0.6315797909344391, "name": "AdvancedParticleOptimizer", "description": "Enhance the exploration mechanism by introducing a random perturbation in the velocity update to improve search efficiency.", "code": "import numpy as np\n\nclass AdvancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(3)  # Additional random factor\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]) +\n                                 0.05 * r3 * (ub - lb))  # Random perturbation added\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + 0.1 * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        self.diversity_threshold = max(0.05, self.diversity_threshold * 0.9)  # Change made here\n                        break\n\n        return global_best", "configspace": "", "generation": 89, "feedback": "The algorithm AdvancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63158 with standard deviation 0.32611.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.1920428072510435, 0.972283645029393, 0.7304129205228805]}}
{"id": "94187aeb-a011-4a98-8c60-302f73244e3b", "fitness": 0.9334620876349488, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer that integrates adaptive learning rates and periodic velocity perturbations to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                \n                # Periodic velocity perturbation\n                if eval_count % (self.num_particles * 2) == 0:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    velocities[i] += perturbation\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 90, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93346 with standard deviation 0.02126.", "error": "", "parent_ids": ["98086254-a09f-4c8a-8a37-e081915c9803"], "operator": null, "metadata": {"aucs": [0.9624340449895401, 0.9259406320368324, 0.9120115858784739]}}
{"id": "e58de01d-6441-40ad-aba6-79a59d3dfbe8", "fitness": 0.24069774897318655, "name": "RefinedParticleOptimizer", "description": "Enhanced particle optimizer integrating dynamic neighborhood-based learning and adaptive velocity scaling to improve convergence reliability.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n\n        # Initialize neighborhood information\n        neighborhood_radius = max(1, self.num_particles // 10)\n\n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                # Dynamic neighborhood-based learning\n                neighbors = np.random.choice(self.num_particles, neighborhood_radius, replace=False)\n                local_best = min(neighbors, key=lambda n: personal_best_values[n])\n                \n                r1, r2, r3 = np.random.rand(3)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]) +\n                                 self.social_coeff * r3 * (personal_best[local_best] - particles[i]))\n\n                # Adaptive velocity scaling\n                velocities[i] *= np.exp(-np.linalg.norm(velocities[i]))\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n\n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n\n            self.inertia_weight = max(self.inertia_weight_min,\n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n\n            self.temperature *= self.cooling_rate\n\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 91, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24070 with standard deviation 0.19926.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.1022325667330386, 0.5224809475490204, 0.09737973263750066]}}
{"id": "65a35319-27f1-427c-a28f-36d8f5e3578e", "fitness": 0.6762364193098168, "name": "MemoryEnhancedParticleOptimizer", "description": "An adaptive memory-based particle swarm optimizer that incorporates dynamic diversity control and adaptive learning rates to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass MemoryEnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.memory_coeff = 1.2\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n        self.memory_size = 5\n        self.particle_memory = np.zeros((self.num_particles, self.memory_size, self.dim))\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n        personal_memory = np.repeat(particles[:, np.newaxis, :], self.memory_size, axis=1)\n        memory_values = np.repeat(personal_best_values[:, np.newaxis], self.memory_size, axis=1)\n        \n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(3)\n                memory_index = np.argmin(memory_values[i])\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]) +\n                                 self.memory_coeff * r3 * (personal_memory[i, memory_index] - particles[i]))\n\n                if eval_count % (self.num_particles * 2) == 0:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    velocities[i] += perturbation\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if current_value < np.max(memory_values[i]):\n                    max_index = np.argmax(memory_values[i])\n                    personal_memory[i, max_index] = particles[i]\n                    memory_values[i, max_index] = current_value\n                \n                if eval_count >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 92, "feedback": "The algorithm MemoryEnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67624 with standard deviation 0.25021.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.9335919734312785, 0.7578698663446186, 0.3372474181535533]}}
{"id": "f49bc165-11de-4787-a57e-a80b6b467d3e", "fitness": 0.3665388802757788, "name": "HybridParticleOptimizer", "description": "A hybrid particle swarm optimizer that combines adaptive learning rates, dynamic neighborhood topology, and Gaussian mutation to enhance exploration and maintain diversity.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n        self.neighborhood_size = 5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                \n                # Choose dynamic neighborhood\n                neighbors_idx = np.random.choice(self.num_particles, self.neighborhood_size, replace=False)\n                local_best_idx = neighbors_idx[np.argmin(personal_best_values[neighbors_idx])]\n                local_best = personal_best[local_best_idx]\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (local_best - particles[i]))\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with Gaussian mutation\n            if np.std(personal_best_values) < self.diversity_threshold:\n                for j in range(self.num_particles):\n                    potential_mutation = particles[j] + self.compression_factor * np.random.randn(self.dim)\n                    potential_mutation = np.clip(potential_mutation, lb, ub)\n                    mutated_value = func(potential_mutation)\n                    eval_count += 1\n                    \n                    if mutated_value < best_value or np.random.rand() < 0.1:\n                        global_best = potential_mutation\n                        best_value = mutated_value\n                        break\n        \n        return global_best", "configspace": "", "generation": 93, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36654 with standard deviation 0.31251.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.13059135111628228, 0.8081535344493966, 0.16087175526165753]}}
{"id": "99c2a0bf-9b6e-4849-8e0f-e51a8aba6b17", "fitness": 0.6686766468911128, "name": "HybridParticleOptimizer", "description": "A hybrid particle swarm optimizer integrating adaptive learning rates, genetic operations, and periodic velocity perturbations for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n        self.learning_rate_adapt = 0.05\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                \n                # Periodic velocity perturbation\n                if eval_count % (self.num_particles * 2) == 0:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    velocities[i] += perturbation\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Genetic algorithm-inspired improvements\n            if np.std(personal_best_values) < self.diversity_threshold:\n                for j in range(self.num_particles):\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.1, self.dim)\n                        particles[j] += mutation\n\n                    if np.random.rand() < self.crossover_rate:\n                        partner_idx = np.random.randint(self.num_particles)\n                        crossover_point = np.random.randint(1, self.dim)\n                        particles[j][:crossover_point] = personal_best[partner_idx][:crossover_point]\n                        \n                        particles[j] = np.clip(particles[j], lb, ub)\n\n                particles_values = np.array([func(x) for x in particles])\n                eval_count += len(particles)\n                \n                best_idx = np.argmin(particles_values)\n                if particles_values[best_idx] < best_value:\n                    global_best = particles[best_idx]\n                    best_value = particles_values[best_idx]\n\n        return global_best", "configspace": "", "generation": 94, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66868 with standard deviation 0.40198.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.9624340449895401, 0.9432963979819396, 0.10029949770185909]}}
{"id": "0b559eed-1693-40c0-91ec-e063f0849381", "fitness": 0.8388950430848893, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with an enhanced exploration mechanism using Gaussian perturbation and improved adaptive inertia weight adjustment for better convergence.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                \n                # Periodic velocity perturbation with increased exploration\n                if eval_count % (self.num_particles * 2) == 0:\n                    perturbation = np.random.normal(0, 0.2, self.dim)  # Increased perturbation scale\n                    velocities[i] += perturbation\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction with improved calculation\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * (self.cooling_rate ** 1.1) + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 95, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83890 with standard deviation 0.08118.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.7249662642509935, 0.8835842619963646, 0.9081346030073094]}}
{"id": "f0ffe8b5-a3dd-4886-8960-58b82e51cc65", "fitness": 0.867769257488423, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer that integrates adaptive learning rates and periodic velocity perturbations to enhance exploration and prevent premature convergence, with improved diversity preservation using a dynamic compression factor adjustment.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                \n                # Periodic velocity perturbation\n                if eval_count % (self.num_particles * 2) == 0:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    velocities[i] += perturbation\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with dynamic compression adjustment\n            if np.std(personal_best_values) < self.diversity_threshold:\n                self.compression_factor = max(0.1, self.compression_factor * 1.1)  # Dynamic adjustment line\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 96, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86777 with standard deviation 0.08618.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.9624340449895401, 0.8869092198886979, 0.753964507587031]}}
{"id": "2aaaf721-2954-4c3b-a3ec-625758283dc6", "fitness": 0.9334620876349488, "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with adaptive inertia weight enhancement and velocity perturbation to boost exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                \n                # Periodic velocity perturbation\n                if eval_count % (self.num_particles * 2) == 0:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    velocities[i] += perturbation\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(personal_best_values)))\n\n            # Simulated annealing-inspired acceptance mechanism\n            if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                global_best = particles[i]\n                best_value = current_value\n            \n            self.temperature *= self.cooling_rate\n            \n            # Enhanced diversity preservation with compression\n            if np.std(personal_best_values) < self.diversity_threshold:\n                compressed_particles = particles + self.compression_factor * np.random.randn(*particles.shape)\n                compressed_particles = np.clip(compressed_particles, lb, ub)\n                compressed_values = np.array([func(x) for x in compressed_particles])\n                eval_count += len(compressed_particles)\n                \n                for j in range(len(compressed_particles)):\n                    if compressed_values[j] < best_value or np.random.rand() < 0.1:\n                        global_best = compressed_particles[j]\n                        best_value = compressed_values[j]\n                        break\n\n        return global_best", "configspace": "", "generation": 97, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93346 with standard deviation 0.02126.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.9624340449895401, 0.9259406320368324, 0.9120115858784739]}}
{"id": "cbc701c1-c36a-47e6-bc22-4cc44fd94a3e", "fitness": 0.3966675319551043, "name": "EnhancedParticleOptimizer", "description": "A novel particle swarm optimizer that combines adaptive velocity control, a differential evolution-inspired mutation mechanism, and dynamic neighborhood topology to enhance exploration and exploitation for improved convergence performance.", "code": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.95\n        self.diversity_threshold = 0.1\n        self.mutation_factor = 0.8\n        self.local_search_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.zeros((self.num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_values = np.array([func(x) for x in personal_best])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        best_value = min(personal_best_values)\n\n        eval_count = self.num_particles\n        \n        while eval_count < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - particles[i]) +\n                                 self.social_coeff * r2 * (global_best - particles[i]))\n                \n                # Differential evolution-inspired mutation\n                indices = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = personal_best[indices[0]] + self.mutation_factor * (personal_best[indices[1]] - personal_best[indices[2]])\n                velocities[i] = (velocities[i] + self.local_search_rate * (mutant_vector - particles[i]))\n                \n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                current_value = func(particles[i])\n                eval_count += 1\n                \n                if current_value < personal_best_values[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_values[i] = current_value\n                    \n                    if current_value < best_value:\n                        global_best = particles[i]\n                        best_value = current_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight reduction\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.cooling_rate)\n\n            # Dynamic neighborhood topology\n            if np.std(personal_best_values) < self.diversity_threshold:\n                local_best_index = np.argmin(personal_best_values[np.random.choice(self.num_particles, size=5, replace=False)])\n                global_best = personal_best[local_best_index]\n                best_value = personal_best_values[local_best_index]\n            \n            self.temperature *= self.cooling_rate\n        \n        return global_best", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39667 with standard deviation 0.36883.", "error": "", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {"aucs": [0.17968818273007636, 0.9159454718297279, 0.09436894130550855]}}
{"id": "afeeb9cd-4e22-45d9-8bfd-ff0a1a8d28f9", "fitness": -Infinity, "name": "DynamicMultiSwarmOptimizer", "description": "A dynamic multi-swarm optimizer with adaptive merging and splitting to balance global exploration and local exploitation, enhancing convergence speed and solution quality.", "code": "import numpy as np\n\nclass DynamicMultiSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles_per_swarm = 30\n        self.num_swarms = 3\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.temperature = 100\n        self.cooling_rate = 0.9\n        self.diversity_threshold = 0.1\n        self.compression_factor = 0.5\n        self.learning_rate_adapt = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarms = [np.random.uniform(lb, ub, (self.num_particles_per_swarm, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.zeros((self.num_particles_per_swarm, self.dim)) for _ in range(self.num_swarms)]\n        personal_best = [swarm.copy() for swarm in swarms]\n        personal_best_values = [np.array([func(x) for x in swarm]) for swarm in personal_best]\n        global_best = min((swarm[np.argmin(values)], np.min(values)) for swarm, values in zip(personal_best, personal_best_values))[0]\n        best_value = min(np.min(values) for values in personal_best_values)\n\n        eval_count = self.num_particles_per_swarm * self.num_swarms\n\n        while eval_count < self.budget:\n            new_swarms = []\n            for swarm_idx, (swarm, velocity, p_best, p_best_values) in enumerate(zip(swarms, velocities, personal_best, personal_best_values)):\n                if eval_count >= self.budget:\n                    break\n\n                for i in range(self.num_particles_per_swarm):\n                    r1, r2 = np.random.rand(2)\n                    velocity[i] = (self.inertia_weight * velocity[i] +\n                                   self.cognitive_coeff * r1 * (p_best[i] - swarm[i]) +\n                                   self.social_coeff * r2 * (global_best - swarm[i]))\n\n                    swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n\n                    current_value = func(swarm[i])\n                    eval_count += 1\n\n                    if current_value < p_best_values[i]:\n                        p_best[i] = swarm[i]\n                        p_best_values[i] = current_value\n                        \n                        if current_value < best_value:\n                            global_best = swarm[i]\n                            best_value = current_value\n\n                # Adaptive inertia weight reduction\n                self.inertia_weight = max(self.inertia_weight_min, \n                                          self.inertia_weight * self.cooling_rate + self.learning_rate_adapt * (best_value - min(p_best_values)))\n\n                # Simulated annealing-inspired acceptance mechanism\n                if np.random.rand() < np.exp(-abs(current_value - best_value) / self.temperature):\n                    global_best = swarm[i]\n                    best_value = current_value\n\n                self.temperature *= self.cooling_rate\n\n                # Check if swarm needs to be split or merged\n                if np.std(p_best_values) < self.diversity_threshold and len(swarms) < 5:\n                    split_swarm = np.array_split(swarm, 2)\n                    split_velocity = np.array_split(velocity, 2)\n                    split_pbest = np.array_split(p_best, 2)\n                    split_pbest_values = np.array_split(p_best_values, 2)\n                    new_swarms.extend(zip(split_swarm, split_velocity, split_pbest, split_pbest_values))\n                else:\n                    new_swarms.append((swarm, velocity, p_best, p_best_values))\n\n            if len(new_swarms) > 1 and len(new_swarms) == self.num_swarms:\n                # Attempt to merge two similar swarms\n                for idx in range(0, len(new_swarms) - 1, 2):\n                    swarm1, vel1, pbest1, pbest_values1 = new_swarms[idx]\n                    swarm2, vel2, pbest2, pbest_values2 = new_swarms[idx+1]\n                    if np.linalg.norm(np.mean(pbest1, axis=0) - np.mean(pbest2, axis=0)) < self.diversity_threshold:\n                        merged_swarm = np.vstack((swarm1, swarm2))\n                        merged_velocity = np.vstack((vel1, vel2))\n                        merged_pbest = np.vstack((pbest1, pbest2))\n                        merged_pbest_values = np.hstack((pbest_values1, pbest_values2))\n                        new_swarms[idx] = (merged_swarm, merged_velocity, merged_pbest, merged_pbest_values)\n                        new_swarms.pop(idx+1)\n\n            swarms = [item[0] for item in new_swarms]\n            velocities = [item[1] for item in new_swarms]\n            personal_best = [item[2] for item in new_swarms]\n            personal_best_values = [item[3] for item in new_swarms]\n\n        return global_best", "configspace": "", "generation": 99, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["94187aeb-a011-4a98-8c60-302f73244e3b"], "operator": null, "metadata": {}}
