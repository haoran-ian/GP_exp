{"id": "0ea2e0c7-8fd1-4438-b49b-e0d9106c6e7e", "fitness": 0.39184819334261706, "name": "AMPSO", "description": "Adaptive Memory-based Particle Swarm Optimization (AMPSO) that dynamically adjusts particles' memory and utilizes a global adaptive learning strategy.", "code": "import numpy as np\n\nclass AMPSO:\n    def __init__(self, budget, dim, population_size=30, w=0.5, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w = w  # inertia weight\n        self.c1 = c1  # cognitive (personal) coefficient\n        self.c2 = c2  # social (global) coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = self.w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 0, "feedback": "The algorithm AMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39185 with standard deviation 0.40103.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06055746336165002, 0.9561407462758804, 0.1588463703903209]}}
{"id": "95a1edb2-052a-4deb-a928-a16e5240f49d", "fitness": 0.10457155737122892, "name": "AMPSO", "description": "Enhanced Adaptive Memory-based Particle Swarm Optimization (AMPSO) with dynamic inertia weight adjustment for improved convergence.", "code": "import numpy as np\n\nclass AMPSO:\n    def __init__(self, budget, dim, population_size=30, w=0.9, c1=2.0, c2=2.0):  # Adjusted initial inertia weight\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w = w  # inertia weight\n        self.c1 = c1  # cognitive (personal) coefficient\n        self.c2 = c2  # social (global) coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = self.w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 1, "feedback": "The algorithm AMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10457 with standard deviation 0.02041.", "error": "", "parent_ids": ["0ea2e0c7-8fd1-4438-b49b-e0d9106c6e7e"], "operator": null, "metadata": {"aucs": [0.10263083740378409, 0.08059637766871552, 0.13048745704118714]}}
{"id": "de6d1a3b-99d5-4f28-b675-b0c1b490e232", "fitness": 0.09126075893004877, "name": "AMPSO", "description": "Enhanced AMPSO by incorporating adaptive inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AMPSO:\n    def __init__(self, budget, dim, population_size=30, w=0.5, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w = w  # inertia weight\n        self.c1 = c1  # cognitive (personal) coefficient\n        self.c2 = c2  # social (global) coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = self.w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 2, "feedback": "The algorithm AMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09126 with standard deviation 0.00947.", "error": "", "parent_ids": ["0ea2e0c7-8fd1-4438-b49b-e0d9106c6e7e"], "operator": null, "metadata": {"aucs": [0.10304039584724378, 0.0798440501446761, 0.09089783079822644]}}
{"id": "7a84ee7c-e39b-45ad-ae03-4291a3213c04", "fitness": 0.14830867657417332, "name": "EMPSO", "description": "Enhanced Memory-based Particle Swarm Optimization (EMPSO) with adaptive inertia and velocity clamping for improved convergence stability.", "code": "import numpy as np\n\nclass EMPSO:\n    def __init__(self, budget, dim, population_size=30, w_min=0.2, w_max=0.9, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_min = w_min  # minimum inertia weight\n        self.w_max = w_max  # maximum inertia weight\n        self.c1 = c1  # cognitive (personal) coefficient\n        self.c2 = c2  # social (global) coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], lower_bounds - upper_bounds, upper_bounds - lower_bounds)\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 3, "feedback": "The algorithm EMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14831 with standard deviation 0.05455.", "error": "", "parent_ids": ["0ea2e0c7-8fd1-4438-b49b-e0d9106c6e7e"], "operator": null, "metadata": {"aucs": [0.22430526932562522, 0.09883499454657452, 0.1217857658503202]}}
{"id": "e7793459-f4ca-490b-aae1-feae6c14036b", "fitness": 0.36935267454050424, "name": "EAMPSO", "description": "Enhanced Adaptive Memory-based Particle Swarm Optimization (EAMPSO) that integrates a dynamic inertia weight adjustment and a local search phase for improved convergence.", "code": "import numpy as np\n\nclass EAMPSO:\n    def __init__(self, budget, dim, population_size=30, w=0.9, c1=2.0, c2=2.0, inertia_decay=0.99, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w = w  # initial inertia weight\n        self.c1 = c1  # cognitive (personal) coefficient\n        self.c2 = c2  # social (global) coefficient\n        self.inertia_decay = inertia_decay  # decay factor for inertia weight\n        self.local_search_radius = local_search_radius  # radius for local search\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def local_search(self, position, func, lower_bounds, upper_bounds):\n        # Perform a simple random local search around a position\n        perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n        candidate_position = np.clip(position + perturbation, lower_bounds, upper_bounds)\n        candidate_value = func(candidate_position)\n        return candidate_position, candidate_value\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n                    \n                    # Local search around the new global best\n                    candidate_position, candidate_value = self.local_search(self.global_best_position, func, lower_bounds, upper_bounds)\n                    evaluations += 1\n                    if candidate_value < self.global_best_value:\n                        self.global_best_value = candidate_value\n                        self.global_best_position = candidate_position.copy()\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = self.w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n            # Decay inertia weight\n            self.w *= self.inertia_decay\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 4, "feedback": "The algorithm EAMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36935 with standard deviation 0.39110.", "error": "", "parent_ids": ["0ea2e0c7-8fd1-4438-b49b-e0d9106c6e7e"], "operator": null, "metadata": {"aucs": [0.922249125431142, 0.08000903410852311, 0.1057998640818476]}}
{"id": "e10cbc9f-e9e5-4c6e-b916-ea8c709e39dc", "fitness": 0.41482421957469523, "name": "E_AMPSO", "description": "Enhanced Adaptive Memory-based Particle Swarm Optimization (E-AMPSO) introducing dynamic inertia and diversity preservation for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass E_AMPSO:\n    def __init__(self, budget, dim, population_size=30, w_max=0.9, w_min=0.4, c1=2.0, c2=2.0, epsilon=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max  # maximum inertia weight\n        self.w_min = w_min  # minimum inertia weight\n        self.c1 = c1  # cognitive (personal) coefficient\n        self.c2 = c2  # social (global) coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.epsilon = epsilon  # diversity threshold\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight dynamically\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 5, "feedback": "The algorithm E_AMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41482 with standard deviation 0.37763.", "error": "", "parent_ids": ["0ea2e0c7-8fd1-4438-b49b-e0d9106c6e7e"], "operator": null, "metadata": {"aucs": [0.12327699519616997, 0.9480979381955228, 0.17309772533239287]}}
{"id": "9a5e3633-889f-4f4f-857a-011529243f3f", "fitness": 0.6103696691728594, "name": "AMPSO_NIAM", "description": "Adaptive Memory-based Particle Swarm Optimization with Nonlinear Inertia and Adaptive Mutation (AMPSO-NIAM) to enhance convergence speed and maintain diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM:\n    def __init__(self, budget, dim, population_size=30, w_max=0.9, w_min=0.4, c1=2.05, c2=2.05, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max  # maximum inertia weight\n        self.w_min = w_min  # minimum inertia weight\n        self.c1 = c1  # cognitive coefficient\n        self.c2 = c2  # social coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.epsilon = epsilon  # diversity threshold\n        self.mutation_chance = mutation_chance  # chance of mutation\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight using nonlinear function\n            w = self.w_min + (self.w_max - self.w_min) * (1 - (evaluations / self.budget)**2)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity\n                if np.random.rand() < self.mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 6, "feedback": "The algorithm AMPSO_NIAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61037 with standard deviation 0.35572.", "error": "", "parent_ids": ["e10cbc9f-e9e5-4c6e-b916-ea8c709e39dc"], "operator": null, "metadata": {"aucs": [0.13523095279062813, 0.991075241683172, 0.7048028130447781]}}
{"id": "2f4e00a0-51a9-409e-b0f8-5b2302b5360d", "fitness": 0.4365123804899776, "name": "AMPSO_NIAM", "description": "Improved Adaptive Memory-based Particle Swarm Optimization with Enhanced Mutation Strategy to Boost Performance.", "code": "import numpy as np\n\nclass AMPSO_NIAM:\n    def __init__(self, budget, dim, population_size=30, w_max=0.9, w_min=0.4, c1=2.05, c2=2.05, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max  # maximum inertia weight\n        self.w_min = w_min  # minimum inertia weight\n        self.c1 = c1  # cognitive coefficient\n        self.c2 = c2  # social coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.epsilon = epsilon  # diversity threshold\n        self.mutation_chance = mutation_chance  # chance of mutation\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight using nonlinear function\n            w = self.w_min + (self.w_max - self.w_min) * (1 - (evaluations / self.budget)**2)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity\n                if np.random.rand() < self.mutation_chance:\n                    mutation_vector = np.random.normal(0, 0.5, self.dim) * (upper_bounds - lower_bounds) * 0.1  # Increased mutation effect\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 7, "feedback": "The algorithm AMPSO_NIAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43651 with standard deviation 0.39285.", "error": "", "parent_ids": ["9a5e3633-889f-4f4f-857a-011529243f3f"], "operator": null, "metadata": {"aucs": [0.1301767665682092, 0.9910749820892742, 0.18828539281244916]}}
{"id": "97108c8f-9d1a-4844-bd2d-d87b63116782", "fitness": 0.4477260830283345, "name": "AMPSO_NIAM", "description": "Improved AMPSO-NIAM using adaptive mutation intensity based on particle diversity to enhance exploration.", "code": "import numpy as np\n\nclass AMPSO_NIAM:\n    def __init__(self, budget, dim, population_size=30, w_max=0.9, w_min=0.4, c1=2.05, c2=2.05, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max  # maximum inertia weight\n        self.w_min = w_min  # minimum inertia weight\n        self.c1 = c1  # cognitive coefficient\n        self.c2 = c2  # social coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.epsilon = epsilon  # diversity threshold\n        self.mutation_chance = mutation_chance  # chance of mutation\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight using nonlinear function\n            w = self.w_min + (self.w_max - self.w_min) * (1 - (evaluations / self.budget)**2)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity\n                if np.random.rand() < self.mutation_chance:\n                    mutation_intensity = np.std(personal_best_values)  # New line\n                    mutation_vector = np.random.normal(0, mutation_intensity, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 8, "feedback": "The algorithm AMPSO_NIAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44773 with standard deviation 0.38421.", "error": "", "parent_ids": ["9a5e3633-889f-4f4f-857a-011529243f3f"], "operator": null, "metadata": {"aucs": [0.1738743599860103, 0.9910743999914066, 0.17822948910758662]}}
{"id": "29254c72-69c5-47c1-9fcd-10dd6022b063", "fitness": 0.38266502599393065, "name": "EAMPSO_DGAM", "description": "Enhanced Adaptive Memory-based Particle Swarm Optimization with Dynamic Grouping and Adaptive Mutation (EAMPSO-DGAM) to improve convergence and solution quality by adaptive subgrouping and mutation.", "code": "import numpy as np\n\nclass EAMPSO_DGAM:\n    def __init__(self, budget, dim, population_size=30, w_max=0.9, w_min=0.4, c1=2.05, c2=2.05, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max  # maximum inertia weight\n        self.w_min = w_min  # minimum inertia weight\n        self.c1 = c1  # cognitive coefficient\n        self.c2 = c2  # social coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.epsilon = epsilon  # diversity threshold\n        self.mutation_chance = mutation_chance  # chance of mutation\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Dynamic grouping based on current performance\n            group_size = max(1, self.population_size // (1 + evaluations // (self.budget // 10)))\n            groups = [particles[i:i + group_size] for i in range(0, self.population_size, group_size)]\n\n            for i, particle in enumerate(particles):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particle)\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particle.copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particle.copy()\n\n            # Calculate inertia weight using nonlinear function\n            w = self.w_min + (self.w_max - self.w_min) * (1 - (evaluations / self.budget)**2)\n\n            # Update particles' velocities and positions with group influence\n            for group in groups:\n                group_best_position = group[np.argmin([func(p) for p in group])]\n                for particle in group:\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particle)\n                    social_component = self.c2 * r2 * (group_best_position - particle)\n                    velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                    # Update particle position\n                    particles[i] += velocities[i]\n\n                    # Ensure particles are within bounds\n                    particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                    # Apply adaptive mutation to maintain diversity\n                    if np.random.rand() < self.mutation_chance:\n                        mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * (0.1 + 0.9 * (evaluations / self.budget))\n                        particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles based on group performance\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 9, "feedback": "The algorithm EAMPSO_DGAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38267 with standard deviation 0.42576.", "error": "", "parent_ids": ["9a5e3633-889f-4f4f-857a-011529243f3f"], "operator": null, "metadata": {"aucs": [0.08986769219012969, 0.9846987268991614, 0.07342865889250083]}}
{"id": "3306c1b9-d9c1-4f6a-8dd2-0f498f45df5c", "fitness": 0.6878035942366476, "name": "AMPSO_NIAM", "description": "Introduced a dynamic mutation rate based on stagnation to improve diversity and convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM:\n    def __init__(self, budget, dim, population_size=30, w_max=0.9, w_min=0.4, c1=2.05, c2=2.05, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max  # maximum inertia weight\n        self.w_min = w_min  # minimum inertia weight\n        self.c1 = c1  # cognitive coefficient\n        self.c2 = c2  # social coefficient\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.epsilon = epsilon  # diversity threshold\n        self.mutation_chance = mutation_chance  # chance of mutation\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight using nonlinear function\n            w = self.w_min + (self.w_max - self.w_min) * (1 - (evaluations / self.budget)**2)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 10, "feedback": "The algorithm AMPSO_NIAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68780 with standard deviation 0.37524.", "error": "", "parent_ids": ["9a5e3633-889f-4f4f-857a-011529243f3f"], "operator": null, "metadata": {"aucs": [0.9292231639521426, 0.1578261461333541, 0.9763614726244462]}}
{"id": "32d68c6f-6734-40e2-93cc-dc683da033dc", "fitness": 0.8927588512635026, "name": "AMPSO_NIAM_Enhanced", "description": "Incorporate an adaptive strategy that dynamically adjusts control parameters based on performance and diversity metrics to improve convergence and robustness.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 11, "feedback": "The algorithm AMPSO_NIAM_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89276 with standard deviation 0.05401.", "error": "", "parent_ids": ["3306c1b9-d9c1-4f6a-8dd2-0f498f45df5c"], "operator": null, "metadata": {"aucs": [0.8794569274220515, 0.8342765256477367, 0.9645431007207199]}}
{"id": "9871797f-b9ee-4e56-bb54-4653bddfcf2c", "fitness": 0.6435453698300503, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce a multi-modal exploration strategy and adaptive learning rates to enhance global search and convergence speed.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            adaptive_lr = 0.1 + 0.9 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = adaptive_lr * c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = adaptive_lr * c2 * r2 * (self.global_best_position - particles[i])\n\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                if np.random.rand() < self.mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 12, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64355 with standard deviation 0.34618.", "error": "", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {"aucs": [0.7683985734693762, 0.9910765323766111, 0.17116100364416365]}}
{"id": "d8b1f84a-8813-41cf-a68c-50f471b8aea0", "fitness": 0.7345536108630322, "name": "Enhanced_AMPSO_NIAM", "description": "Enhance AMPSO_NIAM by incorporating an adaptive learning rate for mutation based on convergence speed to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_AMPSO_NIAM:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.prev_best_value = np.inf\n        self.convergence_speed = 0.0\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Adjust mutation rate based on convergence speed\n            if evaluations > 1:\n                improvement = self.prev_best_value - self.global_best_value\n                self.convergence_speed = improvement / self.prev_best_value if self.prev_best_value != 0 else 0\n                self.mutation_chance = max(self.mutation_chance * (1 + self.convergence_speed), 0.05)\n\n            self.prev_best_value = self.global_best_value\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply adaptive mutation\n                if np.random.rand() < self.mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n                    \n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 13, "feedback": "The algorithm Enhanced_AMPSO_NIAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73455 with standard deviation 0.18950.", "error": "", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {"aucs": [0.8331779650869382, 0.9010418540999224, 0.46944101340223576]}}
{"id": "3582f2e4-46b2-41fd-819b-b853877a3686", "fitness": 0.5825454466795463, "name": "AMPSO_NIAM_Refined", "description": "Enhance the adaptive strategy by introducing a dynamic mutation rate based on performance improvement and incorporate a non-linear inertia weight decay for better convergence control.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n        \n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n        \n        evaluations = 0\n        best_improvement = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    improvement = personal_best_values[i] - value\n                    best_improvement = max(best_improvement, improvement)\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight non-linearly and cognitive/social coefficients adaptively\n            w_exp = (evaluations/self.budget)**2  # non-linear decay\n            w = self.w_initial * (1 - w_exp) + self.w_final * w_exp\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply dynamic mutation based on improvement\n                dynamic_mutation_chance = self.mutation_chance + (best_improvement < self.epsilon) * 0.1\n                if np.random.rand() < dynamic_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 14, "feedback": "The algorithm AMPSO_NIAM_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58255 with standard deviation 0.36091.", "error": "", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {"aucs": [0.6432556657281172, 0.9910765323766111, 0.1133041419339108]}}
{"id": "7a366d49-5c80-4064-88d7-a2efcb4f896f", "fitness": -Infinity, "name": "AMPSO_NIAM_Enhanced", "description": "Enhance exploration by implementing a dynamic adjustment of the population size and utilizing a more aggressive mutation strategy when stagnation is detected.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.2  # More aggressive mutation\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles and adjust population size\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                new_population_size = min(self.population_size + 5, 60)  # Dynamic increase\n                particles = np.vstack((particles, np.random.uniform(lower_bounds, upper_bounds, (new_population_size - self.population_size, self.dim))))\n                personal_best_positions = np.vstack((personal_best_positions, particles[-(new_population_size - self.population_size):].copy()))\n                personal_best_values = np.concatenate((personal_best_values, np.full(new_population_size - self.population_size, np.inf)))\n                self.population_size = new_population_size\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 15, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {}}
{"id": "20771f2a-f65a-4413-9b0a-97f9bc311772", "fitness": 0.6500720706885726, "name": "AMPSO_NIAM_Enhanced", "description": "Introduce a diversity-based reinitialization threshold to maintain diversity more effectively.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon * 1.1) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 16, "feedback": "The algorithm AMPSO_NIAM_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65007 with standard deviation 0.38613.", "error": "", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {"aucs": [0.8794569274220515, 0.10621618392294652, 0.9645431007207199]}}
{"id": "30c7b19f-c190-4229-8321-6c35ae50bc2a", "fitness": 0.5536991482175496, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce a dynamic mutation adaptation technique based on the convergence rate to enhance exploration-exploitation balance in AMPSO.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, dynamic_mutation_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.dynamic_mutation_factor = dynamic_mutation_factor\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.convergence_rate = []\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n        last_global_best_value = np.inf\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n            \n            self.convergence_rate.append(last_global_best_value - self.global_best_value)\n            last_global_best_value = self.global_best_value\n\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                if len(self.convergence_rate) > 1:\n                    recent_convergence_rate = np.abs(self.convergence_rate[-1] - self.convergence_rate[-2])\n                    adaptive_mutation_chance = self.mutation_chance + (recent_convergence_rate < self.dynamic_mutation_factor * self.epsilon) * 0.1\n                else:\n                    adaptive_mutation_chance = self.mutation_chance\n\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 17, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.55370 with standard deviation 0.33073.", "error": "", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {"aucs": [0.4785477899186662, 0.9910765323766111, 0.19147312235737168]}}
{"id": "c21aeaad-3558-4a2e-ba5b-aa4c5dc6e227", "fitness": 0.45169939766723033, "name": "AMPSO_NIAM_MultiSwarm", "description": "Introduce a multi-swarm strategy with adaptive sub-population sizes and information sharing to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_MultiSwarm:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, num_swarms=3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.num_swarms = num_swarms\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Split population into multiple swarms\n        swarm_size = self.population_size // self.num_swarms\n        swarms = [np.random.uniform(lower_bounds, upper_bounds, (swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best_positions = [np.copy(swarm) for swarm in swarms]\n        personal_best_values = [np.full(swarm_size, np.inf) for _ in range(self.num_swarms)]\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                for i in range(swarm_size):\n                    if evaluations >= self.budget:\n                        break\n\n                    # Evaluate current position\n                    value = func(swarms[swarm_idx][i])\n                    evaluations += 1\n\n                    # Update personal best\n                    if value < personal_best_values[swarm_idx][i]:\n                        personal_best_values[swarm_idx][i] = value\n                        personal_best_positions[swarm_idx][i] = swarms[swarm_idx][i].copy()\n\n                    # Update global best\n                    if value < self.global_best_value:\n                        self.global_best_value = value\n                        self.global_best_position = swarms[swarm_idx][i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for swarm_idx in range(self.num_swarms):\n                for i in range(swarm_size):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    cognitive_component = c1 * r1 * (personal_best_positions[swarm_idx][i] - swarms[swarm_idx][i])\n                    social_component = c2 * r2 * (self.global_best_position - swarms[swarm_idx][i])\n                    velocities[swarm_idx][i] = w * velocities[swarm_idx][i] + cognitive_component + social_component\n\n                    # Update particle position\n                    swarms[swarm_idx][i] += velocities[swarm_idx][i]\n\n                    # Ensure particles are within bounds\n                    swarms[swarm_idx][i] = np.clip(swarms[swarm_idx][i], lower_bounds, upper_bounds)\n\n                    # Apply mutation to maintain diversity adaptively\n                    adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values[swarm_idx]) < self.epsilon) * 0.1\n                    if np.random.rand() < adaptive_mutation_chance:\n                        mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                        swarms[swarm_idx][i] = np.clip(swarms[swarm_idx][i] + mutation_vector, lower_bounds, upper_bounds)\n\n                # Maintain diversity by reinitializing stagnant particles\n                if np.std(personal_best_values[swarm_idx]) < self.epsilon:\n                    stagnant_indices = np.where(personal_best_values[swarm_idx] > np.percentile(personal_best_values[swarm_idx], 75))[0]\n                    for idx in stagnant_indices:\n                        swarms[swarm_idx][idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                        personal_best_positions[swarm_idx][idx] = swarms[swarm_idx][idx].copy()\n                        personal_best_values[swarm_idx][idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 18, "feedback": "The algorithm AMPSO_NIAM_MultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45170 with standard deviation 0.29611.", "error": "", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {"aucs": [0.351063775786991, 0.8540503300211378, 0.14998408719356215]}}
{"id": "0b65ed85-ceae-4433-a09c-47edf2736988", "fitness": 0.9458729378430307, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce a neighborhood-based learning component to exploit local information and enhance convergence by dynamically forming subgroups that share information more effectively.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Neighborhood-based learning\n                neighbors_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 19, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94587 with standard deviation 0.01857.", "error": "", "parent_ids": ["32d68c6f-6734-40e2-93cc-dc683da033dc"], "operator": null, "metadata": {"aucs": [0.9291258745327539, 0.9367334737762971, 0.9717594652200412]}}
{"id": "c8e719c8-ee9e-407a-8e61-1358b732ac5c", "fitness": 0.9484643635445439, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance exploration by dynamically adjusting neighborhood size based on diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 20, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94846 with standard deviation 0.01665.", "error": "", "parent_ids": ["0b65ed85-ceae-4433-a09c-47edf2736988"], "operator": null, "metadata": {"aucs": [0.9341260097505595, 0.9394596163416111, 0.9718074645414612]}}
{"id": "49d72d76-0876-48bd-aac1-e9f0e69caa60", "fitness": 0.9484643635445439, "name": "AMPSO_NIAM_Enhanced_Refined_Advanced", "description": "Integrate historical exploration data to dynamically adjust particle inertia and enhance overall convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_Advanced:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.history = []\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n            # Record historical data for inertia adjustment\n            self.history.append(np.mean(personal_best_values))\n            if len(self.history) > 5:\n                recent_improvement = self.history[-1] - self.history[-6]\n                w *= (1 + np.tanh(recent_improvement))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 21, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_Advanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94846 with standard deviation 0.01665.", "error": "", "parent_ids": ["c8e719c8-ee9e-407a-8e61-1358b732ac5c"], "operator": null, "metadata": {"aucs": [0.9341260097505595, 0.9394596163416111, 0.9718074645414612]}}
{"id": "57538f45-6033-459a-9575-506f4b02b6b2", "fitness": 0.6805954839592564, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Improve convergence by introducing dynamic velocity scaling and adaptive mutation based on evaluation progress.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocity_scale = 1 - evaluations / self.budget\n                velocities[i] = velocity_scale * (w * velocities[i] + cognitive_component + social_component)\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation with changing strategy\n                adaptive_mutation_chance = self.mutation_chance + np.exp(-evaluations / self.budget) * 0.05\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 22, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68060 with standard deviation 0.32413.", "error": "", "parent_ids": ["c8e719c8-ee9e-407a-8e61-1358b732ac5c"], "operator": null, "metadata": {"aucs": [0.22761275481367593, 0.9679050296005008, 0.846268667463592]}}
{"id": "f507094b-2625-4913-9f1d-e6d0a3295c65", "fitness": 0.9490563058048535, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Refine exploration by adjusting mutation vector scale based on evaluation progress.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget)  # Refined line\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 23, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94906 with standard deviation 0.01613.", "error": "", "parent_ids": ["c8e719c8-ee9e-407a-8e61-1358b732ac5c"], "operator": null, "metadata": {"aucs": [0.9361942114324018, 0.9391672414406974, 0.9718074645414612]}}
{"id": "b0979865-78f2-4c6d-979f-ec1cdc78e03b", "fitness": 0.9270057351855164, "name": "Enhanced_AMPSO", "description": "Enhance exploration-exploitation balance by dynamically adjusting mutation vector scale and neighborhood size based on diversity and convergence metrics.", "code": "import numpy as np\n\nclass Enhanced_AMPSO:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n\n                # Dynamic neighborhood adjustment for enhanced diversity and convergence\n                diversity_measure = np.std(personal_best_values)\n                adjusted_neighborhood_size = int(self.neighborhood_size + (diversity_measure > self.epsilon) * 3)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (diversity_measure < self.epsilon) * 0.15\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.15 * (1 - evaluations / self.budget)  # Further refined line\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Reinitialize stagnant particles based on a broader diversity measure\n            if diversity_measure < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 24, "feedback": "The algorithm Enhanced_AMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92701 with standard deviation 0.03553.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.894188409726488, 0.9763629527923829, 0.9104658430376784]}}
{"id": "c724e55f-2ac0-4353-acac-500d9d996a53", "fitness": 0.928796400994912, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Improve convergence speed by dynamically adjusting mutation scale and mutation chance based on search space contraction.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance * (1 - evaluations / self.budget)  # Adjusted line\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.1 * np.exp(-3 * evaluations / self.budget)  # Adjusted line\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 25, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92880 with standard deviation 0.01805.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9158579351604614, 0.9543164749028664, 0.9162147929214081]}}
{"id": "a11b0194-2c31-40d3-b5fe-78810ca35e3f", "fitness": 0.9159898594011701, "name": "AMPSO_NIAM_Enhanced_Refined_2", "description": "Enhanced diversity management and adaptive neighborhood size for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_2:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            w = self.w_final + (self.w_initial - self.w_final) * (1 - (evaluations / self.budget)**2)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 3)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + 0.5 * social_component\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.15\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.2 * (1 - evaluations / self.budget)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 80))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 26, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91599 with standard deviation 0.03782.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.8652397196062218, 0.955977197983219, 0.9267526606140697]}}
{"id": "83effcd6-713c-4eb5-944b-e76869fdba3f", "fitness": 0.7971106298650193, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance exploration by dynamically adjusting both mutation vector scale and cognitive component based on progress and diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.15 * (1 - evaluations / self.budget)  # Adjusted line\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n                # Adjust cognitive component based on diversity\n                if np.std(personal_best_values) < self.epsilon:\n                    velocities[i] += 0.1 * (np.random.uniform(lower_bounds, upper_bounds, self.dim) - particles[i])  # New line\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 27, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.79711 with standard deviation 0.23670.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9431149553618704, 0.9849723652567915, 0.4632445689763963]}}
{"id": "db757c6e-37b2-46f0-8b7c-df990d0447bb", "fitness": 0.6548630364592619, "name": "AMPSO_NIAM_Enhanced_Refined_Adaptive", "description": "Enhance exploration by dynamically adapting mutation scale and neighborhood size based on population diversity and iteration progress.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_Adaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                if np.random.rand() < self.mutation_chance:\n                    dynamic_mutation_scale = 0.05 + 0.1 * (1 - evaluations / self.budget) * (np.std(personal_best_values) > self.epsilon)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * dynamic_mutation_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 28, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65486 with standard deviation 0.37205.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.8877499751181254, 0.1298133852992409, 0.9470257489604196]}}
{"id": "fd5bef7c-2dde-4995-8689-b8d857ce1ba7", "fitness": 0.9073687706139193, "name": "AMPSO_NIAM_Enhanced_Dynamic", "description": "Introduce dynamic scaling based on convergence speed and integrate adaptive local search for intensified exploration.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Dynamic:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply dynamic mutation for diversity\n                convergence_speed = 1 - (evaluations / self.budget)\n                dynamic_mutation_chance = self.mutation_chance * convergence_speed\n                if np.random.rand() < dynamic_mutation_chance:\n                    mutation_vector_scale = 0.1 * convergence_speed\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n                # Adaptive local search for intensified exploration\n                if np.random.rand() < 0.05 * convergence_speed:\n                    search_vector = np.random.normal(0, 0.1, self.dim) * (upper_bounds - lower_bounds) * convergence_speed\n                    candidate = particles[i] + search_vector\n                    candidate = np.clip(candidate, lower_bounds, upper_bounds)\n                    candidate_value = func(candidate)\n                    evaluations += 1\n                    if candidate_value < personal_best_values[i]:\n                        personal_best_positions[i] = candidate\n                        personal_best_values[i] = candidate_value\n                        if candidate_value < self.global_best_value:\n                            self.global_best_position = candidate\n                            self.global_best_value = candidate_value\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 29, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Dynamic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90737 with standard deviation 0.05949.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9286719765374087, 0.9672051574936195, 0.82622917781073]}}
{"id": "74d7a6ce-928b-4150-b4a3-10d3e41ba851", "fitness": 0.9490563058048535, "name": "AMPSO_NIAM_Enhanced_Refined_Adaptive", "description": "Enhance exploitation by incorporating an adaptive cooling schedule to the mutation strategy for more effective convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_Adaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    cooling_factor = (1 - evaluations / self.budget) ** 2\n                    mutation_vector_scale = 0.1 * cooling_factor  # Adaptive cooling schedule\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 30, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94906 with standard deviation 0.01613.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9361942114324018, 0.9391672414406974, 0.9718074645414612]}}
{"id": "7426c593-2cfc-4b60-b4c3-4300c1ca2e6c", "fitness": 0.9370792779166895, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance exploration by dynamically adjusting both inertia weight and mutation vector scale to maintain diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.2 * (1 - evaluations / self.budget)  # Modified line\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 31, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93708 with standard deviation 0.03034.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9431492196257086, 0.8972606961395357, 0.9708279179848245]}}
{"id": "2e29f1ae-53a7-49aa-98dc-be1a524f3bb3", "fitness": 0.9124222995296041, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce adaptive mutation scaling based on both evaluation progress and performance diversity to enhance convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (np.std(personal_best_values) / np.inf)  # Refined line\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 32, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91242 with standard deviation 0.01332.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.909655067656104, 0.9299372709976416, 0.8976745599350664]}}
{"id": "34921573-d175-4d18-941e-440d16f4f0b3", "fitness": 0.9444998573906483, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance exploration by adjusting mutation vector scale based on proximity to global best.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    distance_to_global_best = np.linalg.norm(particles[i] - self.global_best_position) / np.linalg.norm(upper_bounds - lower_bounds)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (0.5 + distance_to_global_best)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 33, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94450 with standard deviation 0.02315.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.915201913094115, 0.9464901945363686, 0.9718074645414612]}}
{"id": "46f56e38-b780-4826-bb02-24815b637f07", "fitness": 0.9394972783454358, "name": "AMPSO_NIAM_Enhanced_Adaptive", "description": "Enhance adaptability by dynamically adjusting inertia weight and mutation based on both evaluation progress and particle diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Adaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            diversity_factor = np.std(personal_best_values)\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (diversity_factor > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (diversity_factor < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + diversity_factor)  # Enhanced line\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if diversity_factor < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 34, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93950 with standard deviation 0.02448.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9341260097505595, 0.9125583607442866, 0.9718074645414612]}}
{"id": "916cf3a5-a49f-4a77-84ef-1103989b1a00", "fitness": 0.9101544591691934, "name": "Enhanced_AMPSO", "description": "Enhance exploration by dynamically adjusting mutation based on diversity and evaluation phase to improve convergence.", "code": "import numpy as np\n\nclass Enhanced_AMPSO:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                diversity_factor = np.std(personal_best_values)\n                adaptive_mutation_chance = self.mutation_chance + (diversity_factor < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    phase_factor = 1 - np.cos((np.pi * evaluations) / (2 * self.budget))\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * phase_factor\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 35, "feedback": "The algorithm Enhanced_AMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91015 with standard deviation 0.01595.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.909655067656104, 0.9299372709976416, 0.8908710388538346]}}
{"id": "0dec9571-466b-47c6-a120-868f5192267d", "fitness": 0.6880290802425586, "name": "AMPSO_NIAM_Enhanced_DynamicMutation", "description": "Enhance local exploration by implementing a dynamic mutation strategy that adapts based on the success of recent explorations.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_DynamicMutation:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.recent_success_count = 0\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n                    self.recent_success_count += 1  # Count successful improvements\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply dynamic mutation strategy based on recent successes\n                dynamic_mutation_chance = self.mutation_chance + 0.05 * (self.recent_success_count / self.population_size)\n                if np.random.rand() < dynamic_mutation_chance:\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n            # Reset recent success count for the next iteration\n            self.recent_success_count = 0\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 36, "feedback": "The algorithm AMPSO_NIAM_Enhanced_DynamicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68803 with standard deviation 0.36598.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9329587423353665, 0.9604335466842411, 0.17069495170806825]}}
{"id": "28c03486-170f-4290-b180-7a664e3df54e", "fitness": 0.9501667153902801, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance mutation strategy by dynamically tuning the mutation vector scale based on personal best improvements.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 37, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95017 with standard deviation 0.01532.", "error": "", "parent_ids": ["f507094b-2625-4913-9f1d-e6d0a3295c65"], "operator": null, "metadata": {"aucs": [0.9401865625108989, 0.9385009801354923, 0.971812603524449]}}
{"id": "48bc4084-2bda-4285-b0ca-be6d63ca6856", "fitness": 0.9084913119483525, "name": "AMPSO_NIAM_Enhanced_Refined_v2", "description": "Introduce a multi-phase cooling schedule for adaptive parameters to balance exploration and exploitation dynamically, with stochastic neighborhood reinitialization to maintain diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_v2:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n        phase_duration = self.budget // 3\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Determine the current phase\n            phase = evaluations // phase_duration\n\n            # Update parameters based on the phase\n            if phase == 0:\n                w = self.w_initial * 0.9\n                c1 = self.c1_initial * 1.1\n                c2 = self.c2_initial * 0.9\n            elif phase == 1:\n                w = (self.w_final + self.w_initial) / 2\n                c1 = self.c1_initial * 0.8\n                c2 = self.c2_initial\n            else:\n                w = self.w_final\n                c1 = 1.5\n                c2 = 2.5\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Enhance diversity via stochastic neighborhood reinitialization\n            if np.std(personal_best_values) < self.epsilon:\n                reinitialize_chance = 0.1 + (phase / 3) * 0.2\n                if np.random.rand() < reinitialize_chance:\n                    stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                    for idx in stagnant_indices:\n                        particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                        personal_best_positions[idx] = particles[idx].copy()\n                        personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 38, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90849 with standard deviation 0.01902.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8861750036818274, 0.9326627603229534, 0.9066361718402768]}}
{"id": "aca6f67b-4fae-4148-a63b-d548f15ce4ad", "fitness": 0.9453944068128957, "name": "AMPSO_NIAM_Adaptive_Refined", "description": "Adaptive Neighborhood-based Mutation Strategy leveraging diversity metrics for enhanced convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Adaptive_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * ((1 + best_improvement) / np.var(personal_best_values))  # Added variance for mutation scaling\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 39, "feedback": "The algorithm AMPSO_NIAM_Adaptive_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94539 with standard deviation 0.03364.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.898000868742662, 0.9654505788524399, 0.9727317728435849]}}
{"id": "3d1537b8-07f5-447b-a4c5-092dc4eec064", "fitness": 0.7749802135923661, "name": "AMPSO_NIAM_Adaptive_Reinitialization", "description": "Introduce adaptive particle reinitialization based on individual particle stagnation duration to further enhance diversity and escape local optima.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Adaptive_Reinitialization:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5, stagnation_limit=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.stagnation_limit = stagnation_limit\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n        stagnation_counter = np.zeros(self.population_size)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n                    stagnation_counter[i] = 0\n                else:\n                    stagnation_counter[i] += 1\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Adaptive reinitialization of stagnant particles\n            stagnant_indices = np.where(stagnation_counter >= self.stagnation_limit)[0]\n            for idx in stagnant_indices:\n                particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                personal_best_positions[idx] = particles[idx].copy()\n                personal_best_values[idx] = np.inf\n                stagnation_counter[idx] = 0\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 40, "feedback": "The algorithm AMPSO_NIAM_Adaptive_Reinitialization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.77498 with standard deviation 0.20019.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9165393998727989, 0.9165343171660786, 0.49186692373822083]}}
{"id": "88734551-fab9-4426-a0e1-adcee2f6a911", "fitness": 0.6811736322720917, "name": "AMPSO_NIAM_Enhanced_Refined_V2", "description": "Incorporate an adaptive local search phase to exploit promising regions and dynamically adjust mutation intensity based on particle proximity to the global best.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_V2:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5, local_search_chance=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.local_search_chance = local_search_chance\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                proximity_to_global_best = np.linalg.norm(particles[i] - self.global_best_position) / np.linalg.norm(upper_bounds - lower_bounds)\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + proximity_to_global_best)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n                # Perform local search if conditions are met\n                if np.random.rand() < self.local_search_chance:\n                    step_size = 0.05 * (upper_bounds - lower_bounds)\n                    local_search_vector = np.random.uniform(-step_size, step_size, self.dim)\n                    new_position = np.clip(particles[i] + local_search_vector, lower_bounds, upper_bounds)\n                    new_value = func(new_position)\n                    evaluations += 1\n                    if new_value < personal_best_values[i]:\n                        personal_best_values[i] = new_value\n                        personal_best_positions[i] = new_position\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 41, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68117 with standard deviation 0.37278.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9263300017802627, 0.9627904042212022, 0.15440049081481]}}
{"id": "3617fc24-bdaf-46ca-ab97-242403037a2b", "fitness": 0.6736969321789469, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce adaptive learning rates in AMPSO to enhance convergence by modifying velocity update factors dynamically based on the progress towards the global best.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Introduce adaptive learning rate based on progress towards the global best\n                adaptive_c1 = c1 * (1 + (self.global_best_value - personal_best_values[i]) / (np.abs(self.global_best_value) + 1e-10))\n                adaptive_c2 = c2 * (1 - (self.global_best_value - personal_best_values[i]) / (np.abs(self.global_best_value) + 1e-10))\n                cognitive_component = adaptive_c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = adaptive_c2 * r2 * (self.global_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 42, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67370 with standard deviation 0.37579.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9661617557878065, 0.14317658133970468, 0.9117524594093294]}}
{"id": "d3e5bc4f-3e10-4933-8863-ac9948fffd13", "fitness": 0.8588856591822824, "name": "AMPSO_NIAM_Enhanced_Refined_AdaptiveLearningRate", "description": "Further enhance particle diversity and convergence speed by integrating a dynamic adaptive learning rate mechanism in the velocity update rule.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_AdaptiveLearningRate:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                # Introduce an adaptive learning rate based on the improvement of the personal best positions\n                improvement_factor = np.log1p(personal_best_values[i] - value) / (np.log1p(np.std(personal_best_values)) + 1e-10)\n                adaptive_learning_rate = 1 + improvement_factor\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i]) * adaptive_learning_rate\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 43, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_AdaptiveLearningRate got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85889 with standard deviation 0.10336.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9506603705521566, 0.7144677322071947, 0.911528874787496]}}
{"id": "eb47a376-6fb6-4718-96a3-87ab5fb6d318", "fitness": 0.8726775732867726, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance exploration-exploitation balance by integrating adaptive velocity scaling and diversity-driven mutation strategies.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            velocity_scale = (1 - evaluations / self.budget) + 0.5 * (np.std(personal_best_values) < self.epsilon)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] * velocity_scale + cognitive_component + social_component\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                enhanced_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.15\n                if np.random.rand() < enhanced_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 44, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87268 with standard deviation 0.09123.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9154535353067518, 0.9567037649478062, 0.74587541960576]}}
{"id": "33099a53-f1a6-476a-8634-7b995038f111", "fitness": 0.9395458481419378, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Refine social component's influence by introducing a linearly decreasing factor to encourage exploration in early stages and exploitation in later stages.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n            linear_decrease_factor = 1 - (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = linear_decrease_factor * c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 45, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93955 with standard deviation 0.02330.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9292501060302062, 0.9175830679907608, 0.971804370404846]}}
{"id": "17a7a400-d28f-49b5-b331-bed4eb8508d5", "fitness": 0.42448286815178154, "name": "AMPSO_NIAM_Enhanced_MultiSwarm", "description": "Integrate a multi-swarm approach with entropy-based diversity control to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_MultiSwarm:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5, num_swarms=3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.neighborhood_size = neighborhood_size\n        self.num_swarms = num_swarms\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles across multiple swarms\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size * self.num_swarms, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size * self.num_swarms, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size * self.num_swarms, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size * self.num_swarms):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best \n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size * self.num_swarms):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Swarm-based local best\n                swarm_id = i // self.population_size\n                start_idx = swarm_id * self.population_size\n                end_idx = start_idx + self.population_size\n                neighbors_indices = np.arange(start_idx, end_idx)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity using entropy-based reinitialization\n            if np.std(personal_best_values) < self.epsilon:\n                entropy = -np.sum((personal_best_values / np.sum(personal_best_values)) * np.log(np.maximum(personal_best_values / np.sum(personal_best_values), 1e-10)))\n                if entropy < 0.5:  # Low entropy indicates lack of diversity\n                    stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                    for idx in stagnant_indices:\n                        particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                        personal_best_positions[idx] = particles[idx].copy()\n                        personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 46, "feedback": "The algorithm AMPSO_NIAM_Enhanced_MultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42448 with standard deviation 0.35584.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.1876726002077107, 0.9274257378750752, 0.15835026637255867]}}
{"id": "8e248a74-d887-4953-b822-459d6f391c55", "fitness": 0.9459209897327233, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Improve convergence by enhancing mutation strategy based on velocity magnitude and dynamically adapt cognitive/social coefficients for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * np.linalg.norm(velocities[i])\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 47, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94592 with standard deviation 0.03406.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8978012092995131, 0.9681359637099575, 0.9718257961886994]}}
{"id": "0412eac0-579f-4349-8f27-e50e8ded41bd", "fitness": -Infinity, "name": "AMPSO_NIAM_Enhanced_Reshaped", "description": "Integrate an adaptive swarm reshaping mechanism that dynamically adjusts both the swarm size and sub-swarm configurations based on convergence metrics to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Reshaped:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Adjust population size based on convergence\n            if evaluations / self.budget < 0.5:\n                current_population_size = min(self.population_size + 10, self.population_size * 2)\n            else:\n                current_population_size = max(self.population_size // 2, 10)\n\n            # Update particles' velocities and positions\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(current_population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 48, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {}}
{"id": "66e51149-174b-4066-bcf9-5a72a4b18ceb", "fitness": 0.40901753406590863, "name": "AMPSO_NIAM_Enhanced_Adaptive", "description": "Introduce adaptive velocity clamping based on search space exploration to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Adaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n        search_space_range = upper_bounds - lower_bounds\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Adaptive velocity clamping based on search space exploration\n                exploration_factor = np.clip(np.std(particles, axis=0) / search_space_range, 0.1, 1.0)\n                velocities[i] = np.clip(velocities[i], -exploration_factor * search_space_range, exploration_factor * search_space_range)\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * search_space_range * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 49, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40902 with standard deviation 0.30783.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.18261481643123212, 0.8442318500596834, 0.20020593570681033]}}
{"id": "e6c76c41-95c0-44aa-bc90-453d19270e89", "fitness": 0.9327971199783457, "name": "AMPSO_NIAM_Dynamic_Diversity", "description": "Introduce dynamic mutation scaling based on diversity to enhance convergence and maintain exploration in AMPSO.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Dynamic_Diversity:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                current_diversity = np.var(personal_best_values)\n                adaptive_mutation_chance = self.mutation_chance + (current_diversity < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1 + current_diversity)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 50, "feedback": "The algorithm AMPSO_NIAM_Dynamic_Diversity got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93280 with standard deviation 0.03667.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8837071785775787, 0.9428715778330093, 0.971812603524449]}}
{"id": "1d92d729-eb78-445b-9e12-e4ba7052c8e1", "fitness": 0.4171130914666586, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Further enhance diversity by implementing a two-stage dynamic mutation strategy, which increases mutation intensity when diversity falls below a threshold.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply two-stage dynamic mutation to maintain diversity\n                diversity_ratio = np.std(personal_best_values) / np.mean(personal_best_values)\n                if diversity_ratio < self.epsilon:\n                    mutation_intensity = 1.5 if np.random.rand() < 0.5 else 2.0\n                else:\n                    mutation_intensity = 1.0\n\n                adaptive_mutation_chance = self.mutation_chance + (diversity_ratio < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * mutation_intensity\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 51, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41711 with standard deviation 0.37390.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9455587312685132, 0.16896220291173936, 0.1368183402197234]}}
{"id": "cb9614ec-3ee7-4bc5-89e2-00b15c8785d1", "fitness": 0.7749802135923661, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Integrate dynamic inertia reduction and adaptive local neighborhood strategies for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = np.zeros(population_size, dtype=int)\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            stagnant_mask = self.stagnation_counter >= self.stagnation_threshold\n            for idx in np.where(stagnant_mask)[0]:\n                particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                personal_best_positions[idx] = particles[idx].copy()\n                personal_best_values[idx] = np.inf\n                self.stagnation_counter[idx] = 0\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 52, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.77498 with standard deviation 0.20019.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9165393998727989, 0.9165343171660786, 0.49186692373822083]}}
{"id": "3c812d3f-385a-4239-828d-31ace27b1227", "fitness": 0.6564056279787517, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce adaptive velocity scaling and enhanced mutation diversity based on convergence rate to improve exploration and exploitation balance.  ", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            convergence_rate = np.std(personal_best_values)\n            adaptive_velocity_scaling = 1 + (self.budget - evaluations) / self.budget * (convergence_rate < self.epsilon)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (convergence_rate > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = adaptive_velocity_scaling * (w * velocities[i] + cognitive_component + social_component)\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                adaptive_mutation_chance = self.mutation_chance + (convergence_rate < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if convergence_rate < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 53, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65641 with standard deviation 0.34887.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9296062101265419, 0.16401623059196557, 0.8755944432177479]}}
{"id": "753b86f7-415a-4d12-aed9-3188bc1caadd", "fitness": 0.6888829674644389, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Improve the algorithm by incorporating a non-linear decay factor in velocity update and enhancing diversity control with a differential mutation operator.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations**1.5 / self.budget)  # Non-linear decay\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    random_index = np.random.choice(self.population_size, 3, replace=False)  # Differential mutation\n                    mutation_vector = 0.8 * (particles[random_index[0]] - particles[random_index[1]]) + (particles[random_index[2]] - particles[i])\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 54, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68888 with standard deviation 0.30372.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.26095045531035277, 0.9348558510561016, 0.8708425960268625]}}
{"id": "7a5e3e96-8102-4142-8134-edfd66e2df58", "fitness": 0.37551043672671164, "name": "AMPSO_NIAM_Enhanced_DynamicNeighborhood", "description": "Introduce a dynamic neighborhood adaptation mechanism using local diversity measures to enhance exploitation while maintaining exploration.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_DynamicNeighborhood:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, base_neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.base_neighborhood_size = base_neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Dynamic neighborhood size based on local diversity\n                local_diversity = np.std(particles)\n                dynamic_neighborhood_size = int(self.base_neighborhood_size + local_diversity * 5)\n                neighbors_indices = np.random.choice(self.population_size, dynamic_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 55, "feedback": "The algorithm AMPSO_NIAM_Enhanced_DynamicNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37551 with standard deviation 0.22027.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.30607276675238526, 0.14723610949582988, 0.6732224339319198]}}
{"id": "f5439531-a9f2-467f-9701-ddcb155e5d71", "fitness": 0.9501667153902801, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Improve local exploitation by incorporating a weighted average of neighborhood bests in velocity update.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 56, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95017 with standard deviation 0.01532.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9401865625108989, 0.9385009801354923, 0.971812603524449]}}
{"id": "41a7774b-d502-4bbe-84b0-bbe8f3e37bea", "fitness": 0.9009558550267466, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Refine mutation strategy by adjusting the mutation vector scale using an adaptive cooling schedule based on evaluations.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    # Changed line (mutation_vector_scale calculation):\n                    mutation_vector_scale = 0.1 * np.exp(-5 * evaluations / self.budget) * (1 + (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10))\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 57, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90096 with standard deviation 0.06629.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8123645154921555, 0.9186904460636351, 0.971812603524449]}}
{"id": "cc1781ce-8edb-43f4-acd8-f345c46f893b", "fitness": 0.9379831936929857, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce adaptive acceleration coefficients based on particle diversity to enhance convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            diversity = np.std(personal_best_values)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n            if diversity > self.epsilon:\n                c1, c2 = c1 * 1.1, c2 * 1.1  # Adjust coefficients for high diversity\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (diversity > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (diversity < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if diversity < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 58, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93798 with standard deviation 0.02542.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9104779126447763, 0.931683909263975, 0.9717877591702059]}}
{"id": "48c51b53-895e-4cc7-bb88-9c917b65b12a", "fitness": 0.8176624604309136, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce adaptive velocity clamping and neighborhood size augmentation to improve exploration and convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Adaptive velocity clamping\n                max_velocity = (upper_bounds - lower_bounds) * 0.1\n                velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n                    \n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 59, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81766 with standard deviation 0.08144.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8849341362619665, 0.8649918975232938, 0.7030613475074806]}}
{"id": "560a0bf6-2264-46dc-ad2d-ccf4ee929ee6", "fitness": 0.6025585062299952, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance convergence by introducing dynamic reinitialization of both positions and velocities for stagnant particles.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    velocities[idx] = np.random.uniform(-1, 1, self.dim)  # Reinitialize velocities\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 60, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60256 with standard deviation 0.32826.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9435036470062762, 0.7049312732009003, 0.15924059848280891]}}
{"id": "62041d72-9909-48fa-8147-b310608e8430", "fitness": 0.9064488117393646, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Refine adaptive mutation and incorporate multi-swarm cooperation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5, num_swarms=2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = [None] * num_swarms\n        self.global_best_value = [np.inf] * num_swarms\n        self.neighborhood_size = neighborhood_size\n        self.num_swarms = num_swarms\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = [np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.population_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best_positions = [np.copy(p) for p in particles]\n        personal_best_values = [np.full(self.population_size, np.inf) for _ in range(self.num_swarms)]\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for swarm in range(self.num_swarms):\n                for i in range(self.population_size):\n                    if evaluations >= self.budget:\n                        break\n\n                    # Evaluate current position\n                    value = func(particles[swarm][i])\n                    evaluations += 1\n\n                    # Update personal best\n                    if value < personal_best_values[swarm][i]:\n                        personal_best_values[swarm][i] = value\n                        personal_best_positions[swarm][i] = particles[swarm][i].copy()\n\n                    # Update global best\n                    if value < self.global_best_value[swarm]:\n                        self.global_best_value[swarm] = value\n                        self.global_best_position[swarm] = particles[swarm][i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for swarm in range(self.num_swarms):\n                for i in range(self.population_size):\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values[swarm]) > self.epsilon) * 2)\n                    neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                    local_best_index = neighbors_indices[np.argmin(personal_best_values[swarm][neighbors_indices])]\n                    local_best_position = personal_best_positions[swarm][local_best_index]\n\n                    cognitive_component = c1 * r1 * (personal_best_positions[swarm][i] - particles[swarm][i])\n                    social_component = c2 * r2 * (local_best_position - particles[swarm][i])\n                    velocities[swarm][i] = w * velocities[swarm][i] + cognitive_component + social_component\n\n                    # Update particle position\n                    particles[swarm][i] += velocities[swarm][i]\n\n                    # Ensure particles are within bounds\n                    particles[swarm][i] = np.clip(particles[swarm][i], lower_bounds, upper_bounds)\n\n                    # Apply mutation to maintain diversity adaptively\n                    adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values[swarm]) < self.epsilon) * 0.1\n                    if np.random.rand() < adaptive_mutation_chance:\n                        mutation_vector_scale = 0.1 * (1 - evaluations / self.budget)\n                        mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                        particles[swarm][i] = np.clip(particles[swarm][i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Inter-swarm cooperation to enhance exploration\n            if self.num_swarms > 1:\n                for swarm in range(self.num_swarms - 1):\n                    if self.global_best_value[swarm] < self.global_best_value[swarm + 1]:\n                        self.global_best_position[swarm + 1] = self.global_best_position[swarm]\n                        self.global_best_value[swarm + 1] = self.global_best_value[swarm]\n\n        final_best_swarm = np.argmin(self.global_best_value)\n        return self.global_best_position[final_best_swarm], self.global_best_value[final_best_swarm]", "configspace": "", "generation": 61, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90645 with standard deviation 0.05839.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9217797161123092, 0.9690495128319095, 0.828517206273875]}}
{"id": "26fb5ded-27f9-45f1-98f7-94b29dea208a", "fitness": 0.9071699901420404, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce a dynamic learning strategy by adapting cognitive and social coefficients based on the historical success ratio of particles to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n        success_history = np.zeros(self.population_size)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n                    success_history[i] += 1  # Increment success count\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and dynamic cognitive/social coefficients\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            success_ratio = success_history / (evaluations / self.population_size)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * success_ratio\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (1 - success_ratio)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1[i] * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2[i] * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Reinitialize stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 62, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90717 with standard deviation 0.01754.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8943138831662975, 0.8952239386555376, 0.9319721486042857]}}
{"id": "5ac68d2f-11e8-413b-8eed-ddeba1796631", "fitness": 0.9259835847176697, "name": "AMPSO_NIAM_SelfAdaptive", "description": "Introduce a self-adaptive mutation strategy that dynamically adjusts based on both global and local convergence trends to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_SelfAdaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n        prev_global_best_value = np.inf\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Adaptive mutation strategy\n                global_improvement = (prev_global_best_value - self.global_best_value) / (prev_global_best_value + 1e-10)\n                prev_global_best_value = self.global_best_value\n\n                adaptive_mutation_chance = self.mutation_chance * (1 + global_improvement)\n                if np.random.rand() < adaptive_mutation_chance:\n                    local_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + local_improvement + global_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Reinitialize stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 63, "feedback": "The algorithm AMPSO_NIAM_SelfAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92598 with standard deviation 0.02009.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9100156381670856, 0.9543164749028664, 0.9136186410830567]}}
{"id": "5676ea1e-f770-4599-9ddf-ac83a7cc0fc8", "fitness": 0.6162651575762031, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce a momentum term to enhance velocity updates for faster convergence and stability.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component + 0.1 * velocities[i]\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 64, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61627 with standard deviation 0.29633.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.773385522510059, 0.8741623723083698, 0.20124757791018089]}}
{"id": "f94df262-6628-4dd9-ae78-595799d253e1", "fitness": 0.7254732323930027, "name": "AMPSO_NIAM_Enhanced_DynamicLeader", "description": "Integrate a dynamic leader selection mechanism based on the temporal performance of particles to enhance convergence speed and solution diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_DynamicLeader:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n        temporal_leaders = np.copy(personal_best_positions)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Update temporal leaders based on recent improvements\n            for i in range(self.population_size):\n                if evaluations < self.budget and value < func(temporal_leaders[i]):\n                    temporal_leaders[i] = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                leader_component = r3 * (temporal_leaders[i] - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component + leader_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 65, "feedback": "The algorithm AMPSO_NIAM_Enhanced_DynamicLeader got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72547 with standard deviation 0.20215.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.44356510464161547, 0.8253180645073586, 0.9075365280300338]}}
{"id": "6713e209-2706-4626-94b7-fafe36ad48db", "fitness": 0.9490563058048535, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce a decay-based adaptive mutation strategy for enhanced diversity retention.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    decay_factor = np.exp(-evaluations / self.budget)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * decay_factor\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 66, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94906 with standard deviation 0.01613.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9361942114324018, 0.9391672414406974, 0.9718074645414612]}}
{"id": "693c01f1-4a83-41b3-9692-89475cc9d899", "fitness": 0.2562771922708483, "name": "AMPSO_NIAM_Adaptive_Refinement", "description": "Introduce an adaptive strategy for mutation and velocity by incorporating a diversity measure and feedback from solution improvements to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Adaptive_Refinement:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Compute diversity measure\n            diversity = np.var(particles)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = (w + diversity) * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = diversity * 0.1 * (1 - evaluations / self.budget) * (1 + improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 67, "feedback": "The algorithm AMPSO_NIAM_Adaptive_Refinement got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25628 with standard deviation 0.06840.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.32001218893497374, 0.28743133573672597, 0.16138805214084506]}}
{"id": "5e45b9a8-c291-40af-bbd8-088951d49638", "fitness": 0.10839573771058734, "name": "AMPSO_NIAM_Enhanced_Refined_Adaptive", "description": "Introduce adaptive mutation scale based on convergence rate and dynamic adjustment of exploration-exploitation balance using fitness improvement trends.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_Adaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n        prev_global_best_value = np.inf\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * ((self.budget - evaluations) / self.budget)**2\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * np.abs(prev_global_best_value - self.global_best_value) / (prev_global_best_value + 1e-10)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    convergence_rate = (prev_global_best_value - self.global_best_value) / (prev_global_best_value + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + convergence_rate)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Update previous global best value\n            prev_global_best_value = self.global_best_value\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 68, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10840 with standard deviation 0.01510.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.09605289822340368, 0.12966005664761582, 0.09947425826074252]}}
{"id": "ec3bfac2-e407-41e3-b24a-bba52b66ed9c", "fitness": 0.9378215351390103, "name": "AMPSO_NIAM_DualPhaseMutation", "description": "Introduce a dual-phase mutation strategy that emphasizes early exploration through Gaussian mutations and late exploitation by focusing mutation on promising regions.", "code": "import numpy as np\n\nclass AMPSO_NIAM_DualPhaseMutation:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Dual-phase Mutation Strategy\n                phase_ratio = evaluations / self.budget\n                if np.random.rand() < self.mutation_chance:\n                    if phase_ratio < 0.5:\n                        # Early Exploration\n                        mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * 0.1\n                    else:\n                        # Late Exploitation\n                        target_position = self.global_best_position if np.random.rand() < 0.5 else personal_best_positions[i]\n                        mutation_vector = np.random.normal(0, 1, self.dim) * (target_position - particles[i]) * 0.1\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 69, "feedback": "The algorithm AMPSO_NIAM_DualPhaseMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93782 with standard deviation 0.01622.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9157749420867176, 0.9543164749028664, 0.9433731884274469]}}
{"id": "0ca0a43d-5629-4fad-8499-14e26bcc3931", "fitness": 0.9146310660048601, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Refine mutation and velocity strategies by leveraging diversity metrics and historical performance to enhance convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                # Historical performance impact on cognitive component\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i]) * (1 + np.exp(-personal_best_values[i]))\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    # Improved mutation strategy using diversity metric\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * np.std(personal_best_positions, axis=0).mean()\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 70, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91463 with standard deviation 0.01361.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.926364019262127, 0.8955559236056561, 0.9219732551467973]}}
{"id": "5d04432a-e50c-4074-916d-96ff7b1a123f", "fitness": 0.46508743576621914, "name": "AMPSO_NIAM_Adaptive_Learning", "description": "Incorporate a dynamic learning rate adaptation and an adaptive inertia weight strategy to further balance exploration and exploitation, enhancing convergence speed.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Adaptive_Learning:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            exploration_factor = np.exp(-3 * evaluations / self.budget)\n            convergence_rate = (self.global_best_value - np.mean(personal_best_values)) / (self.global_best_value + 1e-10)\n            w = self.w_final + (self.w_initial - self.w_final) * (exploration_factor + convergence_rate) / 2\n            c1 = self.c1_initial * (1 - convergence_rate)\n            c2 = self.c2_initial * (1 + convergence_rate)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 71, "feedback": "The algorithm AMPSO_NIAM_Adaptive_Learning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46509 with standard deviation 0.32785.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.21771922760336881, 0.9283834641529365, 0.2491596155423521]}}
{"id": "b5ef8141-5ecb-499e-abae-b01eb669d9a7", "fitness": 0.9132388202505738, "name": "AMPSO_Entropy_Adaptive", "description": "Introduce adaptive inertia weight with enhanced exploration-exploitation balance using entropy-based diversity measure.", "code": "import numpy as np\n\nclass AMPSO_Entropy_Adaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def entropy_based_diversity(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        squared_diff = np.sum((particles - mean_position) ** 2, axis=1)\n        normalized_diff = squared_diff / np.sum(squared_diff)\n        return -np.sum(normalized_diff * np.log(normalized_diff + 1e-10))\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and coefficients adaptively using entropy-based diversity\n            diversity = self.entropy_based_diversity(particles)\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-diversity)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 72, "feedback": "The algorithm AMPSO_Entropy_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91324 with standard deviation 0.02084.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9393545059953637, 0.912019710369951, 0.8883422443864065]}}
{"id": "c83b9cab-0163-46ab-a80f-a889ff99beeb", "fitness": 0.9432952406836105, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce velocity dampening mechanism to improve convergence by reducing the velocity magnitude iteratively.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Introduce velocity dampening\n                velocities[i] *= (1 - evaluations / self.budget)\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 73, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94330 with standard deviation 0.02152.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9382521261617406, 0.9198261313476297, 0.9718074645414612]}}
{"id": "48aaf7c5-cc0a-49ac-b7c1-bde260d4049e", "fitness": 0.9501667153902801, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce a small adaptive factor in the global best update condition to enhance convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best with adaptive factor\n                adaptive_factor = 1 - evaluations / self.budget\n                if value < self.global_best_value * adaptive_factor:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 74, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95017 with standard deviation 0.01532.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9401865625108989, 0.9385009801354923, 0.971812603524449]}}
{"id": "241ba519-cad5-4efb-8e70-398de73897b6", "fitness": 0.9019598841671899, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce an adaptive cognitive component to adjust the influence of personal best positions dynamically.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                # Adaptive cognitive component\n                adaptive_c1 = c1 * (1 + np.std(personal_best_values) / (np.abs(personal_best_values[i] - self.global_best_value) + 1e-10))\n                cognitive_component = adaptive_c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 75, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90196 with standard deviation 0.04383.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9114758989949064, 0.8441629675962415, 0.9502407859104214]}}
{"id": "623560b5-ba19-4789-ad26-2769c25dc2c7", "fitness": 0.9501667153902801, "name": "AMPSO_NIAM_Enhanced_Adapted", "description": "Adaptively adjust mutation and reinitialization strategies based on convergence speed and historical diversity to enhance exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Adapted:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.historical_diversity = []\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                self.historical_diversity.append(np.std(personal_best_values))\n                avg_diversity = np.mean(self.historical_diversity[-10:]) if len(self.historical_diversity) >= 10 else np.std(personal_best_values)\n                \n                adaptive_mutation_chance = self.mutation_chance + (avg_diversity < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles adaptively\n            if avg_diversity < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 76, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Adapted got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95017 with standard deviation 0.01532.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9401865625108989, 0.9385009801354923, 0.971812603524449]}}
{"id": "a6580a53-1967-4506-b85b-903f6b3cf99f", "fitness": 0.6444107102634946, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce adaptive velocity clamping to stabilize exploration and exploitation by dynamically adjusting maximum velocity based on evaluation progress.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Adaptive velocity clamping\n                max_velocity = (upper_bounds - lower_bounds) * 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 77, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64441 with standard deviation 0.32691.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8823844870065398, 0.8686941215082531, 0.18215352227569093]}}
{"id": "891c1149-f1a4-4879-a536-5b0f307a3897", "fitness": 0.8501872140933718, "name": "AMPSO_DiversityBased_Inertia", "description": "Enhance particle swarm optimization by introducing an adaptive inertia weight dependent on diversity to balance exploration and exploitation efficiently.", "code": "import numpy as np\n\nclass AMPSO_DiversityBased_Inertia:\n    def __init__(self, budget, dim, population_size=30, w_max=0.9, w_min=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight adaptively based on diversity\n            diversity_measure = np.std(personal_best_values)\n            w = self.w_min + (self.w_max - self.w_min) * (diversity_measure / (diversity_measure + 1))\n\n            # Update cognitive and social coefficients adaptively\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (diversity_measure > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (diversity_measure < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if diversity_measure < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 78, "feedback": "The algorithm AMPSO_DiversityBased_Inertia got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85019 with standard deviation 0.07778.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9407209785162682, 0.8590280137311412, 0.7508126500327059]}}
{"id": "839034f6-1342-4c25-a96e-a5f2f24dec67", "fitness": 0.7036099496839382, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Introduce neighborhood topology adaptation and a differential evolution-inspired mutation mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_scale = 0.2 * (1 - evaluations / self.budget)\n                    a, b = np.random.choice(self.population_size, 2, replace=False)\n                    mutation_vector = mutation_scale * (personal_best_positions[a] - personal_best_positions[b])\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 79, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70361 with standard deviation 0.36511.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9672951173317215, 0.9562232971479854, 0.18731143457210775]}}
{"id": "bc58f6d2-856e-41fe-92ad-509a107e4081", "fitness": 0.9497405136141834, "name": "AMPSO_NIAM_Oscillating_Inertia", "description": "Introduce a dynamic inertia weight that oscillates for improved exploration and exploitation balance in AMPSO.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Oscillating_Inertia:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Oscillating inertia weight for balance between exploration and exploitation\n            w = self.w_final + (self.w_initial - self.w_final) * np.cos(np.pi * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 80, "feedback": "The algorithm AMPSO_NIAM_Oscillating_Inertia got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94974 with standard deviation 0.01576.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9414527029215493, 0.9359625678690013, 0.9718062700519996]}}
{"id": "1a8e93be-f404-4693-a4a7-2d29798094e8", "fitness": 0.6424241708445947, "name": "AMPSO_NIAM_Enhanced_Refined_Adaptive", "description": "Introduce an adaptive neighborhood size and mutation rate based on swarm diversity to enhance convergence speed and robustness.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_Adaptive:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                diversity_measure = np.std(personal_best_values)\n                adjusted_neighborhood_size = max(3, int(self.neighborhood_size * (1 + diversity_measure / self.epsilon)))\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (diversity_measure < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if diversity_measure < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 81, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64242 with standard deviation 0.38625.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.929782739739839, 0.09643316223035758, 0.9010566105635877]}}
{"id": "aa65b096-86da-475f-b924-524cae941ec5", "fitness": 0.2818488928629334, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Improve particle exploration by increasing velocity scaling based on global diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 82, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28185 with standard deviation 0.25620.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.10728831218342572, 0.09416237852705445, 0.6440959878783201]}}
{"id": "e3c43f73-32cb-4edb-a9c9-95e1d5064d59", "fitness": 0.9157710213642506, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance exploration with adaptive neighborhood size and refined mutation scaling.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 3)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.15 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 83, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91577 with standard deviation 0.06845.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.8193927223081348, 0.9561128772431561, 0.9718074645414612]}}
{"id": "061bacdd-2cb3-479a-af0d-484296eee145", "fitness": 0.9528556955371338, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Improve the algorithm by enhancing neighborhood selection accuracy and adaptive mutation scale adjustment.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))  # Adjust mutation scale\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 84, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95286 with standard deviation 0.01696.", "error": "", "parent_ids": ["28c03486-170f-4290-b180-7a664e3df54e"], "operator": null, "metadata": {"aucs": [0.9306449902763823, 0.9561146317935577, 0.9718074645414612]}}
{"id": "971ab331-8767-477b-97fd-7ba39b0d5428", "fitness": 0.6593798696776134, "name": "AMPSO_NIAM_Enhanced_Refined_Adaptive_MultiSwarm", "description": "Introduce adaptive multi-swarm collaboration and dynamically adjusted exploration-exploitation balance for enhanced diversity and convergence.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_Adaptive_MultiSwarm:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5, num_sub_swarms=3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.num_sub_swarms = num_sub_swarms\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles and divide into sub-swarms\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n        sub_swarm_indices = np.array_split(np.arange(self.population_size), self.num_sub_swarms)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Adaptive inertia weight and cognitive/social coefficients\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions with multi-swarm strategy\n            for sub_swarm in sub_swarm_indices:\n                local_best_values = np.min(personal_best_values[sub_swarm])\n                local_best_index = sub_swarm[np.argmin(personal_best_values[sub_swarm])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                for i in sub_swarm:\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                    social_component = c2 * r2 * (local_best_position - particles[i])\n                    velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                    # Update particle position\n                    particles[i] += velocities[i]\n\n                    # Ensure particles are within bounds\n                    particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                    # Adaptive mutation\n                    adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                    if np.random.rand() < adaptive_mutation_chance:\n                        best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                        mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))\n                        mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                        particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Reinitialize stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 85, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined_Adaptive_MultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65938 with standard deviation 0.34043.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.17981843859962277, 0.8623419620875126, 0.9359792083457049]}}
{"id": "36b8812d-0f57-4db3-9c80-01604d4aa731", "fitness": 0.9510098639202672, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance the exploration capability by adaptively adjusting the inertia weight based on the diversity of personal best values.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget * (1 + np.std(personal_best_values)))\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))  # Adjust mutation scale\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 86, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95101 with standard deviation 0.01940.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.9251074954257829, 0.9561146317935577, 0.9718074645414612]}}
{"id": "1b9f1ff5-a5e1-428f-ba1e-4d583f116c99", "fitness": 0.8994385333599229, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Enhance adaptive mechanisms with dynamic neighborhood restructuring and learning rate modulation based on convergence trends to improve exploitation-exploration balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n        convergence_rates = []\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Track convergence rate\n            if evaluations > 1:\n                convergence_rates.append(np.min(personal_best_values))\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n\n                # Dynamic neighborhood restructuring based on convergence trends\n                if len(convergence_rates) > 1:\n                    convergence_trend = np.polyfit(range(len(convergence_rates)), convergence_rates, 1)[0]\n                    adjusted_neighborhood_size = max(3, int(self.neighborhood_size * (1 - convergence_trend)))\n                else:\n                    adjusted_neighborhood_size = self.neighborhood_size\n\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 87, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89944 with standard deviation 0.09144.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.7704415030661697, 0.9561146317935577, 0.9717594652200412]}}
{"id": "822516a6-516f-47ad-aacd-70a28e410e22", "fitness": 0.6832080073065341, "name": "AMPSO_NIAM_Stratified_Dynamic", "description": "Introduce swarm stratification and dynamic inertia for improved convergence diversity and efficiency. ", "code": "import numpy as np\n\nclass AMPSO_NIAM_Stratified_Dynamic:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles with stratified sampling\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Dynamic inertia and adaptive coefficients\n            diversity = np.std(particles, axis=0).mean()\n            w = self.w_final + (self.w_initial - self.w_final) * (1 - diversity)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (diversity / self.dim)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (1 - diversity / self.dim)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 88, "feedback": "The algorithm AMPSO_NIAM_Stratified_Dynamic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68321 with standard deviation 0.33431.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.8900794188977021, 0.21160892361559558, 0.9479356794063045]}}
{"id": "ffe0a232-a04b-46b0-ae25-10d70e859a57", "fitness": 0.8999005714163347, "name": "AMPSO_NIAM_Dynamic", "description": "Introduce a dynamic neighborhood size and a self-adaptive velocity update mechanism to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Dynamic:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, max_neigh_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.max_neigh_size = max_neigh_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            w = self.w_final + (self.w_initial - self.w_final) * (1 - evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                diversity = np.std(personal_best_values)\n                adjusted_neigh_size = int(2 + (self.max_neigh_size - 2) * (diversity / (diversity + self.epsilon)))\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neigh_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                adaptive_mutation_chance = self.mutation_chance + (diversity < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)) * (1.5 - diversity)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 89, "feedback": "The algorithm AMPSO_NIAM_Dynamic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89990 with standard deviation 0.03173.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.8947443884004486, 0.8638728128218244, 0.9410845130267314]}}
{"id": "a9cf7ccd-9032-40de-b70b-d91a0f7078f5", "fitness": 0.6481923586274864, "name": "AMPSO_Dynamic_Neighborhood_Adaptive_Inertia", "description": "Introduce dynamic neighborhood and adaptive inertia adjustment for better convergence and exploration.", "code": "import numpy as np\n\nclass AMPSO_Dynamic_Neighborhood_Adaptive_Inertia:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_min=0.1, c1_max=2.5, c2_min=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_min = w_min\n        self.c1_max = c1_max\n        self.c2_min = c2_min\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_factor = neighborhood_factor\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Dynamic inertia weight and cognitive/social coefficients\n            w = self.w_min + (self.w_initial - self.w_min) * (1 - evaluations / self.budget)\n            c1 = self.c1_max - (self.c1_max - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_min + (2.5 - self.c2_min) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Determine neighborhood size dynamically\n                neighborhood_size = max(2, int(self.neighborhood_factor * self.population_size))\n                neighbors_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to enhance diversity\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Reinitialize particles for diversity\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 90, "feedback": "The algorithm AMPSO_Dynamic_Neighborhood_Adaptive_Inertia got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64819 with standard deviation 0.35023.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.8354020116288617, 0.9517101785725067, 0.15746488568109074]}}
{"id": "2a1f6fdd-1dd3-46dc-bfdd-1af7dec44ff5", "fitness": 0.6741347121718558, "name": "AMPSO_NIAM_Enhanced_Advanced", "description": "Introduce dynamic neighborhood size adaptation and multi-strategy mutation to enhance exploration-exploitation balance in AMPSO optimization.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Advanced:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, base_neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.base_neighborhood_size = base_neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                value = func(particles[i])\n                evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            neighborhood_size = self.base_neighborhood_size + int(5 * (1 - evaluations/self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                neighbors_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                adaptive_mutation_chance = self.mutation_chance + (1 - np.std(personal_best_values) / self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 91, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Advanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67413 with standard deviation 0.38677.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.9321876776719322, 0.9627764595157771, 0.12743999932785843]}}
{"id": "fef3fb45-3a65-48ff-8472-b75b9dd835b3", "fitness": -Infinity, "name": "AMPSO_NIAM_Enhanced_Dynamic", "description": "Introduce a dynamic learning rate and adaptive population size based on convergence feedback to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Dynamic:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = population_size\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n            # Dynamically adapt population size based on convergence\n            diversity_measure = np.std(personal_best_values)\n            if diversity_measure < self.epsilon and evaluations > self.budget * 0.5:\n                self.population_size = max(10, self.population_size // 2)\n            elif diversity_measure > self.epsilon * 2 and evaluations < self.budget * 0.5:\n                new_particles = np.random.uniform(lower_bounds, upper_bounds, (self.initial_population_size, self.dim))\n                particles = np.vstack((particles, new_particles))\n                personal_best_positions = np.vstack((personal_best_positions, new_particles))\n                personal_best_values = np.append(personal_best_values, np.full(self.initial_population_size, np.inf))\n                self.population_size = len(particles)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 92, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {}}
{"id": "5412107e-d20d-47a4-a75b-856446c2db25", "fitness": 0.04546338093610913, "name": "AMPSO_NIAM_Adaptive_Escape", "description": "Enhance the solution by integrating adaptive inertia weight adjustment based on convergence trends and introducing a dynamic escape strategy for particles based on stagnation detection.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Adaptive_Escape:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            prev_global_best_value = self.global_best_value\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight adaptively based on convergence trends\n            if self.global_best_value < prev_global_best_value:\n                convergence_trend = (prev_global_best_value - self.global_best_value) / prev_global_best_value\n                w = (self.w_final + (self.w_initial - self.w_final) * (1 - convergence_trend))\n            else:\n                w = self.w_initial\n\n            # Dynamic coefficients\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Dynamic escape strategy for stagnation detection\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    escape_factor = np.random.uniform(0.5, 1.5)\n                    particles[idx] = np.clip(particles[idx] * escape_factor, lower_bounds, upper_bounds)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 93, "feedback": "The algorithm AMPSO_NIAM_Adaptive_Escape got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04546 with standard deviation 0.00270.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.042758608515468755, 0.0444785976861084, 0.04915293660675024]}}
{"id": "3629e0b4-8479-4627-8bd3-bb5da2f6f747", "fitness": 0.5796141054615537, "name": "AMPSO_NIAM_Dynamic_Topology", "description": "Incorporate a dynamic neighborhood topology and adaptive particle elimination strategy to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Dynamic_Topology:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5, elimination_chance=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n        self.elimination_chance = elimination_chance\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n        \n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                \n                # Dynamic neighborhood topology\n                neighborhood_size_dynamic = self.neighborhood_size + int(self.population_size * np.linalg.norm(personal_best_positions[i] - self.global_best_position) / np.linalg.norm(func.bounds.ub - func.bounds.lb))\n                neighbors_indices = np.random.choice(self.population_size, neighborhood_size_dynamic, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Adaptive particle elimination to enhance exploration\n            if np.random.rand() < self.elimination_chance and np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    if np.random.rand() < 0.5:\n                        particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                        personal_best_positions[idx] = particles[idx].copy()\n                        personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 94, "feedback": "The algorithm AMPSO_NIAM_Dynamic_Topology got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.57961 with standard deviation 0.31303.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.5619077492663672, 0.9715376872145555, 0.20539687990373845]}}
{"id": "964d4b34-638c-4556-b2cd-91c91987f2dd", "fitness": -Infinity, "name": "AMPSO_NIAM_Enhanced_Refined_Improved", "description": "Enhance solution space exploration by integrating dynamic subgroup structures and adaptive perturbation for improved convergence stability and solution diversity.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined_Improved:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Create dynamic subgroups for enhanced exploration\n            subgroup_size = max(2, self.population_size // 4)\n            indices = np.random.permutation(self.population_size)\n\n            for i in range(0, self.population_size, subgroup_size):\n                subgroup_indices = indices[i:i + subgroup_size]\n\n                for j in subgroup_indices:\n                    if evaluations >= self.budget:\n                        break\n\n                    value = func(particles[j])\n                    evaluations += 1\n\n                    if value < personal_best_values[j]:\n                        personal_best_values[j] = value\n                        personal_best_positions[j] = particles[j].copy()\n\n                    if value < self.global_best_value:\n                        self.global_best_value = value\n                        self.global_best_position = particles[j].copy()\n\n                # Adaptive coefficients based on subgroup performance\n                subgroup_best_value = np.min(personal_best_values[subgroup_indices])\n                subgroup_adaptation_factor = 1 + (subgroup_best_value - self.global_best_value) / (abs(self.global_best_value) + 1e-10)\n\n                w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n                c1 = self.c1_initial * subgroup_adaptation_factor\n                c2 = self.c2_initial * subgroup_adaptation_factor\n\n                for j in subgroup_indices:\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                    neighbors_indices = np.random.choice(subgroup_indices, adjusted_neighborhood_size, replace=False)\n                    local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                    local_best_position = personal_best_positions[local_best_index]\n\n                    cognitive_component = c1 * r1 * (personal_best_positions[j] - particles[j])\n                    social_component = c2 * r2 * (local_best_position - particles[j])\n                    velocities[j] = w * velocities[j] + cognitive_component + social_component\n\n                    particles[j] += velocities[j]\n                    particles[j] = np.clip(particles[j], lower_bounds, upper_bounds)\n\n                    adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                    if np.random.rand() < adaptive_mutation_chance:\n                        perturbation = (1 - evaluations / self.budget) * (1.5 - np.std(personal_best_values))\n                        mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * perturbation\n                        particles[j] = np.clip(particles[j] + mutation_vector, lower_bounds, upper_bounds)\n\n                if np.std(personal_best_values[subgroup_indices]) < self.epsilon:\n                    stagnant_indices = subgroup_indices[personal_best_values[subgroup_indices] > np.percentile(personal_best_values[subgroup_indices], 75)]\n                    for idx in stagnant_indices:\n                        particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                        personal_best_positions[idx] = particles[idx].copy()\n                        personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 95, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {}}
{"id": "01d32685-aa46-4fc2-a31e-a07d32d4c0c2", "fitness": -Infinity, "name": "AMPSO_NIAM_Adaptive_Learning", "description": "Incorporate an adaptive learning rate mechanism for velocity updates and introduce a dynamic neighborhood radius based on particle convergence behavior.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Adaptive_Learning:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions with adaptive learning rate\n            learning_rate = 0.5 + 0.5 * np.tanh((1 - evaluations / self.budget) * 10 - 5)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity and convergence\n                dynamic_neighborhood_size = max(2, int(self.neighborhood_size * (1 + np.std(personal_best_positions, axis=0).sum())))\n                neighbors_indices = np.random.choice(self.population_size, dynamic_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + learning_rate * (cognitive_component + social_component)\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))  # Adjust mutation scale\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 96, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {}}
{"id": "4433447e-39a4-4197-a145-e2800f4b50e5", "fitness": 0.9219009451345336, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Further enhance neighborhood selection by incorporating dynamic adjustment of neighborhood size and strategic mutation scale adaptation.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 3)  # Change 1\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (2.0 - np.std(personal_best_values))  # Change 2\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n                    velocities[idx] = np.random.uniform(-1, 1, self.dim)  # Change 3\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 97, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92190 with standard deviation 0.00738.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.912688657197836, 0.9307569461509555, 0.9222572320548093]}}
{"id": "1a18deaf-1c97-41e0-9d52-a6d553701ab2", "fitness": 0.7827921046999741, "name": "AMPSO_NIAM_Dynamic_Influence", "description": "Introduce a dynamic social influence mechanism and non-uniform mutation strategy to enhance convergence and exploration in dynamic environments.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Dynamic_Influence:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-3 * evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Dynamic neighborhood influence\n                influence_scale = 1 + np.sin(np.pi * evaluations / self.budget)\n                adjusted_neighborhood_size = int(self.neighborhood_size + influence_scale * np.std(personal_best_values) > self.epsilon)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply non-uniform mutation strategy\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = influence_scale * 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement)\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 98, "feedback": "The algorithm AMPSO_NIAM_Dynamic_Influence got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.78279 with standard deviation 0.11434.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.8069693513135113, 0.9091606746162064, 0.6322462881702047]}}
{"id": "aa8c6d4b-8dc8-4011-94f6-623b2ee3c740", "fitness": 0.9208766140079584, "name": "AMPSO_NIAM_Enhanced_Refined", "description": "Integrate adaptive inertia weight decay to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass AMPSO_NIAM_Enhanced_Refined:\n    def __init__(self, budget, dim, population_size=30, w_initial=0.9, w_final=0.4, c1_initial=2.5, c2_initial=1.5, epsilon=0.1, mutation_chance=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_initial = w_initial\n        self.w_final = w_final\n        self.c1_initial = c1_initial\n        self.c2_initial = c2_initial\n        self.epsilon = epsilon\n        self.mutation_chance = mutation_chance\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lower_bounds = np.array(func.bounds.lb)\n        upper_bounds = np.array(func.bounds.ub)\n\n        # Initialize particles\n        particles = np.random.uniform(lower_bounds, upper_bounds, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, np.inf)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Evaluate current position\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = particles[i].copy()\n\n            # Calculate inertia weight and cognitive/social coefficients adaptively\n            w = self.w_final + (self.w_initial - self.w_final) * (1 - (evaluations / self.budget)) ** 2  # Modified line: adjusted inertia weight decay\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adjust neighborhood size based on diversity\n                adjusted_neighborhood_size = int(self.neighborhood_size + (np.std(personal_best_values) > self.epsilon) * 2)\n                neighbors_indices = np.random.choice(self.population_size, adjusted_neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_values[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                cognitive_component = c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = c2 * r2 * (local_best_position - particles[i])\n                velocities[i] = w * velocities[i] + cognitive_component + social_component\n\n                # Update particle position\n                particles[i] += velocities[i]\n\n                # Ensure particles are within bounds\n                particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n\n                # Apply mutation to maintain diversity adaptively\n                adaptive_mutation_chance = self.mutation_chance + (np.std(personal_best_values) < self.epsilon) * 0.1\n                if np.random.rand() < adaptive_mutation_chance:\n                    best_improvement = (personal_best_values[i] - value) / (personal_best_values[i] + 1e-10)\n                    mutation_vector_scale = 0.1 * (1 - evaluations / self.budget) * (1 + best_improvement) * (1.5 - np.std(personal_best_values))  # Adjust mutation scale\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (upper_bounds - lower_bounds) * mutation_vector_scale\n                    particles[i] = np.clip(particles[i] + mutation_vector, lower_bounds, upper_bounds)\n\n            # Maintain diversity by reinitializing stagnant particles\n            if np.std(personal_best_values) < self.epsilon:\n                stagnant_indices = np.where(personal_best_values > np.percentile(personal_best_values, 75))[0]\n                for idx in stagnant_indices:\n                    particles[idx] = np.random.uniform(lower_bounds, upper_bounds, self.dim)\n                    personal_best_positions[idx] = particles[idx].copy()\n                    personal_best_values[idx] = np.inf\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 99, "feedback": "The algorithm AMPSO_NIAM_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92088 with standard deviation 0.03604.", "error": "", "parent_ids": ["061bacdd-2cb3-479a-af0d-484296eee145"], "operator": null, "metadata": {"aucs": [0.8937624931154622, 0.8970598843669518, 0.9718074645414612]}}
