{"id": "f290890d-ee05-46db-a1f9-447f18f876f8", "fitness": 0.18258324810991677, "name": "ASAPO", "description": "\"Adaptive Swarm-Adaptive Path Optimization (ASAPO) combines swarm intelligence with adaptive pathfinding for efficient exploration and exploitation in black box optimization.\"", "code": "import numpy as np\n\nclass ASAPO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_component + social_component\n            \n            # Adaptive path update\n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm ASAPO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18258 with standard deviation 0.00689.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.17992303302030965, 0.19202775472999822, 0.17579895657944244]}}
{"id": "5856dd39-f64e-44e9-91b4-0b92af12b5ca", "fitness": 0.18333501845949207, "name": "EASPDL", "description": "\"Enhanced Adaptive Swarm-Path with Dynamic Learning (EASPDL) improves exploration and exploitation by introducing dynamic learning rates and elite sampling in the particle update process, enhancing convergence in black box optimization.\"", "code": "import numpy as np\n\nclass EASPDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EASPDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18334 with standard deviation 0.01348.", "error": "", "parent_ids": ["f290890d-ee05-46db-a1f9-447f18f876f8"], "operator": null, "metadata": {"aucs": [0.1814124744768174, 0.16786922310593766, 0.20072335779572115]}}
{"id": "233ea474-ecbe-4c3d-ba38-ed57d3d062f8", "fitness": 0.17846645436876885, "name": "AEESO", "description": "Adaptive Elite-Enhanced Swarm Optimization (AEESO) introduces a dynamically adjusted elite-enhancement strategy and adaptive velocity scaling, which boosts convergence speed and solution quality in black box optimization.", "code": "import numpy as np\n\nclass AEESO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n        self.elite_enhancement_factor = 1.2\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component * self.elite_enhancement_factor\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n            \n            # Adaptive velocity scaling\n            self.velocities[i] *= 0.5 + 0.5 * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm AEESO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17847 with standard deviation 0.00382.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.18161257894115523, 0.1807033598539134, 0.1730834243112379]}}
{"id": "f17d77e7-2df8-482f-8546-c4877801ea6e", "fitness": 0.1800386537840314, "name": "EASPRDL", "description": "\"Enhanced Adaptive Swarm-Path with Rank-based Dynamic Learning (EASPRDL) refines exploration and exploitation by incorporating rank-based dynamic learning rates and advanced elite selection, significantly improving convergence for black box optimization.\"", "code": "import numpy as np\n\nclass EASPRDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        # Rank-based dynamic learning rates\n        ranks = np.argsort(np.argsort(self.personal_best_scores))\n        dynamic_rate = 1.0 - ranks / float(self.pop_size)\n        \n        # Determine elite threshold dynamically based on standard deviation of scores\n        elite_threshold = max(1, int(self.pop_size * 0.2))\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate[i] * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EASPRDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18004 with standard deviation 0.01044.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.17807534308010675, 0.19369801040304802, 0.1683426078689394]}}
{"id": "ebd3b3de-954f-4d8f-ab0e-aab287ae95b2", "fitness": 0.18333501845949207, "name": "EASPDL", "description": "\"Enhanced Adaptive Swarm-Path with Dynamic Learning (EASPDL) efficiently balances exploration and exploitation by incorporating an adaptive weighting strategy for cognitive and social components.\"", "code": "import numpy as np\n\nclass EASPDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm EASPDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18334 with standard deviation 0.01348.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.1814124744768174, 0.16786922310593766, 0.20072335779572115]}}
{"id": "01723216-3648-4e8c-8308-0cbd533a26ca", "fitness": 0.18253509684223568, "name": "EASPDL", "description": "\"Enhanced Adaptive Swarm-Path with Dynamic Learning (EASPDL) introduces an optimized inertia weight decay to improve convergence speed and solution accuracy in black box optimization.\"", "code": "import numpy as np\n\nclass EASPDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            self.inertia_weight *= 0.99  # Optimized inertia weight decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm EASPDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18254 with standard deviation 0.00100.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.18343677305464645, 0.18303367192066056, 0.18113484555140003]}}
{"id": "283449c6-f204-4910-804c-efad80a49827", "fitness": 0.1767390147940657, "name": "EASPDL", "description": "\"Enhanced Adaptive Swarm-Path with Dynamic Learning (EASPDL) improves exploration and exploitation by introducing dynamic learning rates and elite sampling in the particle update process, enhancing convergence in black box optimization, with refined social coefficient to boost convergence speed and accuracy.\"", "code": "import numpy as np\n\nclass EASPDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.7  # Changed social_coeff from 1.5 to 1.7\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EASPDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17674 with standard deviation 0.00238.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.17383037472996155, 0.17672814204242693, 0.1796585276098086]}}
{"id": "076d6f50-5065-476d-8bd4-61c8fa65f875", "fitness": 0.18333501845949207, "name": "EASPDL", "description": "\"Enhanced Adaptive Swarm-Path with Dynamic Learning (EASPDL) improves exploration and exploitation by introducing dynamic learning rates, a warm-start mechanism, and elite sampling in the particle update process, enhancing convergence in black box optimization.\"  ", "code": "import numpy as np\n\nclass EASPDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EASPDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18334 with standard deviation 0.01348.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.1814124744768174, 0.16786922310593766, 0.20072335779572115]}}
{"id": "c4cb89bb-69b6-4de4-956a-a2d245bb5748", "fitness": 0.16624685079367144, "name": "EASPDL", "description": "\"Improved EASPDL with Dynamic Inertia Weight (EASPDL-DIW) incorporates a dynamic inertia weight that decreases over time, enhancing the convergence speed and avoiding local optima in black box optimization.\"", "code": "import numpy as np\n\nclass EASPDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget) # Dynamic inertia weight\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EASPDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16625 with standard deviation 0.00562.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.16235134699320997, 0.162194108112663, 0.17419509727514138]}}
{"id": "702737bc-88ab-41fd-a964-c4f54a0c0fe1", "fitness": 0.17839941645397858, "name": "EASPDL_DC", "description": "\"Enhanced Adaptive Swarm-Path with Dynamic Learning and Diversity Control (EASPDL-DC) introduces diversity control mechanisms and adaptive inertia weight to improve convergence speed and robustness in black box optimization.\"", "code": "import numpy as np\n\nclass EASPDL_DC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia weight\n        self.inertia_weight_min = 0.4\n        self.inertia_weight_decay = 0.99\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.path_adaptation_rate = 0.1\n        self.diversity_control_rate = 0.2\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.01 * self.budget)\n        elite_threshold = int(self.pop_size * 0.2)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = (self.inertia_weight * self.velocities[i] \n                                  + cognitive_component \n                                  + social_component \n                                  + dynamic_rate * elite_component)\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n            # Diversity Control: Random reinitialization\n            if np.random.rand() < self.diversity_control_rate:\n                self.positions[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n\n        # Decay the inertia weight\n        self.inertia_weight = max(self.inertia_weight * self.inertia_weight_decay, self.inertia_weight_min)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm EASPDL_DC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17840 with standard deviation 0.00304.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.1816804164650454, 0.17436045080489582, 0.1791573820919945]}}
{"id": "0e51cb11-3c02-4513-9ae8-0f42aa45ad1e", "fitness": 0.18593626115778142, "name": "DEGAS", "description": "\"Dynamic Elite-Guided Adaptive Swarm (DEGAS) enhances convergence by dynamically adjusting particle velocities based on elite particle influence and historical momentum, optimizing exploration and exploitation balance during black box optimization.\"", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18594 with standard deviation 0.00832.", "error": "", "parent_ids": ["5856dd39-f64e-44e9-91b4-0b92af12b5ca"], "operator": null, "metadata": {"aucs": [0.19629644347643138, 0.17593366644240627, 0.18557867355450663]}}
{"id": "c265f177-b84c-4f5f-be76-26dafafcab32", "fitness": 0.1829761520436126, "name": "AMIDSO", "description": "\"Adaptive Momentum-Infused Dynamic Swarm Optimization (AMIDSO) enhances convergence by integrating adaptive momentum and elite influence, dynamically balancing exploration and exploitation based on historical performance and elite guidance.\"", "code": "import numpy as np\n\nclass AMIDSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_init = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.adaptive_momentum_coeff = 0.2\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_inertia_weight(self, evaluations):\n        return self.inertia_weight_init - (self.inertia_weight_init - self.inertia_weight_final) * (evaluations / self.budget)\n\n    def update_particles(self, func, evaluations):\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n        inertia_weight = self.update_inertia_weight(evaluations)\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            adaptive_momentum = self.adaptive_momentum_coeff * np.random.rand(self.dim) * (self.global_best_position - self.personal_best_positions[i])\n\n            self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_component + social_component + elite_component + adaptive_momentum\n            self.positions[i] += self.velocities[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func, evaluations)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm AMIDSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18298 with standard deviation 0.00455.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18391089715624276, 0.17699290715154292, 0.18802465182305206]}}
{"id": "bc588e17-6b1c-4482-878f-62476350c55a", "fitness": 0.18106189050108254, "name": "DEGAS", "description": "DEGAS with Adaptive Inertia adjusts the inertia weight dynamically to enhance convergence by balancing exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = (0.9 - 0.5 * (i / self.budget)) * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18106 with standard deviation 0.00801.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18305114827222646, 0.18972832592617872, 0.1704061973048424]}}
{"id": "df27d957-043b-4bbd-84bf-dbc19094785f", "fitness": 0.18106189050108254, "name": "DEGAS", "description": "\"Enhanced Dynamic Elite-Guided Adaptive Swarm (DEGAS+) incorporates a dynamically adapting inertia weight to balance exploration and exploitation more effectively during black box optimization.\"", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            # Adjust the inertia weight dynamically\n            self.inertia_weight = 0.9 - (0.9 - 0.4) * i / self.budget\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18106 with standard deviation 0.00801.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18305114827222646, 0.18972832592617872, 0.1704061973048424]}}
{"id": "b7d5b1f8-2cc5-4a4c-94e7-e5dd6f77a553", "fitness": -Infinity, "name": "E_DEGAS", "description": "Enhanced Dynamic Elite-Guided Adaptive Swarm (E-DEGAS) introduces an adaptive mutation strategy and variable inertia weight, improving exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass E_DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n        self.adaptive_mutation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n\n            # Adaptive mutation strategy\n            mutation = self.adaptive_mutation_rate * np.random.uniform(-1, 1, self.dim) * (bounds.ub - bounds.lb)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component \\\n                                 + mutation\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n        # Update inertia weight\n        self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * 0.99)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "An exception occurred: NameError(\"name 'bounds' is not defined\").", "error": "NameError(\"name 'bounds' is not defined\")", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {}}
{"id": "d2f0afee-6664-4fbb-8337-3c1f7525240a", "fitness": 0.18180331075179076, "name": "AQPSO", "description": "\"Adaptive Quantum-inspired Particle Swarm Optimization (AQPSO) enhances convergence by incorporating quantum behaviors for particle position update, leveraging quantum superposition to maintain diversity and improve exploration-exploitation balance in black box optimization.\"", "code": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptation_rate = 0.15\n        self.q_factor = 0.5\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:int(self.pop_size * 0.15)]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            quantum_component = np.random.uniform(-1, 1, self.dim) * self.q_factor * np.abs(self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptation_rate * elite_component \\\n                                 + quantum_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18180 with standard deviation 0.01147.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.19587534891348657, 0.1817588813155161, 0.1677757020263696]}}
{"id": "d1f60a74-aba2-4ad2-b2ac-67179ec48feb", "fitness": -Infinity, "name": "DEGAS", "description": "\"Enhanced Dynamic Elite-Guided Adaptive Swarm (EDEGAS) introduces adaptive cognitive and social coefficients to balance exploration and exploitation more effectively during black box optimization.\"", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            # Adapt cognitive and social coefficients based on progress\n            progress = (self.budget - evaluations) / self.budget\n            self.cognitive_coeff = 1.5 + 0.2 * progress\n            self.social_coeff = 1.5 + 0.2 * (1 - progress)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {}}
{"id": "e02bcee2-102c-4cf2-b885-3532f28da406", "fitness": -Infinity, "name": "AMSS", "description": "\"Adaptive Multi-Stage Swarm (AMSS) combines dynamic learning rates and adaptive neighborhood influence to enhance exploration and convergence in black box optimization.\"", "code": "import numpy as np\n\nclass AMSS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.neighborhood_coeff = 0.3\n        self.adaptive_rate = np.linspace(0.9, 0.4, self.budget // self.pop_size)\n    \n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func, step):\n        # Adaptive inertia weight\n        inertia_weight = self.adaptive_rate[step]\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles for neighborhood influence\n        sorted_indices = np.argsort(self.personal_best_scores)\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            \n            # Adaptive neighborhood influence\n            neighbor_index = sorted_indices[(i + 1) % self.pop_size]\n            neighborhood_component = self.neighborhood_coeff * (self.personal_best_positions[neighbor_index] - self.positions[i])\n            \n            self.velocities[i] = inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + neighborhood_component\n            \n            self.positions[i] += self.velocities[i]\n            # Ensure particles remain within bounds\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        step = 0\n        while evaluations < self.budget:\n            self.update_particles(func, step)\n            evaluations += self.pop_size\n            step += 1\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "An exception occurred: IndexError('index 204 is out of bounds for axis 0 with size 204').", "error": "IndexError('index 204 is out of bounds for axis 0 with size 204')", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {}}
{"id": "5cc3753f-ebf6-4e78-ab62-0948256a59d4", "fitness": 0.1686926410144509, "name": "AN_DEGAS", "description": "\"Adaptive Neighborhood-DEGAS (AN-DEGAS) introduces adaptive local search inspired by neighborhood influence, dynamically refining particle adjustments for enhanced convergence in black box optimization.\"", "code": "import numpy as np\n\nclass AN_DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n        self.neighborhood_radius = max(1, int(0.1 * self.pop_size))\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            \n            neighbors = sorted_indices[max(0, i - self.neighborhood_radius):min(self.pop_size, i + self.neighborhood_radius)]\n            neighborhood_component = np.mean([self.positions[idx] for idx in neighbors], axis=0) - self.positions[i]\n            \n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component \\\n                                 + dynamic_rate * neighborhood_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm AN_DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16869 with standard deviation 0.00505.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.16758456979773972, 0.1631411761802336, 0.1753521770653793]}}
{"id": "b15acbcf-15a6-4d7e-a505-4c0d8519211c", "fitness": 0.17792454883217976, "name": "DEGAS", "description": "\"Dynamic Elite-Guided Adaptive Swarm (DEGAS) improves convergence by tweaking the path adaptation rate based on particle diversity, optimizing balance between exploration and exploitation in black box optimization.\"", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            diversity = np.mean(np.std(self.positions, axis=0))  # Calculate population diversity\n            path_adaptation_modulation = (1.0 / (1.0 + np.exp(-10 * (diversity - 0.1))))  # Adjust path adaptation rate\n            self.positions[i] += self.velocities[i]\n            self.positions[i] += path_adaptation_modulation * self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17792 with standard deviation 0.00985.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18417870100623623, 0.16401627193579638, 0.18557867355450663]}}
{"id": "2e347942-12a7-42d4-938a-30450f05890e", "fitness": 0.17631180622168383, "name": "DEGAS", "description": "\"Dynamic Elite-Guided Adaptive Swarm (DEGAS) enhances convergence by dynamically adjusting particle velocities based on elite particle influence and historical momentum, optimizing exploration and exploitation balance during black box optimization with improved inertia weight adaptation for diverse search capabilities.\"", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = (0.5 + 0.2 * np.random.rand()) * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17631 with standard deviation 0.00785.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18229671506739964, 0.1814193152472383, 0.1652193883504135]}}
{"id": "8648f338-5f8b-4fff-ab63-426a2d633b0f", "fitness": 0.18136708402752344, "name": "DEGAS", "description": "\"Enhanced Dynamic Elite-Guided Adaptive Swarm (E-DEGAS) introduces adaptive inertia, cognitive, and social coefficients based on performance trends, refining balance between exploration and exploitation in black box optimization.\"", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n        \n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n\n            # Adaptive coefficients\n            self.inertia_weight = 0.5 + 0.4 * np.random.rand()\n            self.cognitive_coeff = 1.5 + 1.0 * np.random.rand()\n            self.social_coeff = 1.5 + 1.0 * np.random.rand()\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18137 with standard deviation 0.00580.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.17849632272476368, 0.18945725895196963, 0.176147670405837]}}
{"id": "43bc9eab-3f38-43f9-87a1-79df652e8ab0", "fitness": 0.16998405712284537, "name": "DEGAS", "description": "Enhanced DEGAS with dynamic adaptation of inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9 - 0.2 * (self.budget / 1000)  # Adjusted line\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16998 with standard deviation 0.00826.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18067997130441837, 0.16056646204596559, 0.16870573801815214]}}
{"id": "c103791c-6d3d-4fdd-accd-54d81c7f81e5", "fitness": 0.1852173694613142, "name": "DEGAS", "description": "Enhance DEGAS by slightly increasing the cognitive coefficient for more exploratory dynamics.", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.8  # Modified from 1.7 to 1.8\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18522 with standard deviation 0.01170.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18046552575836272, 0.2013245855027801, 0.17386199712279982]}}
{"id": "9c68b4b3-7084-462f-9989-ba27482f842e", "fitness": 0.17733951749493979, "name": "DEGAS", "description": "Modify the inertia weight to decay linearly over iterations to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        # Linearly decay inertia weight\n        self.inertia_weight = 0.9 - 0.5 * (self.budget / self.budget)\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17734 with standard deviation 0.00398.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18291743015842576, 0.17523545410795593, 0.17386566821843763]}}
{"id": "1b88d75a-9956-43e2-9d50-bc25a17f4cef", "fitness": 0.14998309428243337, "name": "DEGAS", "description": "Introduced an adaptive cognitive coefficient to enhance convergence by dynamically adjusting individual particle influence based on iteration progress.", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = lambda t: 1.7 * (1 - t / self.budget)  # Changed to adaptive\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff(self.budget) * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14998 with standard deviation 0.02041.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.17724883352814513, 0.14453868591893515, 0.12816176340021979]}}
{"id": "80678fba-dff9-4dee-a262-bbb2084aef05", "fitness": 0.18005506903972332, "name": "DEGAS", "description": "\"Enhanced DEGAS improves convergence by dynamically adjusting particle velocities based on elite particle influence, historical momentum, and a boosted inertia weight, optimizing the exploration-exploitation balance during black box optimization.\"", "code": "import numpy as np\n\nclass DEGAS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.8  # Modified from 0.7 to 0.8\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.path_adaptation_rate = 0.15\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        dynamic_rate = 1.0 - np.exp(-0.005 * self.budget)\n        elite_threshold = int(self.pop_size * 0.15)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        # Sort particles based on their scores\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + dynamic_rate * elite_component\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] += self.path_adaptation_rate * (self.global_best_position - self.positions[i]) * np.random.rand()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm DEGAS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18006 with standard deviation 0.00568.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.184033990731032, 0.184114714296009, 0.17201650209212893]}}
{"id": "fb4ae94c-4e9c-439d-a703-750f6e905ec1", "fitness": 0.18711076121917627, "name": "AMES", "description": "Adaptive Momentum Elite Swarm (AMES) enhances convergence by integrating adaptive momentum and elite-guided strategies for robust exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass AMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n            \n            # Adaptive momentum to dynamically adjust exploration and exploitation\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm AMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18711 with standard deviation 0.00294.", "error": "", "parent_ids": ["0e51cb11-3c02-4513-9ae8-0f42aa45ad1e"], "operator": null, "metadata": {"aucs": [0.18400678862078612, 0.19106303462540553, 0.1862624604113372]}}
{"id": "f12041cb-abd9-48e0-8a44-d88ce8fcd772", "fitness": 0.194550701203941, "name": "AMES", "description": "Optimized adaptive momentum update to enhance convergence speed and precision.", "code": "import numpy as np\n\nclass AMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + (self.adaptive_momentum + 0.05) * elite_component  # Slightly increased adaptive momentum\n            \n            # Adaptive momentum to dynamically adjust exploration and exploitation\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm AMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19455 with standard deviation 0.00490.", "error": "", "parent_ids": ["fb4ae94c-4e9c-439d-a703-750f6e905ec1"], "operator": null, "metadata": {"aucs": [0.19685229964098405, 0.19906027581886532, 0.1877395281519736]}}
{"id": "de4b213f-e0a6-4435-97ea-769ddd096a7e", "fitness": 0.1959409373619547, "name": "HybridAMES", "description": "Hybridized adaptive momentum with differential evolution for enhanced convergence speed and precision.", "code": "import numpy as np\n\nclass HybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n            \n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm HybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19594 with standard deviation 0.00165.", "error": "", "parent_ids": ["f12041cb-abd9-48e0-8a44-d88ce8fcd772"], "operator": null, "metadata": {"aucs": [0.19369301610517842, 0.19651647493728952, 0.19761332104339613]}}
{"id": "a0105e18-0617-4b4d-b16f-4be2c59a267d", "fitness": 0.18894611232950953, "name": "HybridAMES", "description": "Introduced a small random perturbation to the global best position to enhance exploration.", "code": "import numpy as np\n\nclass HybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n            \n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            evaluations += self.pop_size\n            self.global_best_position += 0.01 * np.random.randn(self.dim)  # Perturbing global best position\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm HybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18895 with standard deviation 0.00239.", "error": "", "parent_ids": ["de4b213f-e0a6-4435-97ea-769ddd096a7e"], "operator": null, "metadata": {"aucs": [0.19108130635478882, 0.18560797389699968, 0.1901490567367401]}}
{"id": "f89fd7a5-587d-4431-a45c-058a35958a26", "fitness": 0.1836034427350984, "name": "HybridAMES", "description": "Introduce adaptive inertia weight adjustment in HybridAMES to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass HybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        adapt_factor = 1 - (self.global_best_score / func(self.global_best_position))\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = (self.inertia_weight * adapt_factor) * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n            \n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm HybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18360 with standard deviation 0.00764.", "error": "", "parent_ids": ["de4b213f-e0a6-4435-97ea-769ddd096a7e"], "operator": null, "metadata": {"aucs": [0.17393895857392871, 0.19260850406733654, 0.18426286556402993]}}
{"id": "7c92f0d8-3b55-4669-8973-b00414b59bf8", "fitness": 0.18707176752292207, "name": "EnhancedHybridAMES", "description": "Enhanced hybrid algorithm combining adaptive momentum, elite-guided particle swarm optimization, and differential evolution with dynamic parameters for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale_initial = 0.8\n        self.de_cross_prob_initial = 0.9\n        self.dynamic_adapt_start = 0.3 * self.budget\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func, evaluations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        dynamic_influence = (evaluations / self.budget) if evaluations > self.dynamic_adapt_start else 0\n\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + (self.adaptive_momentum + dynamic_influence * (1 - self.adaptive_momentum)) * elite_component\n            \n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func, evaluations):\n        trial_positions = np.copy(self.positions)\n        de_scale = self.de_scale_initial + (evaluations / self.budget) * (1.0 - self.de_scale_initial)\n        de_cross_prob = self.de_cross_prob_initial + (evaluations / self.budget) * (0.5 - self.de_cross_prob_initial)\n\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func, evaluations)\n            self.differential_evolution(func, evaluations)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18707 with standard deviation 0.00486.", "error": "", "parent_ids": ["de4b213f-e0a6-4435-97ea-769ddd096a7e"], "operator": null, "metadata": {"aucs": [0.1903998576202124, 0.1801981773703054, 0.19061726757824837]}}
{"id": "cf287005-dae0-49f8-8215-502cf8a7532c", "fitness": 0.19069734101054092, "name": "HybridAMES", "description": "Enhanced particle velocity update by slightly increasing the cognitive coefficient for improved local exploration.", "code": "import numpy as np\n\nclass HybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.8  # Changed from 1.7 to 1.8\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n            \n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm HybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19070 with standard deviation 0.01085.", "error": "", "parent_ids": ["de4b213f-e0a6-4435-97ea-769ddd096a7e"], "operator": null, "metadata": {"aucs": [0.20233836258442117, 0.1762209223248291, 0.19353273812237248]}}
{"id": "f9d925bb-5859-4996-a1e6-8cc87d6756ef", "fitness": 0.17915147156907804, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive inertia and adaptive differential evolution scaling to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_base_scale = 0.5\n        self.de_max_scale = 0.9\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_particles(self, func):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n            \n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def adaptive_differential_evolution(self, func, iteration, max_iterations):\n        de_scale = self.de_base_scale + (self.de_max_scale - self.de_base_scale) * (iteration / max_iterations)\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            self.update_particles(func)\n            self.adaptive_differential_evolution(func, iteration, max_iterations)\n            evaluations += self.pop_size\n            iteration += 1\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17915 with standard deviation 0.00281.", "error": "", "parent_ids": ["de4b213f-e0a6-4435-97ea-769ddd096a7e"], "operator": null, "metadata": {"aucs": [0.18116229624657598, 0.1811099649297676, 0.1751821535308905]}}
{"id": "24c2369c-258c-4bb1-ac97-a310c11e160e", "fitness": 0.19146945196983142, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive parameters and mutation strategy for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def update_parameters(self, evaluations):\n        self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n        self.cognitive_coeff = 2.5 - 1.0 * (evaluations / self.budget)\n        self.social_coeff = 1.5 + 1.0 * (evaluations / self.budget)\n\n    def update_particles(self, func, evaluations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        self.update_parameters(evaluations)\n        \n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            \n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n            \n            momentum = 0.3 * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            \n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles(func, evaluations)\n            self.differential_evolution(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19147 with standard deviation 0.00433.", "error": "", "parent_ids": ["de4b213f-e0a6-4435-97ea-769ddd096a7e"], "operator": null, "metadata": {"aucs": [0.19031630877401773, 0.1868419988516128, 0.19725004828386372]}}
{"id": "28fc35b2-986b-45a5-8817-5c6e9d94eeab", "fitness": 0.2007712765924221, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive inertia and chaotic maps for improved exploration-exploitation balance and convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20077 with standard deviation 0.01280.", "error": "", "parent_ids": ["de4b213f-e0a6-4435-97ea-769ddd096a7e"], "operator": null, "metadata": {"aucs": [0.209119595723389, 0.1826815145900591, 0.21051271946381822]}}
{"id": "270e2cb3-0850-44d2-b88e-88b4e9d09bad", "fitness": 0.18372824519610384, "name": "EnhancedHybridAMES2", "description": "Enhanced HybridAMES 2.0 with Levy flight for enhanced global exploration and adaptive mutation for diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.mutation_rate = 0.1  # New parameter for adaptive mutation\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) /\n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_component + social_component + self.adaptive_momentum * elite_component\n\n            # Levy flight step for exploration\n            if np.random.rand() < self.exploration_rate:\n                self.velocities[i] += self.levy_flight()\n\n            # Adaptive mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                self.velocities[i] += np.random.normal(0, 1, self.dim)\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedHybridAMES2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18373 with standard deviation 0.01189.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.20048325017034807, 0.17413084230458564, 0.17657064311337778]}}
{"id": "d754e83d-ae2c-4d25-a1ac-b298d0980cd5", "fitness": 0.18050725544851956, "name": "ImprovedEnhancedHybridAMES", "description": "Improved EnhancedHybridAMES using Lvy flights for enhanced exploration and a dynamic balance between exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedEnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.98  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.elite_rate = 0.15\n        self.de_scale = 0.9\n        self.de_cross_prob = 0.8\n        self.levy_factor = 1.5\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def levy_flight(self):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, 1, self.dim) * sigma\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + 0.5 * elite_component\n\n            if np.random.rand() < self.levy_factor:\n                self.velocities[i] += self.levy_flight()\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm ImprovedEnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18051 with standard deviation 0.00208.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18233109650486357, 0.18158830403424286, 0.17760236580645228]}}
{"id": "c8fae995-6774-41e2-94f3-31e70d528e9f", "fitness": 0.1923691206210806, "name": "EnhancedHybridAMES", "description": "Enhance exploration-exploitation balance by fine-tuning the chaotic factor and introducing dynamic elite selection.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6 + 0.4 * (iteration / max_iterations)  # Dynamic initial value\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate * (1 + 0.1 * iteration / max_iterations))  # Dynamic elite rate\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19237 with standard deviation 0.00764.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1990048966600647, 0.18167112197701096, 0.19643134322616618]}}
{"id": "a36e8dfa-34c8-4543-a153-92752d8309f0", "fitness": 0.2007712765924221, "name": "EnhancedHybridAMESPlus", "description": "EnhancedHybridAMES with adaptive chaos-induced mutation and velocity reset for improved diversity and convergence reliability.", "code": "import numpy as np\n\nclass EnhancedHybridAMESPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.velocity_reset_threshold = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            # Implement velocity reset for stagnation\n            if np.linalg.norm(self.velocities[i]) < self.velocity_reset_threshold:\n                self.velocities[i] = np.random.uniform(-0.5, 0.5, self.dim)\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridAMESPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20077 with standard deviation 0.01280.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.209119595723389, 0.1826815145900591, 0.21051271946381822]}}
{"id": "6b52a3cc-c01e-4a11-ba12-0a35fe4aeb60", "fitness": 0.19150385946411044, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with adaptive dynamic scaling and learning-inspired updates to improve convergence precision and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.learning_rate = 0.1\n        self.dynamic_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def dynamic_differential_evolution(self, func, iteration, max_iterations):\n        trial_positions = np.copy(self.positions)\n        dynamic_factor = self.dynamic_scale * (1 - (iteration / max_iterations))\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.personal_best_positions[a] + dynamic_factor * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.dynamic_differential_evolution(func, iteration, max_iterations)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19150 with standard deviation 0.01397.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.17513061743498315, 0.20926074826904428, 0.19012021268830392]}}
{"id": "88062f29-7cd6-44a9-8cd6-51eeb0ebe7bc", "fitness": 0.1883356037477415, "name": "HybridAMESPlusPlus", "description": "HybridAMES++ integrates quantum-inspired particle dynamics and enhanced differential evolution to boost convergence speed and accuracy in black box optimization.", "code": "import numpy as np\n\nclass HybridAMESPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.quantum_coeff = 0.5  # New quantum-inspired coefficient\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            # Quantum-inspired dynamics\n            quantum_component = self.quantum_coeff * np.random.randn(self.dim) * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + 0.5 * elite_component \\\n                                 + chaotic_factor * self.velocities[i] \\\n                                 + quantum_component\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm HybridAMESPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18834 with standard deviation 0.00142.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1891182693177248, 0.18633814925676506, 0.18955039266873464]}}
{"id": "8b5510e5-5978-4c90-9dcd-096379c0533c", "fitness": 0.19446989126011527, "name": "EnhancedHybridAMES", "description": "Improved inertia decay rate for EnhancedHybridAMES to enhance convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.995  # Improved decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19447 with standard deviation 0.00123.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19561667585179476, 0.19276240805816602, 0.19503058987038502]}}
{"id": "5bb7b0ed-4488-4a76-8237-c7f2d774cb13", "fitness": 0.18786818133440608, "name": "EnhancedHybridAMES", "description": "Introduced a stochastic reset mechanism to improve escaping local optima by occasionally resetting particles' velocities to random values.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            if np.random.rand() < 0.01:  # Stochastic reset with 1% probability\n                self.velocities[i] = np.random.uniform(-0.5, 0.5, self.dim)\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18787 with standard deviation 0.00968.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18675286311979433, 0.20023878113751847, 0.17661289974590544]}}
{"id": "216898ec-ef02-41f1-ac2c-b26641bf3662", "fitness": -Infinity, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive learning rates and dynamic population strategies for improved exploration-exploitation balance and convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.learning_rate = 0.1\n        self.dynamic_pop_factor = 0.5\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.learning_rate * self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n        \n        # Dynamic population strategy: periodically adjust population size\n        if np.random.rand() < self.dynamic_pop_factor:\n            self.pop_size = max(5, int(self.pop_size * np.random.uniform(0.8, 1.2)))\n            self.positions = np.clip(self.positions[:self.pop_size], func.bounds.lb, func.bounds.ub)\n            self.velocities = self.velocities[:self.pop_size]\n            self.personal_best_positions = self.personal_best_positions[:self.pop_size]\n            self.personal_best_scores = self.personal_best_scores[:self.pop_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {}}
{"id": "000c7d5c-4eaf-480a-a64c-98830a75d791", "fitness": 0.17983088273516934, "name": "EnhancedHybridAMES", "description": "Enhanced exploration-exploitation balance by introducing nonlinear time-varying inertia weight and adaptive DE parameters.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            # Nonlinear time-varying inertia weight\n            self.inertia_weight = 0.9 - 0.5 * (iteration / max_iterations) ** 2\n            # Adaptive DE parameters\n            self.de_scale = 0.5 + 0.3 * (1 - iteration / max_iterations)\n            self.de_cross_prob = 0.6 + 0.3 * (iteration / max_iterations)\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17983 with standard deviation 0.00634.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18848205418610142, 0.17344741217459902, 0.17756318184480757]}}
{"id": "9428ffdb-b89f-447a-aeee-3dad0dc7f786", "fitness": 0.19638122477098718, "name": "ImprovedEnhancedHybridAMES", "description": "Improved Enhanced HybridAMES with adaptive chaos control and multi-phase exploration-exploitation strategy for enhanced convergence and precision.", "code": "import numpy as np\n\nclass ImprovedEnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.phase_switch = int(budget * 0.3)  # Switch point for exploration and exploitation phases\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7 + 0.3 * (iteration / max_iterations)  # Adaptive chaos control\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            if iteration < self.phase_switch:\n                # Exploration phase\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            else:\n                # Exploitation phase\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n                \n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm ImprovedEnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19638 with standard deviation 0.01652.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19276044614232912, 0.17820137542326886, 0.21818185274736357]}}
{"id": "e5c6f975-b1de-4fe0-b402-0d40cb2292cb", "fitness": -Infinity, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive inertia and chaotic maps for improved exploration-exploitation balance and convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": "\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.0% of the code, which means if the code has 100 lines, you can only change 1.0 lines, and the rest of the lines should remain unchanged. This input code has 100 lines, so you can only change 1 lines, the rest 99 lines should remain unchanged. This changing rate 1.0% is the mandatory requirement, you cannot change more or less than this rate.\n    ", "metadata": {"aucs": [0.209119595723389, 0.1826815145900591, 0.21051271946381822]}}
{"id": "dd544334-7bc3-4b86-8dbd-ffe92344b4b0", "fitness": 0.1883305644967065, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with improved chaotic map for better exploration-exploitation dynamics.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x * np.sin(iteration)  # Slight modification for enhanced exploration\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18833 with standard deviation 0.00873.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1877486372767353, 0.1779439933266469, 0.19929906288673727]}}
{"id": "d29fc22f-658a-45c4-9977-ab4ba82e973c", "fitness": 0.1724150188161502, "name": "AdaptiveHybridAMES", "description": "Introducing adaptive exploration-exploitation balancing using Lvy flights and elite dynamic scaling for enhanced convergence in the Adaptive HybridAMES algorithm.", "code": "import numpy as np\n\nclass AdaptiveHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def levy_flight(self, iteration):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * pow(2, ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / pow(abs(v), 1 / beta)\n        return step * 0.01 * np.power(iteration, -0.5)\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n            levy_step = self.levy_flight(iteration)\n\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_component +\n                                  social_component +\n                                  self.adaptive_momentum * elite_component +\n                                  chaotic_factor * self.velocities[i] +\n                                  levy_step)\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17242 with standard deviation 0.00272.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.16887635560062386, 0.17288940912038742, 0.17547929172743937]}}
{"id": "e5fddcde-b8f1-499c-937f-0203d5f40b55", "fitness": -Infinity, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with dynamic subgroup formation and adaptive learning rates for optimized exploration and exploitation in varying dimensions.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  \n        self.inertia_decay = 0.99  \n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        subgroup_size = max(2, self.dim // 5)\n        subgroups = [np.random.choice(elite_indices, size=subgroup_size, replace=False) for _ in range(self.pop_size)]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in subgroups[i]], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {}}
{"id": "cc392a26-b42d-4f90-97b7-f3e56ed11b8a", "fitness": -Infinity, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive elitism and Levy flight-based exploration for improved search efficiency and dynamic balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.adaptive_elite_rate = 0.02  # New adaptive elitism rate\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component\n\n            if np.random.rand() < self.adaptive_elite_rate:  # Levy flight exploration\n                self.positions[i] += self.levy_flight(self.dim)\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {}}
{"id": "9f209cb6-831a-4213-bb06-fc1dc2f7acfb", "fitness": 0.18980650433043497, "name": "RefinedHybridAMES", "description": "Introducing adaptive learning factors with a non-linear inertia decay and enhanced chaotic map dynamics to boost convergence reliability and efficiency in the Enhanced HybridAMES algorithm.", "code": "import numpy as np\n\nclass RefinedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.995\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.adaptive_momentum = 0.6\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.9\n        x = 0.7\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm RefinedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18981 with standard deviation 0.01121.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1920139355484991, 0.20229571701332671, 0.17510986042947907]}}
{"id": "f16e73d6-e16c-4fc2-87bc-232d40963fdc", "fitness": 0.1959712408461258, "name": "ImprovedHybridAMES", "description": "Improved HybridAMES with dynamic elite selection and self-adaptive differential evolution for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass ImprovedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x * (1 - iteration / max_iterations)\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        adaptive_de_scale = self.de_scale + np.random.rand() * (1 - self.de_scale)\n        adaptive_de_cross_prob = self.de_cross_prob + np.random.rand() * (1 - self.de_cross_prob)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + adaptive_de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < adaptive_de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm ImprovedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19597 with standard deviation 0.00737.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19052661736014587, 0.20639758362793204, 0.19098952155029947]}}
{"id": "62afb202-2f50-4b15-8e8a-968a77794034", "fitness": 0.18492468528685693, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with adaptive chaotic inertia and elite-based diversity for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        # Using a modified logistic map to adaptively influence inertia\n        beta = 4.0  # Modified logistic map control parameter\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * chaotic_factor * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * chaotic_factor * elite_component\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18492 with standard deviation 0.00625.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18638089690152582, 0.1766450701033575, 0.1917480888556875]}}
{"id": "3b615988-bd35-42f7-90f6-e090ce2803b0", "fitness": 0.19473169777979563, "name": "EnhancedHybridAMES", "description": "Introduce Lvy flight mechanism and adaptive elite strategy into Enhanced HybridAMES for improved exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.power(np.abs(v), 1 / L)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n            \n            levy_step = self.levy_flight(1.5) * chaotic_factor\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i] \\\n                                 + levy_step\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19473 with standard deviation 0.01161.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1985947261104345, 0.17898415142598, 0.2066162158029724]}}
{"id": "1270f8df-a7b0-4fd8-aede-a09ce1c7ded5", "fitness": -Infinity, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with dynamic subpopulation division and chaos-influenced mutation for refined adaptability and precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.subpop_division = 0.5  # Fraction to divide population for varied exploration-exploitation\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        adaptive_de_scale = self.de_scale * self.chaotic_map(func(self.global_best_position), self.budget)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + adaptive_de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def subpopulation_strategy(self, func):\n        subpop_size = int(self.pop_size * self.subpop_division)\n        indices = np.random.choice(self.pop_size, subpop_size, replace=False)\n        for index in indices:\n            self.differential_evolution(func)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.subpopulation_strategy(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "An exception occurred: TypeError(\"'float' object cannot be interpreted as an integer\").", "error": "TypeError(\"'float' object cannot be interpreted as an integer\")", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {}}
{"id": "fadcb380-c126-427c-a68d-6c64f2d40b84", "fitness": -Infinity, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adjusted elite component weight for improved convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + (self.adaptive_momentum + 0.1) * elite_component \\  # Adjust elite component weight\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "An exception occurred: SyntaxError('unexpected character after line continuation character', ('<string>', 60, 306, '            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\\\\n                                 + cognitive_component \\\\\\n                                 + social_component \\\\\\n                                 + (self.adaptive_momentum + 0.1) * elite_component \\\\  # Adjust elite component weight\\n')).", "error": "SyntaxError('unexpected character after line continuation character', ('<string>', 60, 306, '            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\\\\n                                 + cognitive_component \\\\\\n                                 + social_component \\\\\\n                                 + (self.adaptive_momentum + 0.1) * elite_component \\\\  # Adjust elite component weight\\n'))", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {}}
{"id": "65631ebe-a33e-4ac0-9ef8-f2f11102cc4a", "fitness": 0.18729279352272496, "name": "EnhancedHybridAMES_v2", "description": "Introducing a non-linear learning factor and improved chaotic sequence to further enhance convergence speed and precision by dynamically adjusting the exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.97  # Modified decay for adaptive inertia\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.18  # Slightly increased elite rate\n        self.exploration_rate = 0.35  # Increased exploration rate\n        self.de_scale = 0.85  # Adjusted DE scale factor\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        alpha = 0.7 + 0.3 * (iteration / max_iterations)  # Evolving chaos factor\n        x = 0.6\n        for _ in range(iteration):\n            x = alpha * x * (1 - x)\n        return x\n\n    def non_linear_learning_factor(self, iteration, max_iterations):\n        return 0.5 * (1 + np.cos(np.pi * iteration / max_iterations))\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            learning_factor = self.non_linear_learning_factor(iteration, max_iterations)\n            cognitive_component = learning_factor * self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = learning_factor * self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHybridAMES_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18729 with standard deviation 0.00454.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18761434314500813, 0.1926863397877807, 0.181577697635386]}}
{"id": "3f42dc26-ed1e-4dee-a779-f51376a410ce", "fitness": 0.1840165886623167, "name": "RefinedHybridAMES", "description": "Refined HybridAMES with adaptive strategy adjustment and Lvy flight mechanism for enhanced exploration and exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass RefinedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.alpha = 1.5  # Lvy flight parameter\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v)**(1/self.alpha)\n        return step\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + 0.5 * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * self.levy_flight(self.dim)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm RefinedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18402 with standard deviation 0.00103.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18302469650156394, 0.18543882023506553, 0.18358624925032063]}}
{"id": "7a26238e-c10b-496f-bada-442f9eec4e0e", "fitness": -Infinity, "name": "RefinedEnhancedHybridAMES", "description": "Refined Enhanced HybridAMES using adaptive population size and Lvy flight-based exploration for improved diversity and convergence in black box optimization.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.adaptive_pop_size_rate = 0.05\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def levy_flight(self, iteration, max_iterations):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step * (self.positions - self.global_best_position)\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            levy_component = self.levy_flight(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + levy_component\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def adaptive_population_size(self, iteration, max_iterations):\n        initial_size = 10 + 2 * int(np.sqrt(self.dim))\n        min_size = int(initial_size * (1 - self.adaptive_pop_size_rate))\n        max_size = int(initial_size * (1 + self.adaptive_pop_size_rate))\n        self.pop_size = int(min_size + (max_size - min_size) * (1 - (iteration / max_iterations)))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.adaptive_population_size(iteration, max_iterations)\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 22').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 22')", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {}}
{"id": "b3928c62-d64e-4126-9cdc-2af288999411", "fitness": 0.19404715002382053, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with self-adaptive parameters and Lvy flights for improved global exploration and local exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + L) * np.sin(np.pi * L / 2) / (np.math.gamma((1 + L) / 2) * L * 2 ** ((L - 1) / 2))) ** (1 / L)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v) ** (1 / L)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            L = 1.5  # Lvy exponent\n            levy_step = self.levy_flight(L)\n            self.positions[i] += levy_step * (self.global_best_position - self.positions[i])\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19405 with standard deviation 0.01468.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.21159179570083086, 0.19488523597807184, 0.17566441839255886]}}
{"id": "098af93f-e04b-4dcf-8a0e-3fa9a8895fc5", "fitness": 0.19150006245905274, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with a modified inertia decay rate for improved adaptability and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.985  # Adjusted decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19150 with standard deviation 0.00300.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19557961632162202, 0.18846092794630087, 0.19045964310923535]}}
{"id": "76f01f0d-a9ce-410d-8f70-5588b777cc75", "fitness": 0.19638122477098718, "name": "EnhancedHybridAMESV2", "description": "EnhancedHybridAMES V2 with dynamic chaotic maps and adaptive elite selection for improved convergence stability and performance in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridAMESV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.98  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7 + 0.3 * (iteration / max_iterations)  # Dynamic beta for enhanced chaotic exploration\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridAMESV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19638 with standard deviation 0.01652.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19276044614232912, 0.17820137542326886, 0.21818185274736357]}}
{"id": "b81f9195-26c6-4427-bdf8-b291dc608e84", "fitness": 0.12569370087326756, "name": "EnhancedHybridAMES", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution using Lvy Flights to enhance global exploration and local exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def levy_flights(self, size, alpha=1.5):\n        # Generate Lvy flight step sizes\n        u = np.random.normal(0, 1, size) * (np.power(np.random.normal(0, 1), -1 / alpha))\n        return u\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            levy_step = self.levy_flights(self.dim)\n            self.velocities[i] += levy_step\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12569 with standard deviation 0.01457.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.11828779785686783, 0.14605220092677917, 0.11274110383615565]}}
{"id": "3a387f99-38d8-46bf-b109-97732b25e99b", "fitness": 0.193002438491657, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive chaotic maps and exponential inertia decay for robust convergence and search diversification.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.8  # Increased cognitive coefficient\n        self.social_coeff = 1.9  # Increased social coefficient\n        self.adaptive_momentum = 0.6  # Increased adaptive momentum\n        self.elite_rate = 0.2  # Adjusted elite rate\n        self.exploration_rate = 0.35  # Adjusted exploration rate\n        self.de_scale = 0.9  # Increased scaling factor\n        self.de_cross_prob = 0.95  # Increased crossover probability\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        chaotic_value = (beta * x * (1 - x)) ** iteration  # Exponential chaotic map\n        return chaotic_value\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19300 with standard deviation 0.00593.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19386920120347895, 0.18534649552775162, 0.1997916187437404]}}
{"id": "32c4dba5-ed98-47d7-ba9d-adbd0a5a5ed4", "fitness": 0.19768159384953896, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with dynamic exploration rate for improved adaptability and convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            self.exploration_rate = 0.3 * (1 - iteration / max_iterations)  # Dynamic exploration rate\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19768 with standard deviation 0.00953.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19654969539071332, 0.18661325215065272, 0.2098818340072508]}}
{"id": "9c6956fe-2bb3-4c7f-9ec9-ad5483b11664", "fitness": 0.1848969063263589, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with dynamic chaotic maps and self-adaptive parameter tuning for superior convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.chaotic_factor_initial = 0.7\n        self.chaotic_factor_final = 0.9\n        self.mutation_rate = 0.1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def dynamic_chaotic_map(self, iteration, max_iterations):\n        beta = self.chaotic_factor_initial + (self.chaotic_factor_final - self.chaotic_factor_initial) * (iteration / max_iterations)\n        x = 0.6  # Initial value for logistic map\n        x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.dynamic_chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.mutation_rate * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18490 with standard deviation 0.01082.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19132434349571803, 0.1696628775053739, 0.1937034979779848]}}
{"id": "60978312-6195-4fdc-9522-f6d6381780b3", "fitness": 0.19310119056052596, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with multi-phase chaotic adaptation and dynamic swarm diversity control for superior convergence and solution robustness.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.chaotic_phase = 1\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        phi = 4 * np.sin(2 * np.pi * iteration / max_iterations)  # Multi-phase adaptation\n        x = phi * (iteration / max_iterations) * (1 - (iteration / max_iterations))\n        return x\n\n    def calculate_diversity(self):\n        mean_position = np.mean(self.positions, axis=0)\n        diversity = np.mean(np.linalg.norm(self.positions - mean_position, axis=1))\n        return diversity\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        diversity = self.calculate_diversity()\n        adaptive_momentum = 0.5 * (1 + np.tanh(diversity - 1))  # Dynamic momentum adjustment\n\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19310 with standard deviation 0.00176.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19315061691348034, 0.1909258717465333, 0.19522708302156422]}}
{"id": "9408a65c-4bfd-479b-b2bf-d061ffee8c5c", "fitness": 0.19460726588025332, "name": "EnhancedHybridAMES", "description": "Introduce a small random perturbation to the velocity update to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i] + np.random.normal(0, 0.1, self.dim)  # Added small perturbation\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19461 with standard deviation 0.00997.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18323138320480015, 0.2075048236801793, 0.19308559075578047]}}
{"id": "d3d3dbbb-0aa0-4dcc-9678-eef6c3fdb9fe", "fitness": 0.17573235203156934, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with adaptive nonlinear inertia and Lvy flight for better exploration-exploitation balance and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim) * (0.01 / np.abs(np.random.normal(0, 1)))**(1/L)\n        return u\n    \n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            levy = self.levy_flight(1.5)\n            self.positions[i] += levy\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight = self.inertia_min + (self.inertia_weight - self.inertia_min) * (1 - iteration / max_iterations)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17573 with standard deviation 0.00929.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1746201280556534, 0.164951166302021, 0.1876257617370336]}}
{"id": "fd59a082-a948-4de6-bba5-133a5ffdbfc8", "fitness": 0.14028891630105125, "name": "AdvancedHybridAMES", "description": "AdvancedHybridAMES with adaptive swarm intelligence and dynamic parameter control for enhanced optimization performance.", "code": "import numpy as np\n\nclass AdvancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_momentum = 0.6\n        self.elite_rate = 0.1\n        self.exploration_rate = 0.4\n        self.de_scale = 0.85\n        self.de_cross_prob = 0.95\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 3.8\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            # Dynamic adaptive component\n            adaptive_component = self.inertia_weight * np.std(self.velocities, axis=0)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * adaptive_component\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm AdvancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14029 with standard deviation 0.00771.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1471379532364291, 0.14421444974544673, 0.12951434592127797]}}
{"id": "fd7dd91d-9410-4c94-8cd3-7349c002245e", "fitness": 0.18026012016444506, "name": "EnhancedHybridAMES2", "description": "EnhancedHybridAMES2 integrates a dynamic adaptive strategy using a Lvy flight mechanism for improved global exploration and convergence accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridAMES2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def levy_flight(self, L=1.5):\n        sigma = (np.math.gamma(1 + L) * np.sin(np.pi * L / 2) /\n                 (np.math.gamma((1 + L) / 2) * L * 2 ** ((L - 1) / 2))) ** (1 / L)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / L)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * self.levy_flight()\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedHybridAMES2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18026 with standard deviation 0.00259.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.17960600774285806, 0.18370453902235562, 0.17746981372812154]}}
{"id": "2cde2b63-d70e-4ea2-8aee-ab046c121fc6", "fitness": 0.18921839967238688, "name": "EnhancedParticleSwarmEvolutionaryStrategy", "description": "Enhanced Particle-Swarm Evolutionary Strategy (EPSES) with adaptive swarm intelligence and perturbation strategy for improved diversity and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmEvolutionaryStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.perturbation_strength = 0.1\n        self.elite_rate = 0.2\n        self.de_scale = 0.85\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.8\n        x = 0.7\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + chaotic_factor * self.velocities[i] \\\n                                 + self.perturbation_strength * elite_component\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedParticleSwarmEvolutionaryStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18922 with standard deviation 0.00310.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19043448208395197, 0.1849661658924614, 0.1922545510407473]}}
{"id": "e418e18e-9aaf-4ab6-9e5c-8ef769c8b1eb", "fitness": 0.1928207924441517, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with dynamic chaotic maps and adaptive DE parameters for superior convergence and exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7 + 0.2 * (iteration / max_iterations)  # Dynamic control\n        x = np.random.rand()  # Vary initial value for more diversity\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func, iteration, max_iterations):\n        trial_positions = np.copy(self.positions)\n        dynamic_scale = self.de_scale * (1 - iteration / max_iterations)  # Adaptive DE scale\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + dynamic_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func, iteration, max_iterations)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19282 with standard deviation 0.00406.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18810008235733833, 0.19802219969470358, 0.19234009528041318]}}
{"id": "7d276e3e-0cbe-41bb-8daa-f8635cc3e065", "fitness": 0.18026012016444506, "name": "AdvancedHybridAMES", "description": "AdvancedHybridAMES with nonlinear inertia adaptation and Levy flight for enhanced exploration and convergence robustness.", "code": "import numpy as np\n\nclass AdvancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def levy_flight(self):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            levy_step = self.levy_flight()\n            self.velocities[i] += self.exploration_rate * levy_step\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm AdvancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18026 with standard deviation 0.00259.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.17960600774285806, 0.18370453902235562, 0.17746981372812154]}}
{"id": "5be0eb46-dcbc-4ff8-ba2e-b8d20827c67b", "fitness": 0.18144377812698434, "name": "EnhancedHybridAMES", "description": "Improved velocity update by dynamically adjusting the cognitive and social coefficients based on iteration progress.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n        \n        # Dynamic adjustment of cognitive and social coefficients\n        progress = iteration / max_iterations\n        dynamic_cognitive_coeff = self.cognitive_coeff * (1 - progress)\n        dynamic_social_coeff = self.social_coeff * progress\n\n        for i in range(self.pop_size):\n            cognitive_component = dynamic_cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = dynamic_social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18144 with standard deviation 0.00505.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18800636827570893, 0.1757094216578875, 0.1806155444473566]}}
{"id": "61ec32e0-aecc-44e4-a334-08254f9f2256", "fitness": 0.18503138763877444, "name": "OptimizedHybridAMES", "description": "Optimized HybridAMES with dynamic population size, adaptive differential evolution scaling, and enhanced chaotic influence for superior convergence and stability.", "code": "import numpy as np\n\nclass OptimizedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, min(100, int(10 + 2 * np.sqrt(dim))))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.98  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.elite_rate = 0.2\n        self.exploration_rate = 0.3\n        self.de_base_scale = 0.8\n        self.de_scale_decay = 0.99\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.5 + 0.3 * np.sin(np.pi * iteration / max_iterations)  # Dynamic control parameter\n        x = 0.7  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + chaotic_factor * elite_component\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        de_scale = self.de_base_scale * np.exp(-self.de_scale_decay * self.pop_size)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm OptimizedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18503 with standard deviation 0.00475.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18192150433151988, 0.19173814227468644, 0.18143451631011698]}}
{"id": "0265f434-8c1a-4d0e-9d92-cf06ba70da2a", "fitness": 0.18896457582512438, "name": "EnhancedAdaptiveAMES", "description": "EnhancedAdaptiveAMES with synergistic strategy combining adaptive chaotic maps, dynamic parameter adjustment, and elitist learning for robust convergence and solution refinement.", "code": "import numpy as np\n\nclass EnhancedAdaptiveAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.2\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.beta = 0.7  # Control parameter for logistic map\n        self.x0 = 0.6  # Initial value for logistic map\n        self.chaotic_map_values = [self.x0]\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration):\n        if iteration < len(self.chaotic_map_values):\n            return self.chaotic_map_values[iteration]\n        x_new = self.beta * self.chaotic_map_values[-1] * (1 - self.chaotic_map_values[-1])\n        self.chaotic_map_values.append(x_new)\n        return x_new\n    \n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAdaptiveAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18896 with standard deviation 0.00523.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19249627540915382, 0.18157010093060455, 0.19282735113561478]}}
{"id": "cc30fb00-b489-49f2-9236-544221fe6738", "fitness": 0.19249017460057513, "name": "EnhancedHybridAMES", "description": "\"Adaptive Multi-Phase Strategy with Chaotic Perturbations for Enhanced Convergence and Stability in High-Dimensional Spaces.\"", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_momentum = 0.6\n        self.elite_rate = 0.2\n        self.exploration_rate = 0.4\n        self.de_scale = 0.85\n        self.de_cross_prob = 0.9\n        self.chaotic_perturbation = 0.4\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.chaotic_perturbation * np.random.randn(self.dim)\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19249 with standard deviation 0.00559.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19227747604155232, 0.18575161061115852, 0.19944143714901452]}}
{"id": "827b41c9-b055-4798-9b5a-7616900e4953", "fitness": 0.18432793359757726, "name": "HybridAMESPlus", "description": "HybridAMES+ with dynamic chaotic maps and self-adaptive DE parameters for enhanced convergence rates and solution accuracy.", "code": "import numpy as np\n\nclass HybridAMESPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_momentum = 0.6\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        alpha = 0.5 + 0.4 * (iteration / max_iterations)\n        x = 0.5\n        for _ in range(iteration):\n            x = alpha * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            F = self.de_scale + 0.2 * (np.random.rand() - 0.5)  # Adaptive DE scale\n            mutant_vector = self.positions[a] + F * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm HybridAMESPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18433 with standard deviation 0.01007.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18272189669030325, 0.17288165528634947, 0.19738024881607907]}}
{"id": "b4dad2b3-8c1e-44d7-9bff-daff962176d6", "fitness": 0.17334813904692292, "name": "ImprovedAdaptiveHybridAMES", "description": "Improved Adaptive HybridAMES using dynamic inertia weighting and superior diversity control for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass ImprovedAdaptiveHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.95\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.elite_rate = 0.1\n        self.diversity_rate = 0.5\n        self.de_scale = 0.9\n        self.de_cross_prob = 0.8\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.8\n        x = 0.7\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + chaotic_factor * elite_component\n\n            diversity_boost = self.diversity_rate * np.random.uniform(-1, 1, self.dim)\n            self.velocities[i] += diversity_boost\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n            self.inertia_weight *= self.inertia_decay\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm ImprovedAdaptiveHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17335 with standard deviation 0.00310.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.17769201044162364, 0.17065807559006163, 0.1716943311090835]}}
{"id": "96b9a662-9fd7-4c6c-b8c5-d64440d5d901", "fitness": 0.18725008928979225, "name": "EnhancedHybridAMES", "description": "EnhancedHybridAMES with modified elite_rate for improved convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.2  # Modified elite_rate for improved convergence\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18725 with standard deviation 0.00143.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18536683619580685, 0.18754790424756695, 0.18883552742600296]}}
{"id": "570a96e2-703d-48a3-a10e-202d5c548aaa", "fitness": 0.17922257289226143, "name": "EnhancedHybridAMES", "description": "Improved velocity update with adaptive inertia influenced by personal best scores to enhance convergence behavior.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * (1 - self.personal_best_scores[i] / self.global_best_score) * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17922 with standard deviation 0.00671.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.18160675942733817, 0.17007637788552887, 0.18598458136391727]}}
{"id": "7c90d445-d804-4d54-a495-6e4194c55d14", "fitness": 0.17764056372034595, "name": "EnhancedHybridAMES", "description": "Enhanced HybridAMES with self-adaptive parameter tuning and Lvy flight-based exploration for improved convergence rate and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim) * L\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.power(np.abs(v), 1.0 / 1.5)\n        return step\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i] \\\n                                 + self.levy_flight(1.0)\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= 0.99  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17764 with standard deviation 0.00167.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.17936512755098988, 0.17816978172416287, 0.17538678188588508]}}
{"id": "dbd37d41-3399-48a8-ae4b-b6af87369e1d", "fitness": 0.184106401791016, "name": "EnhancedHybridAMES", "description": "Refined inertia weight update with a sigmoid function to balance exploration and exploitation more adaptively.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight = 0.9 / (1 + np.exp(-0.1 * (iteration - max_iterations / 2)))  # Sigmoid function for inertia weight update\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18411 with standard deviation 0.00832.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.1958048606553907, 0.17929950241617587, 0.17721484230148143]}}
{"id": "e7b1a060-e4e0-49ec-ba1d-cdb3ef92f2d1", "fitness": 0.19150006245905274, "name": "EnhancedHybridAMES", "description": "Improved inertia decay factor to enhance dynamic adaptation and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.985  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19150 with standard deviation 0.00300.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.19557961632162202, 0.18846092794630087, 0.19045964310923535]}}
{"id": "00f6ede0-f495-46c6-afae-7af5a753a810", "fitness": 0.20222706045262573, "name": "EnhancedHybridAMES", "description": "Enhanced elite selection by dynamically adjusting the elite_rate based on iteration progress.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20223 with standard deviation 0.01490.", "error": "", "parent_ids": ["28fc35b2-986b-45a5-8817-5c6e9d94eeab"], "operator": null, "metadata": {"aucs": [0.21133903326618075, 0.1812123792259186, 0.21412976886577784]}}
{"id": "b595a92b-a44a-4da8-9f1b-f5a8b07e916a", "fitness": 0.1863242776876183, "name": "EnhancedHybridAMES", "description": "Enhanced elite selection by dynamically adjusting the cognitive coefficient based on iteration progress.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        self.cognitive_coeff = 1.7 * (1 - iteration / max_iterations)  # Dynamic cognitive coefficient\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18632 with standard deviation 0.00190.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.18470709984189282, 0.18527590407882222, 0.1889898291421399]}}
{"id": "321c0f9e-32fe-4122-bf6f-5e132afcf1bb", "fitness": -Infinity, "name": "RefinedHybridAMES", "description": "Integrate a dynamic adaptive memory of successful solutions to guide search trajectories and balance exploration and exploitation in EnhancedHybridAMES.", "code": "import numpy as np\n\nclass RefinedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n        self.memory = []\n        self.memory_capacity = 5\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n                \n            if len(self.memory) < self.memory_capacity:\n                self.memory.append((self.positions[i], score))\n            else:\n                worst_mem_score = max(self.memory, key=lambda x: x[1])[1]\n                if score < worst_mem_score:\n                    self.memory.remove(max(self.memory, key=lambda x: x[1]))\n                    self.memory.append((self.positions[i], score))\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            memory_guidance = np.mean([pos for pos, _ in self.memory], axis=0) - self.positions[i]\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i] \\\n                                 + 0.1 * memory_guidance\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {}}
{"id": "2e23bb65-134c-41fb-b7a1-e4b4f7a52428", "fitness": 0.18824973017990007, "name": "EnhancedHybridAMES", "description": "Improved diversity through adaptive elite rate and multi-stage chaotic perturbation in EnhancedHybridAMES.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7 + 0.3 * (iteration / max_iterations)  # Adaptive control parameter\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.1 + 0.05 * np.sin(np.pi * iteration / max_iterations)  # Sine modulation\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18825 with standard deviation 0.00942.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.1884996637358265, 0.17659088757452746, 0.19965863922934624]}}
{"id": "87ad5440-3953-4f2b-ac49-e56994052544", "fitness": 0.18490772623545162, "name": "EnhancedHybridAMES", "description": "Introduced adaptive cognitive and social coefficients that depend on iteration progress to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        self.cognitive_coeff = 1.5 + 0.2 * (iteration / max_iterations)  # Adaptive cognitive coefficient\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18491 with standard deviation 0.00654.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.19190888483901958, 0.17616456109042278, 0.18664973277691255]}}
{"id": "011c200f-4af2-42d5-8382-2384441bc1cc", "fitness": 0.18710892397561515, "name": "RefinedHybridAMES", "description": "Hybridizes adaptive chaotic mechanisms with particle swarm optimization and differential evolution, utilizing a dynamic elite strategy and adaptive parameters to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.2\n        self.exploration_rate = 0.4\n        self.de_scale = 0.9\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return 4 * x * (1 - x)  # Logistic map for chaotic factor\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.2 * (1 - iteration / max_iterations)\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm RefinedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18711 with standard deviation 0.00516.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.18957272699273076, 0.19183052668575673, 0.17992351824835795]}}
{"id": "2eea8f28-9159-4378-984c-4f5d9f778ec6", "fitness": 0.19860193870980422, "name": "EnhancedHybridAMES", "description": "Enhance convergence by increasing the cross probability in Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.95  # Increased cross probability\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19860 with standard deviation 0.00605.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.19738216451428026, 0.2065468800825857, 0.19187677153254667]}}
{"id": "12912946-6413-4f34-8b3a-2c2e25d05e7b", "fitness": 0.18862667800564817, "name": "AdaptiveEnhancedHybridAMES", "description": "Adaptive Particle Swarm with Enhanced Differential Evolution and Chaotic Exploration for dynamic optimization of complex landscapes.", "code": "import numpy as np\n\nclass AdaptiveEnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_momentum = 0.6\n        self.elite_rate = 0.2\n        self.exploration_rate = 0.4\n        self.de_scale = 0.85\n        self.de_cross_prob = 0.95\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7\n        x = 0.6 + 0.4 * np.sin(np.pi * iteration / max_iterations) \n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.1 + 0.1 * np.sin(np.pi * iteration / max_iterations)\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm AdaptiveEnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18863 with standard deviation 0.00749.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.18173939651311488, 0.18510060323586208, 0.19904003426796757]}}
{"id": "3b2f321d-7576-4b5c-aa67-0f4b4e42ffae", "fitness": 0.18834296962355093, "name": "EnhancedHybridAMES", "description": "Introduce a scaling factor to the social component for improved convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            # Change made here: Introduce a scaling factor to the social component\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + 0.5 * social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18834 with standard deviation 0.00188.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.18591587713960844, 0.19049764460467966, 0.18861538712636472]}}
{"id": "d44dec81-11b6-47f2-907a-5da586ff3b85", "fitness": 0.19007749465706072, "name": "EnhancedHybridAMES", "description": "Refine inertia weight decay by introducing sinusoidal modulation for dynamic adaptability.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + self.de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= (self.inertia_decay + 0.05 * np.sin(2 * np.pi * iteration / max_iterations))  # Sinusoidal modulation\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19008 with standard deviation 0.01081.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.18618692951622218, 0.17922217073000712, 0.2048233837249529]}}
{"id": "7b5a6465-91e5-44f4-9b88-421f0cbe2d8c", "fitness": 0.1883648003002377, "name": "EnhancedHybridAMES", "description": "Incorporate adaptive mutation scaling and dynamic crossover probability in the differential evolution component, improving convergence speed and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.base_de_scale = 0.8\n        self.base_de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func, iteration, max_iterations):\n        trial_positions = np.copy(self.positions)\n        adaptive_de_scale = self.base_de_scale * (1 - iteration / max_iterations)\n        adaptive_de_cross_prob = self.base_de_cross_prob * (iteration / max_iterations)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.positions[a] + adaptive_de_scale * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < adaptive_de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func, iteration, max_iterations)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18836 with standard deviation 0.01155.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.2046642735601265, 0.18107945067875353, 0.17935067666183302]}}
{"id": "743719b1-48a8-4fc2-aa26-bca3d378cfd9", "fitness": 0.19162959976309132, "name": "EnhancedHybridAMES", "description": "Introduce a random uniform scaling factor to the differential evolution step for amplified exploration.", "code": "import numpy as np\n\nclass EnhancedHybridAMES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 + 2 * int(np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.inertia_decay = 0.99  # Decay for adaptive inertia\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.adaptive_momentum = 0.5\n        self.elite_rate = 0.15\n        self.exploration_rate = 0.3\n        self.de_scale = 0.8\n        self.de_cross_prob = 0.9\n\n    def initialize(self, bounds):\n        self.positions = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n\n    def chaotic_map(self, iteration, max_iterations):\n        beta = 0.7  # Control parameter for logistic map\n        x = 0.6  # Initial value for logistic map\n        for _ in range(iteration):\n            x = beta * x * (1 - x)\n        return x\n\n    def update_particles(self, func, iteration, max_iterations):\n        self.elite_rate = 0.15 * (1 - iteration / max_iterations)  # Dynamic elite_rate\n        elite_threshold = int(self.pop_size * self.elite_rate)\n        for i in range(self.pop_size):\n            score = func(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i]\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:elite_threshold]\n\n        for i in range(self.pop_size):\n            cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.positions[i])\n            elite_component = np.mean([self.positions[idx] for idx in elite_indices], axis=0) - self.positions[i]\n            chaotic_factor = self.chaotic_map(iteration, max_iterations)\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] \\\n                                 + cognitive_component \\\n                                 + social_component \\\n                                 + self.adaptive_momentum * elite_component \\\n                                 + chaotic_factor * self.velocities[i]\n\n            momentum = self.exploration_rate * (np.random.rand(self.dim) - 0.5)\n            self.velocities[i] += momentum\n\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n    def differential_evolution(self, func):\n        trial_positions = np.copy(self.positions)\n        for i in range(self.pop_size):\n            indices = list(range(self.pop_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            scale_factor = self.de_scale * np.random.uniform(0.8, 1.2)  # Introduced random scaling\n            mutant_vector = self.positions[a] + scale_factor * (self.positions[b] - self.positions[c])\n            cross_points = np.random.rand(self.dim) < self.de_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_positions[i] = np.where(cross_points, mutant_vector, self.positions[i])\n            trial_positions[i] = np.clip(trial_positions[i], func.bounds.lb, func.bounds.ub)\n            trial_score = func(trial_positions[i])\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.positions[i] = trial_positions[i]\n            if trial_score < self.global_best_score:\n                self.global_best_score = trial_score\n                self.global_best_position = trial_positions[i]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n        max_iterations = self.budget // self.pop_size\n        while evaluations < self.budget:\n            iteration = evaluations // self.pop_size\n            self.update_particles(func, iteration, max_iterations)\n            self.differential_evolution(func)\n            self.inertia_weight *= self.inertia_decay  # Decay inertia weight\n            evaluations += self.pop_size\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedHybridAMES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19163 with standard deviation 0.00192.", "error": "", "parent_ids": ["00f6ede0-f495-46c6-afae-7af5a753a810"], "operator": null, "metadata": {"aucs": [0.19432993537949395, 0.1900549717843406, 0.1905038921254394]}}
