{"id": "c1d86b2f-2ec6-4679-a42f-49cd15791327", "fitness": 0.19518063953917186, "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining differential evolution and swarm intelligence using adaptive parameter control for robust optimization across diverse problem landscapes.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 0, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19518 with standard deviation 0.00817.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1884702334298417, 0.2066792518763344, 0.19039243331133948]}}
{"id": "7a157f9e-30e8-4d92-b279-a135e634962c", "fitness": 0.1886939484597835, "name": "HybridMetaheuristic", "description": "Hybrid metaheuristic enhancement through adaptive velocity scaling in swarm intelligence to improve convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= 0.95  # Adaptive velocity scaling\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 1, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18869 with standard deviation 0.01128.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.1727603838656614, 0.19726155291137637, 0.1960599086023127]}}
{"id": "d5641338-29c4-47ee-b3a6-496ccc018bb4", "fitness": 0.18787273401766155, "name": "RefinedHybridMetaheuristic", "description": "Refined HybridMetaheuristic integrating adaptive inertia weight and dynamic population size for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        initial_pop_size = 50  # Initial population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(initial_pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(initial_pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(initial_pop_size, np.inf)\n        \n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        pop_size = initial_pop_size\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Adaptive Particle Swarm step\n            inertia_weight = 0.5 + 0.1 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n            # Dynamic Population Size Adjustment\n            if eval_count < self.budget / 2:\n                pop_size = min(initial_pop_size, int(pop_size * 1.1))  # Gradually increase\n            else:\n                pop_size = max(10, int(pop_size * 0.9))  # Gradually decrease\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 2, "feedback": "The algorithm RefinedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18787 with standard deviation 0.00827.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.17668002091524093, 0.1905407055512497, 0.196397475586494]}}
{"id": "b4b2c624-433a-4a0b-a8a2-71e267e34b2e", "fitness": 0.17492580594026666, "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic with enhanced exploration by adjusting the mutation strategy in differential evolution for better optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]) + F * (positions[a] - positions[b]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 3, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17493 with standard deviation 0.00149.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.17295917994617194, 0.17527028742674278, 0.1765479504478853]}}
{"id": "700e6090-9574-4711-98fc-d96d37f8a968", "fitness": 0.19438819933298881, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic that integrates dynamic parameter adaptation and crossover strategies with differential evolution and swarm intelligence for improved convergence across diverse optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Adaptive control parameters\n            F = 0.5 + 0.3 * np.random.rand()  # Adapt F dynamically\n            CR = 0.8 + 0.1 * np.sin(eval_count)  # Sinusoidal variation of CR\n\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive inertia\n            inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19439 with standard deviation 0.01380.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.1750859189201759, 0.20657331594149286, 0.20150536313729772]}}
{"id": "68d11aa9-5479-4965-8a23-76e8bb619fd7", "fitness": 0.19475518681323775, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic integrating differential evolution, particle swarm optimization, and local search intensification using adaptive strategies for improved exploration and exploitation across complex search landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def local_search(position):\n            \"\"\"Conducts a simple local search around the current position.\"\"\"\n            nonlocal eval_count\n            candidate_position = np.clip(position + 0.1 * np.random.randn(self.dim), lb, ub)\n            candidate_score = func(candidate_position)\n            eval_count += 1\n            return candidate_position, candidate_score\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n                # Local search intensification\n                if np.random.rand() < 0.1:  # Small probability for local search\n                    new_position, new_score = local_search(trial)\n                    if new_score < personal_best_scores[i]:\n                        personal_best_scores[i] = new_score\n                        personal_best_positions[i] = new_position\n                    if new_score < global_best_score:\n                        global_best_score = new_score\n                        global_best_position = new_position\n\n            # Particle Swarm step\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19476 with standard deviation 0.00748.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.19317849616411076, 0.18648056330650487, 0.2046065009690976]}}
{"id": "d5379294-8136-45af-ac38-c47296be5138", "fitness": 0.19250634963141822, "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining differential evolution and swarm intelligence with a modified inertia weight calculation for enhanced optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step\n            inertia_weight = 0.7 + 0.3 * np.random.rand()  # Modified inertia weight calculation\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 6, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19251 with standard deviation 0.01027.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.17862528775684727, 0.2031553626513467, 0.19573839848606067]}}
{"id": "305f8904-a955-474d-a8f3-f0f2764fcfa3", "fitness": 0.18504975380197106, "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic using enhanced adaptive parameter control for better convergence and optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.9  # Differential weight\n        CR = 0.85  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 7, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18505 with standard deviation 0.00655.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.19413562039265775, 0.1789521853253928, 0.18206145568786258]}}
{"id": "6f98024c-494e-47be-9f9d-20e0aa357db9", "fitness": 0.20044338805614617, "name": "QuantumHybridMetaheuristic", "description": "A novel algorithm leveraging quantum-inspired dynamic population variance and self-adaptive differential evolution with hybrid memory mechanisms for enhanced exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass QuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def quantum_variance(pos, global_best):\n            \"\"\" Introduces quantum-inspired variance to enhance exploration. \"\"\"\n            beta = np.random.rand(self.dim)\n            return pos + beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = 0.5 + np.random.rand() * 0.5  # Self-adaptive F\n                CR = 0.5 + np.random.rand() * 0.5  # Self-adaptive CR\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply quantum variance\n                if np.random.rand() < 0.1:  # Occasionally apply quantum variance\n                    positions[i] = quantum_variance(positions[i], global_best_position)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 8, "feedback": "The algorithm QuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20044 with standard deviation 0.00281.", "error": "", "parent_ids": ["c1d86b2f-2ec6-4679-a42f-49cd15791327"], "operator": null, "metadata": {"aucs": [0.1989860913016619, 0.20437189851563486, 0.19797217435114178]}}
{"id": "44350062-3106-4977-8df6-097f0f0857ef", "fitness": 0.19216672764107054, "name": "QuantumHybridMetaheuristic", "description": "This refined algorithm includes an optimized dynamic inertia weight adjustment for enhanced convergence in black-box optimization.", "code": "import numpy as np\n\nclass QuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def quantum_variance(pos, global_best):\n            \"\"\" Introduces quantum-inspired variance to enhance exploration. \"\"\"\n            beta = np.random.rand(self.dim)\n            return pos + beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = 0.5 + np.random.rand() * 0.5  # Self-adaptive F\n                CR = 0.5 + np.random.rand() * 0.5  # Self-adaptive CR\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with quantum variance\n            inertia_weight = 0.3 + 0.7 * np.random.rand()  # Adjusted dynamic inertia weight\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply quantum variance\n                if np.random.rand() < 0.1:  # Occasionally apply quantum variance\n                    positions[i] = quantum_variance(positions[i], global_best_position)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 9, "feedback": "The algorithm QuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19217 with standard deviation 0.01333.", "error": "", "parent_ids": ["6f98024c-494e-47be-9f9d-20e0aa357db9"], "operator": null, "metadata": {"aucs": [0.17356937012360463, 0.20417127602460938, 0.19875953677499758]}}
{"id": "f368f335-b48b-417e-bc2f-0ca78777a240", "fitness": 0.18412351817227648, "name": "EnhancedQuantumMetaheuristic", "description": "An enhanced algorithm utilizing adaptive population sizing and chaos-driven exploration to improve convergence and robustness in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Initial population size\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def quantum_variance(pos, global_best):\n            \"\"\" Introduces quantum-inspired variance to enhance exploration. \"\"\"\n            beta = np.random.rand(self.dim)\n            return pos + beta * (global_best - pos)\n\n        def logistic_map(x):\n            \"\"\" Chaos-driven exploration using logistic map for diversity. \"\"\"\n            r = 3.99\n            return r * x * (1 - x)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = 0.5 + np.random.rand() * 0.5  # Self-adaptive F\n                CR = 0.5 + np.random.rand() * 0.5  # Self-adaptive CR\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with quantum variance and chaos-driven exploration\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply quantum variance\n                if np.random.rand() < 0.1:  # Occasionally apply quantum variance\n                    positions[i] = quantum_variance(positions[i], global_best_position)\n\n                # Apply chaos-driven exploration\n                chaos_factor = logistic_map(np.random.rand())\n                if np.random.rand() < chaos_factor:\n                    positions[i] = np.random.rand(self.dim) * (ub - lb) + lb\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedQuantumMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18412 with standard deviation 0.01130.", "error": "", "parent_ids": ["6f98024c-494e-47be-9f9d-20e0aa357db9"], "operator": null, "metadata": {"aucs": [0.17441432017905, 0.1999688623423479, 0.17798737199543158]}}
{"id": "da150edc-3c45-46fe-82fa-645a5c95c166", "fitness": 0.16511111202381099, "name": "EnhancedQuantumMetaheuristic", "description": "Enhanced Quantum-Inspired Metaheuristic utilizing adaptive inertia with chaotic map perturbation for improved exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def quantum_variance(pos, global_best):\n            \"\"\" Introduce quantum-inspired variance to enhance exploration. \"\"\"\n            beta = np.random.rand(self.dim)\n            return pos + beta * (global_best - pos)\n\n        def logistic_map(x):\n            \"\"\" Chaotic map function for perturbation. \"\"\"\n            return 4 * x * (1 - x)\n\n        chaotic_factor = np.random.rand()  # Initialize chaotic factor\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = 0.5 + np.random.rand() * 0.5\n                CR = 0.5 + np.random.rand() * 0.5\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with quantum variance and chaotic perturbation\n            inertia_weight = 0.5 + 0.5 * np.random.rand()  # Adaptive inertia\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Apply chaotic perturbation\n                if np.random.rand() < 0.1:\n                    chaotic_factor = logistic_map(chaotic_factor)\n                    positions[i] += chaotic_factor * (global_best_position - positions[i])\n\n                # Apply quantum variance\n                if np.random.rand() < 0.1:\n                    positions[i] = quantum_variance(positions[i], global_best_position)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedQuantumMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16511 with standard deviation 0.01117.", "error": "", "parent_ids": ["6f98024c-494e-47be-9f9d-20e0aa357db9"], "operator": null, "metadata": {"aucs": [0.175118456734903, 0.17069028797070063, 0.1495245913658293]}}
{"id": "a6d4ae4c-a5c2-4697-a2c0-3e684e40a0f6", "fitness": 0.20044338805614617, "name": "QuantumHybridMetaheuristic", "description": "A slightly refined quantum-inspired algorithm with a minor adjustment to crossover probability for improved performance in black-box optimization.", "code": "import numpy as np\n\nclass QuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50  # Population size\n        F = 0.8  # Differential weight\n        CR = 0.92  # Crossover probability changed from 0.9 to 0.92\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1  # Small initial velocities\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def quantum_variance(pos, global_best):\n            \"\"\" Introduces quantum-inspired variance to enhance exploration. \"\"\"\n            beta = np.random.rand(self.dim)\n            return pos + beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = 0.5 + np.random.rand() * 0.5  # Self-adaptive F\n                CR = 0.5 + np.random.rand() * 0.5  # Self-adaptive CR\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply quantum variance\n                if np.random.rand() < 0.1:  # Occasionally apply quantum variance\n                    positions[i] = quantum_variance(positions[i], global_best_position)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 12, "feedback": "The algorithm QuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20044 with standard deviation 0.00281.", "error": "", "parent_ids": ["6f98024c-494e-47be-9f9d-20e0aa357db9"], "operator": null, "metadata": {"aucs": [0.1989860913016619, 0.20437189851563486, 0.19797217435114178]}}
{"id": "ccde634b-bb10-4ebb-a070-79d51244f117", "fitness": 0.19091723897854465, "name": "EnhancedQuantumMetaheuristic", "description": "An enhanced quantum-inspired algorithm integrating adaptive chaotic mutation and dynamic swarm intelligence to improve convergence speed and solution quality in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F = 0.8\n        CR = 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def quantum_variance(pos, global_best):\n            beta = np.random.rand(self.dim)\n            return pos + beta * (global_best - pos)\n\n        def chaotic_mutation(trial):\n            r = np.random.rand(self.dim)\n            return trial + 0.1 * np.sin(2 * np.pi * r)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = 0.5 + np.random.rand() * 0.5\n                CR = 0.5 + np.random.rand() * 0.5\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial = chaotic_mutation(trial)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2.1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2.1 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    positions[i] = quantum_variance(positions[i], global_best_position)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedQuantumMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19092 with standard deviation 0.00779.", "error": "", "parent_ids": ["6f98024c-494e-47be-9f9d-20e0aa357db9"], "operator": null, "metadata": {"aucs": [0.18059853735068165, 0.19275065311078654, 0.1994025264741658]}}
{"id": "e6259aa3-2112-41b9-95bb-93e41cf674e4", "fitness": 0.18881433524845692, "name": "EnhancedQuantumHybridMetaheuristic", "description": "A refined algorithm amplifying quantum-inspired mechanisms with adaptive grouping and multi-agent cooperative strategies to balance exploration and exploitation for improved black-box optimization performance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F = 0.8\n        CR = 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def quantum_variance(pos, global_best):\n            beta = np.random.rand(self.dim)\n            return pos + beta * (global_best - pos)\n\n        def adaptive_grouping():\n            group_size = np.random.randint(3, 6)\n            return np.array_split(np.random.permutation(pop_size), group_size)\n\n        def cooperative_update(group, global_best):\n            for i in group:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (0.5 * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                F = 0.5 + np.random.rand() * 0.5\n                CR = 0.5 + np.random.rand() * 0.5\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            grouped_indices = adaptive_grouping()\n            for group in grouped_indices:\n                cooperative_update(group, global_best_position)\n                if np.random.rand() < 0.1:\n                    for i in group:\n                        positions[i] = quantum_variance(positions[i], global_best_position)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18881 with standard deviation 0.01184.", "error": "", "parent_ids": ["6f98024c-494e-47be-9f9d-20e0aa357db9"], "operator": null, "metadata": {"aucs": [0.17234451724273425, 0.19441183759399372, 0.1996866509086428]}}
{"id": "758dbb4c-77ed-42dc-bbdf-245969fb8d5d", "fitness": 0.20155563190923476, "name": "EnhancedQuantumHybridMetaheuristic", "description": "A refined hybrid algorithm incorporating adaptive quantum-inspired variance, dynamic learning rates, and ensemble strategies to enhance convergence speed and accuracy in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20156 with standard deviation 0.00487.", "error": "", "parent_ids": ["6f98024c-494e-47be-9f9d-20e0aa357db9"], "operator": null, "metadata": {"aucs": [0.2084377997899145, 0.19834946806401377, 0.197879627873776]}}
{"id": "9d1ada80-1917-4bb2-9f8a-97cca675644b", "fitness": 0.16992721404816044, "name": "EnhancedQuantumHybridMetaheuristic", "description": "A hybrid algorithm enhancing convergence by fusing adaptive quantum-inspired variance with chaotic maps and self-organizing velocity patterns for robust black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def chaotic_map(x):\n            return 4 * x * (1 - x)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = chaotic_map(velocities[i])  # Apply chaotic map to velocity\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16993 with standard deviation 0.00170.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.16770685121063778, 0.17182316502704165, 0.17025162590680187]}}
{"id": "25525509-5057-4b0b-9dff-d929310ebf76", "fitness": 0.19650416533021706, "name": "EnhancedQuantumHybridMetaheuristic", "description": "A hybrid metaheuristic algorithm that combines adaptive quantum-inspired variance, dynamic learning rates, and enhanced ensemble strategies to improve convergence speed and accuracy in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.15:  # Increased probability from 0.1 to 0.15\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19650 with standard deviation 0.00624.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.18774422093323573, 0.19997687632386352, 0.2017913987335519]}}
{"id": "0cfcb5cd-0725-4a27-95aa-585226240ed8", "fitness": 0.19512237405040578, "name": "EnhancedQuantumHybridMetaheuristic", "description": "An advanced hybrid approach fusing adaptive quantum variance, dynamic adaptive learning, and neighborhood-based mutation strategies to boost convergence efficiency and solution diversity in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.randn(self.dim)  # Use normal distribution for diversity\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with neighborhood-based mutation\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Introduce neighborhood-based mutation\n                neighbor = personal_best_positions[np.random.choice(range(pop_size))]\n                mutant = np.clip(neighbor + F * (positions[b] - positions[c]), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance strategically\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19512 with standard deviation 0.00851.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.18311534680783415, 0.20045085362222892, 0.20180092172115427]}}
{"id": "13f4f9fc-0827-4812-af36-ef9ea2cde74e", "fitness": 0.18850050178517397, "name": "AdvancedHybridQuantumOptimizer", "description": "An advanced hybrid optimization algorithm integrating adaptive quantum-inspired variance, self-correcting momentum, and dynamic crossover strategies to accelerate convergence and precision in complex black-box optimization tasks.", "code": "import numpy as np\n\nclass AdvancedHybridQuantumOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with adaptive crossover\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with self-correcting momentum\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 19, "feedback": "The algorithm AdvancedHybridQuantumOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18850 with standard deviation 0.01068.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17384208293506231, 0.19267812827186892, 0.19898129414859067]}}
{"id": "ddce5b84-acb7-4da8-a7dd-9ec8f940087d", "fitness": 0.18367375510344508, "name": "EnhancedQuantumHybridMetaheuristic", "description": "An enhanced hybrid algorithm with improved quantum variance, focused on better exploration-exploitation balance and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.6, 1.2  # Adjusted range for F to enhance exploration\n        CR_min, CR_max = 0.4, 0.9  # Adjusted range for CR for diversity\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.3 * (iter / max_iter))  # Modified decay rate for variance\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.15:  # Increased probability for applying variance\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18367 with standard deviation 0.01066.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17135390384123694, 0.1973493617333436, 0.1823179997357547]}}
{"id": "1a94ea3e-8a77-4944-a418-abd14ab2a176", "fitness": 0.18969158092057117, "name": "AdvancedQuantumHybridMetaheuristic", "description": "An advanced hybrid algorithm that integrates adaptive quantum-inspired variance, dynamic learning rates, ensemble strategies, and opposition-based learning to enhance convergence speed and accuracy in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def opposition_based_learning(position, lb, ub):\n            return lb + ub - position\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n                # Apply opposition-based learning\n                if np.random.rand() < 0.1:\n                    opposition_position = opposition_based_learning(positions[i], lb, ub)\n                    opp_score = func(opposition_position)\n                    eval_count += 1\n                    if opp_score < personal_best_scores[i]:\n                        personal_best_scores[i] = opp_score\n                        personal_best_positions[i] = opposition_position.copy()\n                    if opp_score < global_best_score:\n                        global_best_score = opp_score\n                        global_best_position = opposition_position.copy()\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 21, "feedback": "The algorithm AdvancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18969 with standard deviation 0.01121.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17391756965580596, 0.19621063899557944, 0.19894653411032814]}}
{"id": "ecfb9633-edc3-40cf-a0df-3de481496d60", "fitness": 0.1943671223492852, "name": "AdvancedQuantumLevyMetaheuristic", "description": "An advanced hybrid metaheuristic incorporating adaptive quantum variance, variable inertia, Levy flight for global exploration, and a fitness diversity strategy to enhance exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedQuantumLevyMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def levy_flight(Lambda):\n            u = np.random.randn(self.dim) * (0.01 / (np.random.randn() ** (1 / Lambda)))\n            v = np.random.randn(self.dim)\n            step = u / abs(v) ** (1 / Lambda)\n            return step\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance and Levy flight\n            inertia_weight = 0.4 + 0.3 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                if np.random.rand() < 0.1:\n                    positions[i] = positions[i] + levy_flight(1.5)\n                else:\n                    positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 22, "feedback": "The algorithm AdvancedQuantumLevyMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19437 with standard deviation 0.01081.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17909015781879511, 0.20167494586353274, 0.20233626336552768]}}
{"id": "a9a91576-5efd-4c5b-8333-2b1134f7ae9e", "fitness": 0.188377245144018, "name": "AdvancedQuantumHybridMetaheuristic", "description": "An enhanced metaheuristic algorithm combining adaptive quantum-inspired variance, self-adaptive control parameters, and dynamic neighborhood strategies to improve exploration and exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def dynamic_neighborhood(position, neighbors):\n            scale_factor = np.exp(-np.linalg.norm(position - neighbors) / self.dim)\n            return neighbors * scale_factor + position * (1 - scale_factor)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial = dynamic_neighborhood(trial, positions[a])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 23, "feedback": "The algorithm AdvancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18838 with standard deviation 0.01384.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17020001804955553, 0.20376280256105994, 0.1911689148214385]}}
{"id": "8399abee-f0a7-4870-84b9-e5ecccfc6e2f", "fitness": 0.19376962253417696, "name": "AdvancedQuantumSynergisticOptimizer", "description": "A novel hybrid algorithm integrating self-regulating adaptive quantum variances and synergistic evolution strategies to optimize convergence rates and robustness in high-dimensional black-box optimization.", "code": "import numpy as np\n\nclass AdvancedQuantumSynergisticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.3 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.4 + 0.6 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2.5 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2.5 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 24, "feedback": "The algorithm AdvancedQuantumSynergisticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19377 with standard deviation 0.01150.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.1786679284340108, 0.20654578208582752, 0.19609515708269254]}}
{"id": "a5c39328-0431-4e6f-adf9-7b7bce51871c", "fitness": 0.1966911743729122, "name": "EnhancedQuantumHybridMetaheuristic", "description": "A refined hybrid algorithm with a minor adjustment to velocity update to enhance convergence speed and accuracy in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (0.9 * inertia_weight * velocities[i] +  # Slight change in inertia weight factor\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19669 with standard deviation 0.00851.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.185559665700737, 0.20621719788389747, 0.19829665953410214]}}
{"id": "325000a5-21cf-4294-b1b9-dc878851bd17", "fitness": 0.19650416533021706, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Optimized synergy between adaptive quantum variance and differential evolution enhances search diversity and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.15:  # Changed the probability from 0.1 to 0.15\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19650 with standard deviation 0.00624.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.18774422093323573, 0.19997687632386352, 0.2017913987335519]}}
{"id": "b49e7d6c-6d13-46ad-974a-db007419605d", "fitness": 0.19982072762718692, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Improved hybrid algorithm using adaptive quantum-inspired variance and enhanced control parameters for faster convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 0.9  # Reduced F_max to 0.9\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19982 with standard deviation 0.00381.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.1965537336338563, 0.20516271148716125, 0.19774573776054316]}}
{"id": "a0476c45-da45-4249-bbef-a492486fc8b9", "fitness": -Infinity, "name": "RefinedQuantumHybridMetaheuristic", "description": "A novel metaheuristic combining adaptive quantum-inspired variance, dynamic learning rates, and a multi-ensemble approach for enhanced diversification and intensification in black-box optimization.", "code": "import numpy as np\n\nclass RefinedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 60\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.4, 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n        ensemble_strategies = [self._differential_evolution, self._particle_swarm]\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * ((iter / max_iter) ** 2))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Choose an ensemble strategy based on a heuristic\n            ensemble_choice = np.random.choice(ensemble_strategies)\n            ensemble_choice(positions, velocities, personal_best_positions, personal_best_scores, global_best_position, lb, ub, eval_count, func)\n\n            # Apply adaptive quantum variance\n            if np.random.rand() < 0.15:\n                for i in range(pop_size):\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}\n\n    def _differential_evolution(self, positions, velocities, personal_best_positions, personal_best_scores, global_best_position, lb, ub, eval_count, func):\n        pop_size = len(positions)\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.4, 0.9\n        for i in range(pop_size):\n            if eval_count >= self.budget:\n                break\n            F = F_min + np.random.rand() * (F_max - F_min)\n            CR = CR_min + np.random.rand() * (CR_max - CR_min)\n            idxs = [idx for idx in range(pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, positions[i])\n            trial_score = func(trial)\n            eval_count += 1\n            if trial_score < personal_best_scores[i]:\n                personal_best_scores[i] = trial_score\n                personal_best_positions[i] = trial.copy()\n            if trial_score < global_best_score:\n                global_best_score = trial_score\n                global_best_position = trial.copy()\n\n    def _particle_swarm(self, positions, velocities, personal_best_positions, personal_best_scores, global_best_position, lb, ub, eval_count, func):\n        pop_size = len(positions)\n        inertia_weight = 0.5 + 0.5 * np.random.rand()\n        for i in range(pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities[i] = (inertia_weight * velocities[i] +\n                             2 * r1 * (personal_best_positions[i] - positions[i]) +\n                             2 * r2 * (global_best_position - positions[i]))\n            positions[i] = np.clip(positions[i] + velocities[i], lb, ub)", "configspace": "", "generation": 28, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'global_best_score' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'global_best_score' referenced before assignment\")", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {}}
{"id": "9391b0e3-1461-4264-bc21-c8a60e29948f", "fitness": 0.17887514437937746, "name": "EnhancedQuantumHybridMetaheuristic", "description": "An enhanced hybrid algorithm integrating adaptive quantum variance with self-adjusting parameters, nonlinear inertia weight, and adaptive learning rates for improved convergence and solution quality in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance and nonlinear inertia weight\n            inertia_weight = 0.9 - (0.9 - 0.4) * (eval_count / self.budget)**2  # Nonlinear inertia weight\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17888 with standard deviation 0.01162.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17304899587198164, 0.16848317942955726, 0.19509325783659348]}}
{"id": "3627e01c-ddb7-4650-8e89-0fa95d743f04", "fitness": 0.18923760748184493, "name": "EnhancedQuantumHybridAlgorithm_v2", "description": "EnhancedQuantumHybridAlgorithm_v2: Integrated multi-phase optimization with variance scaling and elite selection to optimize efficiency and convergence in black-box optimization tasks.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridAlgorithm_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.7 + 0.3 * np.random.rand()  # Adjusted inertia weight for enhanced exploration\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.2:  # Increased probability of quantum variance application\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n            # Elite selection strategy\n            elite_indices = np.argsort(personal_best_scores)[:10]  # Select top 10 elites\n            elite_positions = positions[elite_indices]\n            elite_scores = personal_best_scores[elite_indices]\n\n            # Update population with elite positions\n            for i in range(len(elite_indices)):\n                if eval_count >= self.budget:\n                    break\n                positions[i] = elite_positions[i]\n                personal_best_positions[i] = elite_positions[i]\n                personal_best_scores[i] = elite_scores[i]\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedQuantumHybridAlgorithm_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18924 with standard deviation 0.01193.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.1723686704741353, 0.19744623093987346, 0.19789792103152604]}}
{"id": "f3fe7790-9142-4762-af83-99bc3311f5ac", "fitness": 0.1805792849818584, "name": "OptimizedQuantumHybridMetaheuristic", "description": "An optimized hybrid metaheuristic leveraging adaptive quantum variance, dynamic learning enhancement with chaotic maps for improved exploration, and accelerated convergence in black-box optimization.", "code": "import numpy as np\n\nclass OptimizedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def logistic_map(t, x0=0.7):\n            r = 3.9\n            return r * x0 * (1 - x0)\n\n        chaotic_factor = logistic_map(0)  # Initial chaotic factor\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance and chaotic influence\n            inertia_weight = 0.5 + chaotic_factor * 0.5\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n            # Update chaotic factor for next iteration\n            chaotic_factor = logistic_map(eval_count / self.budget, chaotic_factor)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 31, "feedback": "The algorithm OptimizedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18058 with standard deviation 0.01201.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17550705758216933, 0.16907401031034097, 0.19715678705306494]}}
{"id": "9cc3e2e3-b79f-45e3-968e-11353d6920f7", "fitness": 0.19287585815607514, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhanced convergence through self-adaptive elite mutation and adjusted exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Use global best for elite mutation\n                mutant = np.clip(global_best_position + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.6 + 0.4 * np.random.rand()  # Adjusted exploration-exploitation balance\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19288 with standard deviation 0.00706.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.1859479535997366, 0.20256801681685022, 0.19011160405163863]}}
{"id": "bc97ba05-1f8f-4baa-a87f-86236300276b", "fitness": 0.19263394304374382, "name": "CrossEnsembleQuantumMetaheuristic", "description": "Introducing a cross-ensemble strategy combining Quantum Variance Adaptation with Differential Evolution and Particle Swarm Optimization to further enhance exploration-exploitation balance and convergence efficiency.", "code": "import numpy as np\n\nclass CrossEnsembleQuantumMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.2:  # Increased probability to apply quantum variance\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n            # Cross-ensemble strategy\n            if eval_count % (self.budget // 10) == 0:  # Periodically inject diversity\n                random_idx = np.random.randint(0, pop_size)\n                positions[random_idx] = np.random.rand(self.dim) * (ub - lb) + lb\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 33, "feedback": "The algorithm CrossEnsembleQuantumMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19263 with standard deviation 0.01540.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.1710769941450736, 0.20071949874823092, 0.20610533623792693]}}
{"id": "241345e8-34a2-49e0-bf50-bbee5712edac", "fitness": 0.19049066929334035, "name": "EnhancedQuantumHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm with refined exploration through chaotic map-based parameter adaptation to improve convergence consistency and precision.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def chaotic_map_parameter(t, min_val, max_val):\n            return min_val + (max_val - min_val) * np.abs(np.sin(t))\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                t = eval_count / self.budget\n                F = chaotic_map_parameter(t, F_min, F_max)  # Changed line\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = chaotic_map_parameter(t, 0.4, 0.9)  # Changed line\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19049 with standard deviation 0.01186.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17440545892936143, 0.1944320725967683, 0.2026344763538913]}}
{"id": "18126411-df76-4583-8ccd-350a3bb08477", "fitness": 0.196474825212693, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduced a dynamic population size adjustment, which adapts based on evaluation progress to improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n            \n            pop_size = max(10, int((1 - eval_count / self.budget) * 50))  # Adjust population size\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19647 with standard deviation 0.01646.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.1734596601729489, 0.21099173891839595, 0.20497307654673413]}}
{"id": "acaf49e7-9993-4f73-bb8f-7e8ea9d893bc", "fitness": 0.20155563190923476, "name": "EnhancedQuantumHybridMetaheuristic", "description": "A refined hybrid algorithm incorporating adaptive quantum-inspired variance, dynamic learning rates, and ensemble strategies with further enhanced exploration mechanisms to improve convergence speed and accuracy in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20156 with standard deviation 0.00487.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.2084377997899145, 0.19834946806401377, 0.197879627873776]}}
{"id": "e7477370-a8b4-42a4-ae07-cafbdab6acb7", "fitness": 0.2004874216999538, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved adaptive quantum variance for better convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            # Slight change: increase variance_factor to potentially enhance exploration\n            variance_factor = np.exp(-0.5 * (iter / max_iter)) * 1.1  \n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20049 with standard deviation 0.00619.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.19596692925242853, 0.20924529696843885, 0.19625003887899395]}}
{"id": "5fa03d85-4a15-40bc-af26-6f3388d3d6c2", "fitness": 0.19419150824296008, "name": "EnhancedQuantumHybridMetaheuristicV2", "description": "An improved hybrid metaheuristic that utilizes a dynamic mixing of quantum-inspired adaptive variance and particle swarm optimization, alongside a novel mutation strategy to enhance global exploration and local exploitation in black-box optimization tasks.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = 0.5 * (1 - iter / max_iter) + 0.1\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.4 + 0.3 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 1.5 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 1.5 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.2:  # Increased likelihood for increased exploration\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19419 with standard deviation 0.01546.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17329382023040252, 0.21021372115339765, 0.1990669833450801]}}
{"id": "e090211e-87aa-42aa-894c-a411e6bda129", "fitness": 0.19108561419283576, "name": "EnhancedQuantumHybridMetaheuristic", "description": "An advanced algorithm combining adaptive quantum-inspired variance, dynamic control parameters, local search enhancements, and elite preservation to improve solution accuracy and convergence speed in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.4, 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n        \n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def local_search(pos):\n            perturbation = (np.random.rand(self.dim) - 0.5) * 0.1\n            return np.clip(pos + perturbation, lb, ub)\n        \n        elite_count = max(1, pop_size // 10)\n        \n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance and local search\n            inertia_weight = 0.4 + 0.4 * np.random.rand()\n            for i in range(pop_size):\n                if i >= elite_count:  # preserve elite solutions\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                     2 * r2 * (global_best_position - positions[i]))\n\n                    positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                    \n                    # Apply adaptive quantum variance\n                    if np.random.rand() < 0.1:\n                        iter_fraction = eval_count / self.budget\n                        positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n                    \n                    # Apply local search strategy occasionally\n                    if np.random.rand() < 0.2:\n                        positions[i] = local_search(positions[i])\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19109 with standard deviation 0.00938.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17817309195013575, 0.2001550706295968, 0.19492867999877472]}}
{"id": "310c0cf0-33a3-4671-80ec-608b4ad7dec2", "fitness": 0.19627351180305797, "name": "EnhancedQuantumHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic combining adaptive quantum-inspired variance with a variable neighborhood search and self-adaptive parameter tuning to improve exploration and exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def variable_neighborhood_search(position, iter, max_iter):\n            neighborhood_size = int(1 + (self.dim - 1) * (iter / max_iter))\n            perturbation = np.random.normal(0, 0.1, (neighborhood_size,))\n            indices = np.random.choice(self.dim, neighborhood_size, replace=False)\n            position[indices] = np.clip(position[indices] + perturbation, lb[indices], ub[indices])\n            return position\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n                \n                # Apply variable neighborhood search\n                if np.random.rand() < 0.05:\n                    positions[i] = variable_neighborhood_search(positions[i], eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19627 with standard deviation 0.00735.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.19486517612299392, 0.20589250762225786, 0.18806285166392211]}}
{"id": "e00aa819-ac42-4e8f-b8b3-3a4f63d8f794", "fitness": 0.19127231128794853, "name": "EnhancedQuantumHybridMetaheuristicV2", "description": "An enhanced hybrid metaheuristic incorporating adaptive neighborhood search, quantum-inspired mutation strategies, and dynamic ensemble learning to boost exploration-exploitation balance and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.3, 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.normal(0, 1, self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def neighborhood_search(position, neighborhood_radius):\n            return np.clip(position + np.random.uniform(-neighborhood_radius, neighborhood_radius, self.dim), lb, ub)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial = neighborhood_search(trial, (ub - lb) * 0.05)  # Enhanced neighborhood search\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.4 + 0.6 * np.random.rand()\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.15:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19127 with standard deviation 0.01303.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17381591795958462, 0.20510156503808363, 0.19489945086617733]}}
{"id": "47e0ac46-1693-4b6f-8f4f-9401feb79058", "fitness": -Infinity, "name": "ImprovedQuantumChaoticHybridMetaheuristic", "description": "A diversified metaheuristic combining adaptive quantum variance with chaotic search and dynamic population resizing to improve exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass ImprovedQuantumChaoticHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        chaotic_map = np.random.rand()\n\n        def chaotic_search(x, iter, max_iter):\n            alpha = 0.75\n            chaotic_map = alpha * chaotic_map * (1 - chaotic_map)\n            chaos_factor = (ub - lb) * chaotic_map * (1 - iter / max_iter)\n            return np.clip(x + chaos_factor, lb, ub)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Dynamic population resizing\n            if eval_count % (self.budget // 10) == 0 and pop_size > 10:\n                pop_size = int(pop_size * 0.9)\n\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply chaotic search for diversification\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = chaotic_search(positions[i], eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 42, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'chaotic_map' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'chaotic_map' referenced before assignment\")", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {}}
{"id": "fd39ccf3-1241-4a6b-91b4-84901d3a683f", "fitness": 0.19004480837251805, "name": "EnhancedQuantumHybridMetaheuristic", "description": "A refined blend of quantum-inspired variance and stochastic techniques with enhanced mutation strategies to boost convergence reliability in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (0.9 * inertia_weight * velocities[i] +  # Changed line 1\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.15:  # Changed line 2\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n            # Additional slight mutation for exploration\n            if eval_count < self.budget and np.random.rand() < 0.1:  # Changed line 3\n                mutation_idx = np.random.choice(range(pop_size))\n                mutation_vector = np.random.normal(0, 0.1, self.dim)\n                positions[mutation_idx] = np.clip(positions[mutation_idx] + mutation_vector, lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19004 with standard deviation 0.01170.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17350705230844354, 0.19772671473845105, 0.1989006580706596]}}
{"id": "de71ce78-4484-4fff-8e14-309b3d230bc8", "fitness": 0.18900307319833864, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduced a dynamic population size adjustment based on evaluation progress to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Dynamic population size adjustment\n            pop_size = max(20, int(50 * (1 - eval_count / self.budget)))\n            positions = positions[:pop_size]\n            velocities = velocities[:pop_size]\n            personal_best_positions = personal_best_positions[:pop_size]\n            personal_best_scores = personal_best_scores[:pop_size]\n            \n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18900 with standard deviation 0.01286.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17246360742870304, 0.20381444812568783, 0.19073116404062507]}}
{"id": "06fc723c-5ed1-44e7-8ea2-ba4c4e431d7f", "fitness": 0.18991039852300073, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance global exploration by adjusting the mutation strategy in Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(global_best_position + F * (positions[b] - positions[c]), lb, ub)  # Changed line\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18991 with standard deviation 0.01416.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.17296383894094114, 0.2076310046889377, 0.18913635193912337]}}
{"id": "bb5fd138-7fd4-4670-a831-9ec1422d1d24", "fitness": 0.20155563190923476, "name": "EnhancedQuantumHybridMetaheuristic", "description": "An enhanced hybrid algorithm integrating adaptive quantum-inspired variance with optimized trial solution selection for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20156 with standard deviation 0.00487.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.2084377997899145, 0.19834946806401377, 0.197879627873776]}}
{"id": "981e7a95-6642-43fb-811a-f448c310854f", "fitness": 0.20460058319764998, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance mutation strategy by incorporating a dynamic scaling factor based on iteration count.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20460 with standard deviation 0.00166.", "error": "", "parent_ids": ["758dbb4c-77ed-42dc-bbdf-245969fb8d5d"], "operator": null, "metadata": {"aucs": [0.20593748786051624, 0.20560357280151265, 0.20226068893092108]}}
{"id": "8e8eef7c-7f82-40cc-9ca8-6b4445de796b", "fitness": 0.1921948377890826, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Hybridize differential evolution and particle swarm optimization with adaptive mutation and velocity control for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def adaptive_mutation_scaling(eval_count, budget):\n            return F_min + (F_max - F_min) * np.cos(np.pi * eval_count / (2 * budget))\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with adaptive mutation scaling\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = adaptive_mutation_scaling(eval_count, self.budget)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19219 with standard deviation 0.01298.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.17671452576298396, 0.20847174843816252, 0.19139823916610132]}}
{"id": "912a028c-f951-4b2b-bc05-e58ab82e4f9c", "fitness": 0.1846896855516197, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance the mutation strategy with a time-varying crossover rate based on the iteration count.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                # Change made here: added time-varying element to CR\n                CR = CR_min + np.random.rand() * (CR_max - CR_min) * (0.5 + 0.5 * (eval_count / self.budget))\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18469 with standard deviation 0.00653.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.17824997908352758, 0.1821784769542526, 0.19364060061707888]}}
{"id": "46b1800b-624c-4fdd-b036-d809978304c6", "fitness": 0.19490605603623234, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce directional bias in velocity updates during the Particle Swarm step to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (0.4 * inertia_weight * velocities[i] +  # Slight modification here\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19491 with standard deviation 0.01596.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.1726342952797003, 0.20920682153442105, 0.20287705129457567]}}
{"id": "03464bee-f915-4c19-a46c-b0538d0b2ee5", "fitness": 0.19819922640764998, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Refine the mutation strategy by introducing a dynamic crossover rate based on iteration progress to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min) * (1 - (eval_count / self.budget))  # Line changed\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19820 with standard deviation 0.00838.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.20999275689909058, 0.1932658670738736, 0.19133905524998573]}}
{"id": "361ed1f6-526a-4bdc-9728-fd4b64dc21ad", "fitness": 0.19324340786144303, "name": "EnhancedQuantumHybridMetaheuristicV2", "description": "Introduced dynamic inertia weight and adaptive differential weight using a sigmoid function for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Sigmoid-based dynamic F and CR\n                F = F_min + (F_max - F_min) * (1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5))))\n                CR = CR_min + (CR_max - CR_min) * (1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5))))\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Dynamic inertia weight with sigmoid function\n            inertia_weight = 0.4 + (0.9 - 0.4) * (1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5))))\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19324 with standard deviation 0.01153.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.1821156981134351, 0.20913446381670386, 0.18848006165419018]}}
{"id": "6f1441f8-16e6-4fa8-902b-4f0d02185554", "fitness": 0.19370107177901108, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce a momentum term in velocity update for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            momentum = 0.1  # New momentum term\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (momentum * velocities[i] +  # Incorporate momentum\n                                 inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19370 with standard deviation 0.00969.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.18037653640509654, 0.19760511981371975, 0.20312155911821694]}}
{"id": "49293167-9686-416f-bd66-d7c2c4ce1106", "fitness": 0.20371898640567584, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce randomized restart strategy to escape local minima and improve convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n            \n            # Random restart strategy\n            if eval_count < self.budget and np.random.rand() < 0.01:\n                positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20372 with standard deviation 0.00461.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.20946001681354043, 0.20353050485855106, 0.198166437544936]}}
{"id": "8b779437-bf5f-40bd-9804-1c1abc7c1058", "fitness": 0.1883337972003497, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce an adaptive inertia weight and crossover probability based on the population diversity to refine exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n        \n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n        \n        eval_count = 0\n        \n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n        \n        def adaptive_inertia_weight(eval_count, budget):\n            return 0.4 + 0.5 * (1 - (eval_count / budget))\n        \n        def adaptive_crossover_probability(diversity):\n            return 0.5 + 0.5 * (1 - diversity)\n        \n        while eval_count < self.budget:\n            # Calculate population diversity\n            diversity = np.mean(np.std(positions, axis=0) / (ub - lb))\n            \n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n            \n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = adaptive_crossover_probability(diversity)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n            \n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = adaptive_inertia_weight(eval_count, self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n        \n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18833 with standard deviation 0.00774.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.19791811515588387, 0.17896683016575787, 0.18811644627940738]}}
{"id": "a20a0f18-c1f1-474b-b7b2-339a3ce55d73", "fitness": 0.20171874799051137, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce a dynamic learning rate in the adaptive quantum variance for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            learning_rate = 0.1 + 0.9 * (1 - iter / max_iter)\n            return pos + learning_rate * variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20172 with standard deviation 0.00184.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.19931220356662716, 0.20204936417322628, 0.20379467623168068]}}
{"id": "f40e42dd-45b0-4af9-904a-29854f44e7fd", "fitness": 0.1907740246062786, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce a feedback mechanism that dynamically adjusts learning rates based on population diversity.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def calculate_diversity(pop):\n            centroid = np.mean(pop, axis=0)\n            return np.mean(np.linalg.norm(pop - centroid, axis=1))\n\n        diversity_threshold = 0.1  # Adjust based on empirical observations\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Calculate diversity and adjust F and CR bounds\n            diversity = calculate_diversity(positions)\n            if diversity < diversity_threshold:\n                F_max = min(F_max + 0.1, 1.0)\n                CR_max = min(CR_max + 0.1, 1.0)\n            else:\n                F_max = max(F_max - 0.1, 0.5)\n                CR_max = max(CR_max - 0.1, 0.5)\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19077 with standard deviation 0.01373.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.17580019596245777, 0.2089739150247807, 0.18754796283159736]}}
{"id": "f9ac0d6e-a138-4c5b-8c46-14bdd11e3ea7", "fitness": 0.20031165981830776, "name": "EnhancedQuantumHybridMetaheuristicV2", "description": "Integrate a quantum-inspired adaptive local search mechanism and adaptive inertia in PSO for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_local_search(pos, global_best, iter_fraction):\n            perturbation = 0.1 * (1 - iter_fraction) * np.random.randn(self.dim)\n            return np.clip(pos + perturbation * (global_best - pos), lb, ub)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive inertia and local search\n            inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive local search\n                if np.random.rand() < 0.2:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_local_search(positions[i], global_best_position, iter_fraction)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20031 with standard deviation 0.00371.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.19703865408395493, 0.20549823434342107, 0.19839809102754724]}}
{"id": "e8edc7f7-4e35-4c06-b04f-74d53f091f49", "fitness": 0.2021651737871818, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Refine adaptive strategy by introducing a nonlinear scaling factor that enhances convergence speed.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * ((iter / max_iter)**2))  # Nonlinear scaling factor\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20217 with standard deviation 0.00243.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.19891617120094185, 0.20475331260110274, 0.2028260375595008]}}
{"id": "ae7b7676-37f1-4b98-94d8-dd44574bdc67", "fitness": 0.2020957669463039, "name": "EnhancedDiverseQuantumMetaheuristic", "description": "Introduce a learning strategy to dynamically adjust exploration and exploitation balance based on population diversity.", "code": "import numpy as np\n\nclass EnhancedDiverseQuantumMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter, diversity_factor):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * diversity_factor * (global_best - pos)\n\n        def calculate_diversity(population):\n            mean_pos = np.mean(population, axis=0)\n            diversity = np.sqrt(np.mean(np.sum((population - mean_pos) ** 2, axis=1)))\n            return diversity\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Calculate diversity\n            diversity = calculate_diversity(positions)\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance with diversity factor\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    diversity_factor = diversity / np.mean(np.abs(ub - lb))\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget, diversity_factor)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedDiverseQuantumMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20210 with standard deviation 0.00451.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.1960848925995855, 0.20694467941597583, 0.20325772882335036]}}
{"id": "dcdae358-e1d1-436c-9e1f-f2447b64558e", "fitness": 0.1994247206203252, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance local search by introducing adaptive inertia weight decay in the Particle Swarm Optimization step.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand() * (1 - eval_count / self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19942 with standard deviation 0.00687.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.19100743440830215, 0.20782558187607836, 0.1994411455765951]}}
{"id": "0a62fc9b-fcf9-49ee-bac2-d436a4fa7534", "fitness": 0.19456356013864862, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Refine the inertia weight to adapt more dynamically with respect to the progress in evaluations. ", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.9 - 0.8 * (eval_count / self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19456 with standard deviation 0.00618.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.18711670955294568, 0.19433520567670182, 0.20223876518629835]}}
{"id": "83900529-c094-4135-98ec-00fd8a6b6819", "fitness": 0.18756642588170971, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Improve exploration by dynamically adjusting the inertia weight based on convergence speed.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.9 - ((0.9 - 0.4) * eval_count / self.budget)  # Adjusted line\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18757 with standard deviation 0.01058.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.17379917351159946, 0.18938116669988103, 0.19951893743364868]}}
{"id": "6bda0445-a498-4feb-b6b0-a5e00ae68863", "fitness": 0.19245692823649965, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce a hybrid mutation strategy combining self-adaptive control parameters and chaotic maps to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n        eval_count = 0\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        # Logistic map for chaotic sequence generation\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = 0.7  # Initial value\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = 4 * chaotic_sequence[i - 1] * (1 - chaotic_sequence[i - 1])\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with chaotic and self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + chaotic_sequence[eval_count] * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19246 with standard deviation 0.00830.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.1855917175890175, 0.20412976190070575, 0.18764930521977574]}}
{"id": "bfb5ed54-9ada-4f22-b934-3ea11f15ffa7", "fitness": 0.21095817843357864, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce a novel fitness diversity mechanism to enhance exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21096 with standard deviation 0.00307.", "error": "", "parent_ids": ["981e7a95-6642-43fb-811a-f448c310854f"], "operator": null, "metadata": {"aucs": [0.214189829414965, 0.21184512369325903, 0.20683958219251186]}}
{"id": "5e76513c-e73d-4b9f-a8c9-fbdaf8eef28e", "fitness": 0.20839531373855424, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance global exploration by adjusting the adaptive quantum variance to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.3 * (iter / max_iter))  # Adjusted for better exploration\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20840 with standard deviation 0.00035.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.208278303974768, 0.2088712325116706, 0.20803640472922413]}}
{"id": "e1454377-c7ba-427e-ab89-11f391c9a393", "fitness": 0.19509507797541384, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance search efficiency by integrating a dynamic convergence threshold and probabilistic learning to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                convergence_threshold = 1 + diversity_factor * 0.5\n                if trial_score < personal_best_scores[i] * convergence_threshold:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19510 with standard deviation 0.01420.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.1755535009020659, 0.20886493608258505, 0.2008667969415906]}}
{"id": "bcc86836-73b6-45c9-bce1-8af0967e909e", "fitness": -Infinity, "name": "DynamicPopulationMetaheuristic", "description": "Introduce a dynamic feedback mechanism for population resizing to balance exploration and exploitation adaptively.", "code": "import numpy as np\n\nclass DynamicPopulationMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        initial_pop_size = 50\n        min_pop_size = 10\n        max_pop_size = 100\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(initial_pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(initial_pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(initial_pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def adaptive_population_size(current_eval):\n            fraction = current_eval / self.budget\n            return int(min_pop_size + (max_pop_size - min_pop_size) * (1 - fraction))\n\n        while eval_count < self.budget:\n            pop_size = adaptive_population_size(eval_count)\n            positions = positions[:pop_size]\n            personal_best_positions = personal_best_positions[:pop_size]\n            personal_best_scores = personal_best_scores[:pop_size]\n            velocities = velocities[:pop_size]\n\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with inertia weight adaptation\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 68, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {}}
{"id": "5341d737-231e-4783-ade3-38785a2febd2", "fitness": 0.1947413090163822, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Tune the inertia weight to enhance convergence speed and stability in the Particle Swarm step.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.7 + 0.3 * np.random.rand()  # Changed line for the update\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19474 with standard deviation 0.00698.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.18520563813480084, 0.19728785897762136, 0.2017304299367244]}}
{"id": "5d7ada8d-4285-4876-a800-d9c467edffcc", "fitness": 0.21095817843357864, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance crossover strategy by introducing dynamic scaling of the mutation factor based on diversity.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21096 with standard deviation 0.00307.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.214189829414965, 0.21184512369325903, 0.20683958219251186]}}
{"id": "6c5d3cb7-9daf-4a92-8287-44578ac913eb", "fitness": 0.20538722547244426, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce adaptive diversity factor scaling to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs]) * (1 - (eval_count / self.budget))\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20539 with standard deviation 0.00358.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.20054605753255272, 0.2090924129749554, 0.20652320590982465]}}
{"id": "210343e4-907c-4673-9838-3c17cea8cf92", "fitness": 0.19411103502354077, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Refine the diversity factor calculation to leverage a scaled difference for enhanced differentiation.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            scale = np.max(diff) - np.min(diff) + 1e-9  # Ensure no zero division\n            return np.mean(diff / scale)  # Use scaled difference for diversity\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19411 with standard deviation 0.01572.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.1721406864573698, 0.20803851660422612, 0.2021539020090264]}}
{"id": "3560f7d4-8870-4dcf-b6c9-e11c3d784ba6", "fitness": 0.19230240576700885, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Utilize adaptive neighborhood diversity and chaos mutation for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def fitness_diversity_factor(idx):\n            distances = np.linalg.norm(positions - positions[idx], axis=1)\n            return np.mean(distances)\n\n        def chaos_mutation(pos):\n            chaos_factor = 0.1\n            return pos + chaos_factor * np.random.uniform(-1, 1, self.dim) * (ub - lb)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(i)\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n                # Apply chaos mutation for additional diversity\n                if np.random.rand() < 0.05:\n                    positions[i] = np.clip(chaos_mutation(positions[i]), lb, ub)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19230 with standard deviation 0.01528.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17205388319765802, 0.2089615106649927, 0.19589182343837586]}}
{"id": "a25e28ac-654d-40ef-b186-b8920b016927", "fitness": 0.18332947668909003, "name": "EnhancedQuantumHybridMetaheuristicV2", "description": "Enhance exploration by incorporating a chaotic map for parameter tuning and a diversity-driven mutation operator.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def chaotic_map(x):\n            return 4 * x * (1 - x)\n\n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        chaotic_param = np.random.rand()\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with chaotic parameter tuning\n            chaotic_param = chaotic_map(chaotic_param)\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + chaotic_param * (F_max - F_min)\n                CR = CR_min + chaotic_param * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * chaotic_param\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18333 with standard deviation 0.00445.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17848753343669788, 0.18923736383929246, 0.18226353279127971]}}
{"id": "f62e9624-23cf-444f-8c9f-004fd21b6b16", "fitness": 0.20594794636082495, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce fitness diversity factor scaling based on the iteration progress for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos, iter, max_iter):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            scaling_factor = 1 + (iter / max_iter) * 0.5  # Changed\n            return np.mean(diff) * scaling_factor  # Changed\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs], eval_count, self.budget)\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20595 with standard deviation 0.00334.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.201484040260005, 0.209520216629958, 0.20683958219251186]}}
{"id": "cf8f19ae-08bc-470b-bb4e-f8669b0f50f0", "fitness": 0.1807128400321825, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Implement a dynamic learning rate in the evolutionary process to enhance convergence speed and adaptability.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def dynamic_learning_rate(iter, max_iter):\n            return 0.5 + 0.5 * np.sin(np.pi * iter / max_iter)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = dynamic_learning_rate(eval_count, self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18071 with standard deviation 0.01400.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17136453570239807, 0.17026604998574402, 0.20050793440840542]}}
{"id": "6409000e-6635-4612-9e9e-3729a9676f0b", "fitness": 0.1798637722482219, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Integrate an adaptive inertia weight strategy to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Adaptive inertia weight strategy\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17986 with standard deviation 0.01657.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17629684446935512, 0.16158956868831287, 0.20170490358699766]}}
{"id": "27c52124-97f2-4433-83d0-9d12f8b2ae9f", "fitness": 0.1943505862496878, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance performance by refining diversity and adaptive variance strategies with reduced randomness.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff) * 0.9  # Reduce randomness by scaling factor\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim) * 0.9  # Reduce randomness by scaling factor\n            variance_factor = np.exp(-0.5 * (iter / max_iter)) * 0.9  # Additional scaling\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19435 with standard deviation 0.01761.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.1694818838632245, 0.20568439862209165, 0.2078854762637472]}}
{"id": "7e10df77-c76c-4771-8186-5ac723e41ecf", "fitness": 0.1832742026744447, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Incorporate dynamic exploration-exploitation balance and adaptive parameter tuning to enhance solution diversity and convergence speed.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic exploration-exploitation balance\n            exploration_factor = 0.5 * (1 - eval_count / self.budget)\n            exploitation_factor = 1 - exploration_factor\n\n            # Differential Evolution step with dynamic self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * exploitation_factor\n                CR = CR_min + np.random.rand() * (CR_max - CR_min) * exploration_factor\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand() * exploitation_factor\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18327 with standard deviation 0.01158.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.1706902975724639, 0.19864643181570496, 0.1804858786351652]}}
{"id": "16d78ef5-4fab-43a4-8407-29a73c10eb2d", "fitness": 0.17401998902595936, "name": "NoveltyDrivenQuantumMetaheuristic", "description": "Integrate a novelty-based exploration mechanism and adaptive parameter tuning to enhance the convergence efficiency and robustness of the hybrid metaheuristic.", "code": "import numpy as np\n\nclass NoveltyDrivenQuantumMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.2, 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def novelty_score(pos, archive):\n            distances = np.linalg.norm(archive - pos, axis=1)\n            return np.sum(distances)\n\n        archive = []\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                \n                archive.append(positions[i].copy())\n                \n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution with novelty-based selection\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min)\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                novelty = novelty_score(trial, np.array(archive))\n                \n                if trial_score < personal_best_scores[i] or novelty > np.random.rand():\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive inertia\n            inertia_weight = 0.9 - (0.7 * (eval_count / self.budget))\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.1:\n                    beta = np.random.rand(self.dim)\n                    positions[i] = (1 - beta) * positions[i] + beta * global_best_position\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 80, "feedback": "The algorithm NoveltyDrivenQuantumMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17402 with standard deviation 0.00308.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17563128992467358, 0.17671523855546933, 0.16971343859773513]}}
{"id": "04a210fb-3378-4cf4-ae80-2462ec40a938", "fitness": 0.20460058319764998, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance adaptive exploration and exploitation balance by introducing mutation control based on diversity measures and dynamic learning from best individuals.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        diversity_threshold = 0.1  # Threshold to change mutation strategy\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with dynamic control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                diversity_factor = fitness_diversity_factor(positions[i], positions[idxs])\n                if diversity_factor < diversity_threshold:\n                    F *= 0.5  # Reduce step size if diversity is low\n\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance and dynamic learning\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20460 with standard deviation 0.00166.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.20593748786051624, 0.20560357280151265, 0.20226068893092108]}}
{"id": "8673f4c1-36a6-4dbb-b38b-4e3caae5ef2d", "fitness": 0.18741602383286637, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce a small perturbation to the global best position to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n            # Introduce perturbation to global best position\n            global_best_position += np.random.normal(0, 0.01, self.dim)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18742 with standard deviation 0.01203.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.19008989328497594, 0.17152238275647957, 0.2006357954571436]}}
{"id": "0cd305db-d809-4b21-a247-0f84fa4ef1ab", "fitness": 0.1824266039346896, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Enhance global exploration by introducing a dynamic inertia weight and adaptive learning rates to improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.4 + 0.3 * (1 - eval_count/self.budget)  # Dynamic inertia\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18243 with standard deviation 0.01413.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17207151722498715, 0.17280778048628487, 0.2024005140927968]}}
{"id": "26504b8d-ae25-48c5-bcfa-bd92e7c03e5f", "fitness": 0.1821271472278726, "name": "AdvancedQuantumDiversityMetaheuristic", "description": "Introduce adaptive diversity control and quantum tunneling to escape local optima and enhance convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumDiversityMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.4, 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pop, idx):\n            diffs = np.linalg.norm(pop - pop[idx], axis=1)\n            return np.mean(diffs) / (ub - lb).mean()\n\n        def adaptive_quantum_tunneling(pos, global_best, iter, max_iter):\n            alpha = 0.9 - 0.8 * (iter / max_iter)\n            gamma = np.random.rand(self.dim)\n            return pos + alpha * gamma * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with adaptive parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(positions, i)\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum tunneling\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum tunneling\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_tunneling(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 84, "feedback": "The algorithm AdvancedQuantumDiversityMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18213 with standard deviation 0.01241.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.16935408231125992, 0.19894012140371187, 0.178087237968646]}}
{"id": "2fe8b303-0043-4f89-ade9-d10d0f6e7db0", "fitness": 0.19586062203432272, "name": "EnhancedQuantumHybridMetaheuristicV2", "description": "Refine the adaptive quantum variance and diversity mechanism with a dynamic exploration-exploitation balance to improve global search capability.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.3, 0.9\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.3 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.4 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                if np.random.rand() < 0.15:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19586 with standard deviation 0.00978.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.18246727419647035, 0.1995607559279322, 0.20555383597856558]}}
{"id": "1d969b9b-3035-472b-9972-ae2cac3331bd", "fitness": 0.183525964406994, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Implement a dynamic inertia weight adjustment for improved convergence speed.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.7 - 0.5 * (eval_count / self.budget)  # Changed line\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18353 with standard deviation 0.01319.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17259001219106718, 0.17590109759935801, 0.20208678343055686]}}
{"id": "c5f5667b-eb2d-4186-a1f3-38a74ef8f2dd", "fitness": 0.2083885592266748, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Integrate dynamic mutation scaling to improve exploration and intensification balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                F_dyn = 0.5 + 0.5 * np.cos((np.pi / 2) * (eval_count / self.budget))  # Dynamic mutation scaling\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor * F_dyn):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20839 with standard deviation 0.00133.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.20912488618421254, 0.2095258653899974, 0.20651492610581446]}}
{"id": "a77921ee-73d7-4f6b-9d8f-39a7833c21ce", "fitness": 0.21095817843357864, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Integrate a dynamic feedback mechanism to adapt mutation and crossover rates based on diversity measures to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Measure diversity\n            population_diversity = np.mean([fitness_diversity_factor(positions[i], positions) for i in range(pop_size)])\n\n            # Adjust F and CR based on diversity\n            if population_diversity < 0.1:\n                F_min, F_max = 0.6, 0.9\n                CR_min, CR_max = 0.7, 1.0\n            else:\n                F_min, F_max = 0.5, 1.0\n                CR_min, CR_max = 0.5, 1.0\n\n            # Differential Evolution step with dynamic control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21096 with standard deviation 0.00307.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.214189829414965, 0.21184512369325903, 0.20683958219251186]}}
{"id": "a01e733b-75b9-4f07-a66f-3868a1fbeab5", "fitness": 0.19831850697121936, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce dynamic swarm topology and adaptive parameter tuning to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def dynamic_topology_adjustment(iter, max_iter):\n            dynamic_factor = np.sin(np.pi * iter / max_iter)\n            return 1 + dynamic_factor, 1 - dynamic_factor\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F, CR = dynamic_topology_adjustment(eval_count, self.budget)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19832 with standard deviation 0.00472.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.20243249740986413, 0.20081044131416514, 0.19171258218962883]}}
{"id": "81d134f5-36c1-4a8e-9c24-d9c69a22b2c0", "fitness": 0.21004095196318592, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Adjusted adaptive quantum variance for enhanced exploration in later stages.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter) * (1 - iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21004 with standard deviation 0.00303.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.2091775846240217, 0.21410568907302419, 0.20683958219251186]}}
{"id": "de19d804-86e4-4c63-b872-de0d5be2bd1b", "fitness": 0.18529275672596154, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Integrate an adaptive neighborhood-based mutation strategy to improve diversity and convergence balance.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def neighborhood_based_mutation(pos, idxs, F, lb, ub):\n            neighbors = positions[idxs]\n            centroid = np.mean(neighbors, axis=0)\n            mutant = np.clip(centroid + F * (centroid - pos), lb, ub)\n            return mutant\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with adaptive neighborhood-based mutation\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = neighborhood_based_mutation(positions[i], [a, b, c], F, lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18529 with standard deviation 0.00468.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.19187190403675503, 0.18142197047412068, 0.1825843956670089]}}
{"id": "9734ac12-f455-4470-8288-2f7341209e04", "fitness": 0.21095817843357864, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Refine global best update strategy by considering diversity to enhance the search capability.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score and diversity_factor > 0.1:  # Line modified\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21096 with standard deviation 0.00307.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.214189829414965, 0.21184512369325903, 0.20683958219251186]}}
{"id": "7d52abad-38e6-4108-89f5-57e09e65e96f", "fitness": 0.20653615299517492, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Slightly increase the variability in quantum variance to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.4 * (iter / max_iter))  # Slightly increased variability factor\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20654 with standard deviation 0.00059.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.2057149415081323, 0.20705393528488059, 0.20683958219251186]}}
{"id": "0bf74eba-dd56-481b-8f89-448d7bd9ac33", "fitness": 0.1879735902896139, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Integrate self-adaptive local search phases into the hybrid metaheuristic to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def local_search(pos):\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            new_pos = np.clip(pos + perturbation, lb, ub)\n            return new_pos\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n                if np.random.rand() < 0.2:  # Introduce local search phase\n                    local_pos = local_search(positions[i])\n                    local_score = func(local_pos)\n                    eval_count += 1\n                    if local_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_score\n                        personal_best_positions[i] = local_pos.copy()\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = local_pos.copy()\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18797 with standard deviation 0.01493.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.19449204232482153, 0.1673197001733462, 0.20210902837067402]}}
{"id": "db7223bc-8fea-410d-884f-eb33397a3653", "fitness": 0.19555268520061306, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Integrate an adaptive elitism mechanism to dynamically adjust exploration and exploitation balance, enhancing convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n\n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        def adaptive_elitism_fraction(eval_count, budget):\n            return 0.2 + 0.3 * (eval_count / budget)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            elitism_fraction = adaptive_elitism_fraction(eval_count, self.budget)\n            elite_size = int(elitism_fraction * pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if i in elite_indices:\n                    velocities[i] *= inertia_weight\n                else:\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                     2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19555 with standard deviation 0.00282.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.19292021421717997, 0.19428110540254218, 0.199456735982117]}}
{"id": "a6f9f43f-738e-4b6d-b706-c487f2254600", "fitness": 0.1771427356995493, "name": "RefinedQuantumHybridMetaheuristic", "description": "Combine multi-strategy exploration with adaptive parameter tuning for enhanced convergence in diverse search spaces.", "code": "import numpy as np\n\nclass RefinedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n        \n        def adaptive_inertia_weight(eval_count, budget):\n            return 0.5 + 0.5 * (1 - eval_count / budget)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = adaptive_inertia_weight(eval_count, self.budget)\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 96, "feedback": "The algorithm RefinedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17714 with standard deviation 0.00927.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.1699021815144367, 0.17129783072927085, 0.19022819485494036]}}
{"id": "a69b0cf8-ec39-4ddf-a880-b6309a01d42e", "fitness": 0.1919618841621263, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Refine the exploration strategy by integrating dynamic scaling of the inertia weight and enhancing diversity in the Differential Evolution step.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial) * (1 + 0.05 * fitness_diversity_factor(trial, positions)) # Improve diversity\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.3 + 0.7 * (1 - eval_count / self.budget) # Dynamic scaling\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19196 with standard deviation 0.01373.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17291778034273286, 0.20478635790011335, 0.1981815142435327]}}
{"id": "a6977a7d-7caa-4a04-b140-4ef56fcd06c0", "fitness": 0.17792725244262675, "name": "EnhancedQuantumHybridMetaheuristicV2", "description": "Implement a dynamically adaptive diversity mechanism with a synergetic hybrid of Differential Evolution and Particle Swarm Optimization to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.4, 0.9\n        CR_min, CR_max = 0.3, 0.8\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.var(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with self-adaptive control parameters\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget))\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.4 + 0.2 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.2:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17793 with standard deviation 0.00608.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17752023632848835, 0.17069665759229746, 0.18556486340709444]}}
{"id": "fc1d620b-b5ad-4bb9-86a7-106619231ddf", "fitness": 0.18009896322536126, "name": "EnhancedQuantumHybridMetaheuristic", "description": "Introduce an adaptive mutation scaling factor for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 50\n        F_min, F_max = 0.5, 1.0\n        CR_min, CR_max = 0.5, 1.0\n        positions = np.random.rand(pop_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(pop_size, self.dim) * 0.1\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_score = np.inf\n        global_best_position = np.zeros(self.dim)\n\n        eval_count = 0\n        \n        def fitness_diversity_factor(pos, other_pos):\n            diff = np.linalg.norm(pos - other_pos, axis=1)\n            return np.mean(diff)\n\n        def adaptive_quantum_variance(pos, global_best, iter, max_iter):\n            beta = np.random.rand(self.dim)\n            variance_factor = np.exp(-0.5 * (iter / max_iter))\n            return pos + variance_factor * beta * (global_best - pos)\n\n        while eval_count < self.budget:\n            # Evaluate current population\n            for i in range(pop_size):\n                score = func(positions[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n                if eval_count >= self.budget:\n                    break\n\n            # Differential Evolution step with adaptive mutation scaling\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                F = F_min + np.random.rand() * (F_max - F_min) * (1 - (eval_count / self.budget)) * (1 + 0.2 * np.random.rand())\n                CR = CR_min + np.random.rand() * (CR_max - CR_min)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(positions[a] + F * (positions[b] - positions[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                eval_count += 1\n                diversity_factor = fitness_diversity_factor(mutant, positions[idxs])\n                if trial_score < personal_best_scores[i] * (1 + diversity_factor):\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial.copy()\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial.copy()\n\n            # Particle Swarm step with adaptive quantum variance\n            inertia_weight = 0.5 + 0.5 * np.random.rand()\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 2 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 2 * r2 * (global_best_position - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                # Apply adaptive quantum variance\n                if np.random.rand() < 0.1:\n                    iter_fraction = eval_count / self.budget\n                    positions[i] = adaptive_quantum_variance(positions[i], global_best_position, eval_count, self.budget)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedQuantumHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18010 with standard deviation 0.00635.", "error": "", "parent_ids": ["bfb5ed54-9ada-4f22-b934-3ea11f15ffa7"], "operator": null, "metadata": {"aucs": [0.17357859666860487, 0.18871149859673875, 0.1780067944107402]}}
